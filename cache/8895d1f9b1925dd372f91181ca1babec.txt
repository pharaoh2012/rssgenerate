
		<h1 class="postTitle">
			<a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/TheMagicalRainbowSea/p/19054054" title="发布于 2025-08-23 09:56">
    <span role="heading" aria-level="2">LLM ，MCP协议，A2A协议，RAG，智能体(AI Agent) 图解详细讲解</span>
    

</a>

		</h1>
		<div class="clear"></div>
		<div class="postBody">
			<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="llm-mcp协议a2a协议rag智能体ai-agent-图解详细讲解">LLM ，MCP协议，A2A协议，RAG，智能体(AI Agent) 图解详细讲解</h1>
<p>@</p><div class="toc"><div class="toc-container-header">目录</div><ul><li><a href="#llm-mcp协议a2a协议rag智能体ai-agent-图解详细讲解" rel="noopener nofollow">LLM ，MCP协议，A2A协议，RAG，智能体(AI Agent) 图解详细讲解</a></li><li><a href="#mcp-概述" rel="noopener nofollow">MCP 概述</a><ul><li><a href="#如何理解-llm-和-mcp" rel="noopener nofollow">如何理解 LLM 和 MCP</a></li><li><a href="#mcp-能做什么" rel="noopener nofollow">MCP 能做什么？</a><ul><li><a href="#对于程序员来说-mcp-能" rel="noopener nofollow">对于程序员来说 MCP 能</a></li><li><a href="#对于大众用户来说-mcp-能" rel="noopener nofollow">对于大众用户来说 MCP 能</a></li></ul></li><li><a href="#mcp-的理解" rel="noopener nofollow">MCP 的理解</a></li><li><a href="#程序员使用-mcp" rel="noopener nofollow">程序员使用 MCP</a><ul><li><a href="#使用前的准备工作" rel="noopener nofollow">使用前的准备工作：</a></li><li><a href="#stdio-的本地环境安装" rel="noopener nofollow">stdio 的本地环境安装</a></li></ul></li><li><a href="#mcp-的工作原理" rel="noopener nofollow">MCP 的工作原理</a></li><li><a href="#mcp-的工作流程" rel="noopener nofollow">MCP 的工作流程</a></li></ul></li><li><a href="#a2a-协议" rel="noopener nofollow">A2A 协议</a></li><li><a href="#rag-概述" rel="noopener nofollow">RAG 概述</a><ul><li><a href="#为什么需要-rag" rel="noopener nofollow">为什么需要 RAG</a></li></ul></li><li><a href="#智能体ai--agent-的概述" rel="noopener nofollow">智能体(AI  Agent) 的概述</a><ul><li><a href="#智能体ai--agent-的核心五要素" rel="noopener nofollow">智能体(AI  Agent) 的核心五要素：</a><ul><li><a href="#一-核心要素-1大模型llm" rel="noopener nofollow">一. 核心要素 1：大模型(LLM)</a></li><li><a href="#二-核心要素-2记忆memory" rel="noopener nofollow">二. 核心要素 2：记忆(Memory)</a></li><li><a href="#三-核心要素-3工具使用tool-use" rel="noopener nofollow">三. 核心要素 3：工具使用(Tool Use)</a></li><li><a href="#四-核心要素-4规划决策planning" rel="noopener nofollow">四. 核心要素 4：规划决策(Planning)</a></li><li><a href="#五-核心要素-5行动action" rel="noopener nofollow">五. 核心要素 5：行动(Action)</a></li></ul></li></ul></li><li><a href="#最后" rel="noopener nofollow">最后：</a></li></ul></div><p></p>
<h1 id="mcp-概述">MCP 概述</h1>
<p><strong>两个互联网领域的重大挑战：</strong></p>
<ul>
<li>第一：Agent 与 Tools(工具)的交互</li>
</ul>
<p>Agent 需要调用外部工具和 API，访问数据库，执行代码等</p>
<p>MCP 协议解决</p>
<ul>
<li>第二：Agent 与 Agent(其他智能体或用户)的交互</li>
</ul>
<p>Agent 需要理解其他 Agent 的意图，协同完成任务，与用户进行自然的对话。</p>
<p>A2A 协议解决</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095527704-596886756.gif" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524293-1510420535.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525848-260004048.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525858-68453862.png" class="lazyload"></p>
<h2 id="如何理解-llm-和-mcp">如何理解 LLM 和 MCP</h2>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095526262-1608094467.png" class="lazyload"></p>
<h2 id="mcp-能做什么">MCP 能做什么？</h2>
<h3 id="对于程序员来说-mcp-能">对于程序员来说 MCP 能</h3>
<ul>
<li>举例 1：开发部署：</li>
</ul>
<p>开发者通过自然语言指令“部署新版本到测试环境”，触发 MCP 链式调用 GitLab API （代码合并）、Jenkins API（构建镜像）、Slack API（通知团队）。</p>
<ul>
<li>举例 2：SQL 查询</li>
</ul>
<p>开发者通过自然语言输入，比如“查询某集团部门上个季度销售额”，就能查询出数 据库的数据，并结合大模型进行回答，不再需要编写 SQL，MCP 自动转换为精准 SQL 语句并执行。</p>
<p>举例 3：manus 智能体</p>
<p>Manus的每一次任务处理都至少需要调用网页搜索、网页访问、网页信息获取、本地文件创建、代码解释器等几十个外部工具。</p>
<p>这里就暴露了两个问题。</p>
<p>问题1：可供大模型调用的工具不足。</p>
<p>问题2：调用工作量很大。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095527782-1568342520.png" class="lazyload"></p>
<p>借助 MCP，只要支持了该协议，就能轻松将各种数据源和工具连接到 LLM。</p>
<h3 id="对于大众用户来说-mcp-能">对于大众用户来说 MCP 能</h3>
<p>举例 1：旅游规划</p>
<p>当我要去旅行时，旅行规划助手通过 MCP 同时调用天气 API（获取目的地气象）、交 通 API（查询航班动态）、地图 API（规划路线），AI 自动生成带实时数据的行程方案。</p>
<p>举例 2：联网搜索</p>
<p>我们在与 LLM 交互时，经常需要联网搜索最新信息以减少幻觉。然而，这里也存在问 题：</p>
<p>1、并非所有聊天机器人都支持联网功能</p>
<p>2、即使支持联网，也可能不包含你习惯使用的搜索引擎。</p>
<p>在没有 MCP 的情况下，用户只能等待开发者添加特定搜索引擎的支持。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524226-1175996882.png" class="lazyload"></p>
<p>有了 MCP 后，只需简单配置，就能将所需服务接入当前使用的聊天机器人。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525882-987934753.png" class="lazyload"></p>
<p>举例 3：业绩查询</p>
<p>用户询问“查询上季度营业额”，MCP 自动组合调用 CRM 系统 API（获取客户数据） + 财务系统 API（调取报表）+ 邮件 API（发送总结报告）。</p>
<h2 id="mcp-的理解">MCP 的理解</h2>
<p><strong>MCP（Model Context Protocol，模型上下文协议</strong>） ，2024年11月底，由 Anthropic 推出的一种开放标准。旨在为大语言模型（LLM）提供统一的、 标准化方式与外部数据源和工具之间进行通信。</p>
<p>MCP（Model Context Protocol，模型上下文协议） ，2024年11月底，由 Anthropic 推出的一种开放标准。旨在为大语言模型（LLM）提供统一的、 标准化方式与外部数据源和工具之间进行通信。</p>
<ul>
<li><strong>传统AI集成的问题：</strong>这种为每个数据源构建独立连接的方式，可以被视为一个M*N问题。</li>
<li><strong>问题</strong>：架构碎片化，难以扩展，限制了AI获取必要上下文信息的能力</li>
<li><strong>MCP解决方案：</strong>提供统一且可靠的方式来访问所需数据，克服了以往集成方法的局限性。</li>
</ul>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095526704-34024158.png" class="lazyload"></p>
<p><strong>MCP 作为一种标准协议，极大地简化了大语言模型与外部世界的交互方式，使开发者能够以统一的方式为 AI 应用添加各种能力。</strong></p>
<p><strong>MCP 的官方文档：</strong><a href="https://modelcontextprotocol.io/introduction" target="_blank" rel="noopener nofollow">https://modelcontextprotocol.io/introduction</a></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525902-1369031723.png" class="lazyload"></p>
<hr>
<h2 id="程序员使用-mcp">程序员使用 MCP</h2>
<p>MCP 的应用场景：</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095526048-1881243505.png" class="lazyload"></p>
<h3 id="使用前的准备工作">使用前的准备工作：</h3>
<p><strong>MCP 的通信机制：</strong></p>
<p>根据 MCP 的规范，当前支持两种通信机制（传输方式）：</p>
<ul>
<li><strong>stdio(标准输入输出)</strong>：主要用在本地服务上，操作你本地的软件或者本地的文件。比如 Bleander 这种就只能用 Stdio 因为它没有在线服务。MCP 默认通信方式。</li>
<li><strong>SSE(Server-Sent-Events)：</strong> 主要用在远程通信服务上，这个服务本身就有在线的 API，比如访问你的谷歌邮箱，天气情况等。简单的理解就是一种流式输出（服务器接受一点，就输出一点）</li>
</ul>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525847-1552174402.png" class="lazyload"></p>
<p><strong>MCP的通信机制：stdio方式：</strong></p>
<p>优点</p>
<p>•   这种方式适用于客户端和服务器在同一台机器上运行的场景，简单。</p>
<p>•   stdio模式无需外部网络依赖，通信速度快，适合快速响应的本地应用。</p>
<p>•   可靠性高，且易于调试。</p>
<p>缺点</p>
<p>•   Stdio 的配置比较复杂，我们需要做些准备工作，你需要提前安装需要的命令行工具。</p>
<p>•   stdio模式为单进程通信，无法并行处理多个客户端请求，同时由于进程资源开销较大，不适合在本地运行大量服务。（限制了其在更复杂分布式场景中的使用）</p>
<hr>
<p><strong>MCP的通信机制：SSE方式：</strong></p>
<p>场景</p>
<p>•   SSE方式适用于客户端和服务器位于不同物理位置的场景。</p>
<p>•   适用于实时数据更新、消息推送、轻量级监控和实时日志流等场景</p>
<p>•   对于分布式或远程部署的场景，基于 HTTP 和 SSE 的传输方式则更为合适。</p>
<p>优点</p>
<p>•   配置方式非常简单，基本上就一个链接就行，直接复制他的链接填上就行</p>
<hr>
<h3 id="stdio-的本地环境安装">stdio 的本地环境安装</h3>
<p>stdio的本地环境有两种：</p>
<ul>
<li>一种是Python 编写的服务，</li>
<li>一种用TypeScript 编写的服务。 分别对应着uvx 和 npx 两种指令。</li>
</ul>
<p>** stdio的本地环境安装：uvx**</p>
<p>第1种：若已配置Python环境，可使用以下命令安装：</p>
<pre><code class="language-bash">pip install uv
</code></pre>
<blockquote>
<p>安装了 uv ，就会按照对应 uvx</p>
</blockquote>
<p>两种安装方式：</p>
<p>第2种：在Windows下可以通过PowerShell运行命令来安装 uv。</p>
<pre><code class="language-bash">
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex”
</code></pre>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525103-478780030.png" class="lazyload"></p>
<p>验证：重启终端并运行以下命令检查是否正常：</p>
<pre><code class="language-bash">uv --version
uvx --help
</code></pre>
<p>stdio的本地环境安装：npx</p>
<p>Node.js下载的官网：<a href="https://nodejs.org/zh-cn" target="_blank" rel="noopener nofollow">https://nodejs.org/zh-cn</a></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524292-999457034.png" class="lazyload"></p>
<p>配置环境变量，并测试</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524264-676444970.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524324-2106766298.png" class="lazyload"></p>
<h2 id="mcp-的工作原理">MCP 的工作原理</h2>
<p><strong>MCP 的 C / S 架构：</strong></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524232-1576015257.png" class="lazyload"></p>
<p>5 个核心概念：</p>
<p>MCP 遵循客户端 —— 服务器架构(client-server) ，其中包含以下几个核心概念：</p>
<ol>
<li>MCP 主机（MCP Hosts）</li>
<li>MCP 客户端（MCP Clients）</li>
<li>MCP 服务器（MCP Servers）</li>
<li>本地资源（Local Resources）</li>
<li>远程资源（Remote Resources）</li>
</ol>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524255-1523063748.png" class="lazyload"></p>
<p><strong>MCP Host：</strong></p>
<p>作为运行 MCP 的主应用程序，例如 Claude Desktop、Cursor、Cline 或 AI 工具。 为用户提供与LLM交互的接口，同时集成 MCP Client 以连接 MCP Server。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524221-935273108.png" class="lazyload"></p>
<p><strong>MCP Client：</strong></p>
<p>MCP client 充当 LLM 和 MCP server 之间的桥梁，嵌入在主机程序中，主要负责：</p>
<p>•   接收来自LLM的请求；</p>
<p>•   将请求转发到相应的 MCP server</p>
<p>•   将 MCP server 的结果返回给 LLM</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524181-1154096844.png" class="lazyload"></p>
<p>有哪些常用的Clients</p>
<p>MCP 官网(<a href="https://modelcontextprotocol.io/clients" target="_blank" rel="noopener nofollow">https://modelcontextprotocol.io/clients)</a>) 列出来一些支持 MCP 的 Clients。 分为两类：</p>
<p>•   AI编程IDE：Cursor、Cline、Continue、Sourcegraph、Windsurf 等</p>
<p>•   聊天客户端：Cherry Studio、Claude、Librechat、Chatwise等</p>
<p>更多的Client参考这里：</p>
<p>MCP Clients：<a href="https://www.pulsemcp.com/clients" target="_blank" rel="noopener nofollow">https://www.pulsemcp.com/clients</a></p>
<p>Awesome MCP Clients：<a href="https://github.com/punkpeye/awesome-mcp-clients/" target="_blank" rel="noopener nofollow">https://github.com/punkpeye/awesome-mcp-clients/</a></p>
<p><strong>MCP Server：</strong></p>
<p>每个 MCP 服务器都提供了一组特定的工具，负责从本地数据或远程服务中检索信息。 是 MCP 架构中的关键组件。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095527644-381474649.png" class="lazyload"></p>
<p>与传统的远程 API 服务器不同，MCP 服务器既可以作为本地应用程序在用户设备上运 行，也可部署至远程服务器。</p>
<p>比如你让助手：</p>
<p>•   “帮我查航班信息” → 它调用航班查询 API</p>
<p>•   “算一下 37% 折扣后多少钱” → 它运行计算器函数</p>
<p>作用：让 LLM 不仅能“说”，还能“做”（执行代码、查询数据等）</p>
<p><strong>MCP Server 的本质：</strong>本质是运行在电脑上的一个nodejs 或 python程序。可以理解为客户端用命令行调用了电脑上的 nodejs或 python程序。</p>
<p>•   使用 TypeScript 编写的 MCP server 可以通过 npx 命令来运行</p>
<p>•   使用 Python 编写的 MCP server 可以通过 uvx 命令来运行。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525055-826114885.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524743-80189952.png" class="lazyload"><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095526436-1673914093.png" class="lazyload"><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524243-772576741.png" class="lazyload"><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525895-1847605852.png" class="lazyload"></p>
<h2 id="mcp-的工作流程">MCP 的工作流程</h2>
<p>API 主要有两个</p>
<p>•   tools/list：列出 Server 支持的所有工具</p>
<p>•   tools/call：Client 请求 Server 去执行某个工具， 并将结果返回</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095527804-86578925.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525243-316921225.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524258-1796216840.png" class="lazyload"></p>
<p>数据流向图：</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524965-1144884372.png" class="lazyload"></p>
<h1 id="a2a-协议">A2A 协议</h1>
<p><strong>A2A协议：开启Agent间 自 然 协 作</strong></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524253-911775551.png" class="lazyload"></p>
<p><strong>在 AI Agent 的世界里，主要解决两大互联领域的挑战：</strong></p>
<ul>
<li>第一、Agent 与 Tools（工具）的交互</li>
</ul>
<p>Agent 需要调用外部 API、访问数据库、执行代码等。</p>
<ul>
<li>第二、Agent 与 Agent（其他智能体或用户）的交互</li>
</ul>
<p>Agent 需要理解其他 Agent 的意图、协同完成任务、 与用户进行自然的对话。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524756-732600998.png" class="lazyload"></p>
<p><strong>A2A 的发布：</strong></p>
<p>谷歌，25年4月10日发布开源的、应用层协议 A2A（Agent-to-Agent 协议），即 Agent-to-Agent。其设计目的是使智能体（Agent）间能够以一种自然的模态进行协 作，类似于人与人之间的互动。</p>
<p>Github 地址：<a href="https://github.com/google/A2A" target="_blank" rel="noopener nofollow">https://github.com/google/A2A</a></p>
<p><strong>A2A 的设计意义：</strong></p>
<p>基于不同底层框架和供应 商平台创建的 AI Agent 之间 可以实现通信、发现彼此 的能力、协商任务并开展 合作，企业可以通过专业 的智能体团队处理复杂的 工作流程。这无疑是其最 为突出的贡献。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524919-255936611.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525335-512885072.png" class="lazyload"></p>
<p><strong>举例：阿里云 &amp; 火山云</strong></p>
<p>阿里云上创建的 AI Agent，通过A2A协议，可以与火山云上创建的 AI Agent 进行无缝的通信与协作。</p>
<p><strong>举例2：修理汽车：</strong></p>
<p>用户（或代表用户的智能体）对修理店智能体说：“给我看看左前轮的照片，似 乎漏液了，这种情况多久了？”</p>
<p>•   A2A 协议使得人与智能体之间这种更自然、多轮次的对话式互动成为可能。</p>
<p>修理店智能体在诊断出问题后，可能需要向零件供应商智能体查询某个零件的库 存和价格。</p>
<p>•   这种智能体与智能体之间的协作同样需要 A2A 协议来支持。</p>
<p><strong>举例3：人才招聘：</strong></p>
<p>利用 A2A 协议，招聘流程可以如此高效：</p>
<p>在谷歌的 Agentspace 统一界面中，招聘经理可以向自己的智能体下达任务， 让其寻找与职位描述、工作地点和技能要求相匹配的候选人。</p>
<p>然后，该智能体立即与其他专业智能体(专门是用来寻找并招聘我们的人才的智能体)展开互动，寻找潜在候选人。 用户会收到推荐人选，之后可以指示自己的智能体安排进一步的面试，面试 环节结束后，还可以启动另一个智能体来协助进行背景调查。</p>
<p><strong>专业的事情，交给专业的处理这部分内容的智能体解决</strong>。</p>
<h1 id="rag-概述">RAG 概述</h1>
<p><strong>什么是 RAG：</strong></p>
<p>RAG（Retrieval-Augmented Generation，检索增强生成）是一种结合<strong>信息检索</strong>（Retrieval）与<strong>文本生成</strong>（Generation）的技术，旨在提升大语言模型在回答专业</p>
<p>问题时的准确性和可靠性。</p>
<h2 id="为什么需要-rag">为什么需要 RAG</h2>
<p><strong>场景 1：</strong>大型语言模型(LLM) 的训练依赖于网络上<strong>海量公开的静态数据(注意仅仅只是公开的数据而已)</strong>，而某些<strong>特定领域</strong>(如企业内部资料，专有技术文档等等)的数据通常不会作为公开的训练数据，导致模型在面对这些领域的查询时，可能因缺乏足够的信息而生产不准确甚至虚构的回复。</p>
<p><strong>解决方案：</strong> 为了解决这一类问题，RAG 技术通过引入<strong>向量数据库(Vector Database)</strong>作为外部知识源，将模型缺失的知识以结构化的形式提供。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524854-984141403.png" class="lazyload"></p>
<p><strong>场景 2：</strong></p>
<p>随着 LLM(大模型) 规模扩大，训练成本与周期相应增加。因此，包含<strong>最新信息的数据难以融入模型训练</strong>过程，无法及时反映最新的信息或动态变化。导致 LLM 在应对诸如 “请推荐当前热门影片”等时间敏感问题。</p>
<p><strong>解决方案：</strong>提供联网搜索功能。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524289-1839836996.png" class="lazyload"></p>
<p>LLM 在考试的时候面对陌生的领域，答复能力有限，然后就准备放飞自我了，而此时 RAG 给了一些提示和思路，让 LLM 懂了开始往这个提示的方向做，最终考试的正确率从 60% 到了 90%。</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525342-256270943.png" class="lazyload"></p>
<h1 id="智能体ai--agent-的概述">智能体(AI  Agent) 的概述</h1>
<p><strong>2025年，被视为智能体落地的元年！</strong></p>
<hr>
<ul>
<li>智能体在自主能力、决策能力、协作交互等方面展现出优势，弥补了大模型的不足，是未来大模型最主流的使用方式。</li>
</ul>
<p>目前国内各大厂商推出的大模型智能体：</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524210-170062125.png" class="lazyload"></p>
<p>智能体的应用领域：</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525048-1669428450.png" class="lazyload"></p>
<p><strong>什么是智能体：</strong></p>
<blockquote>
<p>OpenAI的元老翁丽莲于2023年6月在个人博客首次提出了现代AI Agent 架构。</p>
</blockquote>
<p><strong>智能体（AI Agent）</strong>是一种能够自主行动，感知环境，做出决策并与环境交互的计算机系统或实体，通常依赖大型语言模型作为其核心决策和处理单元，具备独立思考，调用工具去逐步完成给定目标的能力。</p>
<p><strong>智能体架构：</strong></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095524714-70168850.png" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095525406-1373693062.png" class="lazyload"></p>
<hr>
<h2 id="智能体ai--agent-的核心五要素">智能体(AI  Agent) 的核心五要素：</h2>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095526141-1638591961.png" class="lazyload"></p>
<h3 id="一-核心要素-1大模型llm">一. 核心要素 1：大模型(LLM)</h3>
<p><strong>大模型作为“大脑”：提供推理，规划和知识理解能力，是 AI Agent 的决策中枢。</strong></p>
<h3 id="二-核心要素-2记忆memory">二. 核心要素 2：记忆(Memory)</h3>
<p>记忆被分为：短期记忆，长期记忆。</p>
<ul>
<li><strong>短期记忆：</strong>存储<strong>单次对话</strong>周期的<strong>上下文信息</strong>，属于临时信息存储机制。受限于模型的上下文窗口长度。</li>
<li><strong>长期记忆：</strong>可以<strong>横跨多个任务或时间周期</strong>，可存储并调用核心知识，非即时任务。</li>
</ul>
<p>长期记忆，可以通过<strong>大模型参数微调(固化知识)</strong>，<strong>知识图谱</strong>(结构化语义网络)，或<strong>向量数据库</strong>(相似数据库)(相似性检索)方式实现。</p>
<h3 id="三-核心要素-3工具使用tool-use">三. 核心要素 3：工具使用(Tool Use)</h3>
<p><strong>工具使用</strong>：调用外部工具(如 API，数据库)扩展能力边界。</p>
<h3 id="四-核心要素-4规划决策planning">四. 核心要素 4：规划决策(Planning)</h3>
<p><strong>规划决策</strong>：通过任务分解，反思与自省框架实现复杂任务处理。例如：利用思维链(Chain of Thought) 将目标拆解为子任务，并通过反馈优化策略。</p>
<h3 id="五-核心要素-5行动action">五. 核心要素 5：行动(Action)</h3>
<p><strong>行动：</strong> 实际执行决策的模块，涵盖软件接口操作(如自动订票)和物理交互(如机器人执行搬运)。比如：检索，推理，编程等。</p>
<h1 id="最后">最后：</h1>
<blockquote>
<p>“在这个最后的篇章中，我要表达我对每一位读者的感激之情。你们的关注和回复是我创作的动力源泉，我从你们身上吸取了无尽的灵感与勇气。我会将你们的鼓励留在心底，继续在其他的领域奋斗。感谢你们，我们总会在某个时刻再次相遇。”</p>
<p><img alt="在这里插入图片描述" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3084824/202508/3084824-20250823095527377-1759252714.gif" class="lazyload"></p>
</blockquote>

</div>
<div class="clear"></div>

		</div>
		<div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-23 09:56">2025-08-23 09:56</span>&nbsp;
<a href="https://www.cnblogs.com/TheMagicalRainbowSea">Rainbow-Sea</a>&nbsp;
阅读(<span id="post_view_count">79</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19054054);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19054054', targetLink: 'https://www.cnblogs.com/TheMagicalRainbowSea/p/19054054', title: 'LLM ，MCP协议，A2A协议，RAG，智能体(AI Agent) 图解详细讲解' })">举报</a>
</div>
	