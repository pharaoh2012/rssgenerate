
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/whiteBear/p/18881632" title="发布于 2025-05-17 21:55">
    <span role="heading" aria-level="2">使用HuggingFace 模型并预测</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h3 id="下载huggingface-模型">下载HuggingFace 模型</h3>
<p>首先打开网址：<a href="https://huggingface.co/models" target="_blank" rel="noopener nofollow">https://huggingface.co/models</a> 这个网址是huggingface/transformers支持的所有模型，目前大约一千多个。搜索gpt2（其他的模型类似，比如bert-base-uncased等），并点击进去。</p>
<p>进入之后，可以看到gpt2模型的说明页，点击页面中的list all files in model，可以看到模型的所有文件。<br>
<img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517165746968-534818548.png" alt="image" loading="lazy"></p>
<p>通常需要把保存的是三个文件以及一些额外的文件</p>
<ul>
<li>配置文件 -- <strong>config.json</strong></li>
<li>词典文件 -- <strong>vocab.json</strong></li>
<li>预训练模型文件<br>
pytorch -- <strong>pytorch_model.bin文件</strong><br>
tensorflow 2 -- <strong>tf_model.h5文件</strong></li>
</ul>
<p>额外的文件，指的是<strong>merges.txt</strong>、<strong>special_tokens_map.json</strong>、<strong>added_tokens.json</strong>、<strong>tokenizer_config.json</strong>、<strong>sentencepiece.bpe.model</strong>等，这几类是tokenizer需要使用的文件，如果出现的话，也需要保存下来。没有的话，就不必在意。如果不确定哪些需要下，哪些不需要的话，可以把图1中类似的文件全部下载下来。</p>
<p><img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517170411822-1664754348.png" alt="image" loading="lazy"></p>
<p>看下这几个文件都是什么：</p>
<ul>
<li>
<p>config.json配置文件<br>
<img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517171715104-1683373464.png" alt="image" loading="lazy"><br>
包含了模型的类型、激活函数等配置信息</p>
</li>
<li>
<p>vocab.json 词典文件<br>
<img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517171859082-1804639621.png" alt="image" loading="lazy"></p>
</li>
<li>
<p>merges.txt<br>
<img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517171959937-1174014704.png" alt="image" loading="lazy"></p>
</li>
</ul>
<h3 id="使用huggingface模型">使用HuggingFace模型</h3>
<p>将上述下载的模型存储在本地：<br>
<img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517170555960-1161805815.png" alt="image" loading="lazy"></p>
<h4 id="加载本地huggingface模型">加载本地HuggingFace模型</h4>
<ol>
<li>导入依赖</li>
</ol>
<pre><code>import torch
from transformers import GPT2Tokenizer, GPT2LMHeadModel
</code></pre>
<p>导入PyTorch框架和HuggingFace Transformers库的GPT-2组件</p>
<ol start="2">
<li>初始化分词器</li>
</ol>
<pre><code>tokenizer = GPT2Tokenizer.from_pretrained("../../Models/gpt2/")
text = "Who was Jim Henson ? Jim Henson was a"
indexed_tokens = tokenizer.encode(text)
print(indexed_tokens) # [8241, 373, 5395, 367, 19069, 5633]
# 转换为torch Tensor
token_tensor = torch.tensor([indexed_tokens])
print(token_tensor) # tensor([[ 8241,   373,  5395,   367, 19069,  5633]])
</code></pre>
<p><code>tokenizer.encode(text)</code>执行流程如下：<br>
<strong>分词器处理：</strong><br>
首先将文本分词为子词(subwords),如：<br>
"Who was Jim Henson ?" → ['Who', 'Ġwas', 'ĠJim', 'ĠHen', 'son', '?']<br>
<strong>ID转换：</strong><br>
然后将每个子词转换为对应的整数ID(来自vcab.json),如：<br>
['Who', 'Ġwas', 'ĠJim', 'ĠHen', 'son', '?'] -&gt; [8241, 373, 5395, 367, 19069, 5633]<br>
可以查看vcab.json文件：<br>
<img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517212835056-1310277700.png" alt="image" loading="lazy"></p>
<p>返回的是 token ID 列表（整数列表），而非词向量</p>
<ol start="3">
<li>加载预训练模型并预测</li>
</ol>
<pre><code># 加载预训练模型
model = GPT2LMHeadModel.from_pretrained("../../Models/gpt2/")
# print(model)

model.eval()

with torch.no_grad():
    outputs = model(token_tensor)
    predictions = outputs[0]

# 我们需要预测下一个单词，所以是使用predictions第一个batch，最后一个词的logits去计算
# predicted_index = 582，通过计算最大得分的索引得到的
predicted_index = torch.argmax(predictions[0, -1, :]).item()
# 反向解码为我们需要的文本
predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])
# 解码后的文本：'Who was Jim Henson? Jim Henson was a man'
# 成功预测出单词 'man'
print(predicted_text)
</code></pre>
<p>输出结果：<br>
<img src="https://img2024.cnblogs.com/blog/1059417/202505/1059417-20250517214109343-678088661.png" alt="image" loading="lazy"></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.6842026330902777" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-05-17 21:55">2025-05-17 21:55</span>&nbsp;
<a href="https://www.cnblogs.com/whiteBear">牛犁heart</a>&nbsp;
阅读(<span id="post_view_count">34</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18881632);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18881632', targetLink: 'https://www.cnblogs.com/whiteBear/p/18881632', title: '使用HuggingFace 模型并预测' })">举报</a>
</div>
        