
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xiaobaiysf/p/18875723" title="发布于 2025-05-14 16:07">
    <span role="heading" aria-level="2">【保姆级教程】：开源 Qwen3 本地化部署实操详细教程</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="一教学环境">一、教学环境</h1>
<p>1、1Panel：<a href="https://fit2cloud.com/1panel/index.html" target="_blank" rel="noopener nofollow">现代化、开源Linux服务器管理面板</a><br>
2、Ollama：<a href="https://ollama.com/" target="_blank" rel="noopener nofollow">开源大语言模型管理平台</a><br>
3、MaxKB：<a href="https://maxkb.cn/index.html" target="_blank" rel="noopener nofollow">强大易用的企业级 AI 助手</a></p>
<h1 id="二实操步骤">二、实操步骤</h1>
<h2 id="步骤11panel-安装">步骤1、1Panel 安装：</h2>
<p>安装说明参见在线文档：<a href="https://1panel.cn/docs/installation/online_installation/" target="_blank" rel="noopener nofollow">在线安装 - 1Panel 文档</a>：<br>
操作比较简单，参照文档具体操作，此处不做详细说明。<br>
注意事项：如果是公有云，记得开通网络策略，确保1Panel能正常访问。</p>
<h2 id="步骤2通过1panel安装ollama">步骤2、通过1Panel安装Ollama：</h2>
<p>点击进入 1Panel 应用商店，点击AI，选择Ollama点击安装<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514132435751-756017097.png" alt="" loading="lazy"><br>
点击安装输入容器名称，开启端口外部访问，其他保持默认点击确认开始安装。<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514132648797-256898091.png" alt="" loading="lazy"><br>
安装完成后，点击服务端口访问Ollama<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514132736186-1477279325.png" alt="" loading="lazy"><br>
如下图则代表安装成功：<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514132806186-1112694893.png" alt="" loading="lazy"></p>
<blockquote>
<p>⚠️其中如果无法访问则记得开通安全则规则，添加11434端口能被访问，具体添加内容如下图所示：</p>
</blockquote>
<p><img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514132927780-1878628150.png" alt="" loading="lazy"></p>
<h2 id="步骤3通过1panel安装基于ollama玩哼qwen3模型安装">步骤3、通过1Panel安装基于Ollama玩哼Qwen3模型安装：</h2>
<p>进入1Panel的AI管理中的模型管理，点击【添加模型】，需要确保 Ollama 已经安装完成，状态为已启动。<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514151353005-2115964397.png" alt="" loading="lazy"><br>
点击添加模型后，点击快速跳转进入<a href="https://ollama.com/search" target="_blank" rel="noopener nofollow">Ollama官网</a>，找到 <a href="https://ollama.com/library/qwen3" target="_blank" rel="noopener nofollow">Qwen3 模型</a>,根据服务器要求选择需要部署Qwen模型的模型，如qwen3:0.6b，或 qwen3:8b，需要结合自己部署Ollama的服务器的资源情况以及自己的模型使用情况选择本次实操我选择了0.6b和8b，部署到了8c16G的Centos服务器上。<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514151729669-778142210.png" alt="" loading="lazy"><br>
选好模型复制参数，然后在1Panel页面中添加模型名称，点击添加，1Panel开始自行拉取qwen3:8b模型。<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514152036090-884923963.png" alt="" loading="lazy"></p>
<p>可以实时跟踪拉去进度，经过测试0.6b的拉取时间大概在1-2分钟，8b拉取时间大概在5-10分钟。可以通过日志页面实时查看模型拉取进度。</p>
<p><img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514152133421-262574519.png" alt="" loading="lazy"></p>
<p>拉取完成后最终模型状态展示为成功即可，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514152242112-467197986.png" alt="" loading="lazy"></p>
<p>点击运行输入相关内容可以和Qwen3进行对话：</p>
<p><img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514153402721-58348143.png" alt="" loading="lazy"></p>
<h2 id="步骤4通过1panel安装maxkb">步骤4、通过1Panel安装MaxKB：</h2>
<p>此处参见<a href="https://maxkb.cn/docs/installation/1panel_installtion/" target="_blank" rel="noopener nofollow">MaxKB官方安装文章</a>安装即可，同上述的Ollama方式，不做赘述。</p>
<h2 id="步骤5基于-maxkb-添加-qwen-模型">步骤5、基于 MaxKB 添加 Qwen 模型。</h2>
<p>进入系统管理中的模型设置参照如下图所示进行模型配置，其中基础模型输入qwen3:0.6b，或 qwen3:8b，API URL输入Ollama的地址即可，API key输入任意字符串即可，点击保存，则完成模型对接。</p>
<p><img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514152457942-1502640300.png" alt="" loading="lazy"><br>
本次实操添加了0.6b和8b的模型，如下图所示，代表模型添加成功。<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514152809328-309173185.png" alt="" loading="lazy"></p>
<h2 id="步骤6基于-maxkb-结合-qwen3模型搭建ai小助手实现问答就可以快速体验-qwen-最新的大语言模型啦">步骤6、基于 MaxKB 结合 Qwen3模型搭建AI小助手实现问答，就可以快速体验 Qwen 最新的大语言模型啦。</h2>
<p><img src="https://img2024.cnblogs.com/blog/3600464/202505/3600464-20250514160632079-133307154.png" alt="" loading="lazy"></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.009680964373842593" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-05-14 16:07">2025-05-14 16:07</span>&nbsp;
<a href="https://www.cnblogs.com/xiaobaiysf">小白跃升坊</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18875723);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18875723', targetLink: 'https://www.cnblogs.com/xiaobaiysf/p/18875723', title: '【保姆级教程】：开源 Qwen3 本地化部署实操详细教程' })">举报</a>
</div>
        