
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/HunterCode/p/18826898" title="发布于 2025-04-15 15:55">
    <span role="heading" aria-level="2">VMware平台的Ubuntu部署完全分布式Hadoop环境</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="前言">前言：</h1>
<p>此文章是本人初次部署Hadoop的过程记录以及所遇到的问题解决，这篇文章只有实际操作部分，没有理论部分。因本人水平有限，本文难免存在不足的地方，如果您有建议，欢迎留言或私信告知于我，非常感谢。<br>
部分参考网络资料，如有侵权，联系删除。</p>
<h1 id="环境准备需提前下载好">环境准备（需提前下载好）：</h1>
<p>1.VMware workstation 17.5，作为虚拟化平台<br>
(官网下载地址：<a href="https://www.vmware.com/products/desktop-hypervisor/workstation-and-fusion" target="_blank" rel="noopener nofollow">vmware workstation17.5（需登录）</a>)</p>
<p>2.Ubuntu20.04 （18.04，22.04，24.04应该也可以）<br>
（清华源镜像地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/ubuntu-releases/20.04/ubuntu-20.04.6-desktop-amd64.iso" target="_blank" rel="noopener nofollow">Ubuntu20.04</a>）</p>
<p>3.JDK8(其他版本不适配)<br>
（官网下载链接（需登录）：<a href="https://www.oracle.com/java/technologies/downloads/#java8" target="_blank" rel="noopener nofollow">下载页面（选x64 Compressed Archive）</a>）<br>
（清华源的openjdk下载链接: <a href="https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u442b06.tar.gz" target="_blank" rel="noopener nofollow">openjdk8</a>）</p>
<p>4.Hadoop-3.3.6<br>
（官网下载链接：<a href="https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz" target="_blank" rel="noopener nofollow">Hadoop-3.3.6</a>）</p>
<h1 id="1安装ubuntu">1.安装Ubuntu</h1>
<p>（1）点击创建新的虚拟机<br>
（如果没有这一页，可以点击上面的选项卡，再点击转到主页）<br>
<img src="https://i-blog.csdnimg.cn/direct/224ab33f97cd46a9918c5e02cbe2be2d.png" alt="在这里插入图片描述" loading="lazy"><br>
（2）点击自定义，下一步<br>
<img src="https://i-blog.csdnimg.cn/direct/151efd6252b74783a79212ddfcdfbe44.png" alt="在这里插入图片描述" loading="lazy"><br>
（3）默认即可，点下一步<br>
<img src="https://i-blog.csdnimg.cn/direct/247a1eafd43443c3a9a46ec0d362fe25.png" alt="在这里插入图片描述" loading="lazy"><br>
（4）点稍后安装操作系统，下一步<br>
<img src="https://i-blog.csdnimg.cn/direct/893130dede5e4f6b9481bd6c7364e1d1.png" alt="在这里插入图片描述" loading="lazy"><br>
（5）这里选Linux，版本Ubuntu 64位<br>
<img src="https://i-blog.csdnimg.cn/direct/09a57204679e444cafc4db95acfc7f46.png" alt="在这里插入图片描述" loading="lazy"><br>
（6）点击浏览选择合适的存储位置<br>
<img src="https://i-blog.csdnimg.cn/direct/f19d46cf661a406d84660e89a407fbab.png" alt="在这里插入图片描述" loading="lazy"><br>
（7）处理器数量和内核数量选 1<br>
<img src="https://i-blog.csdnimg.cn/direct/b7010ecd8ca345b292782011b8f70ea3.png" alt="在这里插入图片描述" loading="lazy"><br>
（8）内存4GB，可根据个人情况调整（如果物理机只有16G，可改为3GB(3072MB)）。<br>
<img src="https://i-blog.csdnimg.cn/direct/4ac21148506f4453b40ebbfedf8e7fda.png" alt="在这里插入图片描述" loading="lazy"><br>
（9）均默认，点下一步<br>
<img src="https://i-blog.csdnimg.cn/direct/b48a2d9aaa6f4bbd9f4c5b2fe443ef67.png" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://i-blog.csdnimg.cn/direct/394149c1d9a345d1a14e72d679d558b0.png" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://i-blog.csdnimg.cn/direct/0f90a1a3287e4c088de912bf82d46802.png" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://i-blog.csdnimg.cn/direct/6f913f109e5040d28ef4574a69c3708d.png" alt="在这里插入图片描述" loading="lazy"><br>
（10）建议磁盘大小30G，避免后续使用时空间不足，可根据个人情况调整<br>
<img src="https://i-blog.csdnimg.cn/direct/70415e1fcfc14004b869f16e04dcde28.png" alt="在这里插入图片描述" loading="lazy"><br>
（11）默认，点下一步<br>
<img src="https://i-blog.csdnimg.cn/direct/97a6a73dea2645b589e4d7b927efa6a2.png" alt="在这里插入图片描述" loading="lazy"><br>
（12）点击完成<br>
<img src="https://i-blog.csdnimg.cn/direct/73b16461c63a4440aa7d420252e20395.png" alt="在这里插入图片描述" loading="lazy"><br>
（13）点编辑虚拟机设置<br>
<img src="https://i-blog.csdnimg.cn/direct/d83ceeb48aee4b4b987e69de451d53f0.png" alt="在这里插入图片描述" loading="lazy"><br>
（14）点击CD/DVD，点击“使用ISO镜像文件”，再点击浏览，找到刚刚下载的Ubuntu20.04镜像<br>
<img src="https://i-blog.csdnimg.cn/direct/e7d5b3fcd7ee48d1ad8a5d98ff4de14a.png" alt="在这里插入图片描述" loading="lazy"><br>
（15）点击Install Ubuntu ，建议使用英文，避免中文报错。<br>
<img src="https://i-blog.csdnimg.cn/direct/ccff309ad7e54c6c8156059a555e3a44.png" alt="在这里插入图片描述" loading="lazy"><br>
（16）点continue，<br>
这里如果窗口太小，看不到按钮，同时按Alt + F7，然后会出现一个手的标志，可以移动窗口，再点击鼠标左键来固定<br>
<img src="https://i-blog.csdnimg.cn/direct/59cbe4411744441a812e1a1d18267522.png" alt="在这里插入图片描述" loading="lazy"><br>
（17）点Minimal installation，点continue<br>
<img src="https://i-blog.csdnimg.cn/direct/760bff89a4534785b9d8d9b223678ba3.png" alt="在这里插入图片描述" loading="lazy"><br>
（18）默认，点Install Now<br>
<img src="https://i-blog.csdnimg.cn/direct/a79c1a4f4249416dab2339d4823d2bc2.png" alt="在这里插入图片描述" loading="lazy"><br>
（19）点击 continue<br>
<img src="https://i-blog.csdnimg.cn/direct/919e63e2b9e340e1b659f8c45e271d82.png" alt="在这里插入图片描述" loading="lazy"><br>
（20）默认，点击continue<br>
<img src="https://i-blog.csdnimg.cn/direct/1607a895c8c9487194aa8097ddcc05e0.png" alt="在这里插入图片描述" loading="lazy"><br>
（21）<br>
Your name 填Hadoop<br>
Your conputer's name 填master<br>
设置好密码后，点continue<br>
<img src="https://i-blog.csdnimg.cn/direct/73ebbded0b614a6ca911da423b9c154b.png" alt="在这里插入图片描述" loading="lazy"><br>
（22）等待安装<br>
<img src="https://i-blog.csdnimg.cn/direct/e8e98f335ea146109f06b096a66fbed0.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>（23）安装完成，点击Restart Now<br>
<img src="https://i-blog.csdnimg.cn/direct/67c138cdf5d74b5ea7d5b8241acf0168.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>（24）这里直接按回车即可<br>
<img src="https://i-blog.csdnimg.cn/direct/1160bd1d9d394d9b81a7eebdf22c9ce2.png" alt="在这里插入图片描述" loading="lazy"><br>
（25）点击Hadoop，输入密码<br>
注意：Ubuntu安装之后，数字小键盘默认关闭，按键盘上NumLock打开。<br>
<img src="https://i-blog.csdnimg.cn/direct/581daf43bc924e1d9d1d3fc3bf5fd8b6.png" alt="在这里插入图片描述" loading="lazy"><br>
（26）进入之后的设置，全部点击右上角的skip和next即可<br>
<img src="https://i-blog.csdnimg.cn/direct/0de1b49b1fa841068268e61e899050c7.png" alt="在这里插入图片描述" loading="lazy"><br>
（27）会有版本更新弹窗，点击Don't Upgrade,再点击OK<br>
<img src="https://i-blog.csdnimg.cn/direct/eeea82d2a7c345f4a987abcd08e0b13f.png" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://i-blog.csdnimg.cn/direct/c1fe270ec48e4d9fa44bb0c59b6d526f.png" alt="在这里插入图片描述" loading="lazy"><br>
（28）右上角会有一个红色圆圈，点击，再点Show update，然后点击Install Now，之后输入密码，更新即可。<br>
<img src="https://i-blog.csdnimg.cn/direct/f735f525ea364972ba54d2f100bc43d6.png" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://i-blog.csdnimg.cn/direct/9b11881142eb4b9e9ea1ab7436c2fd95.png" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://i-blog.csdnimg.cn/direct/84d5e4ac28d14b3aa2fa3d6e91e2ef64.png" alt="在这里插入图片描述" loading="lazy"><br>
<img src="https://i-blog.csdnimg.cn/direct/e2b72781d74643ca82a858a6be22c73d.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>（29）如果窗口太小，按Ctrl+Alt+T打开终端，输入下面两行代码，运行结束之后再重启一下虚拟机。</p>
<pre><code class="language-bash">sudo apt update
</code></pre>
<pre><code class="language-bash">sudo apt install open-vm-tools-desktop -y
</code></pre>
<p>注：输入 sudo apt update后，如果第（28）的更新未完成的话，会报错，等待更新完成再输入即可<br>
<img src="https://i-blog.csdnimg.cn/direct/6f2ca0c2aa4d4059af26d8a084e918e5.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>（30）现在第一个虚拟机以及创建完毕。<br>
创建第二个和第三个虚拟机时，只有第（21）不一样，<br>
第二个虚拟机的Your conputer's name 填slave01<br>
第三个虚拟机的Your conputer's name 填slave02</p>
<h1 id="2配置hosts网络映射三个机器均需要">2.配置hosts网络映射(三个机器均需要)</h1>
<p>（1）输入命令，安装网络工具<br>
注：Ubuntu中，Ctrl + Shift + C 是复制，Ctrl + Shift + V 是粘贴</p>
<pre><code class="language-bash">sudo apt install net-tools
</code></pre>
<p>（2）输入命令查看ip地址</p>
<pre><code class="language-bash">ifconfig
</code></pre>
<p>图中第三行的192.168.61.142为本机IP，每个人电脑不相同。<br>
<img src="https://i-blog.csdnimg.cn/direct/a59996bab5f84119aa5ab7c9c5e03ec4.png" alt="在这里插入图片描述" loading="lazy"><br>
（3）在slave01机器和slave02机器执行相同操作，并记下IP。<br>
我的slave01的IP：192.168.61.143<br>
<img src="https://i-blog.csdnimg.cn/direct/7ba88e5582144f22a85e794f1e628f8e.png" alt="在这里插入图片描述" loading="lazy"><br>
我的slave02的IP：192.168.61.144<br>
<img src="https://i-blog.csdnimg.cn/direct/ec8d83131d724ac3a5068f4ddd860ed1.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>（4）三个机器都下载vim，方便后续使用。</p>
<pre><code class="language-bash">sudo apt install vim -y
</code></pre>
<p>（5）编辑修改hosts文件，使节点之间通信方便</p>
<pre><code class="language-bash">sudo vim /etc/hosts
</code></pre>
<p>进入之后，如下图所示<br>
<img src="https://i-blog.csdnimg.cn/direct/a66d12c2ad044fd1b3dd693d103bd982.png" alt="在这里插入图片描述" loading="lazy"><br>
按键盘“ i ”进入编辑模式（插入模式），然后用上下左右方向键移动光标到第三行，输入刚刚查询到的IP，然后加上机器名（@后面的）<br>
例：【hadoop@master:~$】，中，master是机器名。<br>
编辑好后如图所示（ip地址不相同，根据自己Ubuntu的IP来修改）<br>
<img src="https://i-blog.csdnimg.cn/direct/ebb9fb820e8b4c689708bfbbf5f88a1f.png" alt="在这里插入图片描述" loading="lazy"><br>
编辑好之后，按键盘左上角ESC退出编辑模式，再按Shift + “；”，左下角会出现一个冒号“：”，然后输入“wq”保存并退出文件。</p>
<p>（6）配置好hosts后，使用ping命令来测试是否配置成功，之后在另外两个机器也配置。</p>
<pre><code class="language-bash">ping slave01
ping slave02
</code></pre>
<p>出现如图类似之后，即hosts配置成功，按Ctrl + C 终止，<br>
<img src="https://i-blog.csdnimg.cn/direct/e4cfd02dfee04bc88dbcec8dd2460e4f.png" alt="在这里插入图片描述" loading="lazy"></p>
<h1 id="3java-jdk8-配置三个机器均需要">3.Java JDK8 配置(三个机器均需要)</h1>
<p>（1）在自己电脑下载好JDK之后，粘贴到虚拟机的<code>Downloads</code>里,鼠标右键，点Paste即可粘贴。<br>
注：打开左边第二个图标，打开之后点<code>Downloads</code>，再粘贴<br>
（也可以复制链接到虚拟机的浏览器，直接在虚拟机下载，省的再复制粘贴）<br>
<img src="https://i-blog.csdnimg.cn/direct/17a2c2af8967499cb28dfb1c49faf86c.png" alt="在这里插入图片描述" loading="lazy"></p>
<p><img src="https://i-blog.csdnimg.cn/direct/b23bc3f4d2a44260bca63d351ee09bbc.png" alt="在这里插入图片描述" loading="lazy"><br>
注：如果出现类似报错，点击Retry再点击Skip。如果不行的话就等待一会再复制粘贴试试。如果还是不行，执行下面的命令之后重启虚拟机。<br>
<img src="https://i-blog.csdnimg.cn/direct/aac6bd2420eb45e5a63aa886dc327f13.png" alt="在这里插入图片描述" loading="lazy"></p>
<pre><code class="language-bash">sudo apt update
sudo apt ​autoremove open-vm-tools -y
sudo apt install open-vm-tools-desktop -y
</code></pre>
<p>（2）执行命令，解压jdk<br>
注：这里<code>jdk-8u441-linux-x64.tar.gz</code>不一定相同，根据个人情况修改，可以输入jdk之后，按Tab键自动补全。</p>
<pre><code class="language-bash">cd /usr/lib
sudo mkdir jvm
cd ~/Downloads        //即 cd /home/hadoop/Downloads
sudo tar -zxvf jdk-8u441-linux-x64.tar.gz -C /usr/lib/jvm
</code></pre>
<p>（3）查看具体安装的jdk版本号,例如我的是<code>jdk1.8.0_441</code></p>
<pre><code class="language-bash">cd /usr/lib/jvm
ls
</code></pre>
<p><img src="https://i-blog.csdnimg.cn/direct/39fb9e01c9c24936939d20c011631ff4.png" alt="在这里插入图片描述" loading="lazy"><br>
（4）配置java环境变量</p>
<pre><code class="language-bash">sudo vim ~/.bashrc
</code></pre>
<p>进入文件后，按上下方向键，翻到最后，插入下面语句<br>
注：第一句的jdk不一定相同，根据第三步查询的来修改。</p>
<pre><code class="language-bash">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_441
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
</code></pre>
<p>执行命令：<code>source ~/.bashrc</code>，然后关闭终端，再重新打开，输入<code>java -version</code>，如下图所示即配置成功<br>
<img src="https://i-blog.csdnimg.cn/direct/4d33b827a56748c4bee81034f33df206.png" alt="在这里插入图片描述" loading="lazy"><br>
（5）在slave01和slave02执行相同的1~4，完成配置</p>
<h1 id="4ssh-配置三个机器均需要">4.SSH 配置（三个机器均需要）</h1>
<p>（1）安装ssh</p>
<pre><code class="language-bash">sudo apt install openssh-server -y
</code></pre>
<p>（2）测试登录本地，验证是否成功。</p>
<pre><code class="language-bash">ssh localhost
</code></pre>
<p>输入之后，会停顿一下，如下图，然后输入<code>yes</code>，之后会让输入本机密码。<br>
<img src="https://i-blog.csdnimg.cn/direct/e7a4ce6e34d945fca0f7bbdab9242fa5.png" alt="在这里插入图片描述" loading="lazy"><br>
成功登录如图<br>
<img src="https://i-blog.csdnimg.cn/direct/7c1f34be35a54129bd1bb45ee165da66.png" alt="在这里插入图片描述" loading="lazy"><br>
然后输入<code>exit</code> 会出现退出登录信息<br>
<img src="https://i-blog.csdnimg.cn/direct/db418ffaf3884c83b0a6d8fddc9e6614.png" alt="在这里插入图片描述" loading="lazy"><br>
（3）前两步骤三个机器均需下载，下载完成之后在进行第四步。</p>
<p>（4）在master节点生成公钥</p>
<pre><code class="language-bash">cd ~/.ssh
rm ./id_rsa*        //如果是第一次下载ssh，可以不执行这一句
ssh-keygen -t rsa   //输入之后有停顿，全部按回车即可
</code></pre>
<p><img src="https://i-blog.csdnimg.cn/direct/98592d087730424b98467e24126c7e70.png" alt="在这里插入图片描述" loading="lazy"><br>
（5）在本机节点上设置免密登录并测试</p>
<pre><code class="language-bash">cat ./id_rsa.pub &gt;&gt; ./authorized_keys
ssh localhost
</code></pre>
<p>会发现，再次执行ssh连接不再需要密码<br>
<img src="https://i-blog.csdnimg.cn/direct/3b0f582aa4ad44f1930f565ed68cdc9d.png" alt="在这里插入图片描述" loading="lazy"><br>
（6）将公钥传到slave01、slave02（只在master机器上操作）<br>
注：第二个命令中<code>hadoop@slave01</code>需要根据自己Ubuntu的用户名和机器名进行修改，如果你的用户名+机器名是<code>zhangsan@slave01</code>，那么命令中的<code>hadoop@slave01</code>就需要修改为<code>zhangsan@slave01</code>，同理<code>/home/hadoop</code>也一样改为<code>/home/zhangsan</code>，如果与示例相同则不需要更改</p>
<pre><code class="language-bash">cd ~/.ssh
scp ~/.ssh/id_rsa.pub hadoop@slave01:/home/hadoop    //将公钥给slave01
scp ~/.ssh/id_rsa.pub hadoop@slave02:/home/hadoop    //将公钥给slave02
</code></pre>
<p>注：第二个和第三个命令之后需要输入密码，这个密码是登录slave01和slave02机器的密码</p>
<p>（7）在slave节点中将公钥保存（此步骤只在slave01和slave02上操作）</p>
<pre><code class="language-bash">cat ~/id_rsa.pub&gt;&gt;~/.ssh/authorized_keys
rm ~/id_rsa.pub
</code></pre>
<p>（8）验证免密连接（只在master机器上执行）</p>
<pre><code class="language-bash">ssh slave01
</code></pre>
<p>注：如果你的用户名和master机器的用户名不一样，那这里需要输入完整的用户名+机器名<br>
例 :  slave节点用户名和机器名是<code>zhangsan@slave01</code>，那你这里需要输入<code>ssh zhangsan@slave01</code><br>
这一次不需要密码就能连接上，并且会看到用户名和机器名由<code>hadoop@master</code>变成<code>hadoop@slave01</code>。</p>
<p>然后输入<code>exit</code>退出连接，再测试slave02</p>
<pre><code class="language-bash">ssh slave02
</code></pre>
<p>成功连接后，输入<code>exit</code>退出连接</p>
<h1 id="5hadoop安装配置">5.Hadoop安装配置</h1>
<h2 id="51master机器执行部分">5.1master机器执行部分</h2>
<p>（1）在自己电脑下载好Hadoop文件之后，粘贴到虚拟机的Downloads里,鼠标右键，点Paste即可粘贴。<br>
注：打开左边第二个图标，打开之后点Downloads，再粘贴<br>
（如果下载速度过慢，可以搜索“磁力下载软件”，找个顺眼的安装，这里不再推荐，将下载链接粘贴到磁力工具中再下载，速度会快点）<br>
<img src="https://i-blog.csdnimg.cn/direct/d80677f5a7db4eb8a50e3f6cbb2c8ddd.png" alt="在这里插入图片描述" loading="lazy"><br>
（2）解压<br>
注：我下载的是Hadoop-3.3.6的版本，根据自己下载的版本修改<code>~/Downloads/hadoop-3.3.6.tar.gz</code>这一部分，</p>
<pre><code class="language-bash">sudo tar -zxvf ~/Downloads/hadoop-3.3.6.tar.gz -C /usr/local
cd /usr/local
sudo mv ./hadoop-3.3.6 ./hadoop    //如果你的不是3.3.6，根据实际修改
sudo chown -R hadoop ./hadoop
</code></pre>
<p>（3）配置环境变量</p>
<pre><code class="language-bash">sudo vim ~/.bashrc
</code></pre>
<p>进入文件后，按上下方向键，翻到最后，插入下面语句</p>
<pre><code class="language-bash">export HADOOP_HOME=/usr/local/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/lin/native
export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH
</code></pre>
<p>执行命令：<code>source ~/.bashrc</code>，然后关闭终端，再重新打开一个终端，输入<code>hadoop version</code>，如下图即配置成功<br>
<img src="https://i-blog.csdnimg.cn/direct/27f596c9015c43949050540e99619d65.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>（4）文件配置<br>
文件1</p>
<pre><code class="language-bash">cd /usr/local/hadoop/etc/hadoop
vim core-site.xml 
</code></pre>
<p>打开文件后，翻到最后一行，先将文件自带的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>删除，（<code>&lt;configuration&gt;</code> 是XML文件的根元素，只能出现一次，必须唯一！）<br>
<img src="https://i-blog.csdnimg.cn/direct/467469de765245c39279c81660a96aa6.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>再将下面内容粘贴到文件中</p>
<pre><code class="language-bash">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		&lt;value&gt;hdfs://master:9000&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;io.file.buffer.size&lt;/name&gt;
		&lt;value&gt;131072&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
		&lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;
		&lt;description&gt;Abasefor other temporary directories.&lt;/description&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.proxyuser.spark.hosts&lt;/name&gt;
		&lt;value&gt;*&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.proxyuser.spark.groups&lt;/name&gt;
		&lt;value&gt;*&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<p>文件2：</p>
<pre><code class="language-bash">vim hdfs-site.xml
</code></pre>
<p>操作跟上面一样，翻到文件最下面后，先将文件自带的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>删除，再将内容粘贴到文件上</p>
<pre><code class="language-bash">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
		&lt;value&gt;master:9001&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;file:/usr/local/hadoop/dfs/name&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;file:/usr/local/hadoop/dfs/data&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;2&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<p>文件3：</p>
<pre><code class="language-bash">vim yarn-site.xml
</code></pre>
<p>操作同上，先将文件自带的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>删除，再将下面代码粘贴到文件里</p>
<pre><code class="language-bash">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
		&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
		&lt;value&gt;master:8032&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
		&lt;value&gt;master:8030&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
		&lt;value&gt;master:8035&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
		&lt;value&gt;master:8033&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
		&lt;value&gt;master:8088&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<p>文件4：</p>
<pre><code class="language-bash">vim mapred-site.xml
//如果你打开之后是空白文件，先退出文件，再执行下面的命令；如果打开之后有内容，不用执行
cp mapred-site.xml.template mapred-site.xml
</code></pre>
<p>操作同上，先将文件自带的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>删除，再将下面代码粘贴到文件里</p>
<pre><code class="language-bash">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
		&lt;value&gt;yarn&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
		&lt;value&gt;master:10020&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
		&lt;value&gt;master:19888&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<p>文件5：</p>
<pre><code class="language-bash">sudo vim hadoop-env.sh
</code></pre>
<p>操作同上，这个不用删<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>，直接将下面代码粘贴到文件最后，可以按方向键上面的PgDn/PageDown按键加快翻动<br>
注：jdk版本根据自己下载的更改，此处与刚刚Java环境变量配置的路径一样。</p>
<pre><code class="language-bash">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_441
</code></pre>
<p>文件6：</p>
<pre><code class="language-bash">sudo vim workers
</code></pre>
<p><img src="https://i-blog.csdnimg.cn/direct/76c7230c9fcd42fb98c069c1956b90d4.png" alt="在这里插入图片描述" loading="lazy"><br>
打开之后默认是localhost,删除，然后将下面内容粘贴到里面。</p>
<pre><code class="language-bash">hadoop@slave01
hadoop@slave02
</code></pre>
<p>注：此处是两个slave节点的完整用户名和机器名，如果你的用户名或机器名与示例不同，需要修改。<br>
<img src="https://i-blog.csdnimg.cn/direct/691f327c740940b6b8e60984717f7735.png" alt="在这里插入图片描述" loading="lazy"><br>
（5）压缩文件</p>
<pre><code class="language-bash">cd /usr/local
sudo rm -rf ./hadoop/tmp
sudo rm -rf ./hadoop/logs
tar -zcvf ~/hadoop.master.tar.gz ./hadoop
</code></pre>
<p>(6)将压缩好的文件发送到slave机器上</p>
<pre><code class="language-bash">scp ~/hadoop.master.tar.gz hadoop@slave01:/home/hadoop
scp ~/hadoop.master.tar.gz hadoop@slave02:/home/hadoop
</code></pre>
<p>注：此处<code>hadoop@slave01</code>是slave01虚拟机的完整用户名和机器名，如果与示例不同，根据自己的用户名和机器名修改，<code>/home/hadoop</code>的hadoop同理。</p>
<h2 id="52-slave机器执行部分slave01和slave02均需要执行一遍">5.2 slave机器执行部分（slave01和slave02均需要执行一遍）</h2>
<p>（1）在slave节点上解压hadoop.master.tar.gz文件，并给予授权</p>
<pre><code class="language-bash">sudo rm -rf /usr/local/hadoop
sudo tar -zxvf ~/hadoop.master.tar.gz -C /usr/local
sudo chown -R hadoop /usr/local/hadoop
</code></pre>
<p>注：-R 后面的hadoop是slave节点的用户名，如果与示例不同，根据自己的情况修改。<br>
<code>/usr/local/hadoop</code>这部分是固定的，不需要修改。</p>
<h1 id="6-hadoop启动与停止">6. Hadoop启动与停止</h1>
<p>（1）格式化NameNode（只在master上操作）</p>
<pre><code class="language-bash">hdfs namenode -format
</code></pre>
<p>注：只执行一次就行，之后再使用Hadoop，不需要再格式化！！！<br>
运行完结果类似下图<br>
<img src="https://i-blog.csdnimg.cn/direct/2009752ac0164480a144b2745a57352b.png" alt="在这里插入图片描述" loading="lazy"></p>
<p>（2）启动HDFS（只在master节点上操作）</p>
<pre><code class="language-bash">start-dfs.sh
</code></pre>
<p>然后在master，slave01，slave02上分别输入jps，结果如下图</p>
<blockquote>
<p>master节点<br>
<img src="https://i-blog.csdnimg.cn/direct/d3ab5efeb7d842b18672b378e066a525.png" alt="在这里插入图片描述" loading="lazy"></p>
</blockquote>
<blockquote>
<p>slave01节点<br>
<img src="https://i-blog.csdnimg.cn/direct/9b6171534ab84fa896ee05277e70c017.png" alt="在这里插入图片描述" loading="lazy"></p>
</blockquote>
<blockquote>
<p>slave02节点<br>
<img src="https://i-blog.csdnimg.cn/direct/e3bd8f00cb794e5b96266f2878ab9997.png" alt="在这里插入图片描述" loading="lazy"></p>
</blockquote>
<p>（3）启动YARN（只在master节点上操作）</p>
<pre><code class="language-bash">start-yarn.sh
</code></pre>
<p>然后在master，slave01，slave02上分别输入jps，结果如下图</p>
<blockquote>
<p>master节点<br>
<img src="https://i-blog.csdnimg.cn/direct/92755b22992949719c67d000d3504072.png" alt="在这里插入图片描述" loading="lazy"></p>
</blockquote>
<blockquote>
<p>slave01节点<br>
<img src="https://i-blog.csdnimg.cn/direct/a6985455568e45f0829afa10cf4b7d43.png" alt="在这里插入图片描述" loading="lazy"></p>
</blockquote>
<blockquote>
<p>salve02节点<br>
<img src="https://i-blog.csdnimg.cn/direct/8196a287a50543cead4e4cb3f610eefc.png" alt="在这里插入图片描述" loading="lazy"></p>
</blockquote>
<p>（4）网页访问（在master机器上操作）<br>
在浏览器中打开<code>http://master:8088/cluster/nodes</code>，节点情况如下图<br>
<img src="https://i-blog.csdnimg.cn/direct/980b88c51b5749dcbd19e8b810af8b34.png" alt="在这里插入图片描述" loading="lazy"><br>
如果能正常打开网页，但没有节点，先stop停止进程，<br>
执行<code>sudo vim /etc/hosts</code>，在第二行加个<code>#</code>和空格，如图，<br>
之后再次运行进程就好了<br>
<img src="https://i-blog.csdnimg.cn/direct/6c7b36d264ef4621adcdfa803b6b4a28.png" alt="在这里插入图片描述" loading="lazy"><br>
（5）停止HDFS和YARN</p>
<pre><code class="language-bash">stop-yarn.sh
stop-dfs.sh
</code></pre>
<p>也可以直接执行<code>stop-all.sh</code>全部关闭。</p>
<blockquote>
<p>附录：<br>
有小伙伴两小时急速完成，期待有新的记录产生<br>
有小伙伴1小时17分钟急速完成，期待有新的记录产生</p>
</blockquote>
<h1 id="7部分问题解决">7.部分问题解决：</h1>
<h2 id="1多次执行格式化操作hdfs-namenode--format之后导致datanode进程或namenode看不到了">1.多次执行格式化操作<code>hdfs namenode -format</code>之后，导致DataNode进程或namenode看不到了。</h2>
<p>解决：<strong>这里给出一个适用于重启运行的方式：删除所有节点的/usr/local/hadoop/dfs中的内容，一般是name和data两个文件夹，因为这里记录了上次运行的集群ID等信息可能会导致冲突（当然这里只是部署阶段，如果运行了很久，重要的数据需要小心）。然后清一下logs数据，方便再运行查看错误问题。最后在master节点上执行hadoop namenode -format，就可以再启动Hadoop了。</strong></p>
<blockquote>
<p>举个不恰当的例子，就好像第一次格式化之后，dfs的实际位置id刷新在麻辣烫，第二次格式化之后，dfs实际位置刷新到火锅，但是文件仍然保存着第一次麻辣烫的位置，实际位置与文件保存的位置不一样，命令运行的时候部分信息就乱跑了，导致datanode与namenode无法加载出来。</p>
</blockquote>
<p>注：在执行之前，先<code>stop-all.sh</code>，将进程都停止了</p>
<p>（1）以下是直接操作的代码：(master和slave上都要执行)</p>
<pre><code class="language-bash">cd /usr/local/hadoop
rm -rf /usr/local/hadoop/dfs
rm -rf /usr/local/hadoop/tmp
rm -rf /usr/local/hadoop/logs
</code></pre>
<p>（2）把第一步的代码，在master和slave机器上都执行之后，再进行下一步<br>
（3）在master机器上执行下面代码</p>
<pre><code class="language-bash">hdfs namenode -format  //格式化
</code></pre>
<p>（4）启动HDFS（只在master节点上操作）</p>
<pre><code class="language-bash">start-dfs.sh
</code></pre>
<p>（5）启动YARN（只在master节点上操作）</p>
<pre><code class="language-bash">start-yarn.sh
</code></pre>
<p>（6）之后jps与查看网页步骤同上</p>
<h2 id="2ip自动更改">2.IP自动更改</h2>
<p>部分人的虚拟机，在再次打开后，会发现ip与上一次的ip不一样了，可以修改hosts（参考第二大步），或者参考网上设置静态IP。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.8505178647210648" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-15 15:55">2025-04-15 15:55</span>&nbsp;
<a href="https://www.cnblogs.com/HunterCode">Hunter_Code</a>&nbsp;
阅读(<span id="post_view_count">118</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18826898);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18826898', targetLink: 'https://www.cnblogs.com/HunterCode/p/18826898', title: 'VMware平台的Ubuntu部署完全分布式Hadoop环境' })">举报</a>
</div>
        