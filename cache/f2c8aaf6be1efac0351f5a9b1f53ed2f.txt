
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/qubernet/p/18702147" title="发布于 2025-02-07 14:32">
    <span role="heading" aria-level="2">通过Ollama本地部署DeepSeek R1以及简单使用的教程（超详细）</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<blockquote>
<p>本文介绍了在Windows环境下，通过Ollama来本地部署DeepSeek R1。该问包含了Ollama的下载、安装、安装目录迁移、大模型存储位置修改、下载DeepSeek以及通过Web UI来对话等相关内容。</p>
</blockquote>
<h1 id="1下载ollama">1、🥇下载Ollama</h1>
<p>首先我们到<a href="https://ollama.com/download/windows" target="_blank" rel="noopener nofollow">Ollama官网</a>去下载安装包，此处我们下载的是<a href="https://ollama.com/download/OllamaSetup.exe" target="_blank" rel="noopener nofollow">Windows版本的安装包</a>，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207093114124-1041633455.png" alt="Windows安装包下载" loading="lazy"></p>
<hr>
<h1 id="2安装ollama">2、🥈安装Ollama</h1>
<p>Windows安装包下载完成后，我们直接双击安装包，然后点击<code>Install</code>按钮等待安装完成即可，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207093648039-1419712369.png" alt="点击安装按钮" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207093716954-353394608.png" alt="安装中" loading="lazy"></p>
<p><strong>注意：</strong><br>
安装完成后，Ollama默认为打开状态，此时我们先退出Ollama（鼠标右键点击任务栏的Ollama图标然后选择退出即可）。</p>
<p>上图中，Ollama默认安装在C盘的<code>C:\Users\quber\AppData\Local\Programs\Ollama</code>目录下，如下图所示为默认安装的文件，大小大概有4.56GB：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207094248863-197751658.png" alt="安装完成" loading="lazy"></p>
<p>Ollama安装完成后，在桌面上是没有快捷启动图标的，我们可以在开始菜单中查找或在搜索框中搜索，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134053104-892548002.png" alt="Ollama" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134135243-740354598.png" alt="Ollama" loading="lazy"></p>
<hr>
<h1 id="3转移ollama安装目录">3、🥉转移Ollama安装目录</h1>
<p>如果不想将Ollama安装到C盘，可以将安装的所有文件全部剪切到其他盘的目录内，如转移到D盘的<code>D:\Net_Program\Net_Ollama</code>目录下，这样可以节约C盘的空间，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207094540718-1677234126.png" alt="转移目录" loading="lazy"></p>
<p><strong>转移后，我们还需要修改Ollama的环境变量</strong>。</p>
<p>打开环境变量，双击用户变量中的<code>Path</code>，我们会看到最后一条信息就是Ollama安装完成后默认添加进来的，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207100747755-555069224.png" alt="环境变量" loading="lazy"></p>
<p>我们双击最后一条信息进入编辑状态，修改为我们转移的目录<code>D:\Net_Program\Net_Ollama</code>，然后点击确定按钮关闭所有窗体即可，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207101034127-524747422.png" alt="环境变量" loading="lazy"></p>
<hr>
<h1 id="4验证ollama">4、🎉验证Ollama</h1>
<p>上述步骤完成后，我们可以打开CMD，输入<code>ollama -v</code>命令，如果出现如下图所示的内容就代表Ollama安装成功了：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207101259084-213960558.png" alt="验证" loading="lazy"></p>
<p>同样我们输入<code>ollama -h</code>命令可以查看Ollama其他操作命令，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207102520059-774497777.png" alt="操作命令" loading="lazy"></p>
<hr>
<h1 id="5修改大模型存储位置">5、🎄修改大模型存储位置</h1>
<p>接下来我们需要配置大模型下载存储的目录位置（默认存储在C盘的<code>C:\Users\quber\.ollama\models</code>目录下）。</p>
<p>同样我们打开环境变量，然后在用户变量中点击<code>新建</code>按钮，变量名为<code>OLLAMA_MODELS</code>，变量值为<code>D:\Net_Program\Net_Ollama\Models</code>，其中的变量值就是大模型下载存储的目录位置，最后点击确定即可，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207132045091-2008884254.png" alt="存储位置" loading="lazy"></p>
<hr>
<h1 id="6下载deepseek">6、🎁下载DeepSeek</h1>
<p>同样我们打开<a href="https://ollama.com/" target="_blank" rel="noopener nofollow">Ollama官网</a>，点击顶部的<a href="https://ollama.com/search" target="_blank" rel="noopener nofollow">Models</a>链接，此时我们就会看到<a href="https://ollama.com/library/deepseek-r1" target="_blank" rel="noopener nofollow">deepseek-r1</a>模型排在第一位，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207102315751-1743984106.png" alt="DeepSeek" loading="lazy"></p>
<p>点击<a href="https://ollama.com/library/deepseek-r1" target="_blank" rel="noopener nofollow">deepseek-r1</a>链接进去，此时我们会看到下拉框中有各个版本的大模型，越往后对电脑硬件的要求越高，此处为了演示效果，我们选择<code>1.5b</code>进行下载（具体可根据自己的电脑和需求有选择性的下载），如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207105059338-1494426742.png" alt="DeepSeek" loading="lazy"></p>
<p><strong>显卡要求：</strong></p>
<table>
<thead>
<tr>
<th>版本</th>
<th>要求</th>
</tr>
</thead>
<tbody>
<tr>
<td>DeepSeek-R1-1.5b</td>
<td>NVIDIA RTX 3060 12GB or higher</td>
</tr>
<tr>
<td>DeepSeek-R1-7b</td>
<td>NVIDIA RTX 3060 12GB or higher</td>
</tr>
<tr>
<td>DeepSeek-R1-8b</td>
<td>NVIDIA RTX 3060 12GB or higher</td>
</tr>
<tr>
<td>DeepSeek-R1-14b</td>
<td>NVIDIA RTX 3060 12GB or higher</td>
</tr>
<tr>
<td>DeepSeek-R1-32b</td>
<td>NVIDIA RTX 4090 24GB</td>
</tr>
<tr>
<td>DeepSeek-R1-70b</td>
<td>NVIDIA RTX 4090 24GB *2</td>
</tr>
<tr>
<td>DeepSeek-R1-671b</td>
<td>NVIDIA A100 80GB *16</td>
</tr>
</tbody>
</table>
<p>随后我们复制下拉框后面的命令<code>ollama run deepseek-r1:1.5b</code>，粘贴到<strong>新打开的CMD窗口</strong>中回车执行（耐心等待下载完成），如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207111224037-1402941553.png" alt="DeepSeek" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207105339733-1230456902.png" alt="DeepSeek" loading="lazy"></p>
<p><strong>注意：</strong>上述下载命令需要在新打开的CMD窗口中执行，否则下载的文件存储在<code>C:\Users\quber\.ollama\models</code>位置，就不是我们修改的<code>D:\Net_Program\Net_Ollama\Models</code>这个位置了。</p>
<p><strong>温馨提示：</strong><br>
下载过程中，最开始下载速度可能要快一些，下载到后面可能就几百KB了，此时我们可以按Ctrl+C停止下载，然后再重新复制命令执行下载，此时的下载速度又恢复到了几MB了（此操作可能会遇到重新下载的情况），如此往复操作即可，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207132515642-1968010411.png" alt="DeepSeek" loading="lazy"></p>
<p>如出现如下图所示的效果就代表下载完成了：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207130711902-949043672.png" alt="DeepSeek" loading="lazy"></p>
<hr>
<h1 id="7验证deepseek">7、🎀验证DeepSeek</h1>
<p>在DeepSeek下载完成后，我们就可以在CMD中输入内容进行对话了，如输入：你好，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207133714317-532891377.gif" alt="演示" loading="lazy"></p>
<p>假设我们安装了多个DeepSeek模型，我们可以通过<code>ollama list</code>命令查看已安装了的模型，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207144433969-1142291958.png" alt="模型" loading="lazy"></p>
<p>如果我们想运行某个模型，我们可以通过<code>ollama run 模型名称</code>命令运行即可，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207144648022-433548372.png" alt="模型" loading="lazy"></p>
<p>如果我们想退出对话，我们可以通过<code>/bye</code>命令退出，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207144837257-321478164.png" alt="模型" loading="lazy"></p>
<p>到此，DeepSeek R1的部署就基本告一段落。</p>
<hr>
<h1 id="8web-ui对话">8、🎑Web UI对话</h1>
<p>虽然我们可以通过CMD窗口进行对话，但是相对不那么直观，于是我们可以通过第三方Web UI来实现对话效果。</p>
<h2 id="81chrome插件-page-assist">8.1、🎨Chrome插件-Page Assist</h2>
<p>首先我们通过谷歌浏览器<a href="https://chromewebstore.google.com/search/Page%20Assist?hl=zh-CN&amp;utm_source=ext_sidebar" target="_blank" rel="noopener nofollow">官方插件地址</a>搜索<code>Page Assist</code>，点击<code>Page Assist - 本地 AI 模型的 Web UI</code>，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207112114759-1698176580.png" alt="Page Assist" loading="lazy"></p>
<p>然后添加到Chrome：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207112330734-1115180946.png" alt="Page Assist" loading="lazy"></p>
<p>安装完成后，我们可以将该插件固定（钉）到浏览器顶部，方便使用，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207112637591-84377829.png" alt="Page Assist" loading="lazy"></p>
<p>随后我们点击该插件，就会出现如下图所示的界面：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134405137-680823572.png" alt="Page Assist" loading="lazy"></p>
<p>在界面中出现了<code>Unable to connect to Ollama</code>的提示，是因为我们安装的Ollama没有启动，此时我们只需要启动Ollama软件即可，启动后的界面效果如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134530329-114999790.png" alt="Page Assist" loading="lazy"></p>
<p><strong>设置中文：</strong><br>
点击界面右上角的<code>Settings</code>按钮，将语言设置为<code>简体中文</code>，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134720322-2007215774.png" alt="Page Assist" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134753188-1910474408.png" alt="Page Assist" loading="lazy"><br>
设置完成后返回主界面，此时就是中文界面了。</p>
<p><strong>选择模型：</strong><br>
点击主界面中的第一个下拉框，选择我们刚才下载的模型<code>deepseek-r1:1.5b</code>，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207135023590-1301032136.png" alt="Page Assist" loading="lazy"></p>
<p>到此，配制就完成了。</p>
<p><strong>对话演示：</strong><br>
接下来我们就可以愉快的对话了，效果如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207140150261-383080642.gif" alt="演示效果" loading="lazy"></p>
<p><strong>温馨提示：</strong><br>
上述演示效果等待时间可能有点长，和电脑的配置有一定的关系，仅供参考。</p>
<h2 id="82chatboxai在线对话">8.2、👑chatboxai在线对话</h2>
<p>我们也可以通过在线Web UI <a href="https://web.chatboxai.app/" target="_blank" rel="noopener nofollow">https://web.chatboxai.app/</a> 进行对话。</p>
<p>首先我们打开<a href="https://web.chatboxai.app/" target="_blank" rel="noopener nofollow">https://web.chatboxai.app/</a>，打开后界面中间会有一个弹出框，我们点击阴影处即可取消该弹框的显示。</p>
<p><strong>设置中文：</strong><br>
我们点击左下角的<code>Settings</code>，在弹出框中点击<code>DISPLAY</code>，在第一个下拉框中选择<code>简体中文</code>，随后点击右下角的<code>SAVE</code>即可显示为中文了，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207113804578-1448796180.png" alt="设置中文" loading="lazy"></p>
<p><strong>配置环境变量：</strong><br>
在用户环境变量中，我们点击新建，分别新建下面两组变量，如下所示：</p>
<pre><code class="language-ruby">OLLAMA_HOST       0.0.0.0    --任何IP都可以访问
OLLAMA_ORIGINS    *
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207141256379-1465830791.png" alt="环境变量" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207141345011-715181957.png" alt="环境变量" loading="lazy"></p>
<p><strong>重启Ollama：</strong><br>
配置好环境变量后，我们重启下Ollama，目的是让<a href="https://web.chatboxai.app/" target="_blank" rel="noopener nofollow">https://web.chatboxai.app/</a>能自动识别连接到Ollama服务，然后刷新下<a href="https://web.chatboxai.app/" target="_blank" rel="noopener nofollow">https://web.chatboxai.app/</a>。</p>
<p><strong>设置模型提供方和模型：</strong><br>
点击左下角的<code>设置</code>按钮，然后在模型选项卡中选择模型提供方为<strong>OLLAMA API</strong>，模型选择<strong>deepseek-r1:1.5b</strong>，然后点击<code>保存</code>，如下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207141749418-1353988593.png" alt="配置" loading="lazy"></p>
<p><strong>对话演示：</strong><br>
接下来我们就可以愉快的对话了，效果图下图所示：<br>
<img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250207142349177-705939206.gif" alt="演示效果" loading="lazy"></p>
<hr>
<p>到此，DeepSeek R1模型的本地部署以及简单对话应用就完成了！！！</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.044600766680555556" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-07 15:14">2025-02-07 14:32</span>&nbsp;
<a href="https://www.cnblogs.com/qubernet">Qubernet</a>&nbsp;
阅读(<span id="post_view_count">376</span>)&nbsp;
评论(<span id="post_comment_count">8</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18702147" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18702147);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18702147', targetLink: 'https://www.cnblogs.com/qubernet/p/18702147', title: '通过Ollama本地部署DeepSeek R1以及简单使用的教程（超详细）' })">举报</a>
</div>
        