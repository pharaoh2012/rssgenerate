
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xiaoniuhululu/p/18628127" title="发布于 2024-12-24 17:01">
    <span role="heading" aria-level="2">性能优化！突破性能瓶颈的尖兵CPU Cache</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>大家好，我是<a href="https://chunjianbase.cn" target="_blank" rel="noopener nofollow">呼噜噜</a>，今天我们来介绍计算机的储存器之一，CPU高速缓冲存储器也叫高速缓存，<strong>CPU Cache</strong></p>
<p>缓存这个专业术语，在计算机世界中是经常使用到的。它并不是CPU所独有的，比如cdn缓存网站信息，浏览器缓存网页的图像视频等，但本文讲述的是狭义Cache，主要指的是<code>CPU Cache</code>，本文将其简称为"缓存"或者"Cache"</p>
<h2 id="计算机性能的瓶颈">计算机性能的瓶颈</h2>
<p>在冯诺依曼架构下，计算机存储器是分层次的，存储器的层次结构如下图所示，是一个金字塔形状的东西。从上到下依次是寄存器、缓存、主存(内存)、硬盘等等<br>
<img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403729-809015092.png" alt="" loading="lazy"></p>
<p><strong>离CPU越近的存储器，访问速度越来越快，容量越来越小，每字节的成本也越来越昂贵</strong></p>
<p>比如一个主频为3.0GHZ的CPU，寄存器的速度最快，可以在1个时钟周期内访问，一个时钟周期(CPU中基本时间单位)大约是0.3纳秒，内存访问大约需要120纳秒，固态硬盘访问大约需要50-150微秒，机械硬盘访问大约需要1-10毫秒，最后网络访问最慢，得几十毫秒左右。</p>
<p>这个大家可能对时间不怎么直观，那如果我们把<strong>一个时钟周期如果按1秒算的话，那寄存器访问大约是1s，内存访问大约就是6分钟 ，固态硬盘大约是2-6天 ，传统硬盘大约是1-12个月，网络访问就得几年了</strong>！我们可以发现CPU的速度和内存等存储器的速度，完全不是一个量级上的。</p>
<p><img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403567-1594509320.png" alt="" loading="lazy"></p>
<p>电子计算机刚出来的时候，其实CPU是没有缓存Cache的，那个时候的CPU主频很低，甚至没有内存高，CPU都是直接读写内存的</p>
<p>随着时代的发展，技术的革新，从1980年代开始，差距开始迅速扩大，<strong>CPU的速度远远超过内存的速度</strong>，在冯诺依曼架构下，<strong>CPU访问内存的速度也就成了计算机性能的瓶颈！！！</strong></p>
<p><img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403572-1446790152.png" alt="" loading="lazy"></p>
<blockquote>
<p>DRAM为内存颗粒,也叫动态随机存取存储器， 图片来源于：<a href="https://www.extremetech.com/extreme/188776-how-l1-and-l2-cpu-caches-work-and-why-theyre-an-essential-part-of-modern-chips" target="_blank" rel="noopener nofollow">How L1 and L2 CPU Caches Work, and Why They're an Essential Part of Modern Chips</a></p>
</blockquote>
<p>为了弥补CPU与内存两者之间的性能差异，也就是要加快CPU访问内存的速度，就引入了<code>缓存CPU Cache</code>，缓存的速度仅次于寄存器，充当了CPU与内存之间的中间角色</p>
<h2 id="缓存及其发展历史">缓存及其发展历史</h2>
<p><code>缓存CPU Cache</code>用的是 <strong>SRAM</strong>(Static Random-Access Memory)的芯片，也叫<strong>静态随机存储器。</strong>其只要有电，数据就可以保持存在，而一旦断电，数据就会丢失。</p>
<p>CPU Cache 如今通常分为大小不等的<strong>3级缓存</strong>，分别是 <strong>L1 Cache</strong>、<strong>L2 Cache</strong> 和 <strong>L3 Cache</strong>，</p>
<table>
<thead>
<tr>
<th><strong>部件</strong></th>
<th><strong>CPU访问所需时间</strong></th>
<th><strong>备注</strong></th>
<th>大小</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1 高速缓存</td>
<td>2~4 个时钟周期</td>
<td>每个 CPU 核心都有一块属于自己的 L1 高速缓存，L1 高速缓存通常分成<strong>指令缓存</strong>和<strong>数据缓存</strong>。</td>
<td>一般256KB~1MB</td>
</tr>
<tr>
<td>L2 高速缓存</td>
<td>10~20 个时钟周期</td>
<td>L2 高速缓存同样是每个 CPU 核心都有的</td>
<td>一般2~8MB</td>
</tr>
<tr>
<td>L3 高速缓存</td>
<td>20~60个时钟周期</td>
<td>L3 高速缓存是<strong>多个 CPU 核心共用</strong>的</td>
<td>一般10~64MB</td>
</tr>
</tbody>
</table>
<p>我们可以发现<strong>越靠近 CPU 核心的缓存，其访问速度越快，其大小越来越小，其制造成本也越昂贵</strong>，常见的Cache典型分布图如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403708-2034580379.png" alt="chunjianbase.cn" loading="lazy"></p>
<p>回顾Cache发展历史，我们可以发现Cache其实一开始并不是在CPU的内部，我们这里以intel系列为例</p>
<p>在80286之前，那个时候是没有缓存Cache的，那个时候的CPU主频很低，甚至没有内存高，CPU都是直接读写内存的<br>
<img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403602-216488668.png" alt="" loading="lazy"></p>
<p>从80386开始，这个CPU速度和内存速度不匹配问题已经开始展露，并且差距开始迅速扩大，慢速度的内存成为了计算机的瓶颈，无法充分发挥CPU的性能，为解决这个问题，Intel主板支持<code>外部Cache</code>，来配合80386运行</p>
<p><img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403675-1205595671.png" alt="" loading="lazy"></p>
<p>80486将<code>L1 Cache(大小8KB)</code>放到CPU内部，同时支持外接Cache，即L2 Cache（大小从128KB到256KB），但是不分指令和数据Cache<br>
<img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403608-1645770680.png" alt="" loading="lazy"></p>
<p>虽然<code>L1 Cache</code>大小只有8KB，但其实对那时候CPU来说够用了，我们来看一副缓存命中率与L1、L2大小的关系图：<br>
<img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403593-2145997335.png" alt="" loading="lazy"></p>
<blockquote>
<p>图片来源于：<a href="https://www.extremetech.com/extreme/188776-how-l1-and-l2-cpu-caches-work-and-why-theyre-an-essential-part-of-modern-chips" target="_blank" rel="noopener nofollow">How L1 and L2 CPU Caches Work, and Why They're an Essential Part of Modern Chips</a></p>
</blockquote>
<p>从上图我们可以发现，增大<code>L1 cache</code>对于CPU来说好处不太明显，缓存命中率并没有显著提升，成本还会更昂高，所以性价比不高。</p>
<p>而随着<code> L2 cache</code> 大小的增加，缓存总命中率会急剧上升，因此容量更大、速度较慢、更便宜的L2成为了更好的选择</p>
<p>等到<code>Pentium-1/80586</code>，也就是我们熟悉的奔腾系列，由于Pentium采用了双路执行的超标量结构，有2条并行整数流水线，需要对数据和指令进行双重的访问，为了使得这些访问互不干涉，于是<code>L1 Cache</code>被一分为二，分为指令Cache和数据Cache(大小都是8K)，此时的<code>L2 Cache</code>还是在主板上，再后来Intel推出了<code>[Pentium Pro](https://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/Pentium_Pro)/80686</code>，为了进一步提高性能<code>L2 Cache</code><strong>被正式放到CPU内部</strong><br>
<img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403579-461575683.png" alt="" loading="lazy"></p>
<p>后来CPU多核时代来临，Intel的<code>Pentium D、Pentium EE</code>系列，CPU内部每个核心都有自己的<code>L1、L2 Cache</code>，但他们并不共享，只能依靠总线来传递同步缓存数据。最后<code>Core Duo</code>酷睿系列的出现，<code>L2 Cache</code>变成多核共享模式，采用Intel的“Smart cache”共享缓存技术，到此为止，就确定了现代缓存的基本模式<br>
<img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403613-463052921.png" alt="" loading="lazy"><br>
如今<code>CPU Cache </code>通常分为大小不等的3级缓存，分别是 <code>L1 Cache、L2 Cache 和 L3 Cache</code>，<strong>L3 高速缓存为多个 CPU 核心共用的，而L2则被每个核心单独占据</strong>，另外现在有的CPU已经有了<code>L4 Cache</code>，未来可能会更多</p>
<h2 id="缓存如何弥补cpu与内存的性能差异">缓存如何弥补CPU与内存的性能差异？</h2>
<p>我们可以思考一个问题：缓存是如何弥补CPU与内存两者之间的性能差异？<br>
<img src="https://img2024.cnblogs.com/blog/2795476/202412/2795476-20241224170403577-1003483457.gif" alt="" loading="lazy"></p>
<p>缓存主要是利用<strong>局部性原理</strong>，来提升计算机的整体性能。因为缓存的性能仅次于寄存器，而CPU与内存两者之间的产生的分歧，主要是二者存取速度数量级的差距，那<strong>尽可能多地让CPU去存取缓存，同时减少CPU直接访问主存的次数</strong>，这样计算机的性能就自然而然地得到巨大的提升</p>
<blockquote>
<p><a href="https://chunjianbase.cn" target="_blank" rel="noopener nofollow">https://chunjianbase.cn</a></p>
</blockquote>
<p>所谓局部性原理，主要分为<code>空间局部性</code>与<code>时间局部性</code>：</p>
<ol>
<li><strong>时间局部性：</strong>被引用过一次的存储器位置在未来会被多次引用（通常在循环中）。</li>
<li><strong>空间局部性：</strong>如果一个存储器的位置被引用，那么将来他附近的位置也会被引用</li>
</ol>
<p>缓存这里，会去把CPU最近访问<code>主存(内存)中的指令和数据</code>，<strong>临时储存着</strong>，因为根据局部性原理，这些指令和数据<strong>在较短的时间间隔内</strong>很可能会被以后多次使用到，其次是当从主存中取回这些数据时，<strong>会同时取回与其位置相邻的主存单元的存放的数据 临时储存到缓存中</strong>，因为该指令和数据附近的内存区域，<strong>在较短的时间间隔内</strong>也可能会被多次访问。</p>
<p>那以后CPU去访问这些指令和数据时，首先去命中<code>L1 Cache</code>，如果命中会直接从对应的缓存中取数据，而不必每次去访问主存，如果没命中，会再去<code>L2 Cache</code>中找，依次类推，如果<code>L3 Cache</code>中不存在，就去内存中找。</p>
<h2 id="尾语">尾语</h2>
<p>本文简单介绍了计算机性能瓶颈的原因，缓存及其发展历史，最后讲解了缓存弥补CPU和内存性能差异的原理，后面我们会继续更详细深入地介绍Cache的组织结构、缓存一致性，以及如何利用缓存提升我们代码的性能等</p>
<p>参考资料：<br>
<a href="https://www.extremetech.com/extreme/188776-how-l1-and-l2-cpu-caches-work-and-why-theyre-an-essential-part-of-modern-chips" target="_blank" rel="noopener nofollow">https://www.extremetech.com/extreme/188776-how-l1-and-l2-cpu-caches-work-and-why-theyre-an-essential-part-of-modern-chips</a><br>
<a href="http://www.cpu-zone.com/80486.htm" target="_blank" rel="noopener nofollow">http://www.cpu-zone.com/80486.htm</a></p>
<hr>
<p>作者：<a href="https://www.yuque.com/xiaoniuhululu" target="_blank" rel="noopener nofollow">小牛呼噜噜 </a>，关注公众号「<a href="https://chunjianbase.cn/xiaoniuhululu_gzh.png" target="_blank" rel="noopener nofollow">小牛呼噜噜</a>」，更多高质量好文等你！</p>
<p><a href="https://mp.weixin.qq.com/s/He1nYkNprzesSc4g8rb3eA" target="_blank" rel="noopener nofollow">Linux0.12内核源码解读(5)-head.s</a></p>
<p><a href="https://mp.weixin.qq.com/s/_MEUeFfLKbbrdd2mdBqjFw" target="_blank" rel="noopener nofollow">突破计算机性能瓶颈的利器CPU Cache</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.04785288457523148" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2024-12-24 17:06">2024-12-24 17:01</span>&nbsp;
<a href="https://www.cnblogs.com/xiaoniuhululu">小牛呼噜噜</a>&nbsp;
阅读(<span id="post_view_count">37</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18628127" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18628127);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18628127', targetLink: 'https://www.cnblogs.com/xiaoniuhululu/p/18628127', title: '性能优化！突破性能瓶颈的尖兵CPU Cache' })">举报</a>
</div>
        