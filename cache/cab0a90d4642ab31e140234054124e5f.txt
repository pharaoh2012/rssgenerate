
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xiezhr/p/18712410" title="发布于 2025-02-13 08:24">
    <span role="heading" aria-level="2">本地部署 DeepSeek：小白也能轻松搞定！</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><strong>大家好，我是晓凡。</strong></p>
<h3 id="写在前面">写在前面</h3>
<p>最近<code>DeepSeek</code>太火了，以至于每个小伙伴都想试试。<code>DeepSeek</code> 的到来可谓是开启了全民AI热潮。</p>
<p>本以为<code>DeepSeek</code>本地化部署有多难，实际上验证后很简单，操作起来就像给电脑装个新软件那么简单，大约十多分钟可完成本地部署。</p>
<p>今天咱们来聊聊如何在自己的电脑上本地部署 <code>DeepSeek-R1-1.5B</code> 模型。</p>
<h3 id="一为啥要部署-deepseek-r1-15b">一、为啥要部署 DeepSeek-R1-1.5B？</h3>
<p>在做的小伙伴可能跟我一样在使用<code>DeepSeek</code>时，经常遇到“服务器繁忙，请稍后再试。”</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212225433837.png" alt="服务器繁忙，请稍后再试" loading="lazy"></p>
<p>先说说为啥我推荐这个版本吧。<code>DeepSeek-R1-1.5B</code> 是一个轻量级的模型，参数量只有 15 亿，听起来是不是很“迷你”？但别小瞧了它，这可是个“小而精”的家伙。它只需要 3GB 的显存就能运行，这意味着即使你的电脑配置不高，也能轻松驾驭它。而且，它在数学推理方面表现相当出色，甚至在某些基准测试中超过了 <code>GPT-4o</code> 和 <code>Claude 3.5</code>。当然了，如果你电脑配置更高，可以尝试其他版本。</p>
<h3 id="二deepseek-不同版本模型硬件要求">二、DeepSeek 不同版本模型硬件要求</h3>
<p>以下是 DeepSeek 不同版本模型的硬件要求，小伙伴们可以结合自己电脑配置选择版本</p>
<table>
<thead>
<tr>
<th>模型版本</th>
<th>参数量</th>
<th>显存需求（FP16）</th>
<th>推荐 GPU（单卡）</th>
<th>多卡支持</th>
<th>量化支持</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DeepSeek-R1-1.5B</strong></td>
<td>15亿</td>
<td>3GB</td>
<td>GTX 1650（4GB显存）</td>
<td>无需</td>
<td>支持</td>
<td>低资源设备部署（树莓派、旧款笔记本）、实时文本生成、嵌入式系统</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-7B</strong></td>
<td>70亿</td>
<td>14GB</td>
<td>RTX 3070/4060（8GB显存）</td>
<td>可选</td>
<td>支持</td>
<td>中等复杂度任务（文本摘要、翻译）、轻量级多轮对话系统</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-8B</strong></td>
<td>80亿</td>
<td>16GB</td>
<td>RTX 4070（12GB显存）</td>
<td>可选</td>
<td>支持</td>
<td>需更高精度的轻量级任务（代码生成、逻辑推理）</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-14B</strong></td>
<td>140亿</td>
<td>32GB</td>
<td>RTX 4090/A5000（16GB显存）</td>
<td>推荐</td>
<td>支持</td>
<td>企业级复杂任务（合同分析、报告生成）、长文本理解与生成</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-32B</strong></td>
<td>320亿</td>
<td>64GB</td>
<td>A100 40GB（24GB显存）</td>
<td>推荐</td>
<td>支持</td>
<td>高精度专业领域任务（医疗/法律咨询）、多模态任务预处理</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-70B</strong></td>
<td>700亿</td>
<td>140GB</td>
<td>2x A100 80GB/4x RTX 4090（多卡并行）</td>
<td>必需</td>
<td>支持</td>
<td>科研机构/大型企业（金融预测、大规模数据分析）、高复杂度生成任务</td>
</tr>
<tr>
<td><strong>DeepSeek-671B</strong></td>
<td>6710亿</td>
<td>512GB+（单卡显存需求极高，通常需要多节点分布式训练）</td>
<td>8x A100/H100（服务器集群）</td>
<td>必需</td>
<td>支持</td>
<td>国家级/超大规模 AI 研究（气候建模、基因组分析）、通用人工智能（AGI）探索</td>
</tr>
</tbody>
</table>
<h3 id="三晓凡硬件配置">三、晓凡硬件配置</h3>
<ul>
<li>
<p><strong>CPU</strong>：AMD Ryzen 7 5800H with Radeon Graphics            3.20 GHz</p>
</li>
<li>
<p><strong>内存</strong>：16GB</p>
</li>
<li>
<p><strong>操作系统</strong>：Windows 11</p>
</li>
<li>
<p><strong>硬盘空间</strong>：500G，剩余335G</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212231257802.png" alt="硬件配置信息" loading="lazy"></p>
</li>
</ul>
<h3 id="四部署步骤">四、部署步骤</h3>
<h4 id="41-下载并安装ollama">4.1 下载并安装Ollama</h4>
<p>访问官网：<a href="https://ollama.com/" target="_blank" rel="noopener nofollow">https://ollama.com/</a> 下载</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212231841097.png" alt="官网下载" loading="lazy"></p>
<p>或者直接到GitHub下载</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212231945316.png" alt="GitHub下载" loading="lazy"></p>
<p>安装文件OllamaSetup.exe大约745MB。</p>
<p>注：如果下载过于缓慢可以使用<strong>迅雷之类的加速下载</strong>；(晓凡将软件打包放网盘了，有需要的小伙伴可在文章末尾自取)</p>
<p>双击<strong>OllamaSetup.exe进行安装：</strong></p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212232447527.png" alt="双击安装" loading="lazy"></p>
<h4 id="42-检验ollama是否安装成功">4.2 检验Ollama是否安装成功</h4>
<blockquote>
<p>命令行输入 ollama -v 命令，出现如下版本号说明安装成功</p>
</blockquote>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212232743537.png" alt="安装成功" loading="lazy"></p>
<h4 id="43-通过-ollama-拉取-deepseek-模型">4.3 通过 Ollama 拉取 DeepSeek 模型</h4>
<p>这里我选择是的<strong>1.5b</strong>，整个模型大小<strong>1.1 GB</strong>。</p>
<ul>
<li><strong>1.5B</strong>：适用于轻量级任务，如边缘设备（如智能手表、物联网设备）上的简单交互、小型智能问答系统等。目前开源的最小版本。</li>
<li><strong>671B</strong>：主要用于大规模云端推理，适合科研分析、数据挖掘等需要处理海量数据的复杂任务。目前开源的最强版本</li>
</ul>
<p>更多版本可以在这里查看：<strong><a href="https://ollama.com/library/deepseek-r1" target="_blank" rel="noopener nofollow">https://ollama.com/library/deepseek-r1</a></strong> 。</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212233235760.png" alt="image-20250212233235760" loading="lazy"></p>
<p>命令行输入：<code>ollama run deepseek-r1:1.5b</code> 拉取<code>DeepSeek</code>模型</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212233756190.png" alt="拉取deepseek模型" loading="lazy"></p>
<p>整个拉取过程还是比较丝滑的，5到6分钟后看到【success】字样，代表成功安装DeepSeek R1，然后就可以与DeepSeek对话了</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212234222695.png" alt="image-20250212234222695" loading="lazy"></p>
<h4 id="44-与deepseek对话">4.4 与DeepSeek对话</h4>
<blockquote>
<p>通过上面步骤之后，我们就可以愉快的与Deep Seek对话了，如输入：程序员如何避免35岁焦虑？</p>
</blockquote>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250212234655061.png" alt="与DeepSeek对话" loading="lazy"></p>
<h4 id="45-安装webui">4.5 安装WebUI</h4>
<p>使用命令提示符与<code>DeepSeek</code>对话并不友好，为了更好的体验，我们可以安装<code>WebUI</code>，这里使用的是浏览器插件：<strong>Page Assit</strong></p>
<p>（如果小伙伴找不到在哪下载<code>Page Assit</code>插件，晓凡打包放网盘了，可在文章末尾自取）</p>
<p><strong>启动ollama服务后，输入快捷键【ctrl + shift+L】快捷键即可打开WebUI页面</strong></p>
<p>刚安装<code>Page Assit</code> 插件， 需要进行一下如下设置</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250213000109243.png" alt="WebUI设置" loading="lazy"></p>
<p>设置完成后，选择模型就可以与<code>DeepSeek</code>对话了</p>
<p><img src="http://blog.xiezhrspace.cn/blog-img/image-20250213001047404.png" alt="与对话" loading="lazy"></p>
<h3 id="五实际应用场景deepseek-r1-15b-能干啥">五、实际应用场景：DeepSeek-R1-1.5B 能干啥？</h3>
<p>别看 DeepSeek-R1-1.5B 体积小，它可一点都不“弱”。它非常适合用在一些轻量级的任务上，比如：</p>
<ul>
<li><strong>智能客服</strong>：在小型企业或者个人项目中，它可以快速回答客户的一些常见问题，提高服务效率。</li>
<li><strong>语言学习</strong>：你可以用它来练习语言表达，比如输入一个中文句子，让它生成英文翻译。</li>
<li><strong>创意写作</strong>：如果你是个作家或者文案策划，它可以帮你快速生成一些创意片段或者文案初稿</li>
</ul>
<h3 id="六小结">六、小结</h3>
<p>小伙伴们，是不是觉得本地部署 DeepSeek-R1-1.5B 模型超简单？只要按照上面的步骤操作，你就能让自己的电脑拥有一个“智能助手”。</p>
<p>而且，这个模型不仅运行速度快，还能在很多场景中发挥大作用。快去试试吧！</p>
<p>DeepSeek本地部署相关软件下载：</p>
<p>通过网盘分享的文件：DeepSeek本地部署软件.zip<br>
链接: <a href="https://pan.baidu.com/s/1gQp1hJ2cTisfcd0hJcO9gw?pwd=ip55" target="_blank" rel="noopener nofollow">https://pan.baidu.com/s/1gQp1hJ2cTisfcd0hJcO9gw?pwd=ip55</a> 提取码: ip55</p>
<p>本期内容到这儿就结束了，希望对您有所帮助。</p>
<p>我们下期再见 ヾ(•ω•`)o (●'◡'●)</p>

</div>
<div id="MySignature" role="contentinfo">
    <p>本文来自博客园，作者：<a href="https://www.cnblogs.com/xiezhr/" target="_blank">程序员晓凡</a>，转载请注明原文链接：<a href="https://www.cnblogs.com/xiezhr/p/18712410" target="_blank">https://www.cnblogs.com/xiezhr/p/18712410</a></p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.026047411119212962" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-13 08:24">2025-02-13 08:24</span>&nbsp;
<a href="https://www.cnblogs.com/xiezhr">程序员晓凡</a>&nbsp;
阅读(<span id="post_view_count">97</span>)&nbsp;
评论(<span id="post_comment_count">1</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18712410" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18712410);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18712410', targetLink: 'https://www.cnblogs.com/xiezhr/p/18712410', title: '本地部署 DeepSeek：小白也能轻松搞定！' })">举报</a>
</div>
        