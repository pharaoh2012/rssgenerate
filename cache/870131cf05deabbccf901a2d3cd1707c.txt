
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/DOMLX/p/18832576" title="发布于 2025-04-18 14:25">
    <span role="heading" aria-level="2">pytorch 实战教程之 SPP（SPPNet---Spatial Pyramid Pooling）空间金字塔池化网络代码实现  和 SPPF （Spatial Pyramid Pooling Fast）详解​​</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<p>原文作者：aircraft</p>
<p>原文链接：<a id="cb_post_title_url" class="postTitle2 vertical-middle" title="发布于 2025-04-18 14:24" href="https://www.cnblogs.com/DOMLX/p/18832576"><span>pytorch 实战教程之 SPP（SPPNet---Spatial Pyramid Pooling）空间金字塔池化网络代码实现 和 SPPF （Spatial Pyramid Pooling Fast）详解​​</span></a></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">　　　　　　<span style="font-size: 16px">学习YOLOv5前的准备就是学习DarkNet53网络，FPN特征金字塔网络，PANet路径聚合网络结构，（从SPP到SPPF）SPPF空间金字塔池化等。本篇讲<span style="font-size: 16px"><span style="font-size: 16px">从SPP到SPPF</span></span>网络结构。。。（其他几篇已经发布在历史博客里------基本YOLO网络的前置学习就在这篇讲的差不多了，后面应该写YOLO目标检测了。。。。）</span></span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h1><span style="font-size: 14pt"><strong>SPPNet（空间金字塔池化网络）详解​</strong>​</span></h1>
<p><span style="font-size: 16px">SPPNet（Spatial Pyramid Pooling Network）是何凯明团队在2014年提出的创新架构，核心是​<strong>​空间金字塔池化（SPP）层​</strong>​，解决了传统卷积神经网络必须固定输入尺寸的限制。以下从技术原理到实践应用进行详解：</span></p>
<p>&nbsp;</p>
<h3><span style="font-size: 16px"><span style="font-size: 18px"><strong>​一、SPPNet的诞生背景​</strong></span>​</span></h3>
<ol>
<li>
<p>​<strong>​传统CNN的痛点​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">全连接层需固定输入维度（如AlexNet强制缩放到227×227的图像大小）</span></li>
<li><span style="font-size: 16px">图像裁剪/变形导致信息丢失（如长宽比失真）---- 想象一下你的小仙女女朋友拍了很多美美哒的照片，这些照片的构图都不同，最后都要缩放到一个固定尺寸，那么每张照片还好看吗？？？</span></li>
<li><span style="font-size: 16px">多尺度特征难以有效融合</span></li>
</ul>
</li>
<li>
<p>​<strong>​SPP的核心突破​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">允许卷积层输出​<strong>​任意尺寸的特征图​</strong>​</span></li>
<li><span style="font-size: 16px">通过SPP层将​<strong>​动态尺寸特征​</strong>​转换为​<strong>​固定维度向量​</strong>​</span></li>
<li><span style="font-size: 16px">全连接层无需修改即可处理不同输入尺寸</span></li>
</ul>
</li>
</ol>
<p>&nbsp;</p>
<h3><span style="font-size: 16px"><strong>二、空间金字塔池化（SPP）层原理​</strong>​</span></h3>
<h4><span style="font-size: 16px">1. ​<strong>​结构设计​</strong>​</span></h4>
<ul>
<li><span style="font-size: 16px">​<strong>​多级空间分箱（Spatial Bins）​</strong>​：</span>
<ul>
<li><span style="font-size: 16px">预设金字塔层级：如 <code>[4×4, 2×2, 1×1]</code> 三级网格</span></li>
<li><span style="font-size: 16px">每级网格将特征图划分为<code>n×n</code>个子区域</span></li>
</ul>
</li>
<li><span style="font-size: 16px">​<strong>​自适应最大池化​</strong>​：</span>
<ul>
<li><span style="font-size: 16px">每个子区域执行最大池化，输出1个值</span></li>
<li><span style="font-size: 16px">池化窗口尺寸自动计算：<code>win_size = ⌈输入尺寸/n⌉</code></span></li>
<li><span style="font-size: 16px">步长（stride）自动计算：<code>stride = ⌊输入尺寸/n⌋</code></span></li>
</ul>
</li>
</ul>
<h4><span style="font-size: 16px">2. ​<strong>​数学形式​</strong>​</span></h4>
<ul>
<li><span style="font-size: 16px">输入特征图尺寸：<code>W×H×C</code>（宽×高×通道）</span></li>
<li><span style="font-size: 16px">第k级金字塔输出维度：<code>n_k × n_k × C</code></span></li>
<li><span style="font-size: 16px">总输出维度：<code>(Σ n_k²) × C</code>（固定长度）</span></li>
</ul>
<p><span style="font-size: 16px">​<strong>​示例​</strong>​：</span></p>
<ul>
<li><span style="font-size: 16px">三级金字塔 <code>[4×4, 2×2, 1×1]</code></span></li>
<li><span style="font-size: 16px">输出维度：<code>(16 + 4 + 1) × C = 21C</code></span></li>
</ul>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418110724674-146127438.webp" alt="" loading="lazy"></p>
<p>&nbsp;<span style="font-size: 16px">具体流程：</span><br><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1、特征图分割：SPP 层将输入的特征图分割成多个不同大小的网格，这些网格的大小通常是 1x1、2x2、4x4 、8x8 等等，形成一个金字塔结构，每个网格的大小决定了池化操作的感受野；</span><br><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2、池化操作：对每个网格进行池化操作，通常使用最大池化（Max Pooling）；最大池化会选择每个网格中的最大值作为输出。这样，每个网格都会生成一个固定大小的特征表示，需要注意的是这个池化操作是一个并发的过程；</span><br><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3、特征拼接：将所有网格的特征表示拼接起来，形成一个固定长度的特征向量；这个特征向量随后可以作为后续全连接层的输入；</span><br><br></p>
<p>&nbsp;</p>
<p><strong><span style="font-size: 18px">为什么很多带全连接层的网络结构都需要固定归一化图像的大小呢（如AlexNet强制缩放到227×227的图像大小）？举个例子就是我在全连接层输出的网络结构是固定大小的，比如是21*512这个大小：</span></strong></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">在最后一层卷积层我们已经固定用了512个卷积核，那么输入到全连接层的数据就是 w * h * 512 (特征图像的长宽乘通道数)，那么在通道数固定的情况下，图像大小变化的话就会和全连接层对应不上。接口对接不起来！！！</span></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">拿全连接层所需数据大小<strong>21*512</strong>举例<strong>，</strong>在卷积层输出的通道数固定为512的情况下，我们构建1x1、2x2、4x4的三层空间金字塔池化：</span></p>
<p><span style="font-size: 16px">&nbsp;</span></p>
<p><span style="font-size: 16px">假设我们有一张 448×448 的输入图像，通过卷积层后得到特征图 56×56×512；接下来，我们使用 SPP 层进行处理：</span><br><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp; 1.特征图分割：</span><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1x1 网格：整个特征图作为一份数据</span><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2x2 网格：特征图被均匀分割成 4 份数据</span><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4x4 网格：特征图被均匀分割为16份数据</span><br><br><span style="font-size: 16px">&nbsp;&nbsp; 2. 池化操作：</span><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1x1 网格：最大池化后的特征图尺寸为 1×1×512；</span><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2x2 网格：最大池化后的特征图尺寸为 2×2×512=4×512=4×512；</span><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4x4 网格：最大池化后的特征图尺寸为 4×4×512=16×512=16×512；</span><br><br><span style="font-size: 16px">&nbsp;&nbsp; 3. 特征拼接：</span><br><span style="font-size: 16px">&nbsp;&nbsp;&nbsp; 拼接后的特征向量长度为：21 x 512&nbsp; =10752&nbsp;&nbsp;&nbsp; 不管你输入图像的大小是多少227x227 ,512x512,318x318也好，经过三层的空间金字塔网络后提取的特征数目都是21份，加上通道数就是 21x512份。这样就不用在意输入图像数据的大小了。</span><br><br></p>
<p><span style="font-size: 16px">下图就非常鲜明了，厚度就是通道数：</span></p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418113057795-1936005592.webp" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">&nbsp;</span></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">大概代码实现（任意输入图像尺寸，输出的大小一致）：</span></p>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)">import torch
import torch.nn </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> nn

</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> SpatialPyramidPooling(nn.Module):
    def __init__(self, levels</span>=[<span style="color: rgba(128, 0, 128, 1)">4</span>, <span style="color: rgba(128, 0, 128, 1)">2</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]):
        super().__init__()
        self.levels </span>=<span style="color: rgba(0, 0, 0, 1)"> levels

    def forward(self, x):
        N, C, H, W </span>=<span style="color: rgba(0, 0, 0, 1)"> x.size()
        outputs </span>=<span style="color: rgba(0, 0, 0, 1)"> []
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> level <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> self.levels:
            kh </span>= H <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> level</span>
            kw = W <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> level</span>
            pool = nn.MaxPool2d(kernel_size=(kh, kw), stride=<span style="color: rgba(0, 0, 0, 1)">(kh, kw))
            outputs.append(pool(x).view(N, </span>-<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">))
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> torch.cat(outputs, dim=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)

# 使用示例
spp </span>= SpatialPyramidPooling(levels=[<span style="color: rgba(128, 0, 128, 1)">4</span>, <span style="color: rgba(128, 0, 128, 1)">2</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">])
input </span>= torch.randn(<span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">13</span>, <span style="color: rgba(128, 0, 128, 1)">13</span><span style="color: rgba(0, 0, 0, 1)">)  # 任意尺寸输入
output </span>= spp(input)                   # 输出固定维度: (<span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(128, 0, 128, 1)">21</span> * <span style="color: rgba(128, 0, 128, 1)">256</span>)</span></pre>
</div>
<p>&nbsp;</p>
<h3><span style="font-size: 16px"><strong>代码的隐藏条件​</strong>​</span></h3>
<p><span style="font-size: 16px">代码​<strong>​隐式要求输入尺寸必须能被所有level整除​</strong>​，否则实际输出网格数会偏离预设level：</span></p>
<ul>
<li><span style="font-size: 16px">​<strong>​反例​</strong>​：输入10×10，level=4</span>
<ul>
<li>池化核：10//4=2，步长2×2</li>
<li>输出尺寸：<code>(10-2)/2 +1 =5</code> → ​<strong>​5×5​</strong>​（而非预设的4×4）</li>
</ul>
</li>
</ul>
<p><span style="font-size: 16px">​若想不管这个隐藏条件，还可以这样改，使用自适应池化：</span><br>
</p>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> SpatialPyramidPooling(nn.Module):
    def __init__(self, levels</span>=[<span style="color: rgba(128, 0, 128, 1)">4</span>, <span style="color: rgba(128, 0, 128, 1)">2</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]):
        super().__init__()
        self.pools </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.ModuleList([
            nn.AdaptiveMaxPool2d((level, level)) </span><span style="color: rgba(0, 0, 255, 1)">for</span> level <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> levels
        ])

    def forward(self, x):
        N, C, _, _ </span>=<span style="color: rgba(0, 0, 0, 1)"> x.size()
        outputs </span>= [pool(x).view(N, -<span style="color: rgba(128, 0, 128, 1)">1</span>) <span style="color: rgba(0, 0, 255, 1)">for</span> pool <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> self.pools]
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> torch.cat(outputs, dim=<span style="color: rgba(128, 0, 128, 1)">1</span>)</span></pre>
</div>
<p><code>AdaptiveMaxPool2d</code>直接强制输出目标尺寸（如4×4），无需计算核尺寸</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h3><span style="font-size: 16px"><span style="font-size: 14pt"><strong>局限性​</strong></span>​</span></h3>
<ol>
<li>
<p>​<strong>​池化信息损失​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">最大池化丢弃非最大值信息</span></li>
<li><span style="font-size: 16px">后续的ROI Align改用双线性插值缓解此问题</span></li>
</ul>
</li>
<li>
<p>​<strong>​计算资源消耗​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">多级池化增加内存占用</span></li>
<li><span style="font-size: 16px">实时性弱于纯全卷积网络（FCN）</span></li>
</ul>
</li>
</ol>
<h3><span style="font-size: 16px"><span style="font-size: 14pt"><strong>总结​</strong></span>​</span></h3>
<p><span style="font-size: 16px">SPPNet通过空间金字塔池化，首次实现了CNN对任意尺寸输入的处理，奠定了多尺度特征融合的基础。其核心思想被后续众多模型（如Fast R-CNN、Mask R-CNN）继承发展，是深度学习发展史上的重要里程碑。理解SPP机制对掌握现代目标检测和图像分类模型至关重要。</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h1><span style="font-size: 14pt"><strong>SPPF（Spatial Pyramid Pooling Fast）详解​</strong>​</span></h1>
<p><span style="font-size: 16px">SPPF（空间金字塔快速池化）是SPPNet的改进版本，由YOLO系列（如YOLOv5、YOLOv7）引入，旨在保持多尺度特征融合能力的同时显著提升计算效率。其核心思想是通过​<strong>​串行重复池化操作​</strong>​替代传统金字塔并行池化，减少计算冗余。以下是详细解析：</span></p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418140914376-138988969.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418142433400-555779147.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><strong>​一、SPPF与SPP的结构对比​</strong>​</span></h4>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">模块</span></th><th><span style="font-size: 16px">池化方式</span></th><th><span style="font-size: 16px">计算路径</span></th><th><span style="font-size: 16px">参数量</span></th><th><span style="font-size: 16px">输出特征维度</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">SPP</span></td>
<td><span style="font-size: 16px">并行多级池化（如4×4, 2×2, 1×1）</span></td>
<td><span style="font-size: 16px">独立分支</span></td>
<td><span style="font-size: 16px">多</span></td>
<td><span style="font-size: 16px">多级特征拼接</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">SPPF</span></td>
<td><span style="font-size: 16px">串行重复池化（如三次5×5池化）</span></td>
<td><span style="font-size: 16px">单链叠加</span></td>
<td><span style="font-size: 16px">少</span></td>
<td><span style="font-size: 16px">等效金字塔融合</span></td>
</tr>
</tbody>
</table>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<table>
<thead>
<tr><th><span style="font-size: 16px">特性</span></th><th><span style="font-size: 16px">SPP</span></th><th><span style="font-size: 16px">SPPF</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">多尺度特征来源</span></td>
<td><span style="font-size: 16px">离散分级（4×4, 2×2, 1×1）</span></td>
<td><span style="font-size: 16px">连续叠加（5→9→13感受野）</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">计算效率</span></td>
<td><span style="font-size: 16px">低（多分支并行池化）</span></td>
<td><span style="font-size: 16px">高（单链串行池化，GPU优化）</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">硬件友好性</span></td>
<td><span style="font-size: 16px">内存碎片化</span></td>
<td><span style="font-size: 16px">连续内存操作</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">适用场景</span></td>
<td><span style="font-size: 16px">分类网络（需全连接层）</span></td>
<td><span style="font-size: 16px">检测网络（全卷积架构）</span></td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><strong>二、SPPF核心原理​</strong>​</span></h4>
<h5><span style="font-size: 16px">1. ​<strong>​串行池化设计​</strong>​</span></h5>
<ul>
<li><span style="font-size: 16px">​<strong>​池化核尺寸固定​</strong>​：通常使用5×5池化窗口，重复三次</span></li>
<li><span style="font-size: 16px">​<strong>​步长固定为1​</strong>​：通过填充（padding）保持特征图尺寸不变</span></li>
<li><span style="font-size: 16px">​<strong>​动态感受野叠加​</strong>​：每次池化扩大感受野，等效多尺度特征提取</span></li>
</ul>
<h5><span style="font-size: 16px">2. ​<strong>​数学过程​</strong>​</span></h5>
<p><span style="font-size: 16px">输入特征图尺寸：<span class="katex"><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.13889em">W<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.08125em">H<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.6833em"><span class="mord mathnormal" style="margin-right: 0.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li><span style="font-size: 16px">​<strong>​第一次池化​</strong>​：5×5池化 → 输出 <span class="katex"><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.13889em">W<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.08125em">H<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.6833em"><span class="mord mathnormal" style="margin-right: 0.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><span style="font-size: 16px">​<strong>​第二次池化​</strong>​：5×5池化 → 输出 <span class="katex"><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.13889em">W<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.08125em">H<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.6833em"><span class="mord mathnormal" style="margin-right: 0.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><span style="font-size: 16px">​<strong>​第三次池化​</strong>​：5×5池化 → 输出 <span class="katex"><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.13889em">W<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.08125em">H<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.6833em"><span class="mord mathnormal" style="margin-right: 0.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><span style="font-size: 16px">​<strong>​特征拼接​</strong>​：原始输入 + 三次池化输出 → 最终维度 <span class="katex"><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em"><span class="mord">4<span class="mord mathnormal" style="margin-right: 0.07153em">C&nbsp;&nbsp;&nbsp; 而SPPF中的<span style="font-size: 16px"><span class="katex"><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.13889em">W<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.08125em">H始终不变，SPP则是通道数和金字塔后输出的数据不变</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
</ul>
<p><span style="font-size: 16px">​<strong>​等效感受野​</strong>​：</span></p>
<ul>
<li><span style="font-size: 16px">三次5×5池化 ≈ 单次13×13池化（5+（5-1）<span style="font-size: 16px">x2</span> ） = 13</span></li>
</ul>
<h5><span style="font-size: 16px">3. ​<strong>​计算效率优化​</strong>​</span></h5>
<ul>
<li><span style="font-size: 16px">​<strong>​参数共享​</strong>​：三次池化使用相同核尺寸，无需额外参数</span></li>
<li><span style="font-size: 16px">​<strong>​内存连续性​</strong>​：串行操作减少内存碎片，提升GPU利用率</span></li>
<li><span style="font-size: 16px">​<strong>​FLOPs对比​</strong>​（以256×13×13输入为例）：</span>
<ul>
<li><span style="font-size: 16px">SPP：约 1.2 GFLOPs</span></li>
<li><span style="font-size: 16px">SPPF：约 0.8 GFLOPs （​<strong>​速度提升33%​</strong>​）</span></li>
</ul>
</li>
</ul>
<p>&nbsp;</p>
<h3><span style="font-size: 18px"><strong>具体示例演示​</strong>​</span></h3>
<h4><span style="font-size: 18px">​<strong>​Case 1：输入尺寸 13×13×256​</strong>​</span></h4>
<ul>
<li>
<p>​<strong>​第一次池化​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">输入：13×13×256</span></li>
<li><span style="font-size: 16px">输出：13×13×256（保持尺寸）</span></li>
<li><span style="font-size: 16px">​<strong>​感受野​</strong>​：5×5（覆盖输入中5×5区域）</span></li>
</ul>
</li>
<li>
<p>​<strong>​第二次池化​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">输入：13×13×256</span></li>
<li><span style="font-size: 16px">输出：13×13×256</span></li>
<li><span style="font-size: 16px">​<strong>​感受野​</strong>​：9×9（叠加两次5×5池化）</span></li>
</ul>
</li>
<li>
<p>​<strong>​第三次池化​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">输入：13×13×256</span></li>
<li><span style="font-size: 16px">输出：13×13×256</span></li>
<li><span style="font-size: 16px">​<strong>​感受野​</strong>​：13×13（叠加三次池化覆盖全图）</span></li>
</ul>
</li>
<li>
<p><span style="font-size: 18px">​<strong>​拼接结果​</strong>​：</span></p>
<ul>
<li><span style="font-size: 18px">输出尺寸：13×13×(256×4) = ​<strong>​13×13×1024​</strong>​</span></li>
</ul>
</li>
</ul>
<p>&nbsp;</p>
<p><span style="font-size: 16px">虽然SPPF输出的空间尺寸 (<span class="katex"><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em"><span class="mord mathnormal" style="margin-right: 0.13889em">W<span class="mspace" style="margin-right: 0.2222em"><span class="mbin">×<span class="mspace" style="margin-right: 0.2222em"><span class="base"><span class="strut" style="height: 0.6833em"><span class="mord mathnormal" style="margin-right: 0.08125em">H) 仍与输入相关，但后续网络通过 ​<strong>​全局池化（Global Pooling）​</strong>​ 或 ​<strong>​自适应层（Adaptive Layers）​</strong>​ 将其转换为固定维度</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418141950384-1074765112.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<h3><span style="font-size: 16px"><span style="font-size: 18px"><strong>SPPF中的感受野计算示例​</strong></span>​</span></h3>
<p><span style="font-size: 16px">以YOLOv5的SPPF模块为例（三次5×5池化，步长=1）：</span></p>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th>层数</th><th>操作</th><th>核尺寸(k)</th><th>步长(stride)</th><th>感受野计算</th><th>累计感受野</th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">1</span></td>
<td><span style="font-size: 16px">输入</span></td>
<td><span style="font-size: 16px">-</span></td>
<td><span style="font-size: 16px">-</span></td>
<td><span style="font-size: 16px">初始感受野=1</span></td>
<td><span style="font-size: 16px">1×1</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">2</span></td>
<td><span style="font-size: 16px">第一次池化</span></td>
<td><span style="font-size: 16px">5×5</span></td>
<td><span style="font-size: 16px">1</span></td>
<td><span style="font-size: 16px">1 + (5-1)*1 = ​<strong>​5​</strong>​</span></td>
<td><span style="font-size: 16px">5×5</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">3</span></td>
<td><span style="font-size: 16px">第二次池化</span></td>
<td><span style="font-size: 16px">5×5</span></td>
<td><span style="font-size: 16px">1</span></td>
<td><span style="font-size: 16px">5 + (5-1)*1 * 1 = ​<strong>​9​</strong>​</span></td>
<td><span style="font-size: 16px">9×9</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">4</span></td>
<td><span style="font-size: 16px">第三次池化</span></td>
<td><span style="font-size: 16px">5×5</span></td>
<td><span style="font-size: 16px">1</span></td>
<td><span style="font-size: 16px">9 + (5-1)*1 * 1 * 1 = ​<strong>​13​</strong>​</span></td>
<td><span style="font-size: 16px">13×13</span></td>
</tr>
</tbody>
</table>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<ul>
<li><span style="font-size: 18px"><strong>不强制固定维度​</strong>​：保留空间信息以支持目标检测中的位置敏感任务。</span></li>
<li><span style="font-size: 18px">​<strong>​与后续卷积层兼容​</strong>​：YOLO的检测头（Head）直接处理可变尺寸特征图。</span></li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<ul>
<li><span style="font-size: 18px"><strong>错误理解​</strong>​：将SPPF用于分类任务（需全连接层）时，才需要额外添加全局池化。</span></li>
<li><span style="font-size: 18px">​<strong>​正确场景​</strong>​：在YOLO等检测网络中，SPPF天然适配全卷积结构，​<strong>​无需任何后续约束​</strong>​</span></li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h3><span style="font-size: 18px"><strong>YOLO中SPPF的实际应用​</strong>​：</span></h3>
<p>&nbsp;</p>
<p><span style="font-size: 16px">在YOLOv5/v7中，SPPF模块后​<strong>​直接连接卷积层​</strong>​，无需全局池化：</span></p>
<p>&nbsp;</p>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)"># YOLOv5的C3模块（包含SPPF）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> C3(nn.Module):
    def __init__(self, c1, c2):
        super().__init__()
        self.sppf </span>=<span style="color: rgba(0, 0, 0, 1)"> SPPF(c1)            # 输出H×W×4C1
        self.conv </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">4</span>*c1, c2, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 压缩通道到C2

    def forward(self, x):
        x </span>=<span style="color: rgba(0, 0, 0, 1)"> self.sppf(x)     # H×W×4C1 → 空间维度保留
        x </span>=<span style="color: rgba(0, 0, 0, 1)"> self.conv(x)     # H×W×C2 → 输入检测头
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> x</span></pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h1><span style="font-size: 14pt"><strong>三、SPPF的具体实现​</strong>​</span></h1>
<h5><span style="font-size: 18px">1. ​<strong>​PyTorch代码示例​：</strong>​</span></h5>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)">import torch
import torch.nn </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> nn

</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> SPPF(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.pool </span>= nn.MaxPool2d(kernel_size=<span style="color: rgba(128, 0, 128, 1)">5</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span>, padding=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)
    
    def forward(self, x):
        x1 </span>=<span style="color: rgba(0, 0, 0, 1)"> self.pool(x)
        x2 </span>=<span style="color: rgba(0, 0, 0, 1)"> self.pool(x1)
        x3 </span>=<span style="color: rgba(0, 0, 0, 1)"> self.pool(x2)
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> torch.cat([x, x1, x2, x3], dim=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">) 

# 输入示例：batch</span>=<span style="color: rgba(128, 0, 128, 1)">1</span>, channels=<span style="color: rgba(128, 0, 128, 1)">256</span>, size=<span style="color: rgba(0, 0, 0, 1)">13x13
input </span>= torch.randn(<span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">13</span>, <span style="color: rgba(128, 0, 128, 1)">13</span><span style="color: rgba(0, 0, 0, 1)">)
sppf </span>= SPPF(<span style="color: rgba(128, 0, 128, 1)">256</span><span style="color: rgba(0, 0, 0, 1)">)
output </span>= sppf(input)  # 输出维度：[<span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(128, 0, 128, 1)">1024</span>, <span style="color: rgba(128, 0, 128, 1)">13</span>, <span style="color: rgba(128, 0, 128, 1)">13</span>]</span></pre>
</div>
<p>&nbsp;</p>
<h5><span style="font-size: 16px">2. ​<strong>​关键参数配置​</strong>​</span></h5>
<ul>
<li><span style="font-size: 16px">​<strong>​核尺寸​</strong>​：通常为5×5（平衡感受野与计算量）</span></li>
<li><span style="font-size: 16px">​<strong>​填充策略​</strong>​：<code>padding=kernel_size//2</code>（保持尺寸不变）</span></li>
<li><span style="font-size: 16px">​<strong>​拼接方式​</strong>​：沿通道维度拼接原始输入与池化结果</span></li>
</ul>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><strong>四、SPPF的优势分析​</strong>​</span></h4>
<ol>
<li>
<p>​<strong>​计算效率提升​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">减少分支操作，利用串行流水线加速</span></li>
<li><span style="font-size: 16px">YOLOv5中SPPF比SPP快2.5倍（相同硬件）</span></li>
</ul>
</li>
<li>
<p>​<strong>​多尺度特征融合增强​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">三次池化等效于13×13、9×9、5×5多级感受野</span></li>
<li><span style="font-size: 16px">保留更精细的局部特征（对比SPP的跳跃式分级）</span></li>
</ul>
</li>
<li>
<p>​<strong>​硬件友好性​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">连续内存访问优化缓存命中率</span></li>
<li><span style="font-size: 16px">适合部署到边缘设备（如Jetson系列）</span></li>
</ul>
</li>
<li>
<p>​<strong>​模型兼容性​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">输入输出尺寸一致，可直接替换SPP模块</span></li>
<li><span style="font-size: 16px">无缝集成到ResNet、CSPNet等主流骨干网络</span></li>
</ul>
</li>
</ol>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><span style="font-size: 14pt"><strong>五、SPPF在YOLO中的实际应用​</strong></span>​</span></h4>
<h5><span style="font-size: 16px">1. ​<strong>​YOLOv5网络结构集成​</strong>​</span></h5>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1); font-size: 16px">Backbone
├── Focus
├── Conv
├── C3
└── SPPF  # 替换原始SPP模块</span></pre>
</div>
<p>&nbsp;</p>
<h5><span style="font-size: 16px">2. ​<strong>​性能提升对比（COCO数据集）​</strong>​</span></h5>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">模型</span></th><th><span style="font-size: 16px">mAP@0.5</span></th><th><span style="font-size: 16px">FPS (Tesla T4)</span></th><th><span style="font-size: 16px">参数量 (M)</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">YOLOv5s</span></td>
<td><span style="font-size: 16px">37.2</span></td>
<td><span style="font-size: 16px">125</span></td>
<td><span style="font-size: 16px">7.2</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">YOLOv5s+SPPF</span></td>
<td><span style="font-size: 16px">​<strong>​37.8​</strong>​</span></td>
<td><span style="font-size: 16px">​<strong>​142​</strong>​</span></td>
<td><span style="font-size: 16px">7.3</span></td>
</tr>
</tbody>
</table>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><span style="font-size: 14pt"><strong>​六、SPPF的局限性​</strong></span>​</span></h4>
<ol>
<li>
<p>​<strong>​小物体检测精度衰减​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">多次池化可能模糊微小物体的细节特征</span></li>
<li><span style="font-size: 16px">需配合FPN（特征金字塔）使用以缓解此问题</span></li>
</ul>
</li>
<li>
<p>​<strong>​理论感受野与实际差异​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">串行池化的等效感受野为线性增长，弱于SPP的指数级覆盖</span></li>
</ul>
</li>
<li>
<p>​<strong>​通道膨胀问题​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">输出通道数变为输入4倍，可能增加后续卷积计算量</span></li>
</ul>
</li>
</ol>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><span style="font-size: 14pt"><strong>七、改进变体​（下面这些都是不断改进升级的版本）</strong></span>​</span></h4>
<ol>
<li>
<p>​<strong>​SPPF+SE​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">加入通道注意力机制（Squeeze-and-Excitation）</span></li>
<li><span style="font-size: 16px">提升重要通道的权重分配</span></li>
</ul>
</li>
<li>
<p>​<strong>​ASPPF（Atrous SPPF）​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">使用空洞池化（Dilated Pooling）扩大感受野</span></li>
<li><span style="font-size: 16px">减少下采样带来的信息损失</span></li>
</ul>
</li>
<li>
<p>​<strong>​轻量化SPPF​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">采用深度可分离卷积（Depthwise Separable Conv）</span></li>
<li><span style="font-size: 16px">适用于移动端部署</span></li>
</ul>
</li>
</ol>
<p><span style="font-size: 16px">还有SimSPPF，SPPCSPC，SPPFCSPC+都可以去了解一下都是YOLO不断升级中改进出来的。</span></p>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><span style="font-size: 14pt"><strong>八、总结​</strong></span>​</span></h4>
<p><span style="font-size: 16px">SPPF通过巧妙的串行池化结构，在保持多尺度特征融合能力的同时，显著提升了计算效率。其设计体现了“​<strong>​简单即有效​</strong>​”的优化哲学，成为实时目标检测模型的标配模块。理解SPPF的工作原理对于优化模型速度和精度平衡至关重要，特别是在边缘计算和实时视频分析场景中具有重要价值。</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">参考博客：https://blog.csdn.net/CITY_OF_MO_GY/article/details/143897303</span></p>
<p><span style="font-size: 16px">　　　　 &nbsp; &nbsp;https://developer.aliyun.com/article/1509544</span></p>
<p><span style="font-size: 16px">　　　　 &nbsp; &nbsp;https://blog.csdn.net/weixin_38346042/article/details/131796263</span></p>
<p>&nbsp;</p>
</div>
<div id="MySignature" role="contentinfo">
    转发和使用本文，请注明作者信息和原文地址---本文原作者为aircraft

---大家好我是徐飞机，有没有大佬们的公司招c++开发/图像处理/opengl/opencv/halcon实习的啊，带上我一个呗QAQ。。。hhhhhh  想要免费获取前端，后端，c/c++,matlab，Python，opencv，机器学习，深度学习，安卓，java，等等全套视频教程请关注机器视觉开发公众号，转发集赞28即可百度云获得hhhhhhhh
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.9116145334444444" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-18 14:26">2025-04-18 14:25</span>&nbsp;
<a href="https://www.cnblogs.com/DOMLX">aircraft</a>&nbsp;
阅读(<span id="post_view_count">69</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18832576);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18832576', targetLink: 'https://www.cnblogs.com/DOMLX/p/18832576', title: 'pytorch 实战教程之 SPP（SPPNet---Spatial Pyramid Pooling）空间金字塔池化网络代码实现  和 SPPF （Spatial Pyramid Pooling Fast）详解​​' })">举报</a>
</div>
        