
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/huggingface/p/18816815" title="发布于 2025-04-09 16:01">
    <span role="heading" aria-level="2">让 LLM 来评判 | 技巧与提示</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<blockquote>
<p>这是 <strong>让 LLM 来评判</strong> 系列文章的第六篇，敬请关注系列文章:</p>
<ul>
<li><a href="https://www.cnblogs.com/huggingface/p/18666189" target="_blank">基础概念</a></li>
<li><a href="https://www.cnblogs.com/huggingface/p/18670887" target="_blank">选择 LLM 评估模型</a></li>
<li><a href="https://www.cnblogs.com/huggingface/p/18741971" target="_blank">设计你自己的评估 prompt</a></li>
<li><a href="https://www.cnblogs.com/huggingface/p/18710538" target="_blank">评估你的评估结果</a></li>
<li><a href="https://www.cnblogs.com/huggingface/p/18715798" target="_blank">奖励模型相关内容</a></li>
<li>技巧与提示</li>
</ul>
</blockquote>
<h2 id="llm-评估模型已知偏差及缓解措施">LLM 评估模型已知偏差及缓解措施:</h2>
<ul>
<li><strong>缺乏内部一致性</strong>：同一 prompt 输入评估模型执行多次得到的结果可能不一样 (如果温度参数不设为 0)。
<ul>
<li>缓解措施：遵循 “自我一致性 (self-consistency)” 设置 prompt，输入模型执行多次并保留多数结果</li>
</ul>
</li>
<li><strong>自我偏好</strong>：LLM 评估模型更 <a href="https://arxiv.org/abs/2404.13076" target="_blank" rel="noopener nofollow">偏好自己的输出模式</a>，因此会对模式相似的结果评分偏高。
<ul>
<li>缓解措施：采用陪审团机制</li>
</ul>
</li>
<li><strong>输入扰动不敏感</strong>：评估模型对 <a href="https://arxiv.org/abs/2406.13439" target="_blank" rel="noopener nofollow">扰动输入</a> 的辨识效果较差，<a href="https://twitter.com/aparnadhinak/status/1748368364395721128" target="_blank" rel="noopener nofollow">难以提供一致的评分范围</a> (更多实验结果可以参考 <a href="https://github.com/LeonEricsson/llmjudge/blob/main/README.md" target="_blank" rel="noopener nofollow">这个链接</a>)。例如对于施加了相同程度噪声的文本，使用评估模型评估文本质量的评分无法反映噪声的程度。
<ul>
<li>缓解措施：
<ul>
<li>要求模型先输出详细的推理过程 <a href="https://twitter.com/seungonekim/status/1749289437165769177" target="_blank" rel="noopener nofollow">再输出评分</a></li>
<li>在 prompt 中添加一致的评分标准</li>
</ul>
</li>
</ul>
</li>
<li><strong>位置偏差</strong>：评估模型更 <a href="https://arxiv.org/abs/2306.05685" target="_blank" rel="noopener nofollow">偏好特定位置的答案</a>。例如在成对比较时，Claude 和 GPT3.5 在多次测试中通常会偏好某一个位置，例如第一个或第二个答案。
<ul>
<li>缓解措施：
<ul>
<li>随机调整答案位置</li>
<li>计算所有选项的对数概率并归一化</li>
</ul>
</li>
</ul>
</li>
<li><strong>冗长偏好 (长度偏差)</strong>：评估模型更偏好冗长的答案。
<ul>
<li>缓解措施：<a href="https://arxiv.org/abs/2404.04475" target="_blank" rel="noopener nofollow">考虑答案中的长度差异</a></li>
</ul>
</li>
<li><strong><a href="https://arxiv.org/abs/2308.15812" target="_blank" rel="noopener nofollow">难以对齐人类答案</a></strong>：
<ul>
<li>在所有评估中，<a href="https://arxiv.org/abs/2202.06935" target="_blank" rel="noopener nofollow">人工评估是否可以作为一个不错的基线尚有争议</a>。例如在某些特定领域 (如医学、法律、数学等)，如果标注员专业性不够，那么得到的结果可能跟直接采用 LLM 一样差。</li>
</ul>
</li>
<li><strong>格式偏差</strong>：如果输入模型的 prompt 格式与其训练数据的格式 <a href="https://arxiv.org/pdf/2310.17631" target="_blank" rel="noopener nofollow">相差甚远</a>，可能导致模型的评估结果不准确。例如，成对比较模型的训练集数据格式中提供了参考答案，如果在评估时没有给定参考答案或者给定的参考答案格式有误，那么评估结果就不可信。
<ul>
<li>缓解措施：仔细遵循评估模型训练集 prompt 格式 (比如指令微调模型的格式)。</li>
</ul>
</li>
</ul>
<h2 id="选择合适的-llm-评估任务">选择合适的 LLM 评估任务</h2>
<p>LLM 评估特性：</p>
<ul>
<li><strong>很难识别幻觉</strong>：尤其是部分幻觉 (与事实非常相近，仅有微小的区别而导致错误)。(可以参考这两篇论文：<a href="https://arxiv.org/abs/2305.11747" target="_blank" rel="noopener nofollow">链接 1</a> 和 <a href="https://arxiv.org/abs/2303.08896" target="_blank" rel="noopener nofollow">链接 2</a>)。</li>
<li><strong>许多任务上与人工评估一致性不高</strong>：如 <a href="https://arxiv.org/abs/2304.02554" target="_blank" rel="noopener nofollow">总结任务</a> (也可以参考 <a href="https://arxiv.org/abs/2303.16634" target="_blank" rel="noopener nofollow">这篇</a>)、<a href="https://arxiv.org/abs/2307.16877" target="_blank" rel="noopener nofollow">输入遵循忠实度</a>，更多任务请参考 <a href="https://arxiv.org/abs/2406.18403" target="_blank" rel="noopener nofollow">这篇论文</a>。</li>
</ul>
<hr>
<blockquote>
<p>英文原文: <a href="https://github.com/huggingface/evaluation-guidebook/blob/main/translations/zh/contents/model-as-a-judge/tips-and-tricks.md" target="_blank" rel="noopener nofollow">evaluation-guidebook/contents/model-as-a-judge/tips-and-tricks.md</a></p>
<p>原文作者: clefourrier</p>
<p>译者: SuSung-boy</p>
<p>审校: adeenayakup</p>
</blockquote>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.33855623266319446" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-09 16:13">2025-04-09 16:01</span>&nbsp;
<a href="https://www.cnblogs.com/huggingface">HuggingFace</a>&nbsp;
阅读(<span id="post_view_count">26</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18816815" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18816815);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18816815', targetLink: 'https://www.cnblogs.com/huggingface/p/18816815', title: '让 LLM 来评判 | 技巧与提示' })">举报</a>
</div>
        