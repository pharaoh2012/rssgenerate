
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/KubeExplorer/p/19002609" title="发布于 2025-07-24 13:34">
    <span role="heading" aria-level="2">HAMi vGPU 原理分析 Part2：hami-webhook 原理分析</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><img alt="hami-analyze-2-hami-webhook.png" loading="lazy" data-src="https://img.lixueduan.com/kubernetes/cover/hami-analyze-2-hami-webhook.png" class="lazyload"></p>
<p>上篇我们分析了 hami-device-plugin-nvidia，知道了 HAMi 的 NVIDIA device plugin 工作原理。</p>
<p>本文为 HAMi 原理分析的第二篇，分析 hami-scheduler 实现原理。</p>

<p>为了实现基于 vGPU 的调度，HAMi 实现了自己的 Scheduler：hami-scheduler，除了基础调度逻辑之外，还有 spread &amp; binpark 等 高级调度策略。</p>
<p>主要包括以下几个问题：</p>
<ul>
<li>
<p>1）Pod 是如何使用到 hami-scheduler，创建 Pod 时我们未指定 SchedulerName 默认会使用 default-scheduler 进行调度才对</p>
</li>
<li>
<p>2）hami-scheduler 逻辑，spread &amp; binpark 等 高级调度策略是如何实现的</p>
</li>
</ul>
<p>由于内容比较多，拆分为了 hami-webhook、 hami-scheduler 以及 Spread&amp;Binpack 调度策略三篇文章，本篇我们主要解决第一个问题。</p>
<blockquote>
<p>以下分析基于 HAMi v2.4.0</p>
</blockquote>
<h2 id="1-hami-scheduler-启动命令">1. hami-scheduler 启动命令</h2>
<p>hami-scheduler 具体包括两个组件：</p>
<ul>
<li>
<p>hami-webhook</p>
</li>
<li>
<p>hami-scheduler</p>
</li>
</ul>
<p>虽然是两个组件，实际上代码是放在一起的，<code>cmd/scheduler/main.go</code> 为启动文件：</p>
<p>这里也是用 corba 库实现的一个命令行工具。</p>
<pre><code class="language-go">var (
    sher        *scheduler.Scheduler
    tlsKeyFile  string
    tlsCertFile string
    rootCmd     = &amp;cobra.Command{
       Use:   "scheduler",
       Short: "kubernetes vgpu scheduler",
       Run: func(cmd *cobra.Command, args []string) {
          start()
       },
    }
)

func main() {
    if err := rootCmd.Execute(); err != nil {
       klog.Fatal(err)
    }
}
</code></pre>
<p>最终启动的 start 方法如下：</p>
<pre><code class="language-go">func start() {
    device.InitDevices()
    sher = scheduler.NewScheduler()
    sher.Start()
    defer sher.Stop()

    // start monitor metrics
    go sher.RegisterFromNodeAnnotations()
    go initMetrics(config.MetricsBindAddress)

    // start http server
    router := httprouter.New()
    router.POST("/filter", routes.PredicateRoute(sher))
    router.POST("/bind", routes.Bind(sher))
    router.POST("/webhook", routes.WebHookRoute())
    router.GET("/healthz", routes.HealthzRoute())
    klog.Info("listen on ", config.HTTPBind)
    if len(tlsCertFile) == 0 || len(tlsKeyFile) == 0 {
       if err := http.ListenAndServe(config.HTTPBind, router); err != nil {
          klog.Fatal("Listen and Serve error, ", err)
       }
    } else {
       if err := http.ListenAndServeTLS(config.HTTPBind, tlsCertFile, tlsKeyFile, router); err != nil {
          klog.Fatal("Listen and Serve error, ", err)
       }
    }
}
</code></pre>
<p>开始初始化了一下 Device</p>
<blockquote>
<p>这个后续 Webhook 会用到，等会再看</p>
</blockquote>
<pre><code class="language-go">device.InitDevices()
</code></pre>
<p>然后启动了 Scheduler</p>
<pre><code class="language-go">sher = scheduler.NewScheduler()
sher.Start()
defer sher.Stop()
</code></pre>
<p> 接着启动了一个 Goroutine 来从之前 device plugin 添加到 Node 对象上的 Annotations 中不断解析拿到具体的 GPU 信息</p>
<pre><code class="language-go">go sher.RegisterFromNodeAnnotations()
</code></pre>
<p>最后则是启动了一个 HTTP 服务</p>
<pre><code class="language-go">router := httprouter.New()
router.POST("/filter", routes.PredicateRoute(sher))
router.POST("/bind", routes.Bind(sher))
router.POST("/webhook", routes.WebHookRoute())
router.GET("/healthz", routes.HealthzRoute())
</code></pre>
<p>其中</p>
<ul>
<li><code>/webhook</code> 就是 Webhook 组件</li>
<li><code>/filter</code> 和 <code>/bind</code> 则是 Scheduler 组件</li>
<li><code>/healthz</code> 则用作健康检查。</li>
</ul>
<p>接下来在通过源码分析 Webhook 以及 Scheduler 各自的实现。</p>
<h2 id="2-hami-webhook">2. hami-webhook</h2>
<p>这里的 Webhook 是一个 Mutating Webhook，主要是为 Scheduler 服务的。</p>
<p>核心功能是：<strong>根据 Pod Resource 字段中的 ResourceName 判断该 Pod 是否使用了 HAMi vGPU，如果是则修改 Pod 的 SchedulerName 为 hami-scheduler，让 hami-scheduler 进行调度，否则不做处理。</strong></p>
<h3 id="mutatingwebhookconfiguration-配置">MutatingWebhookConfiguration 配置</h3>
<p>为了让 Webhook 生效，HAMi 部署时会创建<code>MutatingWebhookConfiguration</code> 对象，具体内容如下：</p>
<pre><code class="language-bash">root@test:~# kubectl -n kube-system get MutatingWebhookConfiguration vgpu-hami-webhook -oyaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  annotations:
    meta.helm.sh/release-name: vgpu
    meta.helm.sh/release-namespace: kube-system
  labels:
    app.kubernetes.io/managed-by: Helm
  name: vgpu-hami-webhook
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    caBundle: xxx
    service:
      name: vgpu-hami-scheduler
      namespace: kube-system
      path: /webhook
      port: 443
  failurePolicy: Ignore
  matchPolicy: Equivalent
  name: vgpu.hami.io
  namespaceSelector:
    matchExpressions:
    - key: hami.io/webhook
      operator: NotIn
      values:
      - ignore
  objectSelector:
    matchExpressions:
    - key: hami.io/webhook
      operator: NotIn
      values:
      - ignore
  reinvocationPolicy: Never
  rules:
  - apiGroups:
    - ""
    apiVersions:
    - v1
    operations:
    - CREATE
    resources:
    - pods
    scope: '*'
  sideEffects: None
  timeoutSeconds: 10
</code></pre>
<p>具体效果是在创建 Pod 时，kube-apiserver 会调用该 service 对应的 webhook，这样就注入了我们的自定义逻辑。</p>
<p>关注的对象为 Pod 的 CREATE 事件：</p>
<pre><code class="language-yaml">  rules:
  - apiGroups:
    - ""
    apiVersions:
    - v1
    operations:
    - CREATE
    resources:
    - pods
    scope: '*'
</code></pre>
<p>但是不包括以下对象</p>
<pre><code class="language-yaml">  namespaceSelector:
    matchExpressions:
    - key: hami.io/webhook
      operator: NotIn
      values:
      - ignore
  objectSelector:
    matchExpressions:
    - key: hami.io/webhook
      operator: NotIn
      values:
      - ignore
</code></pre>
<p>即：namespace 或者 资源对象上带 <code>hami.io/webhook=ignore</code> label 的都不走该 Webhook 逻辑。</p>
<p>请求的 Webhook 为</p>
<pre><code class="language-yaml">    service:
      name: vgpu-hami-scheduler
      namespace: kube-system
      path: /webhook
      port: 443
</code></pre>
<p>即：对于满足条件的 Pod 的 CREATE 时，kube-apiserver 会调用该 service 指定的服务，也就是我们的 hami-webhook。</p>
<p>接下来就开始分析 hami-webhook 具体做了什么。</p>
<h3 id="源码分析">源码分析</h3>
<p>这个 Webhook 的具体实现如下：</p>
<pre><code class="language-go">// pkg/scheduler/webhook.go#L52
func (h *webhook) Handle(_ context.Context, req admission.Request) admission.Response {
    pod := &amp;corev1.Pod{}
    err := h.decoder.Decode(req, pod)
    if err != nil {
       klog.Errorf("Failed to decode request: %v", err)
       return admission.Errored(http.StatusBadRequest, err)
    }
    if len(pod.Spec.Containers) == 0 {
       klog.Warningf(template+" - Denying admission as pod has no containers", req.Namespace, req.Name, req.UID)
       return admission.Denied("pod has no containers")
    }
    klog.Infof(template, req.Namespace, req.Name, req.UID)
    hasResource := false
    for idx, ctr := range pod.Spec.Containers {
       c := &amp;pod.Spec.Containers[idx]
       if ctr.SecurityContext != nil {
          if ctr.SecurityContext.Privileged != nil &amp;&amp; *ctr.SecurityContext.Privileged {
             klog.Warningf(template+" - Denying admission as container %s is privileged", req.Namespace, req.Name, req.UID, c.Name)
             continue
          }
       }
       for _, val := range device.GetDevices() {
          found, err := val.MutateAdmission(c)
          if err != nil {
             klog.Errorf("validating pod failed:%s", err.Error())
             return admission.Errored(http.StatusInternalServerError, err)
          }
          hasResource = hasResource || found
       }
    }

    if !hasResource {
       klog.Infof(template+" - Allowing admission for pod: no resource found", req.Namespace, req.Name, req.UID)
       //return admission.Allowed("no resource found")
    } else if len(config.SchedulerName) &gt; 0 {
       pod.Spec.SchedulerName = config.SchedulerName
    }
    marshaledPod, err := json.Marshal(pod)
    if err != nil {
       klog.Errorf(template+" - Failed to marshal pod, error: %v", req.Namespace, req.Name, req.UID, err)
       return admission.Errored(http.StatusInternalServerError, err)
    }
    return admission.PatchResponseFromRaw(req.Object.Raw, marshaledPod)
}
</code></pre>
<p>逻辑比较简单：</p>
<ul>
<li>
<p>1）判断 Pod 是否需要使用 HAMi-Scheduler 进行调度</p>
</li>
<li>
<p>2）需要的话就修改 Pod 的 SchedulerName 字段为 hami-scheduler(名字可配置)</p>
</li>
</ul>
<p><em>至此，核心部分就是如何判断该 Pod 是否需要使用 hami-scheduler 进行调度呢？</em></p>
<h3 id="如何判断是否使用-hami-scheduler">如何判断是否使用 hami-scheduler</h3>
<p>Webhook 中主要根据 Pod 是否申请 vGPU 资源来确定，不过也有一些特殊逻辑。</p>
<h4 id="特权模式-pod">特权模式 Pod</h4>
<p>首先对于特权模式的 Pod，HAMi 是直接忽略的</p>
<pre><code class="language-go">if ctr.SecurityContext != nil {
  if ctr.SecurityContext.Privileged != nil &amp;&amp; *ctr.SecurityContext.Privileged {
     klog.Warningf(template+" - Denying admission as container %s is privileged", req.Namespace, req.Name, req.UID, c.Name)
     continue
  }
}
</code></pre>
<p>因为开启特权模式之后，Pod 可以访问宿主机上的所有设备，再做限制也没意义了，因此这里直接忽略。</p>
<h4 id="具体判断逻辑">具体判断逻辑</h4>
<p>然后根据 Pod 中的 Resource 来判断是否需要使用 hami-scheduler 进行调度：</p>
<pre><code class="language-go">for _, val := range device.GetDevices() {
    found, err := val.MutateAdmission(c)
    if err != nil {
       klog.Errorf("validating pod failed:%s", err.Error())
       return admission.Errored(http.StatusInternalServerError, err)
    }
    hasResource = hasResource || found
}
</code></pre>
<p>如果 Pod Resource 中有申请 HAMi 这边支持的 vGPU 资源则，那么就需要使用 HAMi-Scheduler 进行调度。</p>
<p>而那些 Device 是 HAMi 支持的呢，就是之前 start 中初始化的：</p>
<pre><code class="language-go">var devices map[string]Devices

func GetDevices() map[string]Devices {
    return devices
}

func InitDevices() {
    devices = make(map[string]Devices)
    DevicesToHandle = []string{}
    devices[cambricon.CambriconMLUDevice] = cambricon.InitMLUDevice()
    devices[nvidia.NvidiaGPUDevice] = nvidia.InitNvidiaDevice()
    devices[hygon.HygonDCUDevice] = hygon.InitDCUDevice()
    devices[iluvatar.IluvatarGPUDevice] = iluvatar.InitIluvatarDevice()
    //devices[d.AscendDevice] = d.InitDevice()
    //devices[ascend.Ascend310PName] = ascend.InitAscend310P()
    DevicesToHandle = append(DevicesToHandle, nvidia.NvidiaGPUCommonWord)
    DevicesToHandle = append(DevicesToHandle, cambricon.CambriconMLUCommonWord)
    DevicesToHandle = append(DevicesToHandle, hygon.HygonDCUCommonWord)
    DevicesToHandle = append(DevicesToHandle, iluvatar.IluvatarGPUCommonWord)
    //DevicesToHandle = append(DevicesToHandle, d.AscendDevice)
    //DevicesToHandle = append(DevicesToHandle, ascend.Ascend310PName)
    for _, dev := range ascend.InitDevices() {
       devices[dev.CommonWord()] = dev
       DevicesToHandle = append(DevicesToHandle, dev.CommonWord())
    }
}
</code></pre>
<p>devices 是一个全局变量， InitDevices 则是在初始化该变量，供 Webhook 中使用，包括 NVIDIA、海光、天数、昇腾等等。</p>
<p>这里以 NVIDIA 为例说明 HAMi 是如何判断一个 Pod 是否需要自己来调度的，MutateAdmission 具体实现如下：</p>
<pre><code class="language-go">func (dev *NvidiaGPUDevices) MutateAdmission(ctr *corev1.Container) (bool, error) {
    /*gpu related */
    priority, ok := ctr.Resources.Limits[corev1.ResourceName(ResourcePriority)]
    if ok {
       ctr.Env = append(ctr.Env, corev1.EnvVar{
          Name:  api.TaskPriority,
          Value: fmt.Sprint(priority.Value()),
       })
    }

    _, resourceNameOK := ctr.Resources.Limits[corev1.ResourceName(ResourceName)]
    if resourceNameOK {
       return resourceNameOK, nil
    }

    _, resourceCoresOK := ctr.Resources.Limits[corev1.ResourceName(ResourceCores)]
    _, resourceMemOK := ctr.Resources.Limits[corev1.ResourceName(ResourceMem)]
    _, resourceMemPercentageOK := ctr.Resources.Limits[corev1.ResourceName(ResourceMemPercentage)]

    if resourceCoresOK || resourceMemOK || resourceMemPercentageOK {
       if config.DefaultResourceNum &gt; 0 {
          ctr.Resources.Limits[corev1.ResourceName(ResourceName)] = *resource.NewQuantity(int64(config.DefaultResourceNum), resource.BinarySI)
          resourceNameOK = true
       }
    }

    if !resourceNameOK &amp;&amp; OverwriteEnv {
       ctr.Env = append(ctr.Env, corev1.EnvVar{
          Name:  "NVIDIA_VISIBLE_DEVICES",
          Value: "none",
       })
    }
    return resourceNameOK, nil
}
</code></pre>
<p>首先判断如果 Pod 申请的 Resource 中有对应的 ResourceName 就直接返回 true</p>
<pre><code class="language-go">_, resourceNameOK := ctr.Resources.Limits[corev1.ResourceName(ResourceName)]
if resourceNameOK {
   return resourceNameOK, nil
}
</code></pre>
<p>NVIDIA GPU 对应的 ResourceName 为：</p>
<pre><code class="language-go">fs.StringVar(&amp;ResourceName, "resource-name", "nvidia.com/gpu", "resource name")
</code></pre>
<p>如果 Pod Resource 中申请了这个资源，就需要由 HAMi 进行调度，其他几个 Resource 也是一样的就不细看了。</p>
<blockquote>
<p>HAMi 会支持 NVIDIA、天数、华为、寒武纪、海光等厂家的 GPU，默认 ResourceName 为：nvidia.com/gpu、iluvatar.ai/vgpu、hygon.com/dcunum、cambricon.com/mlu、huawei.com/Ascend310 等等</p>
<p>使用这些 ResourceName 时都会有 HAMi-Scheduler 进行调度。</p>
<p>ps：这些 ResourceName 都是可以在对应 device plugin 中进行配置的。</p>
</blockquote>
<p>如果没有直接申请<code>nvidia.com/gpu</code> ，但是申请了 gpucore、gpumem 等资源，同时 Webhook 配置的 DefaultResourceNum 大于 0 也会返回 true，并自动添加上 <code>nvidia.com/gpu</code> 资源的申请。</p>
<pre><code class="language-go">_, resourceCoresOK := ctr.Resources.Limits[corev1.ResourceName(ResourceCores)]
_, resourceMemOK := ctr.Resources.Limits[corev1.ResourceName(ResourceMem)]
_, resourceMemPercentageOK := ctr.Resources.Limits[corev1.ResourceName(ResourceMemPercentage)]

if resourceCoresOK || resourceMemOK || resourceMemPercentageOK {
    if config.DefaultResourceNum &gt; 0 {
       ctr.Resources.Limits[corev1.ResourceName(ResourceName)] = *resource.NewQuantity(int64(config.DefaultResourceNum), resource.BinarySI)
       resourceNameOK = true
    }
}
</code></pre>
<h3 id="修改-schedulername">修改 SchedulerName</h3>
<p>对于上述满足条件的 Pod，需要由 HAMi-Scheduler 进行调度，Webhook 中会将 Pod 的 spec.schedulerName 改成 hami-scheduler。</p>
<p>具体如下：</p>
<pre><code class="language-go">if !hasResource {
    klog.Infof(template+" - Allowing admission for pod: no resource found", req.Namespace, req.Name, req.UID)
    //return admission.Allowed("no resource found")
} else if len(config.SchedulerName) &gt; 0 {
    pod.Spec.SchedulerName = config.SchedulerName
}
</code></pre>
<p>这样该 Pod 就会由 HAMi-Scheduler 进行调度了，接下来就是 HAMi-Scheduler 开始工作了。</p>
<p>这里也有一个特殊逻辑：如果创建时直接指定了 nodeName，那 Webhook 就会直接拒绝，因为指定 nodeName 说明 Pod 都不需要调度了，会直接到指定节点启动，但是没经过调度，可能该节点并没有足够的资源。</p>
<pre><code class="language-go">if pod.Spec.NodeName != "" {
        klog.Infof(template+" - Pod already has node assigned", req.Namespace, req.Name, req.UID)
        return admission.Denied("pod has node assigned")
}
</code></pre>
<hr>
<p><strong>【Kubernetes 系列】</strong>持续更新中，搜索公众号【<strong>探索云原生</strong>】订阅，阅读更多文章。</p>
<p><img alt="" loading="lazy" data-src="https://img.lixueduan.com/about/wechat/search.png" class="lazyload"></p>
<hr>
<h2 id="3-小结">3. 小结</h2>
<p>该 Webhook 的作用为：将申请了 vGPU 资源的 Pod 的调度器修改为 hami-scheduler，后续使用 hami-scheduler 进行调度。</p>
<p>也存在一些特殊情况：</p>
<ul>
<li>
<p>对于开启特权模式的 Pod Webhook 会忽略，不会将其切换到 hami-scheduler 进行调度，而是依旧使用 default-scheduler。</p>
</li>
<li>
<p>对于直接指定了 nodeName 的 Pod, Webhook 会直接拒绝，拦截掉 Pod 的创建。</p>
</li>
</ul>
<p>基于以上特殊情况，可能会出现以下问题，也是社区中多次有同学反馈的：</p>
<p><strong><em>特权模式 Pod 申请了 gpucore、gpumem 等资源，创建后一直处于 Pending 状态， 无法调度，提示节点上没有 gpucore、gpumem 等资源。</em></strong></p>
<p>因为 Webhook 直接跳过了特权模式的 Pod，所以该 Pod 会使用 default-scheduler 进行调度，然后 default-scheduler 根据 Pod 中的 ResourceName 查看时发现没有任何 Node 有 gpucore、gpumem 等资源，因此无法调度，Pod 处理 Pending 状态。</p>
<blockquote>
<p>ps：gpucore、gpumem 都是虚拟资源，并不会展示在 Node 上，只有 hami-scheduler 能够处理。</p>
</blockquote>
<p><strong>HAMi Webhook 工作流程如下：</strong></p>
<ul>
<li>
<p>1）用户创建 Pod 并在 Pod 中申请了 vGPU 资源</p>
</li>
<li>
<p>2）kube-apiserver 根据 MutatingWebhookConfiguration 配置请求 HAMi-Webhook</p>
</li>
<li>
<p>3）HAMi-Webhook 检测 Pod 中的 Resource，发现是申请的由 HAMi 管理的 vGPU 资源，因此把 Pod 中的 SchedulerName 改成了 hami-scheduler，这样这个 Pod 就会由 hami-scheduler 进行调度了。</p>
<ul>
<li>
<p>对于特权模式的 Pod，Webhook 会直接跳过不处理</p>
</li>
<li>
<p>对于使用 vGPU 资源但指定了 nodeName 的 Pod，Webhook 会直接拒绝</p>
</li>
</ul>
</li>
<li>
<p>4）接下来则进入 hami-scheduler 调度逻辑，下篇分析~</p>
</li>
</ul>
<p>至此，我们就搞清楚了，<strong>为什么 Pod 会使用上 hami-scheduler 以及哪些 Pod 会使用 hami-scheduler 进行调度</strong>。 同时也说明了为什么特权模式 Pod 会无法调度的问题。</p>
<p>接下来就开始分析 hami-scheduler 实现了。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-07-24 13:34">2025-07-24 13:34</span>&nbsp;
<a href="https://www.cnblogs.com/KubeExplorer">探索云原生</a>&nbsp;
阅读(<span id="post_view_count">10</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19002609);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19002609', targetLink: 'https://www.cnblogs.com/KubeExplorer/p/19002609', title: 'HAMi vGPU 原理分析 Part2：hami-webhook 原理分析' })">举报</a>
</div>
        