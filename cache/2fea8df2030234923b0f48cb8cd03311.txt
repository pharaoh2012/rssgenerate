
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/12lisu/p/19008591" title="发布于 2025-07-28 11:16">
    <span role="heading" aria-level="2">千万级的大表如何新增字段？</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="前言">前言</h2>
<p>线上千万级的大表在新增字段的时候，一定要小心，我见过太多团队在千万级大表上执行DDL时翻车的案例。</p>
<p>很容易影响到正常用户的使用。</p>
<p>本文将深入剖析大表加字段的核心难点，并给出可落地的解决方案。</p>
<p>希望对你会有所帮助。</p>
<h2 id="1为什么大表加字段如此危险">1.为什么大表加字段如此危险？</h2>
<p><strong>核心问题：MySQL的DDL操作会锁表</strong>。</p>
<p>当执行<code>ALTER TABLE ADD COLUMN</code>时：</p>
<ol>
<li>MySQL 5.6之前：全程锁表（阻塞所有读写）</li>
<li>MySQL 5.6+：仅支持部分操作的Online DDL</li>
</ol>
<p>通过实验验证锁表现象：</p>
<pre><code class="language-sql">-- 会话1：执行DDL操作
ALTER TABLE user ADD COLUMN age INT;

-- 会话2：尝试查询（被阻塞）
SELECT * FROM user WHERE id=1; -- 等待DDL完成
</code></pre>
<p>锁表时间计算公式：</p>
<pre><code>锁表时间 ≈ 表数据量 / 磁盘IO速度
</code></pre>
<p>对于1000万行、单行1KB的表，机械磁盘（100MB/s）需要<strong>100秒</strong>的不可用时间！</p>
<p>如果在一个高并发的系统中，这个问题简直无法忍受。</p>
<p>那么，我们要如何解决问题呢？</p>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2238006/202507/2238006-20250728111326882-1871764306.png" class="lazyload"></p>
<h2 id="2原生online-ddl方案">2.原生Online DDL方案</h2>
<p>在MySQL 5.6+版本中可以使用原生Online DDL的语法。</p>
<p>例如：</p>
<pre><code class="language-sql">ALTER TABLE user 
ADD COLUMN age INT,
ALGORITHM=INPLACE, 
LOCK=NONE;
</code></pre>
<p><strong>实现原理</strong>：</p>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2238006/202507/2238006-20250728111416010-337536939.png" class="lazyload"></p>
<p><strong>致命缺陷</strong>：</p>
<ol>
<li>仍可能触发表锁（如添加全文索引）</li>
<li>磁盘空间需双倍（实测500GB表需要1TB空闲空间）</li>
<li>主从延迟风险（从库单线程回放）</li>
</ol>
<h2 id="3停机维护方案">3.停机维护方案</h2>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2238006/202507/2238006-20250728111446557-1874708623.png" class="lazyload"></p>
<p><strong>适用场景</strong>：</p>
<ul>
<li>允许停服时间（如凌晨3点）</li>
<li>数据量小于100GB（减少导入时间）</li>
<li>有完整回滚预案</li>
</ul>
<h2 id="4使用pt-osc工具方案">4.使用PT-OSC工具方案</h2>
<p>Percona Toolkit的<strong>pt-online-schema-change</strong>这个是我比较推荐的工具。</p>
<p>工作原理：</p>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2238006/202507/2238006-20250728111457828-1868669927.png" class="lazyload"></p>
<p>操作步骤：</p>
<pre><code class="language-bash"># 安装工具
sudo yum install percona-toolkit

# 执行迁移（添加age字段）
pt-online-schema-change \
--alter "ADD COLUMN age INT" \
D=test,t=user \
--execute
</code></pre>
<h2 id="5逻辑迁移--双写方案">5.逻辑迁移 + 双写方案</h2>
<p>还有一个金融级安全的方案是：逻辑迁移 + 双写方案。</p>
<p><strong>适用场景</strong>：</p>
<ul>
<li>字段变更伴随业务逻辑修改（如字段类型变更）</li>
<li>要求零数据丢失的金融场景</li>
<li>超10亿行数据的表</li>
</ul>
<p><strong>实施步骤</strong>：</p>
<h4 id="1-创建新表结构">1. 创建新表结构</h4>
<pre><code class="language-sql">-- 创建包含新字段的副本表
CREATE TABLE user_new (
    id BIGINT PRIMARY KEY,
    name VARCHAR(50),
    -- 新增字段
    age INT DEFAULT 0,
    -- 增加原表索引
    KEY idx_name(name)
) ENGINE=InnoDB;
</code></pre>
<h4 id="2-双写逻辑实现java示例">2. 双写逻辑实现（Java示例）</h4>
<pre><code class="language-java">// 数据写入服务
public class UserService {
    @Transactional
    public void addUser(User user) {
        // 写入原表
        userOldDAO.insert(user);
        // 写入新表（包含age字段）
        userNewDAO.insert(convertToNew(user));
    }
    
    private UserNew convertToNew(User old) {
        UserNew userNew = new UserNew();
        userNew.setId(old.getId());
        userNew.setName(old.getName());
        // 新字段处理（从其他系统获取或默认值）
        userNew.setAge(getAgeFromCache(old.getId()));
        return userNew;
    }
}
</code></pre>
<h4 id="3-数据迁移分批处理">3. 数据迁移（分批处理）</h4>
<pre><code class="language-sql">-- 分批迁移脚本
SET @start_id = 0;
WHILE EXISTS(SELECT 1 FROM user WHERE id &gt; @start_id) DO
    INSERT INTO user_new (id, name, age)
    SELECT id, name, 
        COALESCE(age_cache, 0) -- 从缓存获取默认值
    FROM user
    WHERE id &gt; @start_id
    ORDER BY id
    LIMIT 10000;
    
    SET @start_id = (SELECT MAX(id) FROM user_new);
    COMMIT;
    -- 暂停100ms避免IO过载
    SELECT SLEEP(0.1); 
END WHILE;
</code></pre>
<h4 id="4-灰度切换流程">4. 灰度切换流程</h4>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2238006/202507/2238006-20250728111521076-134974890.png" class="lazyload"></p>
<p>这套方案适合10亿上的表新增字段，不过操作起来比较麻烦，改动有点大。</p>
<h2 id="6使用gh-ost方案">6.使用gh-ost方案</h2>
<p>gh-ost（GitHub's Online Schema Transmogrifier）是GitHub开源的一种<strong>无触发器的MySQL在线表结构变更方案</strong>。</p>
<p>专为解决大表DDL（如新增字段、索引变更、表引擎转换）时锁表阻塞、主库负载高等问题而设计。</p>
<p>其核心是通过异步解析binlog，替代触发器同步增量数据，显著降低对线上业务的影响。</p>
<h4 id="与传统方案对比"><strong>与传统方案对比</strong></h4>
<ul>
<li>
<p><strong>触发器方案（如pt-osc）</strong>：<br>
在源表上创建INSERT/UPDATE/DELETE触发器，在同一事务内将变更同步到影子表。<br>
<strong>痛点</strong>：</p>
<ul>
<li>触发器加重主库CPU和锁竞争，高并发时性能下降30%以上</li>
<li>无法暂停，失败需重头开始</li>
<li>外键约束支持复杂</li>
</ul>
</li>
<li>
<p><strong>gh-ost方案</strong>：</p>
<ul>
<li><strong>伪装为从库</strong>：直连主库或从库，拉取ROW格式的binlog，解析DML事件（INSERT/UPDATE/DELETE）</li>
<li><strong>异步应用</strong>：将增量数据通过独立连接应用到影子表（如<code>REPLACE INTO</code>处理INSERT事件），与主库事务解耦</li>
<li><strong>优先级控制</strong>：binlog应用优先级 &gt; 全量数据拷贝，确保数据强一致</li>
</ul>
</li>
</ul>
<h4 id="关键流程"><strong>关键流程：</strong></h4>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2238006/202507/2238006-20250728111532976-1853437550.png" class="lazyload"></p>
<ul>
<li><strong>全量拷贝</strong>：按主键分块（<code>chunk-size</code>控制）执行<code>INSERT IGNORE INTO _table_gho SELECT ...</code>，避免重复插入</li>
<li><strong>增量同步</strong>：
<ul>
<li>INSERT → <code>REPLACE INTO</code></li>
<li>UPDATE → 全行覆盖更新</li>
<li>DELETE → <code>DELETE</code></li>
</ul>
</li>
<li><strong>原子切换（Cut-over）</strong>：
<ol>
<li>短暂锁源表（毫秒级）</li>
<li>执行原子RENAME：<code>RENAME TABLE source TO _source_del, _source_gho TO source</code></li>
<li>清理旧表（<code>_source_del</code>）</li>
</ol>
</li>
</ul>
<h4 id="典型命令示例"><strong>典型命令示例：</strong></h4>
<pre><code class="language-bash">gh-ost \
--alter="ADD COLUMN age INT NOT NULL DEFAULT 0 COMMENT '用户年龄'" \
--host=主库IP --port=3306 --user=gh_user --password=xxx \
--database=test --table=user \
--chunk-size=2000 \       # 增大批次减少事务数
--max-load=Threads_running=80 \ 
--critical-load=Threads_running=200 \
--cut-over-lock-timeout-seconds=5 \  # 超时重试
--execute \               # 实际执行
--allow-on-master         # 直连主库模式
</code></pre>
<h4 id="2-监控与优化建议">2. <strong>监控与优化建议</strong></h4>
<ul>
<li><strong>进度跟踪</strong>：</li>
</ul>
<pre><code class="language-bash">echo status | nc -U /tmp/gh-ost.sock  # 查看实时进度
</code></pre>
<ul>
<li><strong>延迟控制</strong>：
<ul>
<li>设置<code>--max-lag-millis=1500</code>，超阈值自动暂停</li>
<li>从库延迟过高时切换为<code>直连主库模式</code></li>
</ul>
</li>
<li><strong>切换安全</strong>：<br>
使用<code>--postpone-cut-over-flag-file</code>人工控制切换时机</li>
</ul>
<h2 id="7分区表滑动窗口方案">7.分区表滑动窗口方案</h2>
<p>适用场景：</p>
<ul>
<li>按时间分区的日志型大表</li>
<li>需要频繁变更结构的监控表</li>
</ul>
<p>核心原理：<br>
通过分区表特性，仅修改最新分区结构。</p>
<p><strong>操作步骤</strong>：</p>
<p>修改分区定义：</p>
<pre><code class="language-sql">-- 原分区表定义
CREATE TABLE logs (
    id BIGINT,
    log_time DATETIME,
    content TEXT
) PARTITION BY RANGE (TO_DAYS(log_time)) (
    PARTITION p202301 VALUES LESS THAN (TO_DAYS('2023-02-01')),
    PARTITION p202302 VALUES LESS THAN (TO_DAYS('2023-03-01'))
);

-- 添加新字段（仅影响新分区）
ALTER TABLE logs ADD COLUMN log_level VARCHAR(10) DEFAULT 'INFO';
</code></pre>
<p>创建新分区（自动应用新结构）：</p>
<pre><code class="language-sql">-- 创建包含新字段的分区
ALTER TABLE logs REORGANIZE PARTITION p202302 INTO (
    PARTITION p202302 VALUES LESS THAN (TO_DAYS('2023-03-01')),
    PARTITION p202303 VALUES LESS THAN (TO_DAYS('2023-04-01'))
);
</code></pre>
<p>历史数据处理：</p>
<pre><code class="language-sql">-- 仅对最近分区做数据初始化
UPDATE logs PARTITION (p202302) 
SET log_level = parse_log_level(content);
</code></pre>
<h2 id="8千万级表操作注意事项">8.千万级表操作注意事项</h2>
<ol>
<li><strong>主键必须存在</strong>（无主键将全表扫描）</li>
<li><strong>磁盘空间监控</strong>（至少预留1.5倍表空间）</li>
<li><strong>复制延迟控制</strong></li>
</ol>
<pre><code class="language-sql">SHOW SLAVE STATUS; 
-- 确保Seconds_Behind_Master &lt; 10
</code></pre>
<ol start="4">
<li>
<p><strong>灰度验证步骤</strong>：</p>
<ul>
<li>先在从库执行</li>
<li>检查数据一致性</li>
<li>低峰期切主库</li>
</ul>
</li>
<li>
<p><strong>字段属性选择</strong>：</p>
<ul>
<li>避免NOT NULL（导致全表更新）</li>
<li>优先使用ENUM代替VARCHAR</li>
<li>默认值用NULL而非空字符串</li>
</ul>
</li>
</ol>
<h2 id="9各方案对比">9.各方案对比</h2>
<p>以下是针对千万级MySQL表新增字段的6种方案的对比。</p>
<table>
<thead>
<tr>
<th><strong>方案</strong></th>
<th><strong>锁表时间</strong></th>
<th><strong>业务影响</strong></th>
<th><strong>数据一致性</strong></th>
<th><strong>适用场景</strong></th>
<th><strong>复杂度</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>原生Online DDL</strong></td>
<td>秒级~分钟级</td>
<td>中（并发DML受限）</td>
<td>强一致</td>
<td>&lt;1亿的小表变更</td>
<td>低</td>
</tr>
<tr>
<td><strong>停机维护</strong></td>
<td>小时级</td>
<td>高（服务中断）</td>
<td>强一致</td>
<td>允许停服+数据量&lt;100GB</td>
<td>中</td>
</tr>
<tr>
<td><strong>PT-OSC</strong></td>
<td>毫秒级（仅cut-over）</td>
<td>中（触发器开销）</td>
<td>最终一致</td>
<td>无外键/触发器的常规表</td>
<td>中</td>
</tr>
<tr>
<td><strong>逻辑迁移+双写</strong></td>
<td>0</td>
<td>低（需改代码）</td>
<td>强一致</td>
<td>金融级核心表（10亿+）</td>
<td>高</td>
</tr>
<tr>
<td><strong>gh-ost</strong></td>
<td>毫秒级（仅cut-over）</td>
<td>低（无触发器）</td>
<td>最终一致</td>
<td>高并发大表（TB级）</td>
<td>中高</td>
</tr>
<tr>
<td>分区滑动窗口</td>
<td>仅影响新分区</td>
<td>低</td>
<td>分区级一致</td>
<td>按时间分区的日志表</td>
<td>中</td>
</tr>
</tbody>
</table>
<h2 id="总结">总结</h2>
<ol>
<li>
<p><strong>常规场景（&lt;1亿行）</strong>：</p>
<ul>
<li>首选 <strong>Online DDL</strong>（<code>ALGORITHM=INSTANT</code>，MySQL 8.0秒级加字段）</li>
<li>备选 <strong>PT-OSC</strong>（兼容低版本MySQL）</li>
</ul>
</li>
<li>
<p><strong>高并发大表（&gt;1亿行）</strong>：</p>
<ul>
<li>必选 <strong>gh-ost</strong>（无触发器设计，对写入影响&lt;5%）</li>
</ul>
</li>
<li>
<p><strong>金融核心表</strong>：</p>
<ul>
<li><strong>双写方案</strong> 是唯一选择（需2-4周开发周期）</li>
</ul>
</li>
<li>
<p><strong>日志型表</strong>：</p>
<ul>
<li><strong>分区滑动窗口</strong> 最优（仅影响新分区）</li>
</ul>
</li>
<li>
<p><strong>紧急故障处理</strong>：</p>
<ul>
<li>超百亿级表异常时，考虑 <strong>停机维护</strong> + 回滚预案</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>给大家一些建议</strong>：</p>
<ul>
<li>加字段前优先使用 <strong>JSON字段预扩展</strong>（<code>ALTER TABLE user ADD COLUMN metadata JSON</code>）</li>
<li>万亿级表建议 <strong>分库分表</strong> 而非直接DDL</li>
<li>所有方案执行前必须 <strong>全量备份</strong>（<code>mysqldump + binlog</code>）</li>
<li>流量监测（Prometheus+Granfa实时监控QPS）</li>
</ul>
</blockquote>
<p>在千万级系统的战场上，一次草率的ALTER操作可能就是压垮骆驼的最后一根稻草。</p>
<h2 id="最后说一句求关注别白嫖我">最后说一句(求关注，别白嫖我)</h2>
<p>如果这篇文章对您有所帮助，或者有所启发的话，帮忙关注一下我的同名公众号：苏三说技术，您的支持是我坚持写作最大的动力。</p>
<p>求一键三连：点赞、转发、在看。</p>
<p>关注公众号：【苏三说技术】，在公众号中回复：进大厂，可以免费获取我最近整理的10万字的面试宝典，好多小伙伴靠这个宝典拿到了多家大厂的offer。</p>
<p>本文收录于我的技术网站：<a href="http://www.susan.net.cn" target="_blank" rel="noopener nofollow">http://www.susan.net.cn</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-07-28 11:16">2025-07-28 11:16</span>&nbsp;
<a href="https://www.cnblogs.com/12lisu">苏三说技术</a>&nbsp;
阅读(<span id="post_view_count">84</span>)&nbsp;
评论(<span id="post_comment_count">1</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19008591);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19008591', targetLink: 'https://www.cnblogs.com/12lisu/p/19008591', title: '千万级的大表如何新增字段？' })">举报</a>
</div>
        