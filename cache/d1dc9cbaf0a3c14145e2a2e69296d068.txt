
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/leason001/p/18662426" title="发布于 2025-01-09 16:36">
    <span role="heading" aria-level="2">Kubernetes GPU 虚拟化方案</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h3 id="主流架构">主流架构</h3>
<p>Device Plugin：K8s制定设备插件接口规范，定义异构资源的上报和分配，设备厂商只需要实现相应的API接口，无需修改kubelet源码即可实现对其他硬件设备的支持。<br>
Extended Resource：Scheduler可以根据Pod的创建删除计算资源可用量，而不再局限于CPU和内存的资源统计，进而将有特殊资源需求的Pod调度到相应的节点上。</p>
<p>通过Device Plugin 异构资源调度流程如下：</p>
<ol>
<li>Device plugin 向kubelet上报当前节点资源情况</li>
<li>用户通过yaml文件创建负载，定义Resource Request</li>
<li>kube-scheduler根据从kubelet同步到的资源信息和Pod的资源请求，为Pod绑定合适的节点</li>
<li>kubelet监听到绑定到当前节点的Pod，调用Device plugin的allocate接口为Pod分配设备</li>
<li>kubelet启动Pod内的容器，将设备映射给容器</li>
</ol>
<p><img src="https://img2024.cnblogs.com/other/3300446/202501/3300446-20250109163658999-929180138.png" alt="file" loading="lazy"></p>
<p>GPU虚拟化方案大致分为用户态隔离和内核态隔离：</p>
<ol>
<li>用户态主要是通过vcuda的方式，劫持cuda调用，比如下面介绍的两种开源</li>
<li>内核态主要是用过虚拟gpu驱动的方式，比如腾讯云的qgpu和阿里云的cgpu，不过这两个都是闭源的</li>
</ol>
<h3 id="nvidia-gpu">Nvidia-GPU</h3>
<p>NVIDIA 提供的 Time-Slicing GPUs in Kubernetes 是一种通过 oversubscription(超额订阅) 来实现 GPU 共享的策略，有两种策略，单卡调度模式和超卖模式。<br>
单卡的意思就是一个Pod调度一张GPU，当这个GPU有Pod使用了，就不可被其他Pod使用。</p>
<p>超卖模式这种策略能让多个任务在同一个 GPU 上进行，而不是每个任务都独占一个 GPU。Time Slicing(时间片)指的是 GPU 本身的时间片调度。<br>
也就是说假如有两个进程同时使用同一个GPU，两个进程同时把 CUDA 任务发射到 GPU 上去，GPU 并不会同时执行，而是采用时间片轮转调度的方式。<br>
进程和进程间的显存和算力没有任何限制，谁抢到就是谁的。</p>
<h3 id="腾讯gpu-manager">腾讯GPU-manager</h3>
<p>基于Nvidia的k8s Device Plugin 实现<br>
<a href="https://github.com/tkestack/gpu-manager" target="_blank" rel="noopener nofollow">GPUManager</a>是腾讯自研的容器层GPU虚拟化方案，除兼容Nvidia 官方插件的GPU资源管理功能外，还增加碎片资源调度、GPU调度拓扑优化、GPU资源Quota等功能，在容器层面实现了GPU资源的化整为零，而在原理上仅使用了wrap library和linux动态库链接技术，就实现了GPU 算力和显存的上限隔离。</p>
<p>在工程设计上，GPUManager方案包括三个部分，cuda封装库vcuda、k8s device plugin 插件gpu-manager-daemonset和k8s调度插件gpu-quota-admission。</p>
<p>vcuda库是一个对nvidia-ml和libcuda库的封装库，通过劫持容器内用户程序的cuda调用限制当前容器内进程对GPU和显存的使用。</p>
<p>gpu-manager-daemonset是标准的k8s device plugin，实现了GPU拓扑感知、设备和驱动映射等功能。GPUManager支持共享和独占两种模式，当负载里tencent.com/vcuda-core request 值在0-100情况下，采用共享模式调度，优先将碎片资源集中到一张卡上，当负载里的tencent.com/vcuda-core request为100的倍数时，采用独占模式调度，需要注意的是GPUManager仅支持0~100和100的整数倍的GPU需求调度，无法支持150，220类的非100整数倍的GPU需求调度。</p>
<p>gpu-quota-admission是一个k8s Scheduler extender，实现了Scheduler的predicates接口，kube-scheduler在调度tencent.com/vcuda-core资源请求的Pod时，predicates阶段会调用gpu-quota-admission的predicates接口对节点进行过滤和绑定，同时gpu-quota-admission提供了GPU资源池调度功能，解决不同类型的GPU在namespace下的配额问题。<br>
<img src="https://img2024.cnblogs.com/other/3300446/202501/3300446-20250109163659250-985337140.png" alt="file" loading="lazy"></p>
<p>方案优点：</p>
<ol>
<li>同时支持碎片和整卡调度，提高GPU资源利用率</li>
<li>支持同一张卡上容器间GPU和显存的使用隔离</li>
<li>基于拓扑感知，提供最优的调度策略</li>
<li>对用户程序无侵入，用户无感</li>
</ol>
<p>方案缺点：</p>
<ol>
<li>驱动和加速库的兼容性依赖于厂商</li>
<li>存在约5%的性能损耗</li>
</ol>
<p><strong>此项目腾讯云官方已不再支持，社区也处在无人维护状态，亲测cuda12有问题，调用报错</strong></p>
<h3 id="hami">HAMi</h3>
<p><a href="https://github.com/Project-HAMi/HAMi/tree/master" target="_blank" rel="noopener nofollow">HAMi</a> 可为多种异构设备提供虚拟化功能，支持设备共享和资源隔离。<br>
支持的设备：<br>
<img src="https://img2024.cnblogs.com/other/3300446/202501/3300446-20250109163659475-1793151292.png" alt="file" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/other/3300446/202501/3300446-20250109163659671-22415403.png" alt="file" loading="lazy"></p>
<p>HAMi 由多个组件组成，包括统一的 mutatingwebhook、统一的调度器扩展器、不同的设备插件以及针对每种异构 AI 设备的容器内虚拟化技术。<br>
<a href="https://github.com/Project-HAMi/HAMi/tree/master" target="_blank" rel="noopener nofollow">https://github.com/Project-HAMi/HAMi/tree/master</a></p>
<p>能力：</p>
<ul>
<li>支持碎片、整卡、多卡调度隔离，支持按量或者按百分比调度隔离</li>
<li>支持指定目标卡型</li>
<li>支持指定目标卡</li>
</ul>
<p>目前该项目非常活跃，并且支持的cuda版本也比较友好，<a href="https://github.com/Project-HAMi/HAMi/issues/785" target="_blank" rel="noopener nofollow">&gt;10.1</a></p>
<p>原文地址：<a href="https://leason.top/Kubernetes-GPU-%E8%99%9A%E6%8B%9F%E5%8C%96%E6%96%B9%E6%A1%88.html#more" target="_blank" rel="noopener nofollow">https://leason.top/Kubernetes-GPU-虚拟化方案.html#more</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.4049678112685185" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-01-09 16:37">2025-01-09 16:36</span>&nbsp;
<a href="https://www.cnblogs.com/leason001">leason001</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18662426" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18662426);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18662426', targetLink: 'https://www.cnblogs.com/leason001/p/18662426', title: 'Kubernetes GPU 虚拟化方案' })">举报</a>
</div>
        