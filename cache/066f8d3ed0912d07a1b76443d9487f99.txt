
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/grey-wolf/p/18686468" title="发布于 2025-01-22 17:15">
    <span role="heading" aria-level="2">网络抓包文件太大，如何切分</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="背景">背景</h1>
<p>节前最后几天了，随便写点水文吧，今天就记录一下，当我们拿到的网络抓包文件太大，应该怎么分析。</p>
<p>一般来说，我们个人抓包的话，linux上用tcpdump比较多，抓的时候也会用捕获表达式，抓出来的包一般不大，用wireshark分析就很容易。</p>
<p>但是，前一阵的一个晚上，dba突然找我，看能不能帮忙一起分析一个网络抓包文件，连了会议后一看，大小有4g，这么大的包，wireshark打开都很是困难，分析也很卡。</p>
<p>这么大的包，怎么来的呢，原来是网络同事直接在路由器上抓的，过滤条件就是某个数据库服务器的ip:1433端口（sql server数据库）。既然过滤了，包还这么大？问了下，原来在路由器上抓了整整一个半小时，然后这个库流量又大，所以最终就有4g。</p>
<p>dba的诉求是，某个数据库客户端发了某些sql，导致把数据库服务器搞死了，现在就是要找出来是哪个客户端，哪个sql。</p>
<p>最终呢，我只是给dba同事说了下，怎么拆分包，怎么查看包里的sql；后续忙起来后，我也没问进度，估计已经解决了吧。</p>
<p>这里就简单记录下，遇到这种大的包，怎么拆分。</p>
<h1 id="editcap">editcap</h1>
<p>editcap这个命令是wireshark自带的，一般就在wireshark目录下，像我这边在：C:\Program Files\Wireshark\editcap.exe，我一般会加入到环境变量PATH。</p>
<p>介绍如下：</p>
<blockquote>
<p><strong>Editcap</strong> is a program that reads some or all of the captured packets from the <em>infile</em>, optionally converts them in various ways and writes the resulting packets to the capture <em>outfile</em> (or outfiles).</p>
</blockquote>
<p>即，可以读取pcap/pcapng类型的文件，通过各种方式进行一些处理、转换，然后将结果写入到另外的文件。</p>
<p>说明文档：</p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221617672.png" alt="image-20250122161700554" loading="lazy"></p>
<p>在我们场景中，一般使用如下几个选项就行了：</p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221623183.png" alt="image-20250122162346067" loading="lazy"></p>
<h2 id="按时间">按时间</h2>
<h3 id="按包的开始时间">按包的开始时间</h3>
<blockquote>
<p>-A <start time=""></start></p>
<p>Saves only the packets whose timestamp is on or after start time. The time is given in the following format YYYY-MM-DD HH:MM:SS[.nnnnnnnnn] (the decimal and fractional seconds are optional).</p>
</blockquote>
<p>比如，对于如下这个包：</p>
<pre><code class="language-shell">editcap  file20230325.pcap file20230325-after-pm-3.pcap -A "2023-03-25 15:00:00"
</code></pre>
<p>其中，file20230325-after-pm-3.pcap就是要保存的文件名，-A就是选择15点以后的报文。</p>
<p>可以看下图示例效果：</p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221628303.png" alt="image-20250122162808207" loading="lazy"></p>
<h3 id="获取包的时间范围">获取包的时间范围</h3>
<p>但你可能有个疑问，如果不知道包的时间范围呢？</p>
<p>可以先用如下命令获取：</p>
<pre><code class="language-shell">capinfos file20230325.pcap
</code></pre>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221630199.png" alt="image-20250122163028108" loading="lazy"></p>
<h3 id="按包的结束时间">按包的结束时间</h3>
<blockquote>
<p>-B <stop time=""></stop></p>
<p>Saves only the packets whose timestamp is before stop time. The time is given in the following format YYYY-MM-DD HH:MM:SS[.nnnnnnnnn] (the decimal and fractional seconds are optional).</p>
</blockquote>
<pre><code class="language-shell">editcap  file20230325.pcap file20230325-start3-end310.pcap -A "2023-03-25 15:00:00" -B "2023-03-25 15:10:00"
</code></pre>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221633733.png" alt="image-20250122163358633" loading="lazy"></p>
<h2 id="按包的数量">按包的数量</h2>
<pre><code class="language-shell">-c &lt;packets per file&gt;
Splits the packet output to different files based on uniform packet counts with a maximum of &lt;packets per file&gt; each. Each output file will be created with a suffix -nnnnn, starting with 00000. If the specified number of packets is written to the output file, the next output file is opened. The default is to use a single output file.
</code></pre>
<p>这个是把大文件拆分，按照包的数量，届时，每个子文件里的包的数量是一致的。</p>
<pre><code class="language-shell">editcap  file20230325.pcap -c 100000 file20230325-by-packets-number.pcap
</code></pre>
<p>效果：</p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221639921.png" alt="image-20250122163917848" loading="lazy"></p>
<p>但可以看到，每个里面都有1w个包</p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221640716.png" alt="image-20250122164009642" loading="lazy"></p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221640578.png" alt="image-20250122164036502" loading="lazy"></p>
<h2 id="按时间间隔">按时间间隔</h2>
<blockquote>
<p>-i <seconds per="" file=""></seconds></p>
<p>Splits the packet output to different files based on uniform time intervals using a maximum interval of <seconds per="" file=""> each. Floating point values (e.g. 0.5) are allowed. Each output file will be created with a suffix -nnnnn, starting with 00000. If packets for the specified time interval are written to the output file, the next output file is opened. The default is to use a single output file.</seconds></p>
</blockquote>
<p>单位是秒。</p>
<p>我们示例文件总共是1000多秒。</p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221643574.png" alt="image-20250122164317496" loading="lazy"></p>
<pre><code class="language-shell">editcap  file20230325.pcap -i 100 file20230325-by-seconds.pcap
</code></pre>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221644255.png" alt="image-20250122164429164" loading="lazy"></p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221646370.png" alt="image-20250122164648284" loading="lazy"></p>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221647354.png" alt="image-20250122164708275" loading="lazy"></p>
<h2 id="组合时间范围包的数量两个选项">组合时间范围、包的数量两个选项</h2>
<pre><code class="language-shell">editcap  file20230325.pcap file20230325-start3-end310-packets-number.pcap -A "2023-03-25 15:00:00" -B "2023-03-25 15:10:00" -c 10000
</code></pre>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221649632.png" alt="image-20250122164946525" loading="lazy"></p>
<p>这个就是，本来按照时间范围，只会生成一个包。加了-C后，就继续按包的数量拆分了。</p>
<h2 id="组合时间范围时间间隔两个选项">组合时间范围、时间间隔两个选项</h2>
<pre><code class="language-shell">editcap  file20230325.pcap file20230325-start3-end310-seconds.pcap -A "2023-03-25 15:00:00" -B "2023-03-25 15:10:00" -i 100
</code></pre>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221700158.png" alt="image-20250122170035066" loading="lazy"></p>
<h2 id="按序号">按序号</h2>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221707332.png" alt="image-20250122170742237" loading="lazy"></p>
<p>命令中可以指定序号，但是默认是删掉这些序号的包。</p>
<blockquote>
<p>-r</p>
<p>Reverse the packet selection. Causes the packets whose packet numbers are specified on the command line to be written to the output capture file, instead of discarding them.</p>
</blockquote>
<p>加了-r后，意味着反选。即保留这些序号的包。</p>
<pre><code class="language-shell">官方示例：
To limit a capture file to packets from number 200 to 750 (inclusive) use:

editcap -r capture.pcapng small.pcapng 200-750
</code></pre>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221704026.png" alt="image-20250122170404907" loading="lazy"></p>
<p>我这边也试了下：</p>
<pre><code class="language-shell">editcap  -r file20230325.pcap file20230325-frame-number.pcap 1-100
</code></pre>
<p><img src="https://dump-1252523945.cos.ap-shanghai.myqcloud.com/img/202501221706635.png" alt="image-20250122170654536" loading="lazy"></p>
<h1 id="总结">总结</h1>
<p>也没啥好总结的。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.37874504205671294" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-01-22 17:15">2025-01-22 17:15</span>&nbsp;
<a href="https://www.cnblogs.com/grey-wolf">三国梦回</a>&nbsp;
阅读(<span id="post_view_count">122</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18686468" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18686468);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18686468', targetLink: 'https://www.cnblogs.com/grey-wolf/p/18686468', title: '网络抓包文件太大，如何切分' })">举报</a>
</div>
        