
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/rainbond/p/18830786" title="发布于 2025-04-17 14:30">
    <span role="heading" aria-level="2">K8S 部署 Deepseek 要 3 天？别逗了！Ollama+GPU Operator 1 小时搞定</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>最近一年我都在依赖大模型辅助工作，比如 DeepSeek、豆包、Qwen等等。线上大模型确实方便，敲几个字就能生成文案、写代码、做表格，极大提高了效率。但对于企业来说：公司内部数据敏感、使用外部大模型会有数据泄露的风险。</p>
<p>尤其是最近给 Rainbond 开源社区的用户答疑时，发现大家对大模型私有化部署有需求，都希望把大模型部署到企业内网，既能按需定制优化，又能保障安全合规。</p>
<p>网上教程虽多，但大多零散且偏向极客操作，真正能落地到生产环境的少之又少。稍微花了点时间，终于跑通了一套全链路解决方案：</p>
<ul>
<li><strong>Ollama</strong>：让大模型从文件变成可运行的服务，专治模型跑不起来的千古难题。</li>
<li><strong>RKE2</strong>：RKE2 是 Rancher 推出的轻量化 K8s，比传统 K8s 节省 50% 资源，适合本地服务器。</li>
</ul>
<ul>
<li><strong>Rainbond</strong>：让复杂的集群管理去技术化，非运维人员也能轻松管好大模型服务。</li>
<li><strong>GPU Operator</strong>：一站式部署，显卡驱动安装零干预、容器运行时统一管理、深度集成 K8S。</li>
</ul>
<p>这套组合对开发者和企业来说，意味着效率与安全的双重升级：开发者无需处理模型环境和集群配置，Ollama+Rainbond 让部署从 “写代码” 变成 “点鼠标”，专注业务逻辑；企业则实现数据本地化，通过 RKE2 安全策略和 Rainbond 权限管理满足合规要求，搭配 GPU Operator 提升硬件利用率，让私有化部署既简单又高效。</p>
<p>接下来的教程，我会从服务器准备到环境搭建再到大模型部署，拆解每个关键步骤。无论你是想搭建企业专属大模型服务，还是探索本地化 AI 应用，跟着教程走，都能少走弯路，快速落地一个安全、高效、易管理的大模型部署方案。</p>
<h2 id="准备">准备</h2>
<p>首先需要一台<strong>干净的 GPU 服务器</strong>，推荐硬件配置如下（以 NVIDIA A100 为例）：</p>
<ul>
<li><strong>CPU</strong>：14 核及以上</li>
<li><strong>内存</strong>：56GB 及以上</li>
<li><strong>GPU</strong>：NVIDIA A100（24GB 显存，支持其他 CUDA 兼容显卡，需确认<a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/platform-support.html#supported-nvidia-data-center-gpus-and-systems" target="_blank" rel="noopener nofollow">GPU Operator 支持列表</a></li>
<li><strong>操作系统</strong>：Ubuntu 22.04（需匹配 <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/platform-support.html#supported-operating-systems-and-kubernetes-platforms" target="_blank" rel="noopener nofollow">GPU Operator 支持的系统版本</a></li>
</ul>
<h2 id="部署-rke2">部署 RKE2</h2>
<p>先以单节点集群为例快速落地演示。</p>
<h3 id="1-创建-rke2-配置">1. 创建 RKE2 配置</h3>
<p>创建私有镜像仓库配置（Rainbond 默认的私有镜像仓库）</p>
<pre><code class="language-bash">mkdir -p /etc/rancher/rke2
</code></pre>
<pre><code class="language-yaml">cat &gt; /etc/rancher/rke2/registries.yaml &lt;&lt; EOL
mirrors:
  "goodrain.me":
    endpoint:
      - "https://goodrain.me"
configs:
  "goodrain.me":
    auth:
      username: admin
      password: admin1234
    tls:
      insecure_skip_verify: true
EOL
</code></pre>
<p>创建集群基础配置</p>
<pre><code class="language-bash">cat &gt; /etc/rancher/rke2/config.yaml &lt;&lt; EOF
disable:
  - rke2-ingress-nginx #禁用默认Ingress，会与Rainbond网关冲突
system-default-registry: registry.cn-hangzhou.aliyuncs.com # 国内镜像仓库
EOF
</code></pre>
<h3 id="2-安装并启动-rke2">2. 安装并启动 RKE2</h3>
<p>通过国内镜像加速安装，提升部署速度</p>
<pre><code class="language-bash"># 一键安装RKE2（国内源）
curl -sfL https://rancher-mirror.rancher.cn/rke2/install.sh | INSTALL_RKE2_MIRROR=cn sh -  
# 启动服务
systemctl enable rke2-server.service &amp;&amp; systemctl start rke2-server.service
</code></pre>
<blockquote>
<p>提示：安装过程约 5-20 分钟（视网络情况），可通过 <code>journalctl -fu rke2-server</code> 实时查看日志。</p>
</blockquote>
<h3 id="3-验证集群状态">3. 验证集群状态</h3>
<p>安装完成后，拷贝 Kubernetes 工具及配置文件，方便后续操作：</p>
<pre><code class="language-bash">mkdir -p /root/.kube
#集群配置文件
cp /etc/rancher/rke2/rke2.yaml /root/.kube/config
#拷贝命令行工具
cp /var/lib/rancher/rke2/bin/{ctr,kubectl} /bin
</code></pre>
<p>执行以下命令，确认节点与核心组件正常运行：</p>
<pre><code class="language-bash">#查看节点状态（应显示Ready）  
kubectl get node
#查看系统Pod（所有kube-system命名空间下的Pod应为Running状态）  
kubectl get pod -n kube-system
</code></pre>
<p>至此，K8S 集群 RKE2 已部署完成，接下来将通过 GPU Operator 接入显卡资源，为大模型运行提供算力支撑。</p>
<h2 id="部署-gpu-operator">部署 GPU Operator</h2>
<h3 id="1-提前准备国内镜像解决-nfd-镜像拉取问题">1. 提前准备国内镜像（解决 NFD 镜像拉取问题）</h3>
<p>由于<code>node-feature-discovery（NFD）</code>镜像默认仓库在国外，需提前通过国内镜像站下载并打标签：</p>
<pre><code class="language-bash">export CONTAINERD_ADDRESS=/run/k3s/containerd/containerd.sock
ctr -n k8s.io images pull registry.cn-hangzhou.aliyuncs.com/smallqi/node-feature-discovery:v0.17.2
ctr -n k8s.io images tag registry.cn-hangzhou.aliyuncs.com/smallqi/node-feature-discovery:v0.17.2 registry.k8s.io/nfd/node-feature-discovery:v0.17.2
</code></pre>
<h3 id="2-安装-helm">2. 安装 Helm</h3>
<pre><code class="language-bash">curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 \
    &amp;&amp; chmod 700 get_helm.sh \
    &amp;&amp; ./get_helm.sh
</code></pre>
<h3 id="3-配置-gpu-operator-安装参数">3. 配置 GPU Operator 安装参数</h3>
<p>创建<code>gpu-values.yaml</code>，指定所有组件使用国内镜像仓库（避免拉取国外镜像失败）：</p>
<pre><code class="language-yaml">cat &gt; gpu-values.yaml &lt;&lt; EOF
toolkit:
  env:
  - name: CONTAINERD_SOCKET
    value: /run/k3s/containerd/containerd.sock
  - name: CONTAINERD_RUNTIME_CLASS
    value: nvidia
  - name: CONTAINERD_SET_AS_DEFAULT
    value: "true"
  version: v1.17.1-ubuntu20.04
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
validator:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
operator:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
  initContainer:
    repository: registry.cn-hangzhou.aliyuncs.com/smallqi
driver:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
  manager:
    repository: registry.cn-hangzhou.aliyuncs.com/smallqi
devicePlugin:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
dcgmExporter:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
gfd:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
migManager:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
vgpuDeviceManager:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
vfioManager:
  repository: registry.cn-hangzhou.aliyuncs.com/smallqi
  driverManager:
    repository: registry.cn-hangzhou.aliyuncs.com/smallqi
EOF
</code></pre>
<h3 id="4-一键安装-gpu-operator">4. 一键安装 GPU Operator</h3>
<pre><code class="language-bash"># 添加NVIDIA Helm仓库并更新
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia &amp;&amp; helm repo update
# 安装GPU Operator（指定版本和配置文件，无需修改参数）
helm install gpu-operator -n gpu-operator --create-namespace \  
  nvidia/gpu-operator --version=v25.3.0 -f gpu-values.yaml
</code></pre>
<blockquote>
<p>提示：等待约 3-5 分钟，通过 <code>kubectl get pod -n gpu-operator</code> 确认所有 Pod 状态为<code>Running</code>。</p>
</blockquote>
<h3 id="5-配置-rke2-默认容器运行时">5. 配置 RKE2 默认容器运行时</h3>
<p>配置 RKE2 默认使用 <code>nvidia</code> 作为容器运行时</p>
<pre><code class="language-bash">cat &gt; /etc/rancher/rke2/config.yaml &lt;&lt; EOF
disable:
  - rke2-ingress-nginx #禁用默认Ingress，会与Rainbond网关冲突
system-default-registry: registry.cn-hangzhou.aliyuncs.com # 国内镜像仓库
default-runtime: nvidia #指定 nvidia 为默认容器运行时
EOF

# 重启RKE2使配置生效  
$ systemctl restart rke2-server.service  
# 等待5分钟，确保所有系统Pod重新启动完成 
</code></pre>
<h3 id="6-验证-gpu-算力调度">6. 验证 GPU 算力调度</h3>
<p>创建测试 Pod，验证 GPU 是否正常被 K8s 识别和使用：</p>
<pre><code class="language-bash"># 生成测试YAML（运行CUDA示例程序）  
cat &gt; cuda-sample.yaml &lt;&lt; EOF  
apiVersion: v1  
kind: Pod  
metadata:  
  name: cuda-vectoradd  
spec:  
  restartPolicy: OnFailure  
  containers:  
  - name: cuda-vectoradd  
    image: registry.cn-hangzhou.aliyuncs.com/zqqq/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04  
    resources:  
      limits:  
        nvidia.com/gpu: 1  # 声明使用1张GPU  
EOF 

# 部署测试Pod
$ kubectl apply -f cuda-sample.yaml
</code></pre>
<p>查看日志（成功标志）：</p>
<pre><code class="language-bash">$ kubectl logs -f cuda-vectoradd  
# 输出包含以下内容则表示GPU调度正常：  
[Vector addition of 50000 elements]  
...  
Test PASSED  #CUDA程序运行通过  
Done  
</code></pre>
<p>至此，GPU 资源已成功接入 RKE2 集群，已经可以在 K8S 集群内实现 GPU 调度。</p>
<h2 id="部署-rainbond">部署 Rainbond</h2>
<h3 id="1-添加-rainbond-helm-仓库">1. 添加 Rainbond Helm 仓库</h3>
<pre><code class="language-bash">helm repo add rainbond https://chart.rainbond.com  
helm repo update  
</code></pre>
<h3 id="2-配置集群网络参数">2. 配置集群网络参数</h3>
<p>创建 <code>values.yaml</code>，指定集群入口 IP 和节点信息：</p>
<pre><code class="language-bash">cat &gt; values.yaml &lt;&lt; EOF  
Cluster:  
  gatewayIngressIPs: 10.0.0.5  # 填写服务器公网 IP 或负载均衡 IP
  nodesForGateway:
  - externalIP: 10.0.0.5       # 节点公网 IP
    internalIP: 10.0.0.5       # 节点内网 IP
    name: iv-ydtpg1wqo0ay8n6f4k7n  # 节点名称（通过 kubectl get node 查看）
  nodesForChaos:  
  - name: iv-ydtpg1wqo0ay8n6f4k7n  # 节点名称（通过 kubectl get node 查看）
  containerdRuntimePath: /run/k3s/containerd  # 指向 RKE2 的容器运行时路径
EOF  
</code></pre>
<h3 id="3-一键安装-rainbond">3. 一键安装 Rainbond</h3>
<pre><code class="language-bash">  helm install rainbond rainbond/rainbond --create-namespace -n rbd-system -f values.yaml  
</code></pre>
<p><strong>验证安装</strong>：</p>
<pre><code class="language-bash">kubectl get pod -n rbd-system  # 观察名称含 rbd-app-ui 的 Pod 状态  
# 当状态显示 Running 且 Ready 为 1/1 时，说明安装完成（约 5-8 分钟）  
</code></pre>
<p><strong>访问界面</strong>：<br>
通过配置的 <code>gatewayIngressIPs</code> 地址访问，格式：<code>http://10.0.0.5:7070</code>。</p>
<h2 id="部署-ollama">部署 Ollama</h2>
<h3 id="1-通过-rainbond-可视化界面安装-ollama">1. 通过 Rainbond 可视化界面安装 Ollama</h3>
<p>登录后点击创建应用，选择从应用市场创建，在开源应用商店搜索关键词 <code>ollama</code> 并点击安装</p>
<p><img src="https://static.goodrain.com/wechat/local-deploy-deepseek-in-k8s/1.png" alt="" loading="lazy"></p>
<p>Rainbond 会自动拉取 Ollama 镜像并部署（镜像大小约 1.2GB）</p>
<p><img src="https://static.goodrain.com/wechat/local-deploy-deepseek-in-k8s/2.png" alt="" loading="lazy"></p>
<h3 id="2-按需分配计算资源">2. 按需分配计算资源</h3>
<p>安装完成后，进入 Ollama 组件详情页，点击其他设置调整资源配额：</p>
<ul>
<li>CPU / 内存：建议根据模型规模设置（如 deepseek R1 14B 版本至少 12 核 + 32GB 内存），本例中暂时不限制（设置 <code>0</code> 表示使用节点默认资源）</li>
<li>GPU 资源：在 <code>limits</code> 中添加 <code>nvidia.com/gpu: 1</code>（声明使用 1 张 GPU）。</li>
</ul>
<p><img src="https://static.goodrain.com/wechat/local-deploy-deepseek-in-k8s/3.png" alt="" loading="lazy"></p>
<pre><code class="language-yaml">limits:
  cpu: 0
  memory: 0
  nvidia.com/gpu: 1
</code></pre>
<p>保存配置后，点击左上角的重启按钮，等待 Ollama 组件重新启动使资源配置生效。等待约 1 分钟，组件状态恢复为绿色（Running）即可开始使用。</p>
<p>资源配置参考表（根据模型参数选择）：</p>
<table>
<thead>
<tr>
<th>模型版本</th>
<th>CPU 核心</th>
<th>内存要求</th>
<th>硬盘空间</th>
<th>GPU 显存（推荐）</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.5B</td>
<td>4+</td>
<td>8GB+</td>
<td>3GB+</td>
<td>非必需（CPU 推理）</td>
</tr>
<tr>
<td>7B/8B</td>
<td>8+</td>
<td>16GB+</td>
<td>8GB+</td>
<td>8GB+（如 RTX 3070）</td>
</tr>
<tr>
<td>14B</td>
<td>12+</td>
<td>32GB+</td>
<td>15GB+</td>
<td>16GB+（如 RTX 4090）</td>
</tr>
<tr>
<td>32B+</td>
<td>16+/32+</td>
<td>64GB+/128GB+</td>
<td>30GB+/70GB+</td>
<td>24GB+/ 多卡并行（如 A100）</td>
</tr>
</tbody>
</table>
<h2 id="部署-deepseek-r1">部署 DeepSeek R1</h2>
<h3 id="1-通过-web-终端启动模型服务">1. 通过 Web 终端启动模型服务</h3>
<p>在 Rainbond 界面中进入 Ollama 组件详情页，点击右上角Web 终端进入命令行模式（需确保浏览器允许 WebSocket 连接）。<br>
执行 Ollama <a href="https://ollama.com/library/deepseek-r1" target="_blank" rel="noopener nofollow">官方提供的模型启动命令</a>（以 32B 版本为例）：</p>
<pre><code class="language-bash">ollama run deepseek-r1:32b
</code></pre>
<p><img src="https://static.goodrain.com/wechat/local-deploy-deepseek-in-k8s/4.png" alt="" loading="lazy"></p>
<blockquote>
<p>提示：若终端无响应，检查集群 WebSocket 地址是否可达：进入 <strong>平台管理 -&gt; 集群 -&gt; 编辑集群信息</strong>，复制 WebSocket 地址。在本地浏览器或 Postman 中测试该地址连通性。</p>
</blockquote>
<h3 id="2-配置模型访问端口">2. 配置模型访问端口</h3>
<p>在 Ollama 组件详情页中，找到端口设置项：</p>
<ol>
<li>
<p>将默认的 HTTP 协议修改为 TCP</p>
</li>
<li>
<p>复制生成的访问地址（格式为 <code>http://你的服务器IP:随机端口</code>，如 <code>http://10.0.0.5:30000</code>）。</p>
</li>
</ol>
<blockquote>
<p>注意：若使用域名访问，请在网关管理中绑定您的域名。</p>
</blockquote>
<p><img src="https://static.goodrain.com/wechat/local-deploy-deepseek-in-k8s/5.png" alt="" loading="lazy"></p>
<h2 id="接入到-chatbox-使用">接入到 Chatbox 使用</h2>
<h3 id="1-下载并安装-chatbox">1. 下载并安装 Chatbox</h3>
<p>从 <a href="https://chatboxai.app/" target="_blank" rel="noopener nofollow">Chatbox 官方网站</a> 下载对应平台的客户端（支持 Windows/macOS/Linux），完成安装后启动应用。</p>
<h3 id="2-添加-ollama-api-地址">2. 添加 Ollama API 地址</h3>
<p>进入 Chatbox 设置界面（点击左上角菜单 -&gt; 设置 -&gt; 模型管理）：</p>
<ol>
<li>点击添加自定义模型，选择Ollama类型</li>
<li>在地址栏粘贴 Rainbond 中获取的访问地址（如 <code>http://10.0.0.5:30000</code>），点击保存</li>
<li>系统会自动识别已部署的模型（如 <code>deepseek-r1:32b</code>），无需手动配置参数。</li>
</ol>
<p><img src="https://static.goodrain.com/wechat/local-deploy-deepseek-in-k8s/6.png" alt="" loading="lazy"></p>
<h3 id="3-开始对话">3. 开始对话</h3>
<p>返回主界面，选择刚刚添加的 DeepSeek R1 模型，即可进入聊天窗口：</p>
<ul>
<li>输入问题，点击发送</li>
<li>模型会实时返回响应，支持流式输出和历史对话记录查看。</li>
</ul>
<p><img src="https://static.goodrain.com/wechat/local-deploy-deepseek-in-k8s/7.png" alt="" loading="lazy"></p>
<h2 id="最后">最后</h2>
<p>通过 Ollama、RKE2、Rainbond 与 GPU Operator 的高效组合，1 小时内即可完成 Deepseek 大模型的私有化部署。这仅仅是大模型私有部署的第一步，后续可依托 Rainbond 的快速开发能力，通过微服务构建、可视化编排等功能，轻松实现业务系统与大模型的深度集成，让企业在安全可控的本地化环境中，灵活调用大模型能力，加速 AI 应用落地。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.07772614034143518" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-17 14:30">2025-04-17 14:30</span>&nbsp;
<a href="https://www.cnblogs.com/rainbond">Rainbond开源</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18830786);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18830786', targetLink: 'https://www.cnblogs.com/rainbond/p/18830786', title: 'K8S 部署 Deepseek 要 3 天？别逗了！Ollama+GPU Operator 1 小时搞定' })">举报</a>
</div>
        