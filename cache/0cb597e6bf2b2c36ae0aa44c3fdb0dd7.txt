
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/ranjiang/p/18730485" title="发布于 2025-02-25 02:02">
    <span role="heading" aria-level="2">2 本地部署DeepSeek模型构建本地知识库+联网搜索详细步骤</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>在<a href="https://www.cnblogs.com/ranjiang/p/18725581" target="_blank">1 使用ollama完成DeepSeek本地部署</a>中使用ollama完成deepSeek的本地部署和运行，此时我可以在PowerShell中通过对话的方式与DeepSeek交流，但此时本地模型不具备联网搜索能力，无法根据网上信息来回答我的问题，同时我也无法将我自己的知识给他参考，这样本地模型相比直接使用官网的访问接口没有任何优势，接下来我需要做两件事情，来发挥出本地模型的优势：<br>
（1）建立本地知识库，然后将我自己的资料和数据文件放入知识库中，让模型在回答问题是可以参考我本地知识来组织答案；这可以在避免私人数据泄露的同时让模型变成了自己的专有模型，根据知识库的内容实现定向知识领域应用。<br>
（2）通过第三方工具或脚本实现本地模型的联网搜索能力，这样本地模型就能够完全具备官网接口的能力，且本地模型搜索时不会受平台接口搜过内容过滤的限制。<br>
总结网上的实现方案，当前有两种比较有意义的部署方案：<br>
（1）方案一ollama+anythingLLM：开源模型本地部署+本地知识库构建，完全离线运行，适合不需要联网完全本地运行的场景；<br>
（2）方案二ollama+浏览器Page Assist插件：开源模型本地部署+本地知识库构建+联网搜索功能，适合需要联网搜索的场景。</p>
<h1 id="1-方案一使用anythingllm实现本地知识库构建">1 方案一：使用anythingLLM实现本地知识库构建</h1>
<p>安装anythingLLM有两种方式，一种是直接安装桌面版，一种是通过Docker安装；第一种方式安装方便，已经能满足一般用户的使用要求，但安装过程中需要下载库和相关依赖，由于下载速度很慢这个过程十分漫长（可以考虑自己上点□□上网手段），我等待了应该有三四个小时；第二种方式相比于第一种方式功能更多一些，支持多用户访问、嵌入聊天部件、密码保护和用户管理且方便移植，且docker安装anythingLLM可以更换国内镜像源，安装速度要快一些。</p>
<h2 id="11-安装anythingllm桌面版">1.1 安装anythingLLM桌面版</h2>
<p>下载地址：<a href="https://anythingllm.com/desktop" target="_blank" rel="noopener nofollow">https://anythingllm.com/desktop</a><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250222012750925-980314010.png" alt="image" loading="lazy"><br>
双击安装包选择自己的安装位置即可安装，保持联网状态，等待自动下载相关依赖和库就可以；<br>
软件介绍和使用说明可以参考官网：<a href="https://docs.anythingllm.com/introduction" target="_blank" rel="noopener nofollow">https://docs.anythingllm.com/introduction</a></p>
<h2 id="12-通过docker安装anythingllm">1.2 通过Docker安装anythingLLM</h2>
<p>Docker是一种虚拟化的容器技术，能够实现运行环境与运行设备基础架构的隔离，允许用户将应用和依赖打包部署在一个可移植的容器内，在任何支持Docker的环境中运行，方便移植和部署。<br>
（1）去docker官网可以下载Docker安装包：<a href="https://www.docker.com" target="_blank" rel="noopener nofollow">https://www.docker.com</a><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250221235932998-1404446907.png" alt="image" loading="lazy"><br>
双击安装程序，勾选使用WSL 2代替Hyper-V，点击OK等待安装完成。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250222000111863-1234297334.png" alt="image" loading="lazy"><br>
安装完成后需要重启电脑。<br>
（2）运行docker，若运行失败，可以打开PowerShell，更新一下wsl版本：输入<code>wsl --update</code>，若仍然失败，重装一下docker。<br>
Docker说明：<br>
（A） Docker是依赖Linux环境的，无法直接在Windows系统上运行，所以通过WSL2和Hypera-V可以搭建Docker所需的虚拟运行环境；<br>
（B）WSL2是一个轻量级的虚拟化技术，底层利用Hyper-V技术运行了Linux内核来提供完整的调用，无需模拟整个硬件环境，资源占用少，WSL2更适合那些需要在Windows上便捷地使用Linux环境的用户；<br>
（C）Hyper-V是一个全面完整的虚拟化技术和虚拟机管理器，模拟了整个Linux的硬件环境，支持运行独立的操作系统，则适用于需要完整虚拟化功能的场景；<br>
（D）我仅需一个Linux环境运行Docker，所以选择WSL2，节约硬件资源。<br>
（3）打开Docker软件，点击右上角设置，再点击Docker Engine，并添加国内镜像源，然后点击左下角的Apply&amp;Restart；</p>
<pre><code>"registry-mirrors": [
    "https://docker.m.daocloud.io/",
    "https://huecker.io/",
    "https://dockerhub.timeweb.cloud",
    "https://noohub.ru/",
    "https://dockerproxy.com",
    "https://docker.mirrors.ustc.edu.cn",
    "https://docker.nju.edu.cn",
    "https://xx4bwyg2.mirror.aliyuncs.com",
    "http://f1361db2.m.daocloud.io",
    "https://registry.docker-cn.com",
    "http://hub-mirror.c.163.com"
  ]
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224231307397-279507034.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224232121639-1815073471.png" alt="image" loading="lazy"><br>
（4）点击右下角的Terminal或者通过cmd运行PowerShell，然后输入命令<code>docker pull mintplexlabs/anythingllm</code>下载anythingllm；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224232225341-1563302759.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224232525583-1346027368.png" alt="image" loading="lazy"><br>
（5）下载完成后再Termical或PowerShell中输入一下代码并运行即可将anythingLLM运行起来；</p>
<pre><code>$env:STORAGE_LOCATION="$HOME\Documents\anythingllm"; `
If(!(Test-Path $env:STORAGE_LOCATION)) {New-Item $env:STORAGE_LOCATION -ItemType Directory}; `
If(!(Test-Path "$env:STORAGE_LOCATION\.env")) {New-Item "$env:STORAGE_LOCATION\.env" -ItemType File}; `
docker run -d -p 3001:3001 `
--cap-add SYS_ADMIN `
-v "$env:STORAGE_LOCATION`:/app/server/storage" `
-v "$env:STORAGE_LOCATION\.env:/app/server/.env" `
-e STORAGE_DIR="/app/server/storage" `
mintplexlabs/anythingllm;
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225014632040-1979618153.png" alt="image" loading="lazy"><br>
点击端口3001:3001或在浏览器访问http://localhost:3001/ 即可进入anythingLLM界面。</p>
<h2 id="13-anythingllm配置本地知识库基于桌面版">1.3 anythingLLM配置本地知识库——基于桌面版</h2>
<h3 id="131-将ollama-serve运行起来">1.3.1 将ollama serve运行起来</h3>
<p>WIN+R快捷键，输入cmd打开PowerShell，输入<code>ollama serve</code>可以将ollama运行起来，默认ollama可以通过本地的11434端口访问，新开一个PowerShell窗口输入<code>curl http://localhost:11434</code>可以验证。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223002758946-1822092531.png" alt="image" loading="lazy"></p>
<h2 id="132-配置本地anythingllm">1.3.2 配置本地anythingLLM</h2>
<p>运行anythingLLM软件，第一次运行会有一些提示，可以全部跳过，进入如下界面，点击下方的设置可以配置自己的模型。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223014047464-1204000994.png" alt="image" loading="lazy"><br>
（1）首先点击LLM首选项，选择自己的模型提供商为ollama，然后在下方Ollama Base URL处填上ollama的访问地址：<a href="http://127.0.0.1:11434" target="_blank" rel="noopener nofollow">http://127.0.0.1:11434</a> ，Ollama Keep Alive选择Forever使模型一直保持激活状态；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223015658569-1469413238.png" alt="image" loading="lazy"><br>
（2）向量数据库用于存储自己知识库转化得到的模型可识别的向量数据，使用默认的LanceDB即可；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223015354368-656624032.png" alt="image" loading="lazy"><br>
（3）先打开PowerShell输入<code>ollama pull nomic-embed-text</code>下载文本嵌入模型用于将文本转化为向量以及进行相似度计算；在anythingLLM设置的Embedder首选项中选择Ollama并选择刚刚下载的模型，然后保存更改；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225005424241-394072191.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225011552467-2095114473.png" alt="image" loading="lazy"><br>
（4）返回聊天界面新建工作区，并点击上传文件；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012122251-665580924.png" alt="image" loading="lazy"><br>
（5）上传要放入知识库中的文件，然后选中并点击Move to Workspace，将文件导入工作空间，然后下划到工作空间，点击Save and Embeded；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012348209-637582862.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012738928-1296994642.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225010559835-1991696510.png" alt="image" loading="lazy"><br>
（6）嵌入完成后点击pin to workspace即可返回聊天界面，此时向模型提问deepseek即可根据知识库中的知识进行回答。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012846286-1640748709.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225013152728-1611859672.png" alt="image" loading="lazy"></p>
<h1 id="2-方案二使用page-assist插件实现本地知识库构建联网搜索">2 方案二：使用Page Assist插件实现本地知识库构建+联网搜索</h1>
<h2 id="21-安装浏览器">2.1 安装浏览器</h2>
<p>已知Firefox和Chrome浏览器都支持Page Assist插件，edge暂不支持，我测试了火狐浏览器安装Page Assist，火狐浏览器可以去官网下载：<a href="https://www.firefox.com.cn/" target="_blank" rel="noopener nofollow">https://www.firefox.com.cn/</a> 。</p>
<h2 id="22-安装page-assist插件">2.2 安装Page Assist插件</h2>
<p>（1）打开火狐浏览器，点击右上角拓展——管理拓展；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224221721236-292192799.png" alt="image" loading="lazy"><br>
（2）搜索Page Assist，出来的第一个就是，点击添加等待下载完成会弹窗询问是否添加Page Assist，选择添加；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224211143876-1507445686.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224223119236-553634252.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224224329992-1474817443.png" alt="image" loading="lazy"></p>
<h2 id="23-接入本地模型">2.3 接入本地模型</h2>
<p>（1）在配置Page Assist之前先在PowerShell中输入<code>ollama serve</code>将ollama运行起来；<br>
（2）点击拓展中的Page Assist插件进入Page Assist界面，点击右上角设置，先在一般设置里将语言设置为简体中文，ollama设置中已经默认配置好ollama的默认端口，无需更改；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224233738436-523529004.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224234042869-2051932350.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224235758027-974082609.png" alt="image" loading="lazy"><br>
（3）返回聊天界面，在顶部选择你本地部署的模型，此时即可与本地模型进行对话；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224235549536-1048046212.png" alt="image" loading="lazy"></p>
<h2 id="24-开启本地模型联网搜索功能">2.4 开启本地模型联网搜索功能</h2>
<p>打开左下角的联网功能，即可开启模型的联网搜索功能，本地模型可以根据搜索到的信息来回答我的提问；在一般设置里的管理网络设置中，可以设置使用的搜索引擎和搜索的结果数；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225000804349-184682542.png" alt="image" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225001111095-1322318459.png" alt="image" loading="lazy"></p>
<h2 id="25-配置本地知识库">2.5 配置本地知识库</h2>
<p><img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225004606984-1089557290.png" alt="image" loading="lazy"><br>
（1）首先打开PowerShell输入<code>ollama pull nomic-embed-text</code>下载文本嵌入模型用于将文本转化为向量以及进行相似度计算；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225005424241-394072191.png" alt="image" loading="lazy"><br>
（2）在Page Assist设置——RAG设置中选择刚刚安装的nomic-embed-text模型并保存；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225005536905-1525828075.png" alt="image" loading="lazy"><br>
（3）在管理知识中点添加新知识，为新知识起一个标题，然后将需要放入知识库的文档拖入并提交；<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225010051117-2026382387.png" alt="image" loading="lazy"><br>
（4）返回聊天界面，在输入窗中选择知识库，然后提问知识库中的相关知识，模型即可根据本地知识库进行回答。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225010656087-827822952.png" alt="image" loading="lazy"></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.3512527159340278" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-25 02:27">2025-02-25 02:02</span>&nbsp;
<a href="https://www.cnblogs.com/ranjiang">wrj的博客</a>&nbsp;
阅读(<span id="post_view_count">213</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18730485" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18730485);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18730485', targetLink: 'https://www.cnblogs.com/ranjiang/p/18730485', title: '2 本地部署DeepSeek模型构建本地知识库+联网搜索详细步骤' })">举报</a>
</div>
        