
	<h1 class="postTitle"><a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/yexiaochai/p/18713751" title="发布于 2025-02-13 15:43">
    <span role="heading" aria-level="2">李飞飞的50美金比肩DeepSeek把CEO忽悠瘸了，倒霉的却是程序员</span>
    

</a>
</h1>
	<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<blockquote>
<p>关注公众号<strong>回复1</strong></p>
<p>获取<strong>一线、总监、高管《管理秘籍》</strong></p>
</blockquote>
<p>书接上文：<a href="https://mp.weixin.qq.com/s/_zBVmPwPpxZC-aYs10UB2Q" target="_blank" rel="noopener nofollow">DeepSeek怎么突然就比肩GPT了？</a></p>
<p>如前所述，应用层AI开发压根不会去刻意关注大模型底层实现，多数时候也关注不了。</p>
<p>但我们一定会关注的是<strong>各种技术选型最终的优劣与效果</strong>，其中关系最大的一定是<strong>模型训练成本到底是多少？</strong></p>
<p>这个问题搞不清楚，后续做实现时候可能栽大跟头，想象一下你信誓旦旦的告诉CEO要去做模型训练，<strong>几百万RMB丢进去，放个屁就没了，你觉得他会不会想要打死你？</strong></p>
<p>而近期因为想要<strong>抢占DeepSeek热度</strong>，很多<strong>“老演员”</strong>都在抢占注意力，这其实搞得很多技术负责人很难受：<strong>因为，老板对训练的成本预期被标题党们带偏了</strong>，比如网上流传的一篇文章：</p>
<p><strong>李飞飞</strong>等斯坦福大学和华盛顿大学的研究人员以<strong>不到 50 美元</strong>的云计算费用，成功训练出了一个名为 s1 的人工智能推理模型。</p>
<p>如果真的有CEO相信了50美元的训练成本，然后再让技术负责人去做，那会把团队搞爆的...</p>
<h2 id="ai应用的核心成本">AI应用的核心：成本</h2>
<p>模型开发离不开三要素：<strong>算力、算法、数据</strong>。其中底层算法与应用层关系不大，数据与算力的需求要看实际的应用。</p>
<p>比如做AI律师、AI医生、AI教师这种复杂AI项目，是跳不出去的，我粗略整理了一下（复杂AI应用）成本结构，大概是这样的：</p>
<table>
<thead>
<tr>
<th>成本项目</th>
<th>需要程度</th>
<th>成本预估</th>
<th>项目说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>研发团队（含产品）</td>
<td>★★★</td>
<td>不低</td>
<td>主要完成需求细化与具体实现，是大模型项目的核心部分。</td>
</tr>
<tr>
<td>领域专家团队（如律师、医生、老师）</td>
<td>★★☆</td>
<td>适中</td>
<td>提供行业KnowHow、初始规则与数据，帮助研发团队实现高效开发。</td>
</tr>
<tr>
<td>数据成本</td>
<td>★★★</td>
<td>不可控</td>
<td>数据是AI项目的核心，通常包括领域专家提供的数据以及其他额外数据。</td>
</tr>
<tr>
<td>训练成本</td>
<td>★☆☆</td>
<td>不可控</td>
<td>训练过程中需要大量算力，尤其在未优化前，成本非常高。</td>
</tr>
<tr>
<td>推理成本</td>
<td>★★★</td>
<td>可控</td>
<td>推理服务器是必须的，推理阶段的成本较为可控，主要作为服务器费用的一部分。</td>
</tr>
<tr>
<td>合规与安全成本</td>
<td>★☆☆</td>
<td>适中</td>
<td>涉及敏感数据的合规与安全性，特别是在医疗、金融等领域，需保证隐私保护与数据安全。</td>
</tr>
</tbody>
</table>
<p>就过往经验来说，人力成本虽高，但他是可控的，并且可随时动态调整，长期来说也是公司的财富。</p>
<p>所以，尤为不可控的就是<strong>数据成本与训练成本！</strong></p>
<h3 id="一数据成本">一、数据成本</h3>
<p>大模型对数据的质量要求极高，尤其是医疗、法律等领域，获取优质数据不仅需要支付高昂费用，往往还要依赖付费数据库或第三方合作。</p>
<p>大模型的训练需要大量标注数据，特别是涉及领域专家时，标注费用不容小觑。</p>
<p>数据的清洗与预处理更是一个耗费巨大资源的过程，<strong>数据蒸馏在这块可以帮助很大，但必要的真人介入依旧难以避免。</strong></p>
<h3 id="二训练成本">二、训练成本</h3>
<p>将通用模型调整到特定领域（如法律、医疗）时，需要额外的计算资源和领域数据，通常每次微调都伴随着高额开销。</p>
<p>为了找到最佳的超参数配置，进行大量实验和计算是必须的，这无疑会进一步提高训练的成本。</p>
<p>为了降低推理成本，通常需要对模型进行压缩（如剪枝、量化等），这些优化步骤虽然能提高效率，但也需要额外的研发投入。</p>
<p>从这个角度再看<strong>李飞飞的50美元成本</strong>，突然就有点摸不着头脑了，但他已经搞得很多人很蛋疼。</p>
<p><strong>因为CEO们可不会管是不是真的，只要对他们有利，就认为是真的。但技术负责人必须搞清楚她到底怎么做到的？</strong></p>
<h2 id="打开50美元">打开50美元</h2>
<p>根据论文数据来源于对Gemini Thinking Experimental 模型的蒸馏1000 个样本小型数据集。</p>
<p>而后使用阿里的 Qwen2.5-32B-Instruct 进行监督微调；使用 16 个英伟达 H100 GPU 进行了 26 分钟的训练，而后发布信息：<strong>媲美 DeepSeek R1、OpenAI o1 的 AI 推理模型</strong>。</p>
<p>这就让人非常疑惑了，如果只考虑单次微调训练成本，如此小的数据量还用不了50美元，但是从前面的文章我们可以看出来两个问题：</p>
<ol>
<li>第一，李飞飞团队在数据上投入很小，蒸馏数据也花不了几个钱，简单信息AI完全就搞定了，也不需要进一步验证；</li>
<li>第二，不能忽视基座模型Qwen2.5-32B-Instruct的前期投入，天知道阿里在模型调优和数据准备上花了多少钱；</li>
</ol>
<p>但，无所谓，我们核心关注的是<strong>成本与效果</strong>，成本说不清楚就说效果，那么他真的用1000数据超过了o1吗？<strong>想多了！</strong></p>
<p>从对比数据来看，s1只是在1000测试集数据的边界内表现不错，跳出这个边界可能撒也不是...</p>
<p>但是这就让我们很Emo了，因为老板真的让技术负责人拿着<strong>10倍溢出500美金</strong>去复现GPT。说实话，我虽然经常标题党，但他这个标题党的确实过份了...</p>
<p>另外回到1000个数据集这件事本身，就算有人真的基于某开源模型媲美了最顶级的模型能力，<strong>那也不能说明什么！</strong></p>
<p>因为参数量大的大模型，其训练数据量也奇大无比，其结果是数据之中甚至可能会有冲突的情况，并且大数据量训练过程中还会伴随遗忘、覆盖等复杂场景，这其中的成本，绝不是小数据集训练可比拟的！</p>
<p>相比之下，小数据集训练通常意味着更少的复杂性和更容易控制的模型行为，但也会面临<strong>欠拟合</strong>的问题：即模型在面临新的、未见过的情境时表现得不够稳健。</p>
<p>因此，虽然小数据集的训练可以产生一些在特定测试集上表现优异的模型，但它并不能代表模型的通用能力或真实表现。</p>
<p>综上，这50美元无论从什么角度来看，都是不合理的...</p>
<p>但是，这里有个问题依旧没有被很好的解答<strong>现在训练一个领域模型，到底成本如何？</strong></p>
<h2 id="模型训练成本">模型训练成本</h2>
<p>对于AI应用来说，在效果差距不大的情况下，第一考虑一定是<strong>实现成本</strong>，而现在主流实现只有两条：</p>
<ol>
<li><strong>不训练模型。</strong>基于知识图谱+模型的提示词后置策略；</li>
<li><strong>训练模型。</strong>基于领域模型的数据前置训练，API调用策略；</li>
</ol>
<p>第一条路径在2024年，很多公司已经用过了，但市面上真正的AI产品爆款依旧没有出现，只能说明两个问题：</p>
<ol>
<li>第一，<strong>可能技术路径能达到的效果有限</strong>；</li>
<li>第二，<strong>无论产品需要的数据或者工程打磨的预期没有掌握好</strong>；</li>
</ol>
<p>我更相信是第二种：</p>
<blockquote>
<p>本质上说，基于<strong>知识图谱+强大基座模型</strong>的AI应用和基于<strong>垂直领域模型+Prompt</strong>最终都是依赖与强大的<strong>行业knowHow与工程能力</strong>，不应该有太大差距</p>
<p>所以，<strong>如果知识图谱+GPT没做出来好的AI应用，换个路径也没那么容易</strong></p>
</blockquote>
<p>而基于知识图谱（知识库）的技术路径，至少被实践了一年，其成本已经被各个公司摸得比较清晰，其中<strong>包括初始建立知识库，后续根据数据更新再调整程序的成本。</strong></p>
<p>但DeepSeek出现后，训练的成本与之前相比却产生了巨大的变化。</p>
<blockquote>
<p>这里之前做垂直领域模型训练的公司可能会哭晕在厕所...</p>
</blockquote>
<p>所以DeepSeek的训练成本为什么那么低，其他开源模型能不能<strong>复制他的低成本模式</strong>变得很关键了，这会进一步影响技术路径选择，甚至很多人会尝试<strong>混合路径</strong>。</p>
<blockquote>
<p>这里的点是：<strong>无论知识图谱还是私有领域模型，都是公司壁垒，但显然领域模型更有噱头</strong></p>
</blockquote>
<p><strong>PS：这里有误请您指出</strong></p>
<p>而我这里做了很多阅读，最终得出DeepSeek训练成本低的原因是综合的因素：</p>
<h3 id="一mtp架构">一、MTP架构</h3>
<p>MTP（Multi-Token Prediction）：<strong>多token预测技术</strong>。</p>
<p>一种并行优化机制，可以让模型在训练时，同时预测多个连续位置的token。从而提升整体性能和推理速度。</p>
<p>传统的自回归模型在每次预测时都需要依赖前一步的输出，这意味着每个token的生成都依赖于前面已经生成的token。</p>
<p>而MTP通过并行化这一过程，减少了计算时间和资源的消耗，这对于大规模模型的训练尤其重要。</p>
<p>通过这种方式，DeepSeek能够更高效地使用计算资源，从而降低整体训练成本。</p>
<p>MTP不仅能够提升训练效率，还能够在推理阶段带来性能提升。由于模型能够同时生成多个token而不是逐步生成，因此推理速度也会大大加快。</p>
<p>这对于需要快速响应的实际应用场景来说，是一个重要的优势，能够显著减少延迟。</p>
<h3 id="二moe架构">二、MoE架构</h3>
<p>如前所述，大模型的训练依赖于海量数据，数据量过大其处理的复杂度将急剧上升，但如果是领域小模型的训练难度及成本就会好很多了。</p>
<p>这可能是DeepSeek使用混合专家模型（MoE）的原因。其核心思路包含三点：</p>
<ol>
<li><strong>专家模型</strong>，MoE架构包含很多小模型，不同模型回答不同领域的问题；</li>
<li><strong>“全科医生”</strong>，他包含一个能力稍强的<strong>通用模型</strong>做信息分拆、意图识别，所有信息通过“全科医生”去找到最接近的（3个）<strong>“科室医生模型”</strong>，最后通过他们的回复，再由“全科医生”对外作答；</li>
</ol>
<p>这个架构我认为是一种<strong>工程降熵</strong>的策略，因为参数过大的模型训练起来太费劲，那就用多个小模型去抵消一个大模型，从而<strong>降低工程实现难度</strong>。</p>
<h3 id="三数据蒸馏">三、数据蒸馏</h3>
<p>就过往经验启示做数据蒸馏的成本是要高于服务器训练成本的。</p>
<p>因为数据蒸馏需要领域专家，而且数据会存在各种往复，这就会导致多轮数据处理，其成本是极高的。</p>
<p>但数据蒸馏（知识蒸馏）技术可以很好的规避这一切，相当于借助巨人的肩膀，使用优秀模型使用过的数据，这里的成本优化是很吓人的。</p>
<p>数据蒸馏减少了对大量标注数据的需求，最后结合<strong>GRPO技术</strong>，模型在学习过程中能够更好地应对噪声和不确定性，避免过拟合、加速收敛。</p>
<p>GRPO通过持续的反馈机制调整模型权重，确保模型在动态任务和复杂环境下保持较好的推理能力，从而进一步提升了训练效率。</p>
<h3 id="四kvcache">四、KVcache</h3>
<p>KVcache通过在推理过程中缓存 Key 和 Value 矩阵，避免重复计算，显著减少了自注意力机制的计算开销。</p>
<p>在生成每个新 token 时，模型只需计算当前 token 的 Query，并与缓存的 Key 和 Value 矩阵进行注意力计算，从而大幅提升推理速度并降低计算资源消耗。</p>
<p>在训练阶段，KV Cache 的作用有限，因为训练通常以批量方式进行，且需要完整的梯度计算。然而，在长序列训练中，KV Cache 仍可通过缓存部分结果提升效率。</p>
<p>但是 KV Cache会显著降低推理成本，为大规模应用提供了高效支持。</p>
<p>以上，大概是DeepSeek为什么成本低的原因，但具体到什么程度，还得等一段时间后工程应用后的真实数据。</p>
<h2 id="结语">结语</h2>
<p>其实，国内云服务平台在DeepSeek的训练集成上速度会很快的，所以大部分知识后续会被云平台包装变成不可见的部分，这里需要持续跟进。</p>
<p>但，很有可能，留给我们的部分只会包含两点：</p>
<ol>
<li>训练数据的入口；</li>
<li>API测试效果的出口；</li>
</ol>
<p>所以，对于AI应用的各位来说，真正有用的知识可能是如何使用好<strong>知识蒸馏</strong>技术以及深入了解下MoE架构中尤其是门控系统是如何设计的，如果能迁移至工程实现是最好的。</p>
<p>未来，AI应用开发将更加注重成本与效果平衡，技术路径选择更加灵活。</p>
<p>无论是基于知识图谱的提示词策略，还是领域模型的前置训练，开发者需根据需求和资源做出最优决策。</p>
<p>DeepSeek的低成本模式为行业设立了标杆，推动更多企业探索高效、经济的解决方案。随着技术进步，AI应用开发的门槛将降低，创新应用的落地速度将加快，推动AI技术在各行业的深度渗透。</p>
<p>因此，开发者需持续关注技术动态，<strong>并且一定要做好老板的预期管理，近期标题党太多，很容易引起老板们的AI焦虑，到时候吃亏的还是我们自己，</strong>所以，加油吧。</p>
<p><strong>最后，文章有一些错漏，希望各位多指正。</strong></p>
<p><img src="https://files.mdnice.com/user/25507/dfbdbae0-7236-421c-bbb0-badae3db3d76.png" alt="" loading="lazy"></p>

</div>
<div id="MySignature" role="contentinfo">
    <img id="view_img" src="https://img2022.cnblogs.com/blog/294743/202202/294743-20220216140902628-1163053035.png" width="80%" alt="" border="0">

</div>
<div class="clear"></div>

	<div class="postDesc">posted on 
<span id="post-date" data-last-update-days="0.10582378230787037" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-13 15:44">2025-02-13 15:43</span>&nbsp;
<a href="https://www.cnblogs.com/yexiaochai">叶小钗</a>&nbsp;
阅读(<span id="post_view_count">68</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18713751" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18713751);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18713751', targetLink: 'https://www.cnblogs.com/yexiaochai/p/18713751', title: '李飞飞的50美金比肩DeepSeek把CEO忽悠瘸了，倒霉的却是程序员' })">举报</a>
</div>
