
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/SmalBox/p/19042368" title="发布于 2025-08-16 17:34">
    <span role="heading" aria-level="2">【渲染流水线】[几何阶段]-[归一化NDC]以UnityURP为例</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        <img src="https://img2024.cnblogs.com/blog/3685400/202508/3685400-20250816173701263-971092966.png" alt="【渲染流水线】[几何阶段]-[归一化NDC]以UnityURP为例" class="desc_img">
        本文探讨UnityURP渲染管线中的NDC（归一化设备坐标）转换过程，详细解析了透视除法将齐次坐标转换为NDC空间的核心原理。文章指出URP根据平台差异（OpenGL/Direct3D）采用不同的NDC范围（[-1,1]或[0,1]），并通过Shader代码示例展示了手动计算NDC坐标的方法。特别强调了深度值在不同平台的特殊处理方式，以及NDC坐标在视锥裁剪、屏幕空间特效等实际应用场景中的重要作用。文中还包含了几何着色器实现屏幕空间粒子生成的完整代码示例，为开发者提供了实用的技术参考。
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<ul>
<li><strong>NDC空间</strong>‌：透视除法的结果，顶点坐标已归一化，可直接用于视口映射和裁剪‌</li>
</ul>
<blockquote>
<p><a href="https://blog.csdn.net/chenghai37/category_13021255.html?fromshare=blogcolumn&amp;sharetype=blogcolumn&amp;sharerId=13021255&amp;sharerefer=PC&amp;sharesource=chenghai37&amp;sharefrom=from_link" target="_blank" rel="noopener nofollow">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></p>
</blockquote>
<ul>
<li>在渲染管线中，‌<strong>归一化严格等同于透视除法</strong>‌，是齐次坐标到NDC空间转换的核心步骤‌。Unity中这步，自动执行。</li>
<li>数据归一化主要通过‌<strong>NDC空间（归一化设备坐标）转换</strong>‌实现，其核心原理是将裁剪空间坐标统一映射到标准范围（[-1,1]的立方体内（OpenGL标准）或[0,1]（DirectX标准））</li>
<li>可以看作是一个矩形内的坐标体系。经过转化后的坐标体系是 限制在一个立方体内的坐标体系。无论x y z轴在坐标体系内的范围都是(-1, 1)。归一化后，z轴向屏幕内。</li>
<li>归一化范围在OpenGL中范围为[-1, 1]，DirectX中为[0, 1]。映射到屏幕时(0, 0)点：GpenGL是左下角，DirectX是左上角。</li>
</ul>
<h1 id="归一化原理">归一化原理</h1>
<h2 id="透视除法perspective-division">透视除法（Perspective Division）</h2>
<p>将齐次裁剪空间坐标的<code>(x,y,z)</code>分量除以<code>w</code>分量，得到NDC坐标</p>
<p>此操作将坐标归一化至[-1,1]范围（OpenGL/Unity）或[0,1]范围（Direct3D）‌。</p>
<h2 id="ndcexampleshader">NDCExample.shader</h2>
<ul>
<li>1.URP标准坐标转换流程</li>
<li>2.手动NDC坐标计算</li>
<li>3.通过v2f结构传递NDC数据</li>
</ul>
<pre><code class="language-glsl">// hlsl
Shader "Custom/NDCDemo"
{
    SubShader
    {
        Pass
        {
            HLSLPROGRAM
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct Attributes { float4 vertex : POSITION; };
            struct Varyings { float4 pos : SV_POSITION; float3 ndc : TEXCOORD0; };

            Varyings vert(Attributes v)
            {
                Varyings o;
                o.pos = TransformObjectToHClip(v.vertex.xyz);
                // 手动计算NDC坐标
                o.ndc = o.pos.xyz / o.pos.w; 
                return o;
            }
            ENDHLSL
        }
    }
}

</code></pre>
<h1 id="urp中的ndc">URP中的NDC</h1>
<p>Unity URP(Universal Render Pipeline)中，归一化的设备坐标(NDC)映射范围取决于具体的API平台：</p>
<ol>
<li>‌<strong>Direct3D风格平台</strong>‌（如Windows、Xbox等）：
<ul>
<li>NDC范围是 ‌<strong>[-1, 1]³</strong>‌（x,y,z三个维度）</li>
<li>深度值(z)映射到[0,1（通过投影矩阵转换）</li>
</ul>
</li>
<li>‌<strong>OpenGL风格平台</strong>‌（如MacOS、Linux等）：
<ul>
<li>NDC范围是 ‌<strong>[-1, 1]³</strong>‌</li>
<li>深度值(z)保持[-1,1]</li>
</ul>
</li>
</ol>
<p>URP默认使用‌<strong>[-1,1]³</strong>‌的NDC范围（与Built-in管线一致），但最终会适配目标平台的约定。</p>
<h2 id="坐标转换示例过程">坐标转换示例过程</h2>
<p>假设有一个世界空间点(2, 1, 5)：</p>
<ol>
<li>通过视图矩阵转换到视图空间（相机空间）</li>
<li>通过URP投影矩阵转换到裁剪空间（clip space）</li>
<li>透视除法得到NDC坐标（w分量除法）</li>
</ol>
<p>具体数值示例（假设使用D3D风格）：</p>
<pre><code>世界坐标 (2, 1, 5)
↓ 视图矩阵转换
视图坐标 (1.5, 0.8, 4.2)
↓ 投影矩阵转换
裁剪坐标 (3.2, 1.6, 8.4, 4.2)
↓ 透视除法 (x/w, y/w, z/w)
NDC坐标 (0.76, 0.38, 2.0) → 超出[-1,1]会被裁剪
</code></pre>
<h2 id="深度值特殊处理">深度值特殊处理</h2>
<p>在URP中，深度缓冲区的值会被重新映射：</p>
<ul>
<li>原始NDC的z ∈ [-1,1]（OpenGL）或 [0,1]（D3D）</li>
<li>最终存储到深度纹理时统一映射到[0,1]范围</li>
</ul>
<h3 id="可以通过shader验证">可以通过Shader验证：</h3>
<pre><code class="language-glsl">hlsl
// 在Fragment Shader中：
float ndcZ = clipPos.z / clipPos.w; // 透视除法后的z值
float depth = ndcZ * 0.5 + 0.5;    // D3D平台下实际存储值
</code></pre>
<p>URP通过_UNITY_UV_STARTS_AT_TOP等宏处理不同平台的坐标差异，保证跨平台一致性。</p>
<h1 id="ndc转换在实际中的应用">NDC转换在实际中的应用</h1>
<p>虽然默认NDC计算是固定加速计算的过程，但是有时需要手动计算实现一些定制效果。</p>
<p>在Unity URP中，几何着色器(Geometry Shader)手动计算NDC并实现屏幕映射的典型应用场景包括：</p>
<p><strong>1. 视锥裁剪</strong></p>
<ul>
<li>将世界坐标转换为NDC后判断是否在[-1,1]范围内</li>
</ul>
<p><strong>2. 屏幕空间特效</strong></p>
<ul>
<li>‌ 通过NDC坐标计算UV用于采样屏幕纹理</li>
</ul>
<p><strong>3. 几何体动态生成</strong></p>
<ul>
<li>‌  根据NDC坐标控制顶点生成范围</li>
</ul>
<h2 id="计算ndc并实现屏幕空间粒子生成示例screenspaceparticleshader">计算NDC并实现屏幕空间粒子生成示例ScreenSpaceParticle.shader</h2>
<ul>
<li>在几何着色器中通过<code>clipPos.xyz / clipPos.w</code>完成透视除法得到NDC坐标</li>
<li>使用NDC坐标时需注意：
<ul>
<li>D3D平台下y轴需要取反（<code>screenUV.y = 1 - screenUV.y</code>）</li>
<li>深度值在D3D平台需映射到[0,1]范围</li>
</ul>
</li>
<li>示例实现了屏幕空间粒子生成效果，可通过NDC坐标控制生成范围</li>
</ul>
<p>实际应用时可结合_UNITY_MATRIX_VP矩阵进行完整坐标空间转换链验证。</p>
<pre><code class="language-glsl">
Shader "Custom/NDCGeometryShader"
{
    Properties { _MainTex ("Texture", 2D) = "white" {} }
    SubShader
    {
        Tags { "RenderType"="Opaque" }
        Pass
        {
            HLSLPROGRAM
            #pragma vertex vert
            #pragma geometry geom
            #pragma fragment frag
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

            struct v2g {
                float4 pos : SV_POSITION;
                float2 uv : TEXCOORD0;
            };

            struct g2f {
                float4 pos : SV_POSITION;
                float2 uv : TEXCOORD0;
                float3 ndc : TEXCOORD1;
            };

            v2g vert(appdata_base v) {
                v2g o;
                o.pos = TransformObjectToHClip(v.vertex);
                o.uv = v.texcoord;
                return o;
            }

            [maxvertexcount(4)]
            void geom(point v2g input[1], inout TriangleStream&lt;g2f&gt; stream) {
                // 手动计算NDC坐标
                float4 clipPos = input[0].pos;
                float3 ndc = clipPos.xyz / clipPos.w;

                // 屏幕空间扩展（生成四边形粒子）
                float size = 0.1;
                g2f o;
                for(int i=0; i&lt;4; i++) {
                    o.pos = clipPos;
                    o.pos.xy += float2((i%2)*2-1, (i/2)*2-1) * size * clipPos.w;
                    o.uv = input[0].uv;
                    o.ndc = ndc;
                    stream.Append(o);
                }
                stream.RestartStrip();
            }

            half4 frag(g2f i) : SV_Target {
                // 使用NDC坐标采样屏幕纹理
                float2 screenUV = i.ndc.xy * 0.5 + 0.5;
                return SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, screenUV);
            }
            ENDHLSL
        }
    }
}
</code></pre>
<hr>
<blockquote>
<p><a href="https://blog.csdn.net/chenghai37/category_13021255.html?fromshare=blogcolumn&amp;sharetype=blogcolumn&amp;sharerId=13021255&amp;sharerefer=PC&amp;sharesource=chenghai37&amp;sharefrom=from_link" target="_blank" rel="noopener nofollow">【从UnityURP开始探索游戏渲染】</a><strong>专栏-直达</strong></p>
</blockquote>
<p>（欢迎<em>点赞留言</em>探讨，更多人加入进来能更加完善这个探索的过程，🙏）</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.002777777777777778" data-date-updated="2025-08-16 17:38">2025-08-16 17:34</span>&nbsp;
<a href="https://www.cnblogs.com/SmalBox">SmalBox</a>&nbsp;
阅读(<span id="post_view_count">64</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19042368);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19042368', targetLink: 'https://www.cnblogs.com/SmalBox/p/19042368', title: '【渲染流水线】[几何阶段]-[归一化NDC]以UnityURP为例' })">举报</a>
</div>
        