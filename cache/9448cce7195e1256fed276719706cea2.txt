
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/didispace/p/18754629" title="发布于 2025-03-06 11:30">
    <span role="heading" aria-level="2">阿里最新开源QwQ-32B，效果媲美deepseek-r1满血版，部署成本又又又降低了！</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>3月6日最新消息，阿里云通义千问官方宣布推出最新推理模型 QwQ-32B，这一模型仅有 32B 参数，但在效果上与拥有 671B 参数的 DeepSeek-R1 相媲美。如果你自己部署 DeepSeek-R1 但资源不够的话，又多了一个新的选择。</p>
<p>QwQ-32B 的独特之处不仅在于其参数规模和效果表现，还集成了与 Agent 相关的能力。这使得模型在使用工具时能够进行批判性思考，并依据环境反馈灵活调整推理过程，极大提升了模型的适应性与智能性。</p>
<p>目前，QwQ-32B 已上线 Hugging Face、ModelScope、Ollama等平台，具体链接如下：</p>
<ul>
<li><a href="https://huggingface.co/Qwen/QwQ-32B" target="_blank" rel="noopener nofollow">https://huggingface.co/Qwen/QwQ-32B</a></li>
<li><a href="https://modelscope.cn/models/Qwen/QwQ-32B" target="_blank" rel="noopener nofollow">https://modelscope.cn/models/Qwen/QwQ-32B</a></li>
<li><a href="https://ollama.com/library/qwq" target="_blank" rel="noopener nofollow">https://ollama.com/library/qwq</a></li>
</ul>
<p>QwQ-32B 采用 Apache 2.0 开源协议，为广大开发者提供了便捷的使用途径。用户也可通过 <a href="https://chat.qwen.ai/?models=Qwen2.5-Plus" target="_blank" rel="noopener nofollow">Qwen Chat</a>直接体验其强大功能。</p>
<p>下图是其与其他热门模型的测试对比：</p>
<p><img src="https://img2024.cnblogs.com/other/626506/202503/626506-20250306113038761-481981747.png" alt="" loading="lazy"></p>
<p>测试结果令人瞩目。在数学推理的 AIME24 评测集以及编程能力的 LiveCodeBench 测试中，QwQ-32B 表现与 DeepSeek-R1 相当，远超 o1-mini 及相同尺寸的 R1 蒸馏模型。在由 Meta 首席科学家杨立昆领衔的 “最难 LLMs 评测榜” LiveBench、谷歌等提出的指令遵循能力 IFEval 评测集、加州大学伯克利分校等提出的评估准确调用函数或工具方面的 BFCL 测试中，QwQ-32B 更是超越了 DeepSeek-R1，展现出全面的优势。</p>
<h2 id="快速本地部署">快速本地部署</h2>
<p>如果想要快速本地部署尝试，那就继续清楚Ollama，两条命令快速搞定。</p>
<ol>
<li>安装 Ollama</li>
</ol>
<pre><code class="language-bash">curl -fsSL https://ollama.com/install.sh | sh
</code></pre>
<blockquote>
<p>如果本地MacOS或者Windows开发环境使用的话，也可以从前往官网下载客户端版本：<a href="https://ollama.com/download" target="_blank" rel="noopener nofollow">https://ollama.com/download</a></p>
</blockquote>
<ol start="2">
<li>启动 QwQ-32B</li>
</ol>
<pre><code class="language-bash">ollama run qwq
</code></pre>
<h2 id="spring-ai调用api集成">Spring AI调用API集成</h2>
<p>由于这里使用了Ollama来启动QwQ-32B并提供服务，所以Java开发者可以使用使用Spring AI Ollama来集成模型能力到自己的应用中去。</p>
<p>具体如何集成在之前介绍集成DeepSeek-R1的时候介绍过了，方法类似，就是换个模型名称。如果还不会的话，可以参考之前的这篇文章<a href="https://spring.didispace.com/article/spring-ai-ollama-deepseek.html#%E4%BD%BF%E7%94%A8spring-boot-spring-ai" target="_blank" rel="noopener nofollow">Spring AI + Ollama 实现 deepseek-r1 的API服务和调用</a>中使用Spring AI调API的部分。</p>
<p>感谢阅读！如果您也关注前沿AI和开发者相关资讯，欢迎点赞、关注支持一下。</p>
<blockquote>
<p>欢迎关注我的公众号：程序猿DD。第一时间了解前沿行业消息、分享深度技术干货、获取优质学习资源</p>
</blockquote>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.20126115924305554" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-03-06 11:31">2025-03-06 11:30</span>&nbsp;
<a href="https://www.cnblogs.com/didispace">程序猿DD</a>&nbsp;
阅读(<span id="post_view_count">658</span>)&nbsp;
评论(<span id="post_comment_count">2</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18754629" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18754629);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18754629', targetLink: 'https://www.cnblogs.com/didispace/p/18754629', title: '阿里最新开源QwQ-32B，效果媲美deepseek-r1满血版，部署成本又又又降低了！' })">举报</a>
</div>
        