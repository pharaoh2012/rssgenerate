
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/ibrahim/p/18624860/llama-3-2-90b-deploy-usecase" title="å‘å¸ƒäº 2024-12-23 19:22">
    <span role="heading" aria-level="2">Llama 3.2 900äº¿å‚æ•°è§†è§‰å¤šæ¨¡æ€å¤§æ¨¡å‹æœ¬åœ°éƒ¨ç½²åŠæ¡ˆä¾‹å±•ç¤º</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        
        æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•åœ¨æœ¬åœ°éƒ¨ç½²Llama 3.2 90Bï¼ˆ900äº¿å‚æ•°ï¼‰è§†è§‰å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå¹¶å¼€å‘ä¸€äº›Use Caseï¼Œå±•ç¤ºå…¶å¼ºå¤§çš„è§†è§‰ç†è§£èƒ½åŠ›ã€‚
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="llama-32-900äº¿å‚æ•°è§†è§‰å¤šæ¨¡æ€å¤§æ¨¡å‹æœ¬åœ°éƒ¨ç½²åŠæ¡ˆä¾‹å±•ç¤º">Llama 3.2 900äº¿å‚æ•°è§†è§‰å¤šæ¨¡æ€å¤§æ¨¡å‹æœ¬åœ°éƒ¨ç½²åŠæ¡ˆä¾‹å±•ç¤º</h1>
<p>æœ¬æ–‡å°†ä»‹ç»å¦‚ä½•åœ¨æœ¬åœ°éƒ¨ç½²Llama 3.2 90Bï¼ˆ900äº¿å‚æ•°ï¼‰è§†è§‰å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå¹¶å¼€å‘ä¸€äº›Use Caseï¼Œå±•ç¤ºå…¶å¼ºå¤§çš„è§†è§‰ç†è§£èƒ½åŠ›ã€‚</p>
<h2 id="llama-32-ä»‹ç»">Llama 3.2 ä»‹ç»</h2>
<p>ä»Šå¹´9æœˆï¼ŒMetaå…¬å¸å‘å¸ƒäº† Llama 3.2ç‰ˆæœ¬ï¼ŒåŒ…æ‹¬11B å’Œ 90Bçš„ä¸­å°å‹è§†è§‰å¤§è¯­è¨€æ¨¡å‹ï¼Œé€‚ç”¨äºè¾¹ç¼˜è®¡ç®—å’Œç§»åŠ¨è®¾å¤‡çš„1B å’Œ 3Bè½»é‡çº§æ–‡æœ¬æ¨¡å‹ï¼Œï¼Œå‡é¢„è®­ç»ƒåŸºç¡€ç‰ˆå’ŒæŒ‡ä»¤å¾®è°ƒç‰ˆï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œè¿˜å‘å¸ƒäº†ä¸€ä¸ªå®‰å…¨æ¨¡å‹Llama Guard 3ã€‚<br>
Llama 3.2 Vision æ˜¯ Meta å‘å¸ƒçš„æœ€å¼ºå¤§çš„å¼€æºå¤šæ¨¡æ€æ¨¡å‹ã€‚å®ƒå…·æœ‰å‡ºè‰²çš„è§†è§‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ç”¨äºå®Œæˆå„ç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬è§†è§‰æ¨ç†ä¸å®šä½ã€æ–‡æ¡£é—®ç­”å’Œå›¾åƒ - æ–‡æœ¬æ£€ç´¢ï¼Œæ€ç»´é“¾ (Chain of Thought, CoT) ç­”æ¡ˆé€šå¸¸éå¸¸å¥½ï¼Œè¿™ä½¿å¾—è§†è§‰æ¨ç†ç‰¹åˆ«å¼ºå¤§ã€‚</p>
<p>Llama 2äº2023å¹´7æœˆå‘å¸ƒï¼ŒåŒ…å«7Bã€13Bå’Œ70Bå‚æ•°çš„æ¨¡å‹ã€‚ä¹‹åMetaåœ¨2024å¹´4æœˆæ¨å‡ºäº†Llama 3ï¼Œå¹¶åœ¨2024å¹´7æœˆè¿…é€Ÿå‘å¸ƒäº†Llama 3.1ç‰ˆæœ¬ï¼Œæ›´æ–°äº†8Bå’Œ70Bçš„æ¨¡å‹ï¼Œæœ€é‡è¦çš„æ˜¯æ¨å‡ºäº†ä¸€ä¸ªæ‹¥æœ‰405Bå‚æ•°çš„åŸºç¡€çº§æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹æ”¯æŒ8ç§è¯­è¨€ï¼Œå…·å¤‡å·¥å…·è°ƒç”¨åŠŸèƒ½ï¼Œå¹¶ä¸”æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡çª—å£ã€‚</p>
<p>2024å¹´9æœˆä»½åˆšåˆšå‘å¸ƒäº†Llama 3.2æ¨¡å‹ï¼Œå¢å¼ºäº†Llama 3.1çš„8Bå’Œ70Bæ¨¡å‹ï¼Œæ„å»ºå‡º11Bå’Œ90Bå¤šæ¨¡æ€æ¨¡å‹ï¼Œä½¿å…¶å…·å¤‡äº†è§†è§‰èƒ½åŠ›ã€‚</p>
<p>Llama 3.2 ç³»åˆ—ä¸­æœ€å¤§çš„ä¸¤ä¸ªæ¨¡å‹ 11B å’Œ 90B æ”¯æŒå›¾åƒæ¨ç†ä½¿ç”¨æ¡ˆä¾‹ï¼Œä¾‹å¦‚æ–‡æ¡£çº§ç†è§£ï¼ˆåŒ…æ‹¬å›¾è¡¨å’Œå›¾å½¢ï¼‰ã€å›¾åƒå­—å¹•å’Œè§†è§‰æ¥åœ°ä»»åŠ¡ï¼ˆä¾‹å¦‚æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°å®šå‘ç²¾ç¡®å®šä½å›¾åƒä¸­çš„å¯¹è±¡ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥é—®ä»–ä»¬å…¬å¸åœ¨ä¸Šä¸€å¹´çš„å“ªä¸ªæœˆé”€å”®é¢æœ€å¥½ï¼Œç„¶å Llama 3.2 å¯ä»¥æ ¹æ®å¯ç”¨å›¾è¡¨è¿›è¡Œæ¨ç†å¹¶å¿«é€Ÿæä¾›ç­”æ¡ˆã€‚è¿˜å¯ä»¥ä½¿ç”¨åœ°å›¾è¿›è¡Œæ¨ç†å¹¶å¸®åŠ©å›ç­”è¯¸å¦‚å¾’æ­¥æ—…è¡Œä½•æ—¶ä¼šé‡åˆ°é™¡å³­çš„åœ°å½¢ï¼Œæˆ–åœ¨åœ°å›¾ä¸Šæ ‡è®°è·¯çº¿çš„è·ç¦»ç­‰é—®é¢˜ã€‚11B å’Œ 90B å‹å·è¿˜å¯ä»¥é€šè¿‡ä»å›¾åƒä¸­æå–ç»†èŠ‚ã€ç†è§£åœºæ™¯ï¼Œç„¶åç”Ÿæˆä¸€ä¸¤ä¸ªå¯ç”¨ä½œå›¾åƒæ ‡é¢˜çš„å¥å­æ¥å¸®åŠ©è®²è¿°æ•…äº‹ï¼Œä»è€Œå¼¥åˆè§†è§‰å’Œè¯­è¨€ä¹‹é—´çš„å·®è·ã€‚</p>
<p>æ­¤å¤–ï¼ŒMetaè¿˜å‘å¸ƒäº†ä¸¤ä¸ªè½»é‡çº§çš„æ¨¡å‹ï¼š1Bå’Œ3Bæ¨¡å‹ï¼Œè¿™äº›å°†å¸®åŠ©æ”¯æŒè®¾å¤‡ç«¯çš„AIåº”ç”¨ã€‚</p>
<p>åœ¨æœ¬åœ°è¿è¡Œè¿™äº›æ¨¡å‹æœ‰ä¸¤ä¸ªä¸»è¦ä¼˜åŠ¿ã€‚é¦–å…ˆï¼Œæç¤ºå’Œå“åº”å¯èƒ½ä¼šè®©äººæ„Ÿè§‰æ˜¯å³æ—¶çš„ï¼Œå› ä¸ºå¤„ç†æ˜¯åœ¨æœ¬åœ°å®Œæˆçš„ã€‚å…¶æ¬¡ï¼Œåœ¨æœ¬åœ°è¿è¡Œæ¨¡å‹ä¸ä¼šå°†æ¶ˆæ¯å’Œæ—¥å†ä¿¡æ¯ç­‰æ•°æ®å‘é€åˆ°äº‘ä¸­ï¼Œä»è€Œä¿æŠ¤éšç§ï¼Œä»è€Œä½¿æ•´ä¸ªåº”ç”¨ç¨‹åºæ›´åŠ ç§å¯†ã€‚ç”±äºå¤„ç†æ˜¯åœ¨æœ¬åœ°å¤„ç†çš„ï¼Œå› æ­¤åº”ç”¨ç¨‹åºå¯ä»¥æ¸…æ¥šåœ°æ§åˆ¶å“ªäº›æŸ¥è¯¢ä¿ç•™åœ¨è®¾å¤‡ä¸Šï¼Œå“ªäº›æŸ¥è¯¢å¯èƒ½éœ€è¦ç”±äº‘ä¸­çš„æ›´å¤§æ¨¡å‹å¤„ç†ã€‚</p>
<p>Llama Guard 3ä¹Ÿæ˜¯3.2ç‰ˆæœ¬çš„ä¸€éƒ¨åˆ†ï¼Œè¿™æ˜¯ä¸€ç§è§†è§‰å®‰å…¨æ¨¡å‹ï¼Œå¯ä»¥æ ‡è®°å’Œè¿‡æ»¤ç”¨æˆ·è¾“å…¥çš„æœ‰é—®é¢˜çš„å›¾åƒå’Œæ–‡æœ¬æç¤ºè¯ã€‚</p>
<h2 id="gpuæ˜¾å¡å†…å­˜ä¼°ç®—">GPUæ˜¾å¡å†…å­˜ä¼°ç®—</h2>
<p>å¦‚ä½•è®¡ç®—å¤§æ¨¡å‹åˆ°åº•éœ€è¦å¤šå°‘æ˜¾å­˜ï¼Œæ˜¯å¸¸å¸¸è¢«é—®èµ·çš„é—®é¢˜ï¼Œäº†è§£å¦‚ä½•ä¼°ç®—æ‰€éœ€çš„ GPU å†…å­˜ã€æ­£ç¡®è°ƒæ•´ç¡¬ä»¶å¤§å°ä»¥æœåŠ¡è¿™äº›æ¨¡å‹è‡³å…³é‡è¦ã€‚è¿™æ˜¯è¡¡é‡ä½ å¯¹è¿™äº›å¤§æ¨¡å‹åœ¨ç”Ÿäº§ä¸­çš„éƒ¨ç½²å’Œå¯æ‰©å±•æ€§çš„ç†è§£ç¨‹åº¦çš„å…³é”®æŒ‡æ ‡ã€‚</p>
<p>è¦ä¼°ç®—æœåŠ¡å¤§å‹è¯­è¨€æ¨¡å‹æ‰€éœ€çš„ GPU å†…å­˜ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å…¬å¼ï¼š</p>
<p>$M=\frac{(P * 4 B)}{(32 / Q)} * 1.2$</p>
<ul>
<li>Mæ˜¯æ‰€éœ€çš„ GPU æ˜¾å¡å†…å­˜ï¼ˆå•ä½ï¼šGBåƒå…†å­—èŠ‚ï¼‰ã€‚</li>
<li>Pæ˜¯æ¨¡å‹ä¸­çš„å‚æ•°æ•°é‡ï¼Œè¡¨ç¤ºæ¨¡å‹çš„å¤§å°ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œä½¿ç”¨çš„ Llama 90Bæ¨¡å‹æœ‰ 900 äº¿ä¸ªå‚æ•°ï¼Œåˆ™è¯¥å€¼å°†ä¸º 90ã€‚</li>
<li>4Bè¡¨ç¤ºæ¯ä¸ªå‚æ•°ä½¿ç”¨ 4 ä¸ªå­—èŠ‚ã€‚æ¯ä¸ªå‚æ•°é€šå¸¸éœ€è¦ 4 ä¸ªå­—èŠ‚çš„å†…å­˜ã€‚è¿™æ˜¯å› ä¸ºæµ®ç‚¹ç²¾åº¦é€šå¸¸å ç”¨ 4 ä¸ªå­—èŠ‚ï¼ˆ32 ä½ï¼‰ã€‚ä½†æ˜¯ï¼Œå¦‚æœä½¿ç”¨åŠç²¾åº¦ï¼ˆ16 ä½ï¼‰ï¼Œåˆ™è®¡ç®—å°†ç›¸åº”è°ƒæ•´ã€‚</li>
<li>Qæ˜¯åŠ è½½æ¨¡å‹çš„ä½æ•°ï¼ˆä¾‹å¦‚ï¼Œ16 ä½æˆ– 32 ä½ï¼‰ã€‚æ ¹æ®ä»¥ 16 ä½è¿˜æ˜¯ 32 ä½ç²¾åº¦åŠ è½½æ¨¡å‹ï¼Œæ­¤å€¼å°†ä¼šå‘ç”Ÿå˜åŒ–ã€‚16 ä½ç²¾åº¦åœ¨è®¸å¤šå¤§æ¨¡å‹éƒ¨ç½²ä¸­å¾ˆå¸¸è§ï¼Œå› ä¸ºå®ƒå¯ä»¥å‡å°‘å†…å­˜ä½¿ç”¨é‡ï¼ŒåŒæ—¶ä¿æŒè¶³å¤Ÿçš„å‡†ç¡®æ€§ã€‚</li>
<li>1.2 ä¹˜æ•°å¢åŠ äº† 20% çš„å¼€é”€ï¼Œä»¥è§£å†³æ¨ç†æœŸé—´ä½¿ç”¨çš„é¢å¤–å†…å­˜é—®é¢˜ã€‚è¿™ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå®‰å…¨ç¼“å†²åŒºï¼›å®ƒå¯¹äºè¦†ç›–æ¨¡å‹æ‰§è¡ŒæœŸé—´æ¿€æ´»å’Œå…¶ä»–ä¸­é—´ç»“æœæ‰€éœ€çš„å†…å­˜è‡³å…³é‡è¦ã€‚</li>
</ul>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/gpu-compute-components.png" alt="gpu-compute-components" loading="lazy"></p>
<p>è¿™é‡Œæƒ³è¦ä¼°ç®—ä¸ºå…·æœ‰ 90Bï¼ˆ900 äº¿ï¼‰ä¸ªå‚æ•°ã€ä»¥ 16 ä½ç²¾åº¦åŠ è½½çš„ Llama 3.2 90B è§†è§‰å¤§æ¨¡å‹æä¾›æœåŠ¡æ‰€éœ€çš„å†…å­˜ï¼š</p>
<p>$M=\frac{(90 * 4)}{(32 / 16)} * 1.2 = 216 GB$</p>
<p>è¿™ä¸ªè®¡ç®—å‘Šè¯‰æˆ‘ä»¬ï¼Œéœ€è¦å¤§çº¦216 GB çš„ GPU å†…å­˜æ¥ä¸º 16 ä½æ¨¡å¼ä¸‹å…·æœ‰ 900 äº¿ä¸ªå‚æ•°çš„ Llama 3.2 90B å¤§æ¨¡å‹æä¾›æœåŠ¡ã€‚</p>
<p>å› æ­¤ï¼Œå•ä¸ªå…·æœ‰ 80 GB å†…å­˜çš„ NVIDIA A100 GPU æˆ–è€… H00 GPU ä¸è¶³ä»¥æ»¡è¶³æ­¤æ¨¡å‹çš„éœ€æ±‚ï¼Œéœ€è¦è‡³å°‘3å¼ å…·æœ‰ 80 GB å†…å­˜çš„ A100 GPU æ‰èƒ½æœ‰æ•ˆå¤„ç†å†…å­˜è´Ÿè½½ã€‚</p>
<p>æ­¤å¤–ï¼Œä»…åŠ è½½ CUDA å†…æ ¸å°±ä¼šæ¶ˆè€— 1-2GB çš„å†…å­˜ã€‚å®é™…ä¸Šï¼Œæ— æ³•ä»…ä½¿ç”¨å‚æ•°å¡«æ»¡æ•´ä¸ª GPU å†…å­˜ä½œä¸ºä¼°ç®—ä¾æ®ã€‚</p>
<p>å¦‚æœæ˜¯è®­ç»ƒå¤§æ¨¡å‹æƒ…å†µï¼ˆä¸‹ä¸€ç¯‡æ–‡ç« ä¼šä»‹ç»ï¼‰ï¼Œåˆ™éœ€è¦æ›´å¤šçš„ GPU å†…å­˜ï¼Œå› ä¸ºä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œå‰å‘æ¿€æ´»æ¯ä¸ªå‚æ•°éƒ½éœ€è¦é¢å¤–çš„å†…å­˜ã€‚</p>
<p>ä½†åšä¸»å›Šä¸­ç¾æ¶©ï¼Œä¸ºäº†å®Œæˆè¿™ç¯‡æ–‡ç« ï¼Œé€‰æ‹© <a href="https://huggingface.co/unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit" target="_blank" rel="noopener nofollow">unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit</a> çš„Llama 3.2 90B è§†è§‰å¤§æ¨¡å‹çš„4bité‡åŒ–æ¨¡å‹ï¼Œæ ¹æ®ä¸Šé¢çš„ä¼°ç®—å…¬å¼ï¼Œä»…ä½¿ç”¨1å¼ å…·æœ‰ 80 GB å†…å­˜çš„ GPU å°±å¯ä»¥è¿è¡Œå®Œæˆæœ¬æ–‡æ¡ˆä¾‹æ‰€éœ€çš„æ¨¡å‹æ¨ç†ä»»åŠ¡ã€‚</p>
<h2 id="ç¯å¢ƒæ­å»º">ç¯å¢ƒæ­å»º</h2>
<h3 id="äº‘æœåŠ¡å™¨">äº‘æœåŠ¡å™¨</h3>
<p>æ‰¾ä¸€å°å¸¦ä¸€å¼ H800 GPU æ˜¾å¡çš„æœåŠ¡å™¨ï¼ˆåšä¸»ç§Ÿç”¨äº†ä¸€å°æœåŠ¡å™¨ï¼ŒèŠ±è´¹å¤§æ¦‚50å…ƒå·¦å³å°±èƒ½è·‘å®Œæœ¬æ–‡æ¡ˆä¾‹use caseï¼Œå½“ç„¶è¿˜éœ€è¦ä¸€äº›é™ä½è´¹ç”¨çš„å°æŠ€å·§ï¼Œæ¯”å¦‚æå‰ç§Ÿç”¨é…ç½®çš„æœåŠ¡å™¨æŠŠæ¨¡å‹æ–‡ä»¶ä¸‹è½½åˆ°æœåŠ¡å™¨ï¼Œè¿™æ ·å°±å¯ä»¥èŠ‚çœå¾ˆå¤šè´¹ç”¨ğŸ’°ï¼‰ï¼Œå…·ä½“é…ç½®å¦‚ä¸‹ï¼š</p>
<ul>
<li>GPUï¼šH800ï¼Œ80GBæ˜¾å­˜</li>
<li>CPU:20 æ ¸ï¼ŒXeon(R) Platinum 8458P</li>
<li>å†…å­˜:100 GB</li>
<li>ç³»ç»Ÿç›˜:30 GB</li>
<li>æ•°æ®ç›˜:200 GBï¼ˆç”¨äºå­˜æ”¾æ¨¡å‹æ–‡ä»¶ï¼‰</li>
</ul>
<blockquote>
<p>è¯»è€…å¯ä»¥æ·»åŠ ä¸‹é¢åšä¸»å…¬ä¼—å·ï¼Œå›å¤241220ï¼Œè·å–ç§Ÿç”¨äº‘æœåŠ¡å™¨çš„é“¾æ¥å’Œæ–¹æ³•ï¼Œæ— éœ€å®‰è£…ä»¥ä¸‹æ‰€éœ€çš„CUDAã€cuDNNã€Pythonå’ŒPyTorchï¼Œç›´æ¥ä½¿ç”¨ã€‚</p>
</blockquote>
<blockquote>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/qrcode.jpg" alt="å…¬ä¼—å·" loading="lazy"></p>
</blockquote>
<p>å¦‚æœè¯»è€…è‡ªè¡Œå®‰è£…CUDAå’ŒcuDNNï¼Œå¹¶é…ç½®ç¯å¢ƒå˜é‡ï¼Œå…·ä½“æ–¹æ³•å¯ä»¥å‚è€ƒè‹±ä¼Ÿè¾¾å®˜ç½‘ï¼š</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener nofollow">CUDAå®‰è£…æ•™ç¨‹</a>ã€‚</li>
</ul>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/cuda.png" alt="CUDA" loading="lazy"></p>
<ul>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener nofollow">cuDNNå®‰è£…æ•™ç¨‹</a></li>
</ul>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/cuDNN.png" alt="cuDNN" loading="lazy"></p>
<p>æœ¬æ–‡æ‰€éœ€çš„çš„CUDAã€cuDNNã€Pythonå’ŒPyTorchç‰ˆæœ¬å¦‚ä¸‹ï¼š</p>
<ul>
<li>CUDAç‰ˆæœ¬ï¼š12.4</li>
<li>cuDNNç‰ˆæœ¬ï¼š9.1.0.70</li>
<li>Pythonç‰ˆæœ¬ï¼š3.12.2</li>
<li>PyTorchç‰ˆæœ¬ï¼š2.5.1</li>
</ul>
<p>è¯»è€…å¯ä»¥ä½¿ç”¨VSCodeã€Cursoræˆ–è€…å…¶å®ƒSSHå®¢æˆ·ç«¯è¿æ¥åˆ°äº‘æœåŠ¡å™¨ï¼Œç„¶åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…CUDAå’ŒcuDNNã€‚</p>
<p>å®‰è£…å‰éœ€è¦ç¡®ä¿æœåŠ¡å™¨ä¸Šå·²ç»å®‰è£…äº†NVIDIAé©±åŠ¨ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ˜¯å¦å®‰è£…äº†NVIDIAé©±åŠ¨ï¼š</p>
<pre><code class="language-shell">   nvidia-smi
</code></pre>
<p>å®‰è£…å‰ï¼Œéœ€è¦ç¡®ä¿<a href="https://pytorch.org/" target="_blank" rel="noopener nofollow">PyTorch</a>ä¸CUDAçš„ç‰ˆæœ¬å¯¹åº”ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚</p>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/pytorch-version.png" alt="PyTorchä¸CUDAçš„å¯¹åº”ç‰ˆæœ¬" loading="lazy"></p>
<h3 id="1-å®‰è£…cuda-124">1. å®‰è£…CUDA 12.4</h3>
<pre><code class="language-shell">wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda_12.4.0_535.104.05_linux.run
sudo sh cuda_12.4.0_535.104.05_linux.run
</code></pre>
<h3 id="2-å®‰è£…cudnn-91070">2. å®‰è£…cuDNN 9.1.0.70</h3>
<pre><code class="language-shell"># é¦–å…ˆä»NVIDIAå¼€å‘è€…ç½‘ç«™ä¸‹è½½cuDNN
tar -xvf cudnn-linux-x86_64-9.1.0.70_cuda12-archive.tar.xz
sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda/include 
sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
</code></pre>
<h3 id="3-é…ç½®ç¯å¢ƒå˜é‡">3. é…ç½®ç¯å¢ƒå˜é‡</h3>
<pre><code class="language-shell">echo 'export PATH=/usr/local/cuda-12.4/bin:$PATH' &gt;&gt; ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc
source ~/.bashrc
</code></pre>
<h3 id="4-å®‰è£…python-3122">4. å®‰è£…Python 3.12.2</h3>
<pre><code class="language-shell">sudo apt update
sudo apt install software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt install python3.12
sudo apt install python3.12-venv python3.12-dev
</code></pre>
<h3 id="5-å®‰è£…pip">5. å®‰è£…pip</h3>
<pre><code class="language-shell">curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
python3.12 get-pip.py
</code></pre>
<h3 id="6-å®‰è£…pytorch-251">6. å®‰è£…PyTorch 2.5.1</h3>
<pre><code class="language-shell">pip3 install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
</code></pre>
<p>è¯»è€…å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹GPUå†…å­˜ä¿¡æ¯</p>
<pre><code class="language-shell">   nvidia-smi
</code></pre>
<p>å¦‚æœå®‰è£…æ­£ç¡®ï¼Œåˆ™å¯ä»¥çœ‹åˆ°ç±»ä¼¼å¦‚ä¸‹çš„GPUå†…å­˜ä¿¡æ¯</p>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/nvidia-smi.png" alt="nvidia-smi" loading="lazy"></p>
<h2 id="ä¸‹è½½æ¨¡å‹æ–‡ä»¶">ä¸‹è½½æ¨¡å‹æ–‡ä»¶</h2>
<p>ä¸ºäº†åœ¨æœ¬åœ°éƒ¨ç½²æ¨¡å‹ï¼Œäº‹å…ˆéœ€è¦ä»Huggingfaceä¸Šæ‰‹åŠ¨ä¸‹è½½Unslothé‡åŒ–è¿‡çš„Llama 3.2 90B è§†è§‰å¤§æ¨¡å‹çš„4 bité‡åŒ–æ¨¡å‹<a href="https://huggingface.co/unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit" target="_blank" rel="noopener nofollow">unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit</a> ã€‚</p>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/hf_unsloth_llama90b.png" alt="unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit" loading="lazy"></p>
<ol>
<li>å®‰è£…Huggingface Hubå®¢æˆ·ç«¯</li>
</ol>
<pre><code class="language-shell">pip install -U huggingface_hub
</code></pre>
<ol start="2">
<li>è®¾ç½®Huggingfaceé•œåƒæºï¼ˆå¿…é¡»è®¾ç½®ï¼Œå¦åˆ™ä¸‹è½½æ¨¡å‹ä¼šæŠ¥é”™âš ï¸ï¼‰</li>
</ol>
<pre><code class="language-shell">export HF_ENDPOINT=https://hf-mirror.com
</code></pre>
<ol start="3">
<li>ç™»å½•Huggingface ï¼ˆè·³è¿‡è¿™æ­¥ï¼‰</li>
</ol>
<pre><code class="language-shell">huggingface-cli login
</code></pre>
<ol start="4">
<li>ä¸‹è½½æ¨¡å‹</li>
</ol>
<pre><code class="language-shell">huggingface-cli download --resume-download unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit --local-dir ã€è¿™é‡Œæ›¿æ¢ä¸ºæ¨¡å‹æœ¬åœ°å­˜æ”¾è·¯å¾„ã€‘
</code></pre>
<p>ä¸‹è½½æˆåŠŸåçš„Llama 3.2 90Bè§†è§‰å¤§æ¨¡å‹çš„æ–‡ä»¶åˆ—è¡¨å¦‚ä¸‹ï¼š</p>
<pre><code class="language-shell">drwxr-xr-x 3 root root       4096 Dec 19 16:33 ./
drwxr-xr-x 3 root root       4096 Dec 19 16:33 ../
drwxr-xr-x 3 root root       4096 Dec 19 10:08 .cache/
-rw-r--r-- 1 root root       1570 Dec 19 10:08 .gitattributes
-rw-r--r-- 1 root root       6131 Dec 19 10:08 README.md
-rw-r--r-- 1 root root       5151 Dec 19 10:08 chat_template.json
-rw-r--r-- 1 root root       5870 Dec 19 10:08 config.json
-rw-r--r-- 1 root root        210 Dec 19 10:08 generation_config.json
-rw-r--r-- 1 root root 4947107668 Dec 19 11:22 model-00001-of-00010.safetensors
-rw-r--r-- 1 root root 4977064274 Dec 19 10:58 model-00002-of-00010.safetensors
-rw-r--r-- 1 root root 4977064462 Dec 19 10:36 model-00003-of-00010.safetensors
-rw-r--r-- 1 root root 4977098481 Dec 19 10:40 model-00004-of-00010.safetensors
-rw-r--r-- 1 root root 4933796471 Dec 19 10:34 model-00005-of-00010.safetensors
-rw-r--r-- 1 root root 4977064512 Dec 19 10:40 model-00006-of-00010.safetensors
-rw-r--r-- 1 root root 4977064455 Dec 19 11:08 model-00007-of-00010.safetensors
-rw-r--r-- 1 root root 4977098479 Dec 19 10:47 model-00008-of-00010.safetensors
-rw-r--r-- 1 root root 4933796461 Dec 19 11:07 model-00009-of-00010.safetensors
-rw-r--r-- 1 root root 4263159971 Dec 19 16:33 model-00010-of-00010.safetensors
-rw-r--r-- 1 root root     678066 Dec 19 10:40 model.safetensors.index.json
-rw-r--r-- 1 root root        477 Dec 19 10:40 preprocessor_config.json
-rw-r--r-- 1 root root        454 Dec 19 10:40 special_tokens_map.json
-rw-r--r-- 1 root root   17210088 Dec 19 10:40 tokenizer.json
-rw-r--r-- 1 root root      55931 Dec 19 10:40 tokenizer_config.json
</code></pre>
<h2 id="å®‰è£…æ¨¡å‹è¿è¡Œç¯å¢ƒunsloth">å®‰è£…æ¨¡å‹è¿è¡Œç¯å¢ƒUnsloth</h2>
<h3 id="å®‰è£…conda">å®‰è£…Conda</h3>
<pre><code class="language-shell">mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
~/miniconda3/bin/conda init zsh
</code></pre>
<h3 id="å®‰è£…æ¨¡å‹è¿è¡Œç¯å¢ƒunsloth-1">å®‰è£…æ¨¡å‹è¿è¡Œç¯å¢ƒUnsloth</h3>
<p>ä»¥ä¸‹ä»£ç ç”¨äºå®‰è£…æ¨¡å‹è¿è¡Œç¯å¢ƒUnslothï¼Œå¹¶å¯¼å…¥æ¨¡å‹è¿è¡Œæ‰€éœ€çš„ä¾èµ–åŒ…ã€‚</p>
<pre><code class="language-shell">conda create --name unsloth_env \
    python=3.11 \
    pytorch-cuda=12.1 \
    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \
    -y
conda activate unsloth_env

pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
pip install --no-deps trl peft accelerate bitsandbytes
</code></pre>
<pre><code class="language-python">import warnings
warnings.filterwarnings('ignore')

%pip install unsloth
</code></pre>
<h2 id="åŠ è½½æ¨¡å‹">åŠ è½½æ¨¡å‹</h2>
<pre><code class="language-python">from unsloth import FastVisionModel # ä»unslothåº“ä¸­å¯¼å…¥FastVisionModelç±»ï¼Œç”¨äºå¤„ç†è§†è§‰ç›¸å…³çš„å¤§è¯­è¨€æ¨¡å‹

import torch

model, tokenizer = FastVisionModel.from_pretrained(
    "/root/autodl-fs/model/unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit", # æ­¤å¤„æ›¿æ¢ä¸ºLlama-3.2-90B-Vision-Instruct-bnb-4bitåœ¨æ¨¡å‹æœ¬åœ°å­˜æ”¾çš„ç»å¯¹è·¯å¾„
    load_in_4bit = True, # ä½¿ç”¨4bitä»¥å‡å°‘å†…å­˜ä½¿ç”¨ã€‚Falseåˆ™ä½¿ç”¨16bit LoRAã€‚
    use_gradient_checkpointing = "unsloth", # Trueæˆ–"unsloth"ç”¨äºé•¿æ–‡æœ¬ä¸Šä¸‹æ–‡
)

FastVisionModel.for_inference(model) # å¯åŠ¨è§†è§‰å¤§æ¨¡å‹çš„æ¨ç†æ¨¡å¼
</code></pre>
<pre><code>==((====))==  Unsloth 2024.12.8: Fast Mllama vision patching. Transformers: 4.46.3.
   \\   /|    GPU: NVIDIA H800 PCIe. Max memory: 79.205 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!



Loading checkpoint shards:   0%|          | 0/10 [00:00&lt;?, ?it/s]
</code></pre>
<p>åŠ è½½æ¨¡å‹æˆåŠŸåï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ¨¡å‹å ç”¨å†…å­˜</p>
<pre><code class="language-shell">nvidia-smi -l 2
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/gpu-mem.png" alt="nvidia-smi" loading="lazy"></p>
<h2 id="llama-32-90b-å¤šæ¨¡æ€è§†è§‰å¤§æ¨¡å‹æ¨ç†æ¡ˆä¾‹å±•ç¤º">Llama 3.2 90B å¤šæ¨¡æ€è§†è§‰å¤§æ¨¡å‹æ¨ç†æ¡ˆä¾‹å±•ç¤º</h2>
<p>æœ¬æ–‡ä»¥ä¸‹å†…å®¹ä½¿ç”¨jupyter notebookè¿›è¡Œæ¼”ç¤ºã€‚</p>
<blockquote>
<p>è¯»è€…å¯ä»¥æ·»åŠ ä¸‹é¢åšä¸»å…¬ä¼—å·ï¼Œå›å¤241220ï¼Œè·å–æœ¬æ–‡æ‰€ä½¿ç”¨çš„notebookæ–‡ä»¶ã€‚</p>
</blockquote>
<blockquote>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/qrcode.jpg" alt="å…¬ä¼—å·" loading="lazy"></p>
</blockquote>
<p>å°è£…æ¨¡å‹æ¨ç†å‡½æ•°</p>
<pre><code class="language-python">def llama32_image(instruction, image_url):
    from PIL import Image
    image = Image.open(image_url)

    messages = [
        {"role": "user", "content": [
            {"type": "image"},
            {"type": "text", "text": instruction}
        ]}
    ]
    
    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
    inputs = tokenizer(
        image,
        input_text,
        add_special_tokens = False,
        return_tensors = "pt",
    ).to("cuda")

    from transformers import TextStreamer
    text_streamer = TextStreamer(tokenizer, skip_prompt = True)
    output = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 2048,
                    use_cache = True, temperature = 1.5, min_p = 0.1)
    return output


def llama32_text(instruction):
    messages = [
        {"role": "user", "content": [
            {"type": "text", "text": instruction}
        ]}
    ]
    
    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
    inputs = tokenizer(
        None,
        input_text,
        add_special_tokens = False,
        return_tensors = "pt",
    ).to("cuda")

    from transformers import TextStreamer
    text_streamer = TextStreamer(tokenizer, skip_prompt = True)
    output = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 2048,
                    use_cache = True, temperature = 1.5, min_p = 0.1)
    return output

import os
import requests
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt

def disp_image(address):
    if address.startswith("http://") or address.startswith("https://"):
        response = requests.get(address)
        img = Image.open(BytesIO(response.content))
    else:
        img = Image.open(address)
    
    plt.imshow(img)
    plt.axis('off')
    plt.show()
</code></pre>
<h3 id="1-èƒå‹è­¦å‘Šè¯†åˆ«">1. èƒå‹è­¦å‘Šè¯†åˆ«</h3>
<pre><code class="language-python">disp_image("images/tire_pressure.png")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/tire_pressure.png" alt="png" loading="lazy"></p>
<p>ä¸Šå›¾æ˜¯ä¸€å¼ æ±½è½¦ä»ªè¡¨ç›˜ä¸Šè½®èƒå‹åŠ›å‘Šè­¦çš„å›¾ç‰‡ï¼Œä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡è¿›è¡Œæé—®ï¼Œé—®é¢˜åœ¨questionå˜é‡ä¸­ï¼Œæ¨¡å‹æ¨ç†ç»“æœåœ¨resultå˜é‡ä¸­ã€‚</p>
<blockquote>
<p>ç”±äºLlama 3.2ç›®å‰æ²¡æœ‰ä¸­æ–‡ç‰ˆæœ¬ï¼Œæ‰€ä»¥æ¨¡å‹æ¨ç†çš„è¾“å…¥è¾“å‡ºéƒ½æ˜¯è‹±æ–‡ï¼Œåšä¸»ä¼šå°†è¾“å…¥è¾“å‡ºçš„è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼Œæ–¹ä¾¿è¯»è€…ç†è§£ã€‚</p>
</blockquote>
<blockquote>
<p>æœŸå¾…ä¸ä¹…çš„å°†æ¥Llama 3.2 90B è§†è§‰å¤§æ¨¡å‹ä¼šæ¨å‡ºä¸­æ–‡ç‰ˆæœ¬ã€‚</p>
</blockquote>
<pre><code class="language-python">question = ("What's the problem this is about?"
             " What should be good numbers?")
# è¿™ä¸ªæ˜¯å…³äºä»€ä¹ˆçš„é—®é¢˜ï¼Ÿä»€ä¹ˆæ ·çš„æ•°å€¼æ‰æ˜¯åˆé€‚çš„ï¼Ÿ
result = llama32_image(question, "images/tire_pressure.png")

print(result)
</code></pre>
<pre><code>The problem being shown is a low tire pressure warning. The recommended tire pressures are displayed in the dashboard's display screen, with the current pressure displayed next to each tire. The recommended pressure for this particular car is 33 pounds per square inch (psi) for both the front and back tires. 

To rectify this issue, one should inflate the tires to the recommended pressure to ensure proper safety and performance while driving. It's also a good idea to check tire pressures regularly, as under-inflated tires can lead to reduced fuel efficiency, uneven tire wear, and increased risk of tire failure.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>è¿™ä¸ªé—®é¢˜æ˜¾ç¤ºçš„æ˜¯è½®èƒå‹åŠ›è¿‡ä½è­¦å‘Šã€‚ä»ªè¡¨ç›˜æ˜¾ç¤ºå±ä¸Šæ˜¾ç¤ºäº†æ¨èçš„è½®èƒå‹åŠ›ï¼Œæ¯ä¸ªè½®èƒæ—è¾¹éƒ½æ˜¾ç¤ºäº†å½“å‰å‹åŠ›ã€‚å¯¹äºè¿™è¾†ç‰¹å®šçš„æ±½è½¦æ¥è¯´ï¼Œå‰è½®å’Œåè½®çš„æ¨èå‹åŠ›éƒ½æ˜¯33ç£…/å¹³æ–¹è‹±å¯¸(psi)ã€‚<br>
ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåº”è¯¥å°†è½®èƒå……æ°”åˆ°æ¨èçš„å‹åŠ›ï¼Œä»¥ç¡®ä¿è¡Œé©¶æ—¶çš„å®‰å…¨æ€§å’Œæ€§èƒ½ã€‚å®šæœŸæ£€æŸ¥è½®èƒå‹åŠ›ä¹Ÿæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå› ä¸ºè½®èƒå……æ°”ä¸è¶³ä¼šå¯¼è‡´ç‡ƒæ²¹æ•ˆç‡é™ä½ã€è½®èƒç£¨æŸä¸å‡åŒ€ï¼Œå¹¶å¢åŠ è½®èƒæ•…éšœçš„é£é™©ã€‚</p>
</blockquote>
<h3 id="2-çŠ¬ç§è¯†åˆ«">2. çŠ¬ç§è¯†åˆ«</h3>
<pre><code class="language-python">disp_image("images/ww1.jpg")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/ww1.jpg" alt="png" loading="lazy"></p>
<p>ä¸Šå›¾æ˜¯ä¸€å¼ ç‹—ç‹—çš„å›¾ç‰‡ï¼Œä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡è¿›è¡Œæé—®ï¼Œé—®é¢˜åœ¨questionå˜é‡ä¸­ï¼Œæ¨¡å‹æ¨ç†ç»“æœåœ¨resultå˜é‡ä¸­ã€‚</p>
<pre><code class="language-python">question = ("What dog breed is this? Describe in one paragraph,"
            "and 3-5 short bullet points")
# è¿™æ˜¯ä»€ä¹ˆå“ç§çš„ç‹—ï¼Ÿç”¨ä¸€æ®µè¯æè¿°ï¼Œå¹¶åˆ—å‡º3-5ä¸ªè¦ç‚¹

result = llama32_image(question, "images/ww1.jpg")

print(result)
</code></pre>
<pre><code>The dog breed depicted in the image is a Labrador Retriever. 

Here are 3 key details that support this answer:

*   **Physical Characteristics**: The dog has a short, dense coat and a broad head with a well-defined stop at the eyes, which are hallmarks of the Labrador Retriever breed.
*   **Size and Proportion**: The dog appears to be a puppy, but its overall size and proportion are consistent with that of an adult Labrador Retriever.
*   **Temperament**: The dog's friendly and outgoing demeanor is also typical of the breed, which is known for its gentle nature and high intelligence.&lt;|eot_id|&gt;
tensor([[128000, 128006,    882, 128007,    271, 128256,   3923,   5679,  28875,
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>å›¾ä¸­æ˜¾ç¤ºçš„æ˜¯ä¸€åªæ‹‰å¸ƒæ‹‰å¤šçŠ¬ã€‚<br>
ä»¥ä¸‹æ˜¯3ä¸ªæ”¯æŒè¿™ä¸ªç»“è®ºçš„å…³é”®ç»†èŠ‚ï¼š</p>
<ul>
<li><strong>ä½“å‹ç‰¹å¾</strong>ï¼šè¿™åªç‹—æœ‰çŸ­è€Œæµ“å¯†çš„è¢«æ¯›ï¼Œå®½é˜”çš„å¤´éƒ¨ï¼Œçœ¼ç›å¤„æœ‰æ˜æ˜¾çš„é¢éª¨ï¼Œè¿™äº›éƒ½æ˜¯æ‹‰å¸ƒæ‹‰å¤šçŠ¬çš„å…¸å‹ç‰¹å¾ã€‚</li>
<li><strong>ä½“å‹å’Œæ¯”ä¾‹</strong>ï¼šè™½ç„¶è¿™åªç‹—çœ‹èµ·æ¥æ˜¯ä¸€åªå¹¼çŠ¬ï¼Œä½†å…¶æ•´ä½“ä½“å‹å’Œæ¯”ä¾‹ä¸æˆå¹´æ‹‰å¸ƒæ‹‰å¤šçŠ¬ä¸€è‡´ã€‚</li>
<li><strong>æ€§æ ¼ç‰¹å¾</strong>ï¼šè¿™åªç‹—å‹å¥½å¤–å‘çš„æ€§æ ¼ä¹Ÿæ˜¯è¯¥å“ç§çš„å…¸å‹ç‰¹å¾ï¼Œæ‹‰å¸ƒæ‹‰å¤šçŠ¬ä»¥å…¶æ¸©å’Œçš„æ€§æ ¼å’Œé«˜æ™ºå•†è€Œé—»åã€‚</li>
</ul>
</blockquote>
<pre><code class="language-python">disp_image("images/ww2.png")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/ww2.png" alt="png" loading="lazy"></p>
<p>å†æ¥çœ‹ä¸€å¼ ç‹—ç‹—çš„å›¾ç‰‡ï¼Œä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡è¿›è¡ŒåŒæ ·çš„æé—®ï¼Œé—®é¢˜åœ¨questionå˜é‡ä¸­ï¼Œæ¨¡å‹æ¨ç†ç»“æœåœ¨resultå˜é‡ä¸­ã€‚</p>
<pre><code class="language-python">result = llama32_image(question, "images/ww2.png")

print(result)   
</code></pre>
<pre><code>This dog appears to be a Labrador Retriever, a popular breed known for its friendly and outgoing nature.

Here are some key characteristics of Labradors:

â€¢ **Coat**: Short, dense, and smooth
â€¢ **Size**: Medium to large (55-80 pounds)
â€¢ **Eyes**: Brown or hazel
â€¢ **Ears**: Hanging, triangular in shape
â€¢ **Temperament**: Friendly, outgoing, and energetic&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>è¿™åªç‹—çœ‹èµ·æ¥æ˜¯ä¸€åªæ‹‰å¸ƒæ‹‰å¤šçŠ¬ï¼Œè¿™æ˜¯ä¸€ç§ä»¥å‹å¥½å’Œå¤–å‘æ€§æ ¼è‘—ç§°çš„æµè¡ŒçŠ¬ç§ã€‚<br>
ä»¥ä¸‹æ˜¯æ‹‰å¸ƒæ‹‰å¤šçŠ¬çš„ä¸€äº›ä¸»è¦ç‰¹å¾ï¼š</p>
<ul>
<li><strong>è¢«æ¯›</strong>ï¼šçŸ­ã€å¯†ã€å…‰æ»‘</li>
<li><strong>ä½“å‹</strong>ï¼šä¸­å‹åˆ°å¤§å‹ï¼ˆ25-36å…¬æ–¤ï¼‰</li>
<li><strong>çœ¼ç›</strong>ï¼šæ£•è‰²æˆ–æ¦›è‰²</li>
<li><strong>è€³æœµ</strong>ï¼šä¸‹å‚ï¼Œå‘ˆä¸‰è§’å½¢</li>
<li><strong>æ€§æ ¼</strong>ï¼šå‹å¥½ã€å¤–å‘ã€ç²¾åŠ›å……æ²›</li>
</ul>
</blockquote>
<h3 id="3-æ¤ç‰©è¯†åˆ«">3. æ¤ç‰©è¯†åˆ«</h3>
<pre><code class="language-python">disp_image("images/tree.jpg")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/tree.jpg" alt="png" loading="lazy"></p>
<p>è¿™æ˜¯èŠ±å›­é‡Œçš„ä¸€æ£µæ ‘ï¼Œä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡è¿›è¡Œæé—®ï¼Œé—®é¢˜åœ¨questionå˜é‡ä¸­ï¼Œæ¨¡å‹æ¨ç†ç»“æœåœ¨resultå˜é‡ä¸­ã€‚</p>
<pre><code class="language-python">question = ("What kind of plant is this in my garden?"
            "Describe it in a short paragraph.")
# è¿™æ˜¯æˆ‘çš„èŠ±å›­é‡Œçš„ä¸€æ£µä»€ä¹ˆæ¤ç‰©ï¼Ÿç”¨ä¸€æ®µè¯æè¿°

result = llama32_image(question, "images/tree.jpg")

print(result)
</code></pre>
<pre><code>This appears to be a pomegranate tree in your garden. Pomegranates are a shrubby tree with short spines in some species and smooth bark. They have many thin, leathery leaves, that are dark green on top and gray green below, that drop during winter and new leaves develop in the spring. The pomegranate flowers in the late spring and summer after the new leaves emerge. They produce small white flowers that produce large, fleshy fruit with many tiny seed pods.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>è¿™çœ‹èµ·æ¥æ˜¯ä¸€æ£µçŸ³æ¦´æ ‘ã€‚çŸ³æ¦´æ˜¯ä¸€ç§çŒæœ¨çŠ¶çš„æ ‘ï¼ŒæŸäº›å“ç§æœ‰çŸ­åˆºï¼Œæ ‘çš®å…‰æ»‘ã€‚å®ƒæœ‰è®¸å¤šè–„è€Œé©è´¨çš„å¶å­ï¼Œå¶å­ä¸Šé¢æ·±ç»¿è‰²ï¼Œä¸‹é¢ç°ç»¿è‰²ï¼Œå†¬å­£ä¼šè½å¶ï¼Œæ˜¥å­£ä¼šé•¿å‡ºæ–°å¶ã€‚çŸ³æ¦´æ ‘åœ¨æ–°å¶é•¿å‡ºåçš„æ™šæ˜¥å’Œå¤å­£å¼€èŠ±ã€‚å®ƒä¼šå¼€å‡ºå°ç™½èŠ±ï¼Œç»“å‡ºå«æœ‰è®¸å¤šå°ç±½çš„å¤§è€Œå¤šæ±çš„æœå®ã€‚</p>
</blockquote>
<h3 id="4-å‘ç¥¨ocrè¯†åˆ«">4. å‘ç¥¨OCRè¯†åˆ«</h3>
<pre><code class="language-python">for i in range(1, 4):
  disp_image(f"images/receipt-{i}.jpg")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/receipt-1.jpg" alt="png" width="300" height="400" loading="lazy"><br>
)</p>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/receipt-2.jpg" alt="png" width="300" height="400" loading="lazy"></p>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/receipt-3.jpg" alt="png" width="300" height="400" loading="lazy"></p>
<p>ä¸Šé¢æ˜¯ä¸‰å¼ å‘ç¥¨çš„å›¾ç‰‡ï¼Œä¸‹é¢é’ˆå¯¹è¿™ä¸‰å¼ å‘ç¥¨åˆ†åˆ«è¿›è¡Œæé—®ã€‚</p>
<pre><code class="language-python">question = "What's the total charge in the receipt?"
# è¿™å¼ å‘ç¥¨çš„æ€»é‡‘é¢æ˜¯å¤šå°‘ï¼Ÿ

result = llama32_image(question, "images/receipt-1.jpg")
print(result)
</code></pre>
<pre><code>The total charge is $13.96, which includes the cost of two slices of pizza ($6.25) and a tip ($1.69).&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>æ€»é‡‘é¢æ˜¯$13.96ï¼ŒåŒ…æ‹¬ä¸¤ç‰‡æŠ«è¨çš„è´¹ç”¨($6.25)å’Œå°è´¹($1.69)ã€‚</p>
</blockquote>
<pre><code class="language-python">question = "What's the total charge in the receipt?"
# è¿™å¼ å‘ç¥¨çš„æ€»é‡‘é¢æ˜¯å¤šå°‘ï¼Ÿ

result = llama32_image(question, "images/receipt-2.jpg")
print(result)
</code></pre>
<pre><code>According to the receipt, the total charge is $15.38, with $14.09 being the subtotal, and $1.29 for taxes. The total was paid in cash.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>æ ¹æ®å‘ç¥¨ï¼Œæ€»é‡‘é¢æ˜¯$15.38ï¼Œå…¶ä¸­$14.09æ˜¯å•†å“æ€»ä»·ï¼Œ$1.29æ˜¯ç¨ã€‚æ€»é‡‘é¢ä»¥ç°é‡‘æ”¯ä»˜ã€‚</p>
</blockquote>
<pre><code class="language-python">question = "What's the total charge in the receipt?"
# è¿™å¼ å‘ç¥¨çš„æ€»é‡‘é¢æ˜¯å¤šå°‘ï¼Ÿ

result = llama32_image(question, "images/receipt-3.jpg")
print(result)
</code></pre>
<pre><code>The total charge in the receipt is $4.39, which includes a subtotal of $4.00 for the purchase and a tip of $0.61, with a total tip of $5.00.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>å‘ç¥¨çš„æ€»é‡‘é¢æ˜¯$4.39ï¼Œå…¶ä¸­åŒ…æ‹¬$4.00çš„å•†å“å°è®¡å’Œ$0.61çš„å°è´¹ï¼Œæ€»å°è´¹ä¸º$5.00ã€‚</p>
</blockquote>
<h3 id="5-é€‰æ‹©åˆé€‚çš„é¥®æ–™">5. é€‰æ‹©åˆé€‚çš„é¥®æ–™</h3>
<pre><code class="language-python">disp_image("images/drinks.png")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/drinks.png" alt="png" loading="lazy"></p>
<p>ä¸Šé¢æ˜¯ä¸€å¼ 2ç“¶é¥®æ–™çš„å›¾ç‰‡ï¼Œä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡è¿›è¡Œæé—®ã€‚</p>
<pre><code class="language-python">question = "I am on a diet. Which drink should I drink?"
# æˆ‘æ­£åœ¨èŠ‚é£Ÿï¼Œåº”è¯¥å–å“ªç§é¥®æ–™ï¼Ÿ

result = llama32_image(question, "images/drinks.png")
print(result)
</code></pre>
<pre><code>Since you are on a diet, the choice between the two drinks should be based on their caloric content. 

The 7UP can is completely transparent, indicating that it has zero calories. On the other hand, the Rockstar energy drink has 130 calories per serving. Therefore, if you are trying to reduce your caloric intake, the 7UP would be the better choice. 

**Key Points:**

*   The 7UP can has 0 calories.
*   The Rockstar energy drink has 130 calories.

**Recommendation:**

Based on the information provided, the 7UP would be the more suitable option for someone who is on a diet.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>ç”±äºæ‚¨æ­£åœ¨èŠ‚é£Ÿï¼Œä¸¤ç§é¥®æ–™çš„é€‰æ‹©åº”è¯¥åŸºäºå®ƒä»¬çš„çƒ­é‡å«é‡ã€‚<br>
7UPç½è£…é¥®æ–™å®Œå…¨é€æ˜ï¼Œè¡¨æ˜å®ƒä¸å«çƒ­é‡ã€‚å¦ä¸€æ–¹é¢ï¼ŒRockstarèƒ½é‡é¥®æ–™æ¯ä»½å«æœ‰130å¡è·¯é‡Œã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨æƒ³å‡å°‘çƒ­é‡æ‘„å…¥ï¼Œ7UPå°†æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚<br>
<strong>è¦ç‚¹ï¼š</strong></p>
<ul>
<li>7UPå«0å¡è·¯é‡Œã€‚</li>
<li>Rockstarèƒ½é‡é¥®æ–™å«130å¡è·¯é‡Œã€‚<br>
<strong>å»ºè®®ï¼š</strong><br>
æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œå¯¹äºæ­£åœ¨èŠ‚é£Ÿçš„äººæ¥è¯´ï¼Œ7UPæ˜¯æ›´åˆé€‚çš„é€‰æ‹©ã€‚</li>
</ul>
</blockquote>
<p>ä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡å†æ¬¡æé—®ã€‚</p>
<pre><code class="language-python">question = ("Generete nurtrition facts of the two drinks " 
            "in JSON format for easy comparison.")
# ç”Ÿæˆä¸¤ç“¶é¥®æ–™çš„è¥å…»æˆåˆ†ï¼Œä»¥JSONæ ¼å¼ï¼Œä¾¿äºæ¯”è¾ƒ  

result = llama32_image(question, "images/drinks.png")
print(result)   
</code></pre>
<pre><code>The provided image does not contain enough information about the drinks in the picture. However, the nutrition facts can be represented in JSON format as follows:

```
[
  {
    "serving_size": "1 can (330 ml)",
    "calories": 0,
    "fat": "0%",
    "sodium": "0mg",
    "carbohydrates": "0g",
    "sugars": "0%",
    "protein": "0g"
  },
  {
    "serving_size": "1 can",
    "calories": 130,
    "fat": "0g",
    "sodium": "50mg",
    "carbohydrates": "33g",
    "sugars": "33g",
    "protein": "0g"
  }
]
```

This JSON format provides a clear comparison of the nutritional information between the two drinks.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>å›¾ç‰‡ä¸­æ²¡æœ‰æä¾›è¶³å¤Ÿçš„é¥®æ–™è¥å…»ä¿¡æ¯ã€‚ä½†æ˜¯ï¼Œè¥å…»æˆåˆ†å¯ä»¥ç”¨JSONæ ¼å¼è¡¨ç¤ºå¦‚ä¸‹ï¼š</p>
</blockquote>
<pre><code class="language-json"> [
   {
     "serving_size": "1ç½ (330æ¯«å‡)", 
     "calories": 0,
     "fat": "0%",
     "sodium": "0æ¯«å…‹",
     "carbohydrates": "0å…‹",
     "sugars": "0%", 
     "protein": "0å…‹"
   },
   {
     "serving_size": "1ç½",
     "calories": 130,
     "fat": "0å…‹",
     "sodium": "50æ¯«å…‹",
     "carbohydrates": "33å…‹",
     "sugars": "33å…‹",
     "protein": "0å…‹"
   }
 ]
</code></pre>
<h3 id="6-ç†è§£å¤§æ¨¡å‹æ¶æ„å›¾å¹¶ç”Ÿæˆå®ç°ä»£ç ">6. ç†è§£å¤§æ¨¡å‹æ¶æ„å›¾å¹¶ç”Ÿæˆå®ç°ä»£ç </h3>
<pre><code class="language-python">disp_image("images/llama32mm.png")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/llama32mm.png" alt="png" loading="lazy"></p>
<p>ä¸Šé¢æ˜¯ä¸€å¼ Llama 3.2å¤šæ¨¡æ€å¤§æ¨¡å‹æ¶æ„å›¾ï¼Œä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡è¿›è¡Œæé—®ã€‚<br>
è¿™æ˜¯ä¸€å¼ Llama 3.2å¤šæ¨¡æ€å¤§æ¨¡å‹çš„æ¶æ„å›¾ï¼Œå±•ç¤ºäº†æ¨¡å‹å¦‚ä½•å¤„ç†å›¾åƒå’Œæ–‡æœ¬è¾“å…¥ã€‚<br>
å›¾ä¸­æ˜¾ç¤ºäº†æ¨¡å‹çš„ä¸»è¦ç»„ä»¶å’Œæ•°æ®æµå‘ï¼ŒåŒ…æ‹¬å›¾åƒç¼–ç å™¨ã€æ–‡æœ¬ç¼–ç å™¨å’Œè§£ç å™¨ç­‰éƒ¨åˆ†ã€‚<br>
ä¸‹é¢æˆ‘ä»¬å°†è¯·æ±‚æ¨¡å‹è§£é‡Šè¿™ä¸ªæ¶æ„å›¾ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„Pythonå®ç°ä»£ç ã€‚</p>
<pre><code class="language-python">question = ("I see this diagram in the Llama 3 paper. "
            "Summarize the flow in text and then return a "
            "python script that implements the flow.")
# æˆ‘åœ¨Llama 3è®ºæ–‡ä¸­çœ‹åˆ°è¿™ä¸ªå›¾è¡¨ã€‚è¯·ç”¨æ–‡å­—æ€»ç»“æµç¨‹ï¼Œç„¶åè¿”å›ä¸€ä¸ªå®ç°è¯¥æµç¨‹çš„Pythonè„šæœ¬ã€‚

result = llama32_image(question, "images/llama32mm.png")
print(result)   
</code></pre>
<pre><code>The diagram illustrates the compositional approach to adding multimodal capabilities to Llama 3. This approach leads to a multimodal model that is trained in five stages:

*   **Language Model Pre-training**: The first stage involves pre-training a language model on text data.
*   **Vision Adapter Training**: In the second stage, the pre-trained language model is fine-tuned as a vision adapter using a visual-linguistic dataset. This step helps the model to understand the relationship between visual inputs and text descriptions.
*   **Multimodal Encoder Pre-training**: In the third stage, the vision adapter model is further pre-trained with a multimodal encoder. This step allows the model to learn how to combine visual and linguistic information effectively.
*   **Model Finetuning**: The fourth stage involves fine-tuning the multimodal encoder on downstream tasks that require both visual and linguistic understanding. This step enables the model to learn task-specific representations that are relevant to the specific task at hand.
*   **Speech Adapter Training**: In the final stage, the fine-tuned multimodal encoder model is trained as a speech adapter using audio-linguistic datasets. This step enables the model to learn how to incorporate speech inputs into its multimodal representation.

**Python Implementation**

To implement the flow outlined in the diagram, the following python script can be used as a reference. Please note that this implementation is a high-level overview and might require significant additional coding and refinement to make it operational.

```python
import torch
import torchvision
import numpy as np

# Define the model architectures
class LanguageModel(torch.nn.Module):
    def __init__(self):
        super(LanguageModel, self).__init__()
        # Define the text encoder
        self.text_encoder = torch.nn.LSTM(input_size=256, hidden_size=512, num_layers=2)
    
    def forward(self, x):
        # Pass the input through the text encoder
        outputs, _ = self.text_encoder(x)
        return outputs

class VisionAdapter(torch.nn.Module):
    def __init__(self):
        super(VisionAdapter, self).__init__()
        # Define the visual-linguistic dataset adapter
        self.visual_adapter = torch.nn.Linear(input_size=256, output_size=512)
    
    def forward(self, x):
        # Pass the input through the visual adapter
        outputs = self.visual_adapter(x)
        return outputs

class MultimodalEncoder(torch.nn.Module):
    def __init__(self):
        super(MultimodalEncoder, self).__init__()
        # Define the multimodal encoder
        self.multimodal_encoder = torch.nn.LSTM(input_size=1024, hidden_size=512, num_layers=2)
    
    def forward(self, x):
        # Pass the input through the multimodal encoder
        outputs, _ = self.multimodal_encoder(x)
        return outputs

class SpeechAdapter(torch.nn.Module):
    def __init__(self):
        super(SpeechAdapter, self).__init__()
        # Define the audio-linguistic dataset adapter
        self.speech_adapter = torch.nn.Linear(input_size=256, output_size=512)
    
    def forward(self, x):
        # Pass the input through the speech adapter
        outputs = self.speech_adapter(x)
        return outputs

# Initialize the models
language_model = LanguageModel()
vision_adapter = VisionAdapter()
multimodal_encoder = MultimodalEncoder()
speech_adapter = SpeechAdapter()

# Train the models
for epoch in range(100):
    # Train the language model
    language_model.zero_grad()
    output = language_model(torch.randn(1, 10, 256))
    loss = torch.nn.MSELoss()(output, torch.randn(1, 10, 256))
    loss.backward()
    optimizer = torch.optim.Adam(language_model.parameters(), lr=0.001)
    optimizer.step()

    # Train the vision adapter
    vision_adapter.zero_grad()
    output = vision_adapter(torch.randn(1, 10, 256))
    loss = torch.nn.MSELoss()(output, torch.randn(1, 10, 256))
    loss.backward()
    optimizer = torch.optim.Adam(vision_adapter.parameters(), lr=0.001)
    optimizer.step()

    # Train the multimodal encoder
    multimodal_encoder.zero_grad()
    output = multimodal_encoder(torch.randn(1, 10, 1024))
    loss = torch.nn.MSELoss()(output, torch.randn(1, 10, 1024))
    loss.backward()
    optimizer = torch.optim.Adam(multimodal_encoder.parameters(), lr=0.001)
    optimizer.step()

    # Train the speech adapter
    speech_adapter.zero_grad()
    output = speech_adapter(torch.randn(1, 10, 256))
    loss = torch.nn.MSELoss()(output, torch.randn(1, 10, 256))
    loss.backward()
    optimizer = torch.optim.Adam(speech_adapter.parameters(), lr=0.001)
    optimizer.step()

# Test the models
print("Language Model:")
print(language_model(torch.randn(1, 10, 256)))

print("Vision Adapter:")
print(vision_adapter(torch.randn(1, 10, 256)))

print("Multimodal Encoder:")
print(multimodal_encoder(torch.randn(1, 10, 1024)))

print("Speech Adapter:")
print(speech_adapter(torch.randn(1, 10, 256)))

```

Please note that this implementation is a high-level overview and might require significant additional coding and refinement to make it operational.&lt;|eot_id|&gt;
</code></pre>
<h3 id="7-ç†è§£å›¾è¡¨">7. ç†è§£å›¾è¡¨</h3>
<pre><code class="language-python">disp_image("images/llama31speed.png")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/llama31speed.png" alt="png" loading="lazy"></p>
<p>ä¸Šé¢æ˜¯ä¸€å¼ æŸ±çŠ¶å›¾ï¼Œä¸‹é¢é’ˆå¯¹è¯¥å›¾ç‰‡è¿›è¡Œæé—®ã€‚</p>
<pre><code class="language-python">question = "Convert the chart to an HTML table."
# å°†å›¾è¡¨è½¬æ¢ä¸ºHTMLè¡¨æ ¼

result = llama32_image(question, "images/llama31speed.png")
print(result)   
</code></pre>
<pre><code>Sure, here is the information you requested:
  &lt;table&gt;&lt;colgroup&gt;&lt;col&gt;&lt;/colgroup&gt;
    &lt;thead&gt;&lt;tr&gt;
      &lt;th&gt;Lama 5 (Meta)&lt;/th&gt;&lt;th&gt;GLaM Large&lt;/th&gt;&lt;th&gt;J1 7B (LLaMA)&lt;/th&gt;&lt;th&gt;J1 13B (LLaMA)&lt;/th&gt;&lt;th&gt;Cicada 7 1e10&lt;/th&gt;&lt;th&gt;OPT-6B-All&lt;/th&gt;&lt;th&gt;OPT-13B&lt;/th&gt;&lt;th&gt;OPT-30B&lt;/th&gt;&lt;th&gt;Chinchilla 70B&lt;/th&gt;&lt;th&gt;Chimera 2 (OAI)&lt;/th&gt;&lt;th&gt;Galactica 2 (OAI)&lt;/th&gt;&lt;th&gt;Galactica 3 (OAI)&lt;/th&gt;&lt;th&gt;GPT-3.5 2B&lt;/th&gt;&lt;th&gt;GPT-3.5 Large&lt;/th&gt;&lt;th&gt;Llama 2 (Meta)&lt;/th&gt;
      &lt;th&gt;217&lt;/th&gt;&lt;th&gt;38&lt;/th&gt;&lt;th&gt;214&lt;/th&gt;&lt;th&gt;169&lt;/th&gt;&lt;th&gt;133&lt;/th&gt;&lt;th&gt;129&lt;/th&gt;&lt;th&gt;111&lt;/th&gt;&lt;th&gt;79&lt;/th&gt;&lt;th&gt;64&lt;/th&gt;&lt;th&gt;62&lt;/th&gt;&lt;th&gt;61&lt;/th&gt;&lt;th&gt;38&lt;/th&gt;&lt;th&gt;34&lt;/th&gt;&lt;th&gt;28&lt;/th&gt;&lt;th&gt;25&lt;/th&gt;
      &lt;/tr&gt;&lt;tr&gt;
        &lt;th&gt;Output Tokens per Second; Higher is better&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;
        &lt;th&gt;Output Tokens per Second&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;
        &lt;th&gt;Higher is better&lt;/th&gt;
      &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;/tbody&gt;&lt;/table&gt;

Note that the table does not contain information as the graph seems to only compare the models' output speeds in "output tokens per second", not much more information is provided in the graph, please provide me with the accurate information and I would be glad to create a table for you.

The above is an approximation of how the table will look like using html as you requested.&lt;|eot_id|&gt;
</code></pre>
<p>ç„¶åæ ¹æ®è¾“å‡ºçš„HTMLä»£ç ï¼Œå°±å¯ä»¥ç”¨ä¸‹é¢çš„æ–¹æ³•ä»¥å¯è¯»çš„å½¢å¼å±•ç¤ºå‡ºæ¥ã€‚</p>
<pre><code class="language-python">from IPython.display import HTML
minified_html_table = "&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;Output Tokens per Second&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Llama 2 1.5B&lt;/td&gt;&lt;td&gt;217&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google's PaLM 2 540B&lt;/td&gt;&lt;td&gt;214&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google's PaLM 2 540B&lt;/td&gt;&lt;td&gt;163&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Meta's LLaMA 2 70B&lt;/td&gt;&lt;td&gt;133&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Meta's LLaMA 2 70B&lt;/td&gt;&lt;td&gt;129&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google's T5 3.5B&lt;/td&gt;&lt;td&gt;123&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;OPT-6B&lt;/td&gt;&lt;td&gt;111&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;OPT-6B&lt;/td&gt;&lt;td&gt;75&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;ChatGPT-3.5&lt;/td&gt;&lt;td&gt;64&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google's T5 3.5B&lt;/td&gt;&lt;td&gt;62&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google's T5 3.5B&lt;/td&gt;&lt;td&gt;61&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Meta's LLaMA 2 7B&lt;/td&gt;&lt;td&gt;68&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Meta's LLaMA 2 7B&lt;/td&gt;&lt;td&gt;38&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Meta's LLaMA 2 7B&lt;/td&gt;&lt;td&gt;38&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Meta's LLaMA 2 7B&lt;/td&gt;&lt;td&gt;25&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;"
HTML(minified_html_table)
</code></pre>
<table><thead><tr><th>Model</th><th>Output Tokens per Second</th></tr></thead><tbody><tr><td>Llama 2 1.5B</td><td>217</td></tr><tr><td>Google's PaLM 2 540B</td><td>214</td></tr><tr><td>Google's PaLM 2 540B</td><td>163</td></tr><tr><td>Meta's LLaMA 2 70B</td><td>133</td></tr><tr><td>Meta's LLaMA 2 70B</td><td>129</td></tr><tr><td>Google's T5 3.5B</td><td>123</td></tr><tr><td>OPT-6B</td><td>111</td></tr><tr><td>OPT-6B</td><td>75</td></tr><tr><td>ChatGPT-3.5</td><td>64</td></tr><tr><td>Google's T5 3.5B</td><td>62</td></tr><tr><td>Google's T5 3.5B</td><td>61</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>68</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>38</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>38</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>25</td></tr></tbody></table>
<h3 id="8-è§‚å¯Ÿå†°ç®±">8. è§‚å¯Ÿå†°ç®±</h3>
<pre><code class="language-python">disp_image("images/fridge-3.jpg")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/fridge-3.jpg" alt="png" loading="lazy"></p>
<p>ä¸Šé¢æ˜¯ä¸€å¼ å†°ç®±å†…éƒ¨çš„ç…§ç‰‡ï¼Œé’ˆå¯¹è¿™å¼ å›¾ç‰‡è¿›è¡Œæé—®ã€‚</p>
<pre><code class="language-python">question = ("What're in the fridge? What kind of food can be made? Give "
            "me 2 examples, based on only the ingredients in the fridge.")
# å†°ç®±é‡Œæœ‰ä»€ä¹ˆï¼ŸåŸºäºå†°ç®±é‡Œçš„é£Ÿæï¼Œèƒ½åšä»€ä¹ˆé£Ÿç‰©ï¼Ÿè¯·ç»™å‡º2ä¸ªä¾‹å­ã€‚

result = llama32_image(question, "images/fridge-3.jpg")
print(result)   
</code></pre>
<pre><code>The fridge contains a variety of ingredients, including vegetables like asparagus and apples, as well as beverages such as beer and juice. 

If I were to make food based on only these ingredients, two possibilities that come to mind are: 

1. Asparagus and Apple Salad: A simple salad made with asparagus, apples, and a squeeze of lemon juice could be a refreshing option.
2. Beer-Braised Asparagus: Searing asparagus in butter, then adding beer and reducing it to a syrup, would result in a savory dish perfect for a main course or side.

These dishes would not only utilize the available ingredients but also showcase the versatility of beer in cooking.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>å†°ç®±é‡Œæœ‰å„ç§é£Ÿæï¼ŒåŒ…æ‹¬èŠ¦ç¬‹å’Œè‹¹æœç­‰è”¬èœæ°´æœï¼Œä»¥åŠå•¤é…’å’Œæœæ±ç­‰é¥®æ–™ã€‚<br>
å¦‚æœåªç”¨è¿™äº›é£Ÿææ¥åšèœçš„è¯ï¼Œæˆ‘èƒ½æƒ³åˆ°ä¸¤ç§å¯èƒ½çš„åšæ³•ï¼š</p>
<ol>
<li>èŠ¦ç¬‹è‹¹æœæ²™æ‹‰ï¼šç”¨èŠ¦ç¬‹ã€è‹¹æœå’ŒæŸ æª¬æ±åˆ¶ä½œçš„æ¸…çˆ½ç®€å•æ²™æ‹‰ã€‚</li>
<li>å•¤é…’ç„–èŠ¦ç¬‹ï¼šå…ˆç”¨é»„æ²¹ç…èŠ¦ç¬‹ï¼Œç„¶ååŠ å…¥å•¤é…’æ”¶æ±ï¼Œå¯ä»¥åšæˆä¸€é“ç¾å‘³çš„ä¸»èœæˆ–é…èœã€‚<br>
è¿™äº›èœä¸ä»…å……åˆ†åˆ©ç”¨äº†ç°æœ‰çš„é£Ÿæï¼Œè¿˜å±•ç¤ºäº†å•¤é…’åœ¨çƒ¹é¥ªä¸­çš„å¤šæ ·æ€§ã€‚</li>
</ol>
</blockquote>
<p>ä¸‹é¢å°è£…ä¸€ä¸ªå¸¦æœ‰ä¸Šä¸‹æ–‡çš„å‡½æ•°llama32_image_reï¼Œå†æé—®ä¸€æ¬¡ã€‚</p>
<pre><code class="language-python">def llama32_image_re(instruction, result, new_instruction, image_url):
    from PIL import Image
    image = Image.open(image_url)

    messages = [
    {"role": "user", "content": [
                {"type": "image"},
                {"type": "text", "text": instruction}
    ]},
    {"role": "assistant", "content": result},
    {"role": "user", "content": new_instruction}
    ]
    
    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
    inputs = tokenizer(
        image,
        input_text,
        add_special_tokens = False,
        return_tensors = "pt",
    ).to("cuda")

    from transformers import TextStreamer
    text_streamer = TextStreamer(tokenizer, skip_prompt = True)
    output = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 2048,
                    use_cache = True, temperature = 1.5, min_p = 0.1)
    return output
</code></pre>
<pre><code class="language-python">new_question = "is there banana in the fridge? where?"
# å†°ç®±é‡Œæœ‰é¦™è•‰å—ï¼Ÿåœ¨å“ªé‡Œï¼Ÿ

res = llama32_image_re(question, result, new_question, "images/fridge-3.jpg")
print(res)
</code></pre>
<pre><code>The fridge does not contain any bananas. The fruit container on the middle right of the fridge contains blackberries, and the bottom right of the fridge contains apples and two green vegetables. There are no bananas or their peels.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>å†°ç®±é‡Œæ²¡æœ‰é¦™è•‰ã€‚å†°ç®±ä¸­é—´å³ä¾§çš„æ°´æœå®¹å™¨é‡Œè£…æœ‰é»‘è“ï¼Œå†°ç®±å³ä¸‹æ–¹æœ‰è‹¹æœå’Œä¸¤ä¸ªç»¿è‰²è”¬èœã€‚æ²¡æœ‰çœ‹åˆ°é¦™è•‰æˆ–é¦™è•‰çš®ã€‚</p>
</blockquote>
<h3 id="9-æ‰¹æ”¹æ•°å­¦ä½œä¸š">9. æ‰¹æ”¹æ•°å­¦ä½œä¸š</h3>
<pre><code class="language-python">disp_image("images/math_hw3.jpg")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/math_hw3.jpg" alt="png" loading="lazy"></p>
<p>ä¸Šå›¾æ˜¯ä¸€ä»½æ•°å­¦ä½œä¸šï¼Œä¸‹é¢ç¼–å†™æç¤ºè¯è®©å¤§æ¨¡å‹æ‰¹æ”¹è¿™ä»½ä½œä¸šã€‚</p>
<pre><code class="language-python">question = ("Check carefully each answer in a kid's math homework, first "
          "do the calculation, then compare the result with the kid's "
          "answer, mark correct or incorrect for each answer, and finally"
          " return a total score based on all the problems answered.")
# ä»”ç»†æ£€æŸ¥å­©å­æ•°å­¦ä½œä¸šä¸­çš„æ¯ä¸ªç­”æ¡ˆï¼Œé¦–å…ˆè¿›è¡Œè®¡ç®—ï¼Œç„¶åå°†ç»“æœä¸å­©å­çš„ç­”æ¡ˆè¿›è¡Œæ¯”è¾ƒï¼Œæ ‡è®°æ¯ä¸ªç­”æ¡ˆæ˜¯å¦æ­£ç¡®ï¼Œæœ€åæ ¹æ®æ‰€æœ‰å·²å›ç­”çš„é—®é¢˜ç»™å‡ºæ€»åˆ†ã€‚

result = llama32_image(question, "images/math_hw3.jpg")
print(result)   
</code></pre>
<pre><code>Here is the annotated math homework:

**Problem 1:**

* Correct calculation: 26 + 17 = 43
* Kid's answer: 43
* Mark: Correct

**Problem 2:**

* Correct calculation: 24 + 38 = 62
* Kid's answer: 62
* Mark: Correct

**Problem 3:**

* Correct calculation: 65 + 27 = 92
* Kid's answer: 92
* Mark: Correct

**Problem 4:**

* Correct calculation: 39 + 41 = 80
* Kid's answer: 80
* Mark: Correct

**Problem 5:**

* Correct calculation: 77 + 16 = 93
* Kid's answer: 93
* Mark: Correct

**Problem 6:**

* Correct calculation: 38 + 29 = 67
* Kid's answer: 67
* Mark: Correct

**Problem 7:**

* Correct calculation: 79 + 12 = 91
* Kid's answer: 91
* Mark: Correct

**Problem 8:**

* Correct calculation: 32 + 19 = 51
* Kid's answer: 51
* Mark: Correct

**Problem 9:**

* Correct calculation: 56 + 26 = 82
* Kid's answer: 82
* Mark: Correct

**Problem 10:**

* Correct calculation: 68 + 27 = 95
* Kid's answer: 95
* Mark: Correct

**Problem 11:**

* Correct calculation: 27 + 47 = 74
* Kid's answer: 74
* Mark: Correct

**Problem 12:**

* Correct calculation: 79 + 15 = 94
* Kid's answer: 94
* Mark: Correct

Total score: 12/12 = 100%&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>ä»¥ä¸‹æ˜¯æ‰¹æ”¹åçš„æ•°å­¦ä½œä¸šï¼š<br>
<strong>ç¬¬1é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š26 + 17 = 43</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š43</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬2é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š24 + 38 = 62</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š62</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬3é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š65 + 27 = 92</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š92</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬4é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š39 + 41 = 80</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š80</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬5é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š77 + 16 = 93</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š93</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬6é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š38 + 29 = 67</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š67</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬7é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š79 + 12 = 91</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š91</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬8é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š32 + 19 = 51</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š51</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬9é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š56 + 26 = 82</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š82</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬10é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š68 + 27 = 95</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š95</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬11é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š27 + 47 = 74</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š74</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p><strong>ç¬¬12é¢˜ï¼š</strong></p>
<ul>
<li>æ­£ç¡®è®¡ç®—ï¼š79 + 15 = 94</li>
<li>å­¦ç”Ÿç­”æ¡ˆï¼š94</li>
<li>è¯„åˆ†ï¼šæ­£ç¡®</li>
</ul>
<p>æ€»åˆ†ï¼š12/12 = 100%</p>
</blockquote>
<h3 id="10-è¯†åˆ«æ™¯ç‚¹åç§°">10. è¯†åˆ«æ™¯ç‚¹åç§°</h3>
<pre><code class="language-python">disp_image("images/golden_gate.png")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/golden_gate.png" alt="png" loading="lazy"></p>
<p>ä¸Šé¢æ˜¯ä¸€å¤„è‘—åæ™¯ç‚¹çš„ç…§ç‰‡</p>
<pre><code class="language-python">question = ("Where is the location of the place shown in the picture?")
# å›¾ç‰‡ä¸­æ˜¾ç¤ºçš„åœ°ç‚¹åœ¨å“ªé‡Œï¼Ÿ


result = llama32_image(question, "images/golden_gate.png")
print(result)   
</code></pre>
<pre><code>**Location Details**

* Region: San Francisco, California, USA
* Situated across: Golden Gate Strait, connecting San Francisco Bay to the Pacific Ocean.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>åœ°ç‚¹è¯¦æƒ…</p>
<ul>
<li>åœ°åŒºï¼šç¾å›½åŠ åˆ©ç¦å°¼äºšå·æ—§é‡‘å±±å¸‚</li>
<li>ä½ç½®è·¨è¶Šï¼šé‡‘é—¨æµ·å³¡ï¼Œè¿æ¥æ—§é‡‘å±±æ¹¾ä¸å¤ªå¹³æ´‹</li>
</ul>
</blockquote>
<h3 id="11-å®¤å†…è£…ä¿®è¯†åˆ«å’Œç©ºé—´ä½ç½®åˆ¤æ–­">11. å®¤å†…è£…ä¿®è¯†åˆ«å’Œç©ºé—´ä½ç½®åˆ¤æ–­</h3>
<pre><code class="language-python">disp_image("images/001.jpeg")
</code></pre>
<p><img src="https://mz-blog-res.oss-cn-beijing.aliyuncs.com/img/c001/001.jpeg" alt="png" loading="lazy"></p>
<p>ä¸Šé¢æ˜¯ä¸€å¼ å®¤å†…è£…ä¿®å¸ƒå±€å›¾</p>
<pre><code class="language-python">question = ("Describe the design, style, color, material and other "
            "aspects of the fireplace in this photo. Then list all "
            "the objects in the photo.")
# æè¿°è¿™å¼ ç…§ç‰‡ä¸­å£ç‚‰çš„è®¾è®¡ã€é£æ ¼ã€é¢œè‰²ã€ææ–™ç­‰æ–¹é¢ã€‚ç„¶ååˆ—å‡ºç…§ç‰‡ä¸­çš„æ‰€æœ‰ç‰©å“ã€‚

result = llama32_image(question, "images/001.jpeg")
print(result)   
</code></pre>
<pre><code>**Answer:**

* The fireplace is a modern, sleek design with a black frame and a rectangular shape. It features an open flame, giving the appearance of a wood-burning fire. The fireplace is set into a light grey wall made of concrete or faux concrete, which adds to the modern aesthetic.

**Objects Present:**

* A white couch sits on the left side of the room, accompanied by a black and white sculpture on a stand behind it.
* A black coffee table with a glossy finish holds a glass vase with white flowers and a magazine on top of it.
* Two decorative white objects, possibly vases or sculptures, are placed on either side of the fireplace.
* A light grey rug covers the floor beneath the coffee table.
* The room has a white wall on the left side with a tall window that allows natural light to enter.
* The overall atmosphere of the room exudes modernity and minimalism, with a focus on clean lines, simple shapes, and a neutral color palette.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p><strong>å›ç­”ï¼š</strong></p>
<ul>
<li>å£ç‚‰é‡‡ç”¨ç°ä»£ç®€çº¦è®¾è®¡ï¼Œå¸¦æœ‰é»‘è‰²æ¡†æ¶å’ŒçŸ©å½¢å¤–å½¢ã€‚å®ƒé‡‡ç”¨æ˜ç«è®¾è®¡ï¼Œå‘ˆç°å‡ºæœ¨æç‡ƒçƒ§çš„æ•ˆæœã€‚å£ç‚‰åµŒå…¥æµ…ç°è‰²çš„æ··å‡åœŸæˆ–ä»¿æ··å‡åœŸå¢™é¢ä¸­ï¼Œå¢æ·»äº†ç°ä»£ç¾æ„Ÿã€‚</li>
</ul>
<p><strong>æˆ¿é—´å†…çš„ç‰©å“ï¼š</strong></p>
<ul>
<li>æˆ¿é—´å·¦ä¾§æœ‰ä¸€å¼ ç™½è‰²æ²™å‘ï¼Œæ²™å‘åé¢çš„æ”¯æ¶ä¸Šæ”¾ç½®ç€ä¸€ä¸ªé»‘ç™½ç›¸é—´çš„é›•å¡‘ã€‚</li>
<li>ä¸€å¼ é»‘è‰²äº®é¢èŒ¶å‡ ä¸Šæ”¾ç€ä¸€ä¸ªç»ç’ƒèŠ±ç“¶ï¼Œé‡Œé¢æ’ç€ç™½è‰²èŠ±æœµï¼Œæ—è¾¹è¿˜æ”¾ç€ä¸€æœ¬æ‚å¿—ã€‚</li>
<li>å£ç‚‰ä¸¤ä¾§å„æ”¾ç½®ç€ä¸€ä¸ªç™½è‰²è£…é¥°ç‰©ï¼Œå¯èƒ½æ˜¯èŠ±ç“¶æˆ–é›•å¡‘ã€‚</li>
<li>èŒ¶å‡ ä¸‹æ–¹é“ºç€ä¸€å—æµ…ç°è‰²åœ°æ¯¯ã€‚</li>
<li>æˆ¿é—´å·¦ä¾§æ˜¯ç™½è‰²å¢™é¢ï¼Œä¸Šé¢æœ‰ä¸€æ‰‡é«˜å¤§çš„çª—æˆ·ï¼Œå¯ä»¥è®©è‡ªç„¶å…‰çº¿è¿›å…¥å®¤å†…ã€‚</li>
</ul>
<p>æ•´ä¸ªæˆ¿é—´æ•£å‘å‡ºç°ä»£ç®€çº¦çš„æ°›å›´ï¼Œæ³¨é‡å¹²å‡€çš„çº¿æ¡ã€ç®€å•çš„å½¢çŠ¶å’Œä¸­æ€§çš„è‰²è°ƒã€‚</p>
</blockquote>
<p>åŸºäºä¸Šé¢çš„å›ç­”ï¼Œå†æ¬¡è¿½é—®</p>
<pre><code class="language-python">new_question = ("How many balls and vases are there? Which one is closer "
                "to the fireplace: the balls or the vases?")
# æœ‰å¤šå°‘ä¸ªçƒå’ŒèŠ±ç“¶ï¼Ÿå“ªä¸ªç¦»å£ç‚‰æ›´è¿‘ï¼šçƒè¿˜æ˜¯èŠ±ç“¶ï¼Ÿ


res = llama32_image_re(question, result, new_question, "images/001.jpeg")
print(res)
</code></pre>
<pre><code>There are 2 balls and 2 vases, and the balls are closer to the fireplace than the vases. The balls are on either side of the flowers at the front of the mantel, while the vases are both on a stand against the back wall. The vases are shaped like hourglasses, while the balls have many small spheres cut into the surface, creating an intriguing effect of both being hollow and full at once. The balls are white, and the vases appear to have the same coloring as the hourglasses.&lt;|eot_id|&gt;
</code></pre>
<p>è¾“å‡ºç»“æœï¼š</p>
<blockquote>
<p>æœ‰2ä¸ªçƒå’Œ2ä¸ªèŠ±ç“¶ï¼Œçƒæ¯”èŠ±ç“¶ç¦»å£ç‚‰æ›´è¿‘ã€‚çƒæ”¾ç½®åœ¨å£ç‚‰å°å‰æ–¹ä¸¤ä¾§çš„èŠ±æœµæ—è¾¹ï¼Œè€ŒèŠ±ç“¶åˆ™éƒ½æ”¾åœ¨é åå¢™çš„æ¶å­ä¸Šã€‚èŠ±ç“¶çš„å½¢çŠ¶åƒæ²™æ¼ï¼Œè€Œçƒçš„è¡¨é¢åˆ™é›•åˆ»ç€è®¸å¤šå°çƒä½“ï¼Œåˆ›é€ å‡ºä¸€ç§æ—¢ç©ºå¿ƒåˆå……å®çš„æœ‰è¶£æ•ˆæœã€‚çƒæ˜¯ç™½è‰²çš„ï¼ŒèŠ±ç“¶ä¼¼ä¹å’Œæ²™æ¼æœ‰ç€ç›¸åŒçš„é¢œè‰²ã€‚</p>
</blockquote>
<h2 id="æ€»ç»“">æ€»ç»“</h2>
<p>é€šè¿‡ä¸Šé¢çš„å®éªŒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒLlama 3.2 90Bå¤šæ¨¡æ€è§†è§‰å¤§æ¨¡å‹åœ¨å¤„ç†å›¾åƒå’Œæ–‡æœ¬ä»»åŠ¡æ—¶ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°ç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†ï¼Œå¹¶ç»™å‡ºåˆç†çš„ç­”æ¡ˆï¼Œå¹¶ä¸”èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡è¿›è¡Œè¿½é—®ï¼Œç»™å‡ºæ›´è¯¦ç»†çš„ç­”æ¡ˆã€‚åŒæ—¶å‡†ç¡®ç‡å¾ˆé«˜ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°å®Œæˆä»»åŠ¡ã€‚è™½ç„¶æœ¬æ–‡é‡‡ç”¨çš„æ˜¯4bité‡åŒ–ï¼Œä½†æ˜¯æ•ˆæœä¾ç„¶å¾ˆå¥½ã€‚</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.04133166917476852" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2024-12-23 19:27">2024-12-23 19:22</span>&nbsp;
<a href="https://www.cnblogs.com/ibrahim">ibrahim</a>&nbsp;
é˜…è¯»(<span id="post_view_count">10</span>)&nbsp;
è¯„è®º(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18624860" rel="nofollow">ç¼–è¾‘</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18624860);return false;">æ”¶è—</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18624860', targetLink: 'https://www.cnblogs.com/ibrahim/p/18624860/llama-3-2-90b-deploy-usecase', title: 'Llama 3.2 900äº¿å‚æ•°è§†è§‰å¤šæ¨¡æ€å¤§æ¨¡å‹æœ¬åœ°éƒ¨ç½²åŠæ¡ˆä¾‹å±•ç¤º' })">ä¸¾æŠ¥</a>
</div>
        