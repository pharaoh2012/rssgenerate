
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/KoiC/p/18757075" title="发布于 2025-03-07 10:23">
    <span role="heading" aria-level="2">内网环境部署Deepseek+Dify，构建企业私有化AI应用</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h3 id="0简介">0.简介</h3>
<p>公司为生产安全和保密，内部的服务器不可连接外部网络，为了可以在内网环境下部署，采用的方案为ollama(Docker)+Dify(Docker Compose)，方便内网环境下迁移和备份，下文将介绍部署的全部过程。</p>
<h3 id="1镜像拉取">1.镜像拉取</h3>
<p>镜像拉取为准备工作，因服务器在内网环境，需要先在可以连接外网的电脑上拉取相关镜像或文件。由于公司笔记本的Windows系统屏蔽了Microsoft Store，导致Docker Desktop安装不成功，故使用虚拟机创建Ubuntu系统，在Ubuntu下进行相关操作。</p>
<h4 id="11-ollama">1.1 ollama</h4>
<p>ollama采用docker进行部署，首先拉取ollama docker镜像</p>
<pre><code class="language-sh">docker pull ollama/ollama
</code></pre>
<p>通过以下命令可以创建容器</p>
<pre><code class="language-sh">docker run -d --name ollama -v /home/LLM/ollama/models:/usr/share/ollama/.ollama/models -p 11434:11434 ollama/ollama:latest
</code></pre>
<p>可以根据实际情况更改配置：</p>
<ul>
<li>--name:容器名</li>
<li>-v:硬盘挂载，<code>宿主机路径:容器内部路径</code></li>
<li>-p:端口映射，<code>宿主机端口:容器内端口</code></li>
</ul>
<blockquote>
<p>在Linux非root用户下，ollama模型默认保存位置为/usr/share/ollama/.ollama/models</p>
<p>root用户默认存储在/root/.ollama/models，docker容器默认使用root用户</p>
<p>Tips:-v参数建议不要更改为root用户路径，和模型导入有关，在后文会提到</p>
</blockquote>
<p>模型拉取需要进入容器内进行操作</p>
<p>在启动ollama的容器后，通过以下命令查看ollama容器的信息</p>
<pre><code class="language-sh">docker ps | grep ollama
</code></pre>
<p>根据容器ID来进入容器内部</p>
<pre><code class="language-sh">docker exec -it 容器ID /bin/bash
</code></pre>
<p>模型可以在<a href="https://ollama.com/search" target="_blank" rel="noopener nofollow">ollama官网</a>查看</p>
<p><img src="https://img2024.cnblogs.com/blog/2918335/202503/2918335-20250307101422244-1445471298.png" alt="image" loading="lazy"></p>
<p>以Deepseek为例，选择14b参数量的模型后，复制右侧的命令到ollama，即可拉取模型并运行</p>
<pre><code class="language-sh"># 拉取模型并运行
ollama run deepseek-r1:14b
# 仅拉取模型
ollama pull deepseek-r1:14b 
</code></pre>
<p>运行后可以在终端中进行对话测试</p>
<p>已有的模型可以通过 <code>ollama list</code> 命令来查看，模型文件的保存位置可以通过以下命令查看</p>
<pre><code class="language-sh">ollama show deepseek-r1:14b --modelfile
</code></pre>
<p>输出结果的第一行就是模型文件的存储位置。至此，ollama相关的镜像文件全部下载完毕。</p>
<h4 id="12-dify">1.2 Dify</h4>
<p>Dify社区版支持多种部署方式，我们选择使用Docker Compose方式来部署</p>
<p>按照<a href="https://docs.dify.ai/zh-hans/getting-started/install-self-hosted/docker-compose" target="_blank" rel="noopener nofollow">官方文档</a>进行操作，首先克隆Dify的源代码到本地环境</p>
<pre><code class="language-sh"># 假设当前最新版本为 0.15.3
git clone https://github.com/langgenius/dify.git --branch 0.15.3
</code></pre>
<blockquote>
<p>注意：在2025.3.3时，最新版为1.0.0版本，该版本为测试版本，在接入Deepseek时存在严重Bug，无法成功接入，实测0.15.3版本使用正常，建议先使用稳定版本</p>
</blockquote>
<p>进入Dify的docker目录并复制环境配置文件</p>
<pre><code class="language-sh">cd dify/docker
cp .env.example .env
</code></pre>
<p>根据系统上的Docker Compose版本，选择合适的命令来启动容器</p>
<pre><code class="language-sh"># Docker Compose V2
docker compose up -d
# Docker Compose V1
docker-compose up -d
</code></pre>
<p>使用Docker Compose拉取镜像时会受到镜像源的影响，一旦存在拉取失败,全部镜像都会拉取失败，需要配置多个可用国内镜像源才能成功</p>
<p>或者可以逐个拉取所需要的镜像，0.15.3版本所需的各个镜像为：</p>
<table>
<thead>
<tr>
<th>REPOSITORY</th>
<th>TAG</th>
<th>SIZE</th>
</tr>
</thead>
<tbody>
<tr>
<td>ubuntu/squid</td>
<td>latest</td>
<td>243MB</td>
</tr>
<tr>
<td>postgres</td>
<td>15-alpine</td>
<td>273MB</td>
</tr>
<tr>
<td>langgenius/dify-web</td>
<td>0.15.3</td>
<td>436MB</td>
</tr>
<tr>
<td>langgenius/dify-api</td>
<td>0.15.3</td>
<td>2.97GB</td>
</tr>
<tr>
<td>nginx</td>
<td>latest</td>
<td>192MB</td>
</tr>
<tr>
<td>redis</td>
<td>6-alpine</td>
<td>30.2MB</td>
</tr>
<tr>
<td>langgenius/dify-sandbox</td>
<td>0.2.10</td>
<td>567MB</td>
</tr>
<tr>
<td>semitechnologies/weaviate</td>
<td>1.19.0</td>
<td>52.5MB</td>
</tr>
</tbody>
</table>
<p>镜像拉取成功后使用 <code>docker compose up -d</code> 命令启动Dify，服务器所使用的Docker没有集成Docker Compose工具，需要手动进行安装。（参考<a href="https://www.cnblogs.com/lqqgis/p/18707631" target="_blank">手动安装docker compose - 博客园</a>进行安装，内网服务器选用独立安装的方式离线安装）</p>
<p>Dify默认使用80端口，可以通过.env文件进行修改，部署时可以根据实际情况修改</p>
<p>首次启动需要访问以下地址设置管理员账户：</p>
<pre><code>http://your_server_ip/install
</code></pre>
<p>访问主页面进入以下地址：</p>
<pre><code>http://your_server_ip
</code></pre>
<p>如需要停止容器，使用</p>
<pre><code class="language-sh">docker compose down
</code></pre>
<h3 id="2镜像导出">2.镜像导出</h3>
<h4 id="21-docker镜像导出">2.1 Docker镜像导出</h4>
<p>使用以下命令查看本机docker镜像，并根据镜像ID保存对应镜像到本地</p>
<pre><code class="language-sh">docker images
docker save 镜像ID &gt; 文件名.tar
</code></pre>
<p>将所需要的全部docker镜像都导出（包括ollama和Dify）</p>
<p>Dify导出镜像的同时还需要将上一步操作的Dify/docker文件夹也复制导出，该文件夹会存储Dify的全部配置以及相关数据，为Dify运行的主目录</p>
<h4 id="22-模型文件导出">2.2 模型文件导出</h4>
<p>在ollama容器内下载的模型，首先查看模型文件的存储位置</p>
<pre><code class="language-sh">ollama show deepseek-r1:14b --modelfile
</code></pre>
<p>ollama docker内，模型默认存储在/root/.ollama/models/blobs下，该路径下还存有一些验证文件，一个模型文件+三个验证文件共四个文件</p>
<p><img src="https://img2024.cnblogs.com/blog/2918335/202503/2918335-20250307101707705-397199391.png" alt="image" loading="lazy"></p>
<p>将这些文件复制到上一步启动时挂载的路径下，这样就可以在宿主机中操作这些文件了，通过cp命令来复制</p>
<pre><code class="language-sh">cp 源文件 目标文件
</code></pre>
<blockquote>
<p>这是我踩的一个坑，参考博客 <a href="https://www.cnblogs.com/deali/p/18722239" target="_blank">数据不出内网：基于Ollama+OneAPI构建企业专属DeepSeek智能中台</a> 时，该博客并未提到ollama在首次运行或下载Deepseek模型时会进行验证，在按照博客的步骤导入服务器后ollama运行报错验证失败，也没有查到相关的解决方法，在花费一些时间后才发现还需要迁移这些验证文件，实属不易。</p>
</blockquote>
<p>除模型文件外还需要导出一个ModelFile文件，用于后续模型导入，该文件也放入blobs文件夹下</p>
<pre><code>ollama show deepseek-r1:14b --modelfile &gt; Modelfile
</code></pre>
<h4 id="23-传输文件到物理机">2.3 传输文件到物理机</h4>
<p>VirtualBox创建的虚拟机，可使用自带的共享文件夹功能将保存后的镜像文件传输到物理机中，具体可参考：<a href="https://blog.csdn.net/danshiming/article/details/117997558" target="_blank" rel="noopener nofollow">手把手教你在VirtualBox中与主机共享文件夹_virtualbox共享文件夹在哪-CSDN博客</a></p>
<p>将全部所需文件传输到物理机，再通过物理机传输到内网服务器中。</p>
<h3 id="3镜像导入及启动">3.镜像导入及启动</h3>
<p>将镜像传输到服务器后，进行导入</p>
<pre><code class="language-sh">docker load -i 文件名.tar
</code></pre>
<p>通过该命令导入镜像后，会丢失镜像的标签信息，需要再手动添加标签信息</p>
<pre><code class="language-sh">docker tag 镜像ID 镜像名:版本
# 以 Ubuntu/squid 为例
docker tag 镜像ID ubuntu/squid:latest
</code></pre>
<h4 id="31-ollama">3.1 ollama</h4>
<p>在服务器上创建ollama docker容器</p>
<pre><code class="language-sh">docker run -d --name ollama -v /home/LLM/ollama/models:/usr/share/ollama/.ollama/models -p 11434:11434 ollama/ollama:latest
</code></pre>
<p>容器创建成功后访问 <code>http://your_server_ip:11434</code> 可以看到Ollama is running的消息提示</p>
<p>/home/LLM/ollama/models目录为自定义的服务器存储模型文件的路径，这个路径要挂载到容器上，以便容器内部进行访问</p>
<p>将模型文件夹blobs存储到你设置的这个目录下，进入ollama容器内部</p>
<pre><code class="language-sh">docker ps | grep ollama
docker exec -it ollama容器ID /bin/bash
</code></pre>
<p>在容器内切换到挂载的路径/usr/share/ollama/.ollama/models/blobs</p>
<p>打开之前导出的ModelFile文件，修改第一行的路径，指向挂载的路径</p>
<pre><code>FROM /usr/share/ollama/.ollama/models/blobs/sha256-6e9f90f02bb3b39b59e81916e8cfce9deb45aeaeb9a54a5be4414486b907dc1e
</code></pre>
<p>使用以下命令导入模型</p>
<pre><code class="language-sh">ollama create 模型名 -f Modelfile文件路径
</code></pre>
<p>导入成功会返回成功的提示，chat模型可以通过run命令运行测试</p>
<pre><code class="language-sh">ollama run deepseek-r1:14b
</code></pre>
<h4 id="32-dify">3.2 Dify</h4>
<p>将上一步导出的Dify/docker文件夹放置在服务器指定位置，进入该目录后通过Docker Compose工具再次启动即可，若镜像导入无问题，就可以直接启动成功</p>
<p>如果服务器的Docker不包含Docker Compose工具，1.2中已经介绍了离线安装Docker Compose的方法</p>
<h3 id="4dify使用">4.Dify使用</h3>
<p>启动完成后即可正常访问Dify，在设置页可以配置ollama，这样就可以配置Deepseek模型了，Dify的使用可以参考<a href="https://docs.dify.ai/zh-hans" target="_blank" rel="noopener nofollow">官方文档</a></p>
<h3 id="5结束语">5.结束语</h3>
<p>Deepseek的突然爆火使得AI相关应用再一次迎来了发展，相关的博客或知识还在逐步增加中，这次的部署可参考的不多，且过于杂乱，本文总结了我在部署时遇到的问题，希望可以给大家一些帮助。</p>
<h3 id="参考">参考</h3>
<p><a href="https://www.cnblogs.com/deali/p/18722239" target="_blank">数据不出内网：基于Ollama+OneAPI构建企业专属DeepSeek智能中台</a></p>
<p><a href="https://www.hangge.com/blog/cache/detail_2411.html" target="_blank" rel="noopener nofollow">Docker - 实现本地镜像的导出、导入（export、import、save、load）</a></p>
<p><a href="https://blog.csdn.net/exision/article/details/145436094" target="_blank" rel="noopener nofollow">Dify丝滑云或本地docker部署步骤 适用Linux &amp; macOS</a></p>
<p><a href="https://docs.dify.ai/zh-hans" target="_blank" rel="noopener nofollow">欢迎使用 Dify | Dify</a></p>
<p><a href="https://blog.csdn.net/m0_60707708/article/details/137393519" target="_blank" rel="noopener nofollow">docker常用命令大全（详细版），Linux运维开发经验的有效总结</a></p>
<p><a href="https://blog.csdn.net/qq_42997214/article/details/122867372" target="_blank" rel="noopener nofollow">docker load -i 导入后 看不到image镜像_docker load之后,镜像不见了-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/weixin_44470482/article/details/126162448" target="_blank" rel="noopener nofollow">linux加载tar文件成镜像找不到问题及解决办法_docker load 后找不到镜像-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/danshiming/article/details/117997558" target="_blank" rel="noopener nofollow">手把手教你在VirtualBox中与主机共享文件夹_virtualbox共享文件夹在哪-CSDN博客</a></p>
<p><a href="https://devpress.csdn.net/cloud-native/670bc1be2db35d1195f9e3f9.html" target="_blank" rel="noopener nofollow">使用 Docker 安装 Ollama 部署本地大模型并接入 One-API_docker_程序员羊羊-云原生技术专区</a></p>
<p><a href="https://www.cnblogs.com/lqqgis/p/18707631" target="_blank">手动安装docker compose - lqqgis - 博客园</a></p>
<p><a href="https://blog.csdn.net/weixin_44355653/article/details/140267707" target="_blank" rel="noopener nofollow">Ubuntu 22.04安装Docker-CSDN博客</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.02300996338078704" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-03-07 10:24">2025-03-07 10:23</span>&nbsp;
<a href="https://www.cnblogs.com/KoiC">KoiC</a>&nbsp;
阅读(<span id="post_view_count">15</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18757075" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18757075);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18757075', targetLink: 'https://www.cnblogs.com/KoiC/p/18757075', title: '内网环境部署Deepseek+Dify，构建企业私有化AI应用' })">举报</a>
</div>
        