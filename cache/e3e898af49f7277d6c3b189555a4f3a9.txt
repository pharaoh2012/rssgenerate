
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/Johny-zhao/p/18931339" title="发布于 2025-06-16 16:15">
    <span role="heading" aria-level="2">CentOS Stream 8 高可用 Kuboard 部署方案</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<p>下面是在 CentOS Stream 8 上部署高可用 Kuboard 管理平台的详细方案，包含多副本、持久化存储和定期备份配置。</p>
<p><strong>一、架构设计</strong></p>
<p><strong>高可用架构图</strong></p>
<p><strong>图表</strong></p>
<p>&nbsp;</p>
<p><strong>节点规划</strong></p>
<table border="0" cellspacing="0" cellpadding="0">
<thead>
<tr>
<td>
<p><strong>主机名</strong></p>
</td>
<td>
<p><strong>IP 地址</strong></p>
</td>
<td>
<p><strong>角色</strong></p>
</td>
<td>
<p><strong>资源配置</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
<p>lb1</p>
</td>
<td>
<p>192.168.1.10</p>
</td>
<td>
<p>HAProxy + Keepalived</p>
</td>
<td>
<p>2C/4G</p>
</td>
</tr>
<tr>
<td>
<p>lb2</p>
</td>
<td>
<p>192.168.1.11</p>
</td>
<td>
<p>HAProxy + Keepalived</p>
</td>
<td>
<p>2C/4G</p>
</td>
</tr>
<tr>
<td>
<p>master1</p>
</td>
<td>
<p>192.168.1.101</p>
</td>
<td>
<p>Kubernetes 控制平面</p>
</td>
<td>
<p>4C/8G</p>
</td>
</tr>
<tr>
<td>
<p>master2</p>
</td>
<td>
<p>192.168.1.102</p>
</td>
<td>
<p>Kubernetes 控制平面</p>
</td>
<td>
<p>4C/8G</p>
</td>
</tr>
<tr>
<td>
<p>worker1</p>
</td>
<td>
<p>192.168.1.201</p>
</td>
<td>
<p>Kubernetes 工作节点</p>
</td>
<td>
<p>8C/32G</p>
</td>
</tr>
<tr>
<td>
<p>worker2</p>
</td>
<td>
<p>192.168.1.202</p>
</td>
<td>
<p>Kubernetes 工作节点</p>
</td>
<td>
<p>8C/32G</p>
</td>
</tr>
<tr>
<td>
<p>worker3</p>
</td>
<td>
<p>192.168.1.203</p>
</td>
<td>
<p>Kubernetes 工作节点</p>
</td>
<td>
<p>8C/32G</p>
</td>
</tr>
<tr>
<td>
<p>storage</p>
</td>
<td>
<p>192.168.1.50</p>
</td>
<td>
<p>MinIO 备份存储</p>
</td>
<td>
<p>4C/16G</p>
</td>
</tr>
</tbody>
</table>
<p><strong>二、前置条件准备</strong></p>
<p><strong>1. 所有节点基础配置</strong></p>
<p>bash</p>
<p><em># 关闭 SELinux</em></p>
<p>sudo setenforce 0</p>
<p>sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config</p>
<p>&nbsp;</p>
<p><em># 关闭防火墙</em></p>
<p>sudo systemctl stop firewalld</p>
<p>sudo systemctl disable firewalld</p>
<p>&nbsp;</p>
<p><em># 禁用 Swap</em></p>
<p>sudo swapoff -a</p>
<p>sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab</p>
<p>&nbsp;</p>
<p><em># 设置 hosts 解析</em></p>
<p>sudo tee -a /etc/hosts &lt;&lt;EOF</p>
<p>192.168.1.10 lb1</p>
<p>192.168.1.11 lb2</p>
<p>192.168.1.101 master1</p>
<p>192.168.1.102 master2</p>
<p>192.168.1.201 worker1</p>
<p>192.168.1.202 worker2</p>
<p>192.168.1.203 worker3</p>
<p>192.168.1.50 storage</p>
<p>EOF</p>
<p><strong>2. 负载均衡节点配置 (lb1, lb2)</strong></p>
<p>bash</p>
<p><em># 安装 HAProxy 和 Keepalived</em></p>
<p>sudo dnf install -y haproxy keepalived</p>
<p>&nbsp;</p>
<p><em># 配置 HAProxy (/etc/haproxy/haproxy.cfg)</em></p>
<p>sudo tee /etc/haproxy/haproxy.cfg &lt;&lt;EOF</p>
<p>global</p>
<p>&nbsp;&nbsp;&nbsp; log /dev/log local0</p>
<p>&nbsp;&nbsp;&nbsp; maxconn 10000</p>
<p>&nbsp;&nbsp;&nbsp; user haproxy</p>
<p>&nbsp;&nbsp;&nbsp; group haproxy</p>
<p>&nbsp;</p>
<p>defaults</p>
<p>&nbsp;&nbsp;&nbsp; mode tcp</p>
<p>&nbsp;&nbsp;&nbsp; timeout connect 5s</p>
<p>&nbsp;&nbsp;&nbsp; timeout client 50s</p>
<p>&nbsp;&nbsp;&nbsp; timeout server 50s</p>
<p>&nbsp;</p>
<p>frontend k8s-api</p>
<p>&nbsp;&nbsp;&nbsp; bind *:6443</p>
<p>&nbsp;&nbsp;&nbsp; default_backend k8s-masters</p>
<p>&nbsp;</p>
<p>frontend kuboard-http</p>
<p>&nbsp;&nbsp;&nbsp; bind *:80</p>
<p>&nbsp;&nbsp;&nbsp; default_backend kuboard-http-backend</p>
<p>&nbsp;</p>
<p>frontend kuboard-https</p>
<p>&nbsp;&nbsp;&nbsp; bind *:443</p>
<p>&nbsp;&nbsp;&nbsp; default_backend kuboard-https-backend</p>
<p>&nbsp;</p>
<p>backend k8s-masters</p>
<p>&nbsp;&nbsp;&nbsp; balance roundrobin</p>
<p>&nbsp;&nbsp;&nbsp; option tcp-check</p>
<p>&nbsp;&nbsp;&nbsp; server master1 192.168.1.101:6443 check fall 3 rise 2</p>
<p>&nbsp;&nbsp;&nbsp; server master2 192.168.1.102:6443 check fall 3 rise 2</p>
<p>&nbsp;</p>
<p>backend kuboard-http-backend</p>
<p>&nbsp;&nbsp;&nbsp; balance roundrobin</p>
<p>&nbsp;&nbsp;&nbsp; server worker1 192.168.1.201:30080 check</p>
<p>&nbsp;&nbsp;&nbsp; server worker2 192.168.1.202:30080 check</p>
<p>&nbsp;&nbsp;&nbsp; server worker3 192.168.1.203:30080 check</p>
<p>&nbsp;</p>
<p>backend kuboard-https-backend</p>
<p>&nbsp;&nbsp;&nbsp; balance roundrobin</p>
<p>&nbsp;&nbsp;&nbsp; server worker1 192.168.1.201:30443 check</p>
<p>&nbsp;&nbsp;&nbsp; server worker2 192.168.1.202:30443 check</p>
<p>&nbsp;&nbsp;&nbsp; server worker3 192.168.1.203:30443 check</p>
<p>EOF</p>
<p>&nbsp;</p>
<p><em># 启动 HAProxy</em></p>
<p>sudo systemctl enable --now haproxy</p>
<p><strong>3. Keepalived 配置 (lb1 为主节点)</strong></p>
<p>bash</p>
<p><em># lb1 配置 (/etc/keepalived/keepalived.conf)</em></p>
<p>sudo tee /etc/keepalived/keepalived.conf &lt;&lt;EOF</p>
<p>vrrp_script chk_haproxy {</p>
<p>&nbsp;&nbsp;&nbsp; script "pidof haproxy"</p>
<p>&nbsp;&nbsp;&nbsp; interval 2</p>
<p>}</p>
<p>&nbsp;</p>
<p>vrrp_instance VI_1 {</p>
<p>&nbsp;&nbsp;&nbsp; state MASTER</p>
<p>&nbsp;&nbsp;&nbsp; interface ens192&nbsp; # 替换为实际网卡名</p>
<p>&nbsp;&nbsp;&nbsp; virtual_router_id 51</p>
<p>&nbsp;&nbsp;&nbsp; priority 100</p>
<p>&nbsp;&nbsp;&nbsp; advert_int 1</p>
<p>&nbsp;&nbsp;&nbsp; authentication {</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; auth_type PASS</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; auth_pass secretpassword</p>
<p>&nbsp;&nbsp;&nbsp; }</p>
<p>&nbsp;&nbsp;&nbsp; virtual_ipaddress {</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 192.168.1.100/24</p>
<p>&nbsp;&nbsp;&nbsp; }</p>
<p>&nbsp;&nbsp;&nbsp; track_script {</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; chk_haproxy</p>
<p>&nbsp;&nbsp;&nbsp; }</p>
<p>}</p>
<p>EOF</p>
<p>&nbsp;</p>
<p><em># lb2 配置 (备用节点)</em></p>
<p>sudo tee /etc/keepalived/keepalived.conf &lt;&lt;EOF</p>
<p>vrrp_script chk_haproxy {</p>
<p>&nbsp;&nbsp;&nbsp; script "pidof haproxy"</p>
<p>&nbsp;&nbsp;&nbsp; interval 2</p>
<p>}</p>
<p>&nbsp;</p>
<p>vrrp_instance VI_1 {</p>
<p>&nbsp;&nbsp;&nbsp; state BACKUP</p>
<p>&nbsp;&nbsp;&nbsp; interface ens192&nbsp; # 替换为实际网卡名</p>
<p>&nbsp;&nbsp;&nbsp; virtual_router_id 51</p>
<p>&nbsp;&nbsp;&nbsp; priority 90</p>
<p>&nbsp;&nbsp;&nbsp; advert_int 1</p>
<p>&nbsp;&nbsp;&nbsp; authentication {</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; auth_type PASS</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; auth_pass secretpassword</p>
<p>&nbsp;&nbsp;&nbsp; }</p>
<p>&nbsp;&nbsp;&nbsp; virtual_ipaddress {</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 192.168.1.100/24</p>
<p>&nbsp;&nbsp;&nbsp; }</p>
<p>&nbsp;&nbsp;&nbsp; track_script {</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; chk_haproxy</p>
<p>&nbsp;&nbsp;&nbsp; }</p>
<p>}</p>
<p>EOF</p>
<p>&nbsp;</p>
<p><em># 启动 Keepalived</em></p>
<p>sudo systemctl enable --now keepalived</p>
<p><strong>三、Kubernetes 集群部署</strong></p>
<p><strong>1. 所有节点安装容器运行时</strong></p>
<p>bash</p>
<p>sudo dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo</p>
<p>sudo dnf install -y containerd.io</p>
<p>&nbsp;</p>
<p><em># 配置 containerd</em></p>
<p>sudo mkdir -p /etc/containerd</p>
<p>containerd config default | sudo tee /etc/containerd/config.toml</p>
<p>sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml</p>
<p>sudo systemctl restart containerd &amp;&amp; sudo systemctl enable containerd</p>
<p><strong>2. 所有节点安装 Kubernetes 组件</strong></p>
<p>bash</p>
<p>cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo</p>
<p>[kubernetes]</p>
<p>name=Kubernetes</p>
<p>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</p>
<p>enabled=1</p>
<p>gpgcheck=1</p>
<p>repo_gpgcheck=1</p>
<p>gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</p>
<p>EOF</p>
<p>&nbsp;</p>
<p>sudo dnf install -y kubelet-1.28 kubeadm-1.28 kubectl-1.28 --disableexcludes=kubernetes</p>
<p>sudo systemctl enable kubelet</p>
<p><strong>3. 初始化控制平面 (master1)</strong></p>
<p>bash</p>
<p>sudo kubeadm init \</p>
<p>&nbsp; --control-plane-endpoint="192.168.1.100:6443" \</p>
<p>&nbsp; --upload-certs \</p>
<p>&nbsp; --pod-network-cidr=10.244.0.0/16 \</p>
<p>&nbsp; --apiserver-advertise-address=192.168.1.101</p>
<p>&nbsp;</p>
<p>mkdir -p $HOME/.kube</p>
<p>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</p>
<p>sudo chown $(id -u):$(id -g) $HOME/.kube/config</p>
<p><strong>4. 添加其他控制平面节点 (master2)</strong></p>
<p>bash</p>
<p><em># 在 master1 上获取 join 命令</em></p>
<p>kubeadm token create --print-join-command</p>
<p>&nbsp;</p>
<p><em># 在 master2 上执行（添加 --control-plane 参数）</em></p>
<p>sudo kubeadm join 192.168.1.100:6443 --token &lt;token&gt; \</p>
<p>&nbsp; --discovery-token-ca-cert-hash &lt;hash&gt; \</p>
<p>&nbsp; --control-plane \</p>
<p>&nbsp; --certificate-key &lt;cert-key&gt;</p>
<p><strong>5. 添加工作节点</strong></p>
<p>bash</p>
<p><em># 在 worker 节点上执行 join 命令</em></p>
<p>sudo kubeadm join 192.168.1.100:6443 --token &lt;token&gt; \</p>
<p>&nbsp; --discovery-token-ca-cert-hash &lt;hash&gt;</p>
<p><strong>6. 安装网络插件 (Calico)</strong></p>
<p>bash</p>
<p>kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml</p>
<p><strong>四、存储解决方案部署</strong></p>
<p><strong>1. 安装 Longhorn 分布式存储</strong></p>
<p>bash</p>
<p><em># 添加 Helm 仓库</em></p>
<p>helm repo add longhorn https://charts.longhorn.io</p>
<p>helm repo update</p>
<p>&nbsp;</p>
<p><em># 安装 Longhorn</em></p>
<p>helm install longhorn longhorn/longhorn \</p>
<p>&nbsp; --namespace longhorn-system \</p>
<p>&nbsp; --create-namespace \</p>
<p>&nbsp; --set persistence.defaultClass=true \</p>
<p>&nbsp; --set defaultSettings.defaultDataLocality="best-effort" \</p>
<p>&nbsp; --set defaultSettings.replicaSoftAntiAffinity=true \</p>
<p>&nbsp; --set defaultSettings.storageOverProvisioningPercentage=200 \</p>
<p>&nbsp; --set defaultSettings.storageMinimalAvailablePercentage=15 \</p>
<p>&nbsp; --set defaultSettings.guaranteedEngineCPU=0.25</p>
<p><strong>2. 创建 Kuboard 专用存储类</strong></p>
<p>yaml</p>
<p><em># kuboard-storageclass.yaml</em></p>
<p>apiVersion: storage.k8s.io/v1</p>
<p>kind: StorageClass</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-storage</p>
<p>provisioner: driver.longhorn.io</p>
<p>allowVolumeExpansion: true</p>
<p>reclaimPolicy: Retain</p>
<p>volumeBindingMode: Immediate</p>
<p>parameters:</p>
<p>&nbsp; numberOfReplicas: "3"</p>
<p>&nbsp; staleReplicaTimeout: "2880" <em># 48</em><em>小时</em></p>
<p>&nbsp; dataLocality: "best-effort"</p>
<p><strong>五、高可用 Kuboard 部署</strong></p>
<p><strong>1. 创建 Kuboard 命名空间和 PVC</strong></p>
<p>bash</p>
<p>kubectl create namespace kuboard-system</p>
<p>yaml</p>
<p><em># kuboard-pvc.yaml</em></p>
<p>apiVersion: v1</p>
<p>kind: PersistentVolumeClaim</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-data</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>spec:</p>
<p>&nbsp; accessModes:</p>
<p>&nbsp;&nbsp;&nbsp; - ReadWriteMany</p>
<p>&nbsp; storageClassName: kuboard-storage</p>
<p>&nbsp; resources:</p>
<p>&nbsp;&nbsp;&nbsp; requests:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; storage: 20Gi</p>
<p><strong>2. 部署高可用 Kuboard</strong></p>
<p>bash</p>
<p><em># 下载原始部署文件</em></p>
<p>curl -LO https://addons.kuboard.cn/kuboard/kuboard-v3.yaml</p>
<p>&nbsp;</p>
<p><em># 修改为高可用版本</em></p>
<p>sed -i 's/replicas: 1/replicas: 3/' kuboard-v3.yaml</p>
<p>sed -i '/containers:/i \&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; volumes:\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - name: data\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; persistentVolumeClaim:\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; claimName: kuboard-data' kuboard-v3.yaml</p>
<p>sed -i '/containers:/,/ports:/ {/imagePullPolicy:/a \&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; volumeMounts:\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - name: data\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mountPath: /data' kuboard-v3.yaml</p>
<p>&nbsp;</p>
<p><em># 应用配置</em></p>
<p>kubectl apply -f kuboard-v3.yaml</p>
<p><strong>3. 配置服务暴露</strong></p>
<p>yaml</p>
<p><em># kuboard-service.yaml</em></p>
<p>apiVersion: v1</p>
<p>kind: Service</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-v3</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>spec:</p>
<p>&nbsp; selector:</p>
<p>&nbsp;&nbsp;&nbsp; app: kuboard</p>
<p>&nbsp; ports:</p>
<p>&nbsp;&nbsp;&nbsp; - name: http</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; port: 80</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; targetPort: 80</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nodePort: 30080</p>
<p>&nbsp;&nbsp;&nbsp; - name: https</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; port: 443</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; targetPort: 443</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nodePort: 30443</p>
<p>&nbsp; type: NodePort</p>
<p><strong>4. 创建长期有效的访问 Token</strong></p>
<p>bash</p>
<p>kubectl -n kuboard-system create serviceaccount kuboard-admin</p>
<p>kubectl create clusterrolebinding kuboard-admin-binding \</p>
<p>&nbsp; --clusterrole=cluster-admin \</p>
<p>&nbsp; --serviceaccount=kuboard-system:kuboard-admin</p>
<p>&nbsp;</p>
<p><em># 创建有效期1年的Token</em></p>
<p>kubectl -n kuboard-system create token kuboard-admin --duration=8760h &gt; kuboard-token.txt</p>
<p><strong>六、备份解决方案</strong></p>
<p><strong>1. 安装 MinIO 备份存储</strong></p>
<p>bash</p>
<p><em># 在 storage 节点安装 MinIO</em></p>
<p>sudo dnf install -y minio</p>
<p>&nbsp;</p>
<p><em># 创建数据目录</em></p>
<p>sudo mkdir -p /data/backups</p>
<p>sudo chown minio-user:minio-user /data/backups</p>
<p>&nbsp;</p>
<p><em># 配置 MinIO 服务</em></p>
<p>sudo tee /etc/default/minio &lt;&lt;EOF</p>
<p>MINIO_VOLUMES="/data/backups"</p>
<p>MINIO_OPTS="--address :9000 --console-address :9001"</p>
<p>MINIO_ROOT_USER=admin</p>
<p>MINIO_ROOT_PASSWORD=StrongPassword123!</p>
<p>EOF</p>
<p>&nbsp;</p>
<p><em># 启动 MinIO</em></p>
<p>sudo systemctl enable --now minio</p>
<p><strong>2. 安装 Velero 备份工具</strong></p>
<p>bash</p>
<p><em># 下载 Velero 客户端</em></p>
<p>wget https://github.com/vmware-tanzu/velero/releases/download/v1.11.1/velero-v1.11.1-linux-amd64.tar.gz</p>
<p>tar -zxvf velero-v1.11.1-linux-amd64.tar.gz</p>
<p>sudo mv velero-v1.11.1-linux-amd64/velero /usr/local/bin/</p>
<p>&nbsp;</p>
<p><em># 创建备份凭证</em></p>
<p>cat &lt;&lt;EOF &gt; credentials-velero</p>
<p>[default]</p>
<p>aws_access_key_id = admin</p>
<p>aws_secret_access_key = StrongPassword123!</p>
<p>EOF</p>
<p>&nbsp;</p>
<p><em># 安装 Velero</em></p>
<p>velero install \</p>
<p>&nbsp; --provider aws \</p>
<p>&nbsp; --plugins velero/velero-plugin-for-aws:v1.7.0 \</p>
<p>&nbsp; --bucket kuboard-backups \</p>
<p>&nbsp; --secret-file ./credentials-velero \</p>
<p>&nbsp; --use-volume-snapshots=true \</p>
<p>&nbsp; --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=http://192.168.1.50:9000 \</p>
<p>&nbsp; --snapshot-location-config region=minio</p>
<p><strong>3. 配置定期备份</strong></p>
<p>bash</p>
<p><em># 每日全量备份</em></p>
<p>velero schedule create kuboard-daily \</p>
<p>&nbsp; --schedule="0 3 * * *" \</p>
<p>&nbsp; --include-namespaces kuboard-system \</p>
<p>&nbsp; --ttl 72h</p>
<p>&nbsp;</p>
<p><em># 每周快照备份</em></p>
<p>velero schedule create kuboard-weekly \</p>
<p>&nbsp; --schedule="0 4 * * 0" \</p>
<p>&nbsp; --include-namespaces kuboard-system \</p>
<p>&nbsp; --ttl 720h \</p>
<p>&nbsp; --snapshot-volumes</p>
<p><strong>4. 备份验证脚本</strong></p>
<p>bash</p>
<p>#!/bin/bash</p>
<p><em># check-backup.sh</em></p>
<p>&nbsp;</p>
<p><em># 检查最新备份状态</em></p>
<p>LATEST_BACKUP=$(velero backup get | grep kuboard-daily | sort -r | head -n1 | awk '{print $1}')</p>
<p>BACKUP_STATUS=$(velero backup describe $LATEST_BACKUP --details | grep Phase | awk '{print $3}')</p>
<p>&nbsp;</p>
<p>if [ "$BACKUP_STATUS" != "Completed" ]; then</p>
<p>&nbsp; echo "Backup $LATEST_BACKUP failed! Status: $BACKUP_STATUS"</p>
<p>&nbsp; exit 1</p>
<p>else</p>
<p>&nbsp; echo "Backup $LATEST_BACKUP completed successfully"</p>
<p>fi</p>
<p>&nbsp;</p>
<p><em># 添加至 cron 每日检查</em></p>
<p><em># 0 4 * * * /path/to/check-backup.sh | mail -s "Kuboard Backup Report" admin@example.com</em></p>
<p><strong>七、访问与监控</strong></p>
<p><strong>1. 访问 Kuboard</strong></p>
<ul>
<li>URL:&nbsp;<a href="http://192.168.1.100/" target="_blank" rel="noopener nofollow">http://192.168.1.100</a></li>
<li>登录方式: 使用&nbsp;<strong>kuboard-token.txt</strong>&nbsp;中的 Token</li>
</ul>
<p><strong>2. 监控配置</strong></p>
<p>yaml</p>
<p><em># kuboard-monitor.yaml</em></p>
<p>apiVersion: monitoring.coreos.com/v1</p>
<p>kind: ServiceMonitor</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-monitor</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>spec:</p>
<p>&nbsp; selector:</p>
<p>&nbsp;&nbsp;&nbsp; matchLabels:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; app: kuboard</p>
<p>&nbsp; endpoints:</p>
<p>&nbsp; - port: http</p>
<p>&nbsp;&nbsp;&nbsp; interval: 30s</p>
<p>&nbsp;&nbsp;&nbsp; path: /metrics</p>
<p><strong>3. 告警规则</strong></p>
<p>yaml</p>
<p><em># kuboard-alerts.yaml</em></p>
<p>apiVersion: monitoring.coreos.com/v1</p>
<p>kind: PrometheusRule</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-alerts</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>spec:</p>
<p>&nbsp; groups:</p>
<p>&nbsp; - name: kuboard-rules</p>
<p>&nbsp;&nbsp;&nbsp; rules:</p>
<p>&nbsp;&nbsp;&nbsp; - alert: KuboardDown</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; expr: up{job="kuboard"} == 0</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for: 5m</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; labels:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; severity: critical</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; annotations:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; summary: Kuboard pod down in {{ $labels.namespace }}</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp; - alert: KuboardHighLatency</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; expr: histogram_quantile(0.95, sum(rate(kuboard_request_duration_seconds_bucket[5m])) by (le) &gt; 3</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for: 10m</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; labels:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; severity: warning</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; annotations:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; summary: Kuboard high request latency</p>
<p><strong>八、运维与维护</strong></p>
<p><strong>1. 日常维护命令</strong></p>
<table border="0" cellspacing="0" cellpadding="0">
<thead>
<tr>
<td>
<p><strong>操作</strong></p>
</td>
<td>
<p><strong>命令</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
<p>查看 Kuboard 状态</p>
</td>
<td>
<p><strong>kubectl -n kuboard-system get pods -l app=kuboard</strong></p>
</td>
</tr>
<tr>
<td>
<p>检查备份状态</p>
</td>
<td>
<p><strong>velero backup get</strong></p>
</td>
</tr>
<tr>
<td>
<p>查看存储使用</p>
</td>
<td>
<p><strong>kubectl -n longhorn-system get volumes</strong></p>
</td>
</tr>
<tr>
<td>
<p>重启 Kuboard</p>
</td>
<td>
<p><strong>kubectl -n kuboard-system rollout restart deployment kuboard-v3</strong></p>
</td>
</tr>
</tbody>
</table>
<p><strong>2. 灾难恢复流程</strong></p>
<ol start="1">
<li><strong>恢复集群状态</strong>:</li>
</ol>
<p>bash</p>
<p>velero restore create --from-backup kuboard-daily-latest</p>
<ol start="2">
<li><strong>恢复存储卷</strong>:</li>
</ol>
<p>bash</p>
<p><em># 列出可用快照</em></p>
<p>velero snapshot location get</p>
<p>&nbsp;</p>
<p><em># 恢复特定卷</em></p>
<p>velero restore create --from-backup kuboard-daily-latest \</p>
<p>&nbsp; --restore-volumes \</p>
<p>&nbsp; --include-resources persistentvolumeclaims,persistentvolumes</p>
<p><strong>3. 升级策略</strong></p>
<p><strong>图表</strong></p>
<p>&nbsp;</p>
<p><strong>九、安全加固</strong></p>
<p><strong>1. RBAC 权限控制</strong></p>
<p>yaml</p>
<p>apiVersion: rbac.authorization.k8s.io/v1</p>
<p>kind: Role</p>
<p>metadata:</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>&nbsp; name: kuboard-viewer</p>
<p>rules:</p>
<p>- apiGroups: [""]</p>
<p>&nbsp; resources: ["pods", "services", "deployments"]</p>
<p>&nbsp; verbs: ["get", "list", "watch"]</p>
<p><strong>2. 网络策略</strong></p>
<p>yaml</p>
<p>apiVersion: projectcalico.org/v3</p>
<p>kind: NetworkPolicy</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-access</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>spec:</p>
<p>&nbsp; selector: app == 'kuboard'</p>
<p>&nbsp; ingress:</p>
<p>&nbsp; - action: Allow</p>
<p>&nbsp;&nbsp;&nbsp; protocol: TCP</p>
<p>&nbsp;&nbsp;&nbsp; source:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; namespaceSelector: name == 'ingress-nginx'</p>
<p>&nbsp;&nbsp;&nbsp; destination:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ports: [80, 443]</p>
<p>&nbsp; egress:</p>
<p>&nbsp; - action: Allow</p>
<p>&nbsp;&nbsp;&nbsp; protocol: TCP</p>
<p>&nbsp;&nbsp;&nbsp; destination:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ports: [80, 443]</p>
<p>&nbsp; - action: Allow</p>
<p>&nbsp;&nbsp;&nbsp; protocol: UDP</p>
<p>&nbsp;&nbsp;&nbsp; destination:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ports: [53]</p>
<p><strong>3. 证书管理</strong></p>
<p>bash</p>
<p><em># 为 Kuboard 生成 TLS 证书</em></p>
<p>openssl req -x509 -nodes -days 365 -newkey rsa:2048 \</p>
<p>&nbsp; -keyout kuboard.key -out kuboard.crt \</p>
<p>&nbsp; -subj "/CN=kuboard.example.com" \</p>
<p>&nbsp; -addext "subjectAltName=DNS:kuboard.example.com,IP:192.168.1.100"</p>
<p>&nbsp;</p>
<p><em># 创建 Kubernetes Secret</em></p>
<p>kubectl -n kuboard-system create secret tls kuboard-tls \</p>
<p>&nbsp; --key kuboard.key \</p>
<p>&nbsp; --cert kuboard.crt</p>
<p><strong>十、性能优化建议</strong></p>
<p><strong>1. Kuboard 资源配置</strong></p>
<p>yaml</p>
<p><em># kuboard-resources.yaml</em></p>
<p>apiVersion: apps/v1</p>
<p>kind: Deployment</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-v3</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>spec:</p>
<p>&nbsp; template:</p>
<p>&nbsp;&nbsp;&nbsp; spec:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; containers:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - name: kuboard</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; resources:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; requests:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; memory: "512Mi"</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu: "250m"</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; limits:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; memory: "2Gi"</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu: "1"</p>
<p><strong>2. 数据库性能优化</strong></p>
<p>sql</p>
<p><em>-- 在 Kuboard 的 PostgreSQL 中执行</em></p>
<p>ALTER SYSTEM SET shared_buffers = '1GB';</p>
<p>ALTER SYSTEM SET work_mem = '32MB';</p>
<p>ALTER SYSTEM SET maintenance_work_mem = '256MB';</p>
<p>ALTER SYSTEM SET effective_cache_size = '3GB';</p>
<p><strong>3. 缓存配置</strong></p>
<p>yaml</p>
<p><em># kuboard-cache.yaml</em></p>
<p>apiVersion: apps/v1</p>
<p>kind: Deployment</p>
<p>metadata:</p>
<p>&nbsp; name: kuboard-v3</p>
<p>&nbsp; namespace: kuboard-system</p>
<p>spec:</p>
<p>&nbsp; template:</p>
<p>&nbsp;&nbsp;&nbsp; spec:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; containers:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - name: kuboard</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; env:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - name: CACHE_TYPE</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; value: "redis"</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;- name: REDIS_URL</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; value: "redis://redis.kuboard-system:6379/0"</p>
<p><strong>总结</strong></p>
<p>此方案提供了在 CentOS Stream 8 上部署高可用 Kuboard 的完整解决方案，关键特点包括：</p>
<ol start="1">
<li><strong>高可用架构</strong>：</li>
<ul>
<li>多副本 Kuboard (3个实例)</li>
<li>负载均衡 (HAProxy + Keepalived VIP)</li>
<li>分布式存储 (Longhorn)</li>
</ul>
<li><strong>持久化存储</strong>：</li>
<ul>
<li>Longhorn 提供分布式块存储</li>
<li>专用存储类配置</li>
<li>多副本数据保护</li>
</ul>
<li><strong>备份解决方案</strong>：</li>
<ul>
<li>Velero 定时备份</li>
<li>MinIO 备份存储</li>
<li>备份状态监控</li>
</ul>
<li><strong>安全加固</strong>：</li>
<ul>
<li>RBAC 权限控制</li>
<li>网络策略隔离</li>
<li>TLS 加密通信</li>
</ul>
<li><strong>监控告警</strong>：</li>
<ul>
<li>Prometheus 集成</li>
<li>关键指标告警</li>
<li>性能监控</li>
</ul>
</ol>
<p>此架构能够支持中等规模生产环境的使用，建议每季度进行一次全链路压力测试，每月验证一次备份恢复流程，确保系统的高可用性和数据安全性。</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-06-16 16:16">2025-06-16 16:15</span>&nbsp;
<a href="https://www.cnblogs.com/Johny-zhao">Johny_Zhao</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18931339);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18931339', targetLink: 'https://www.cnblogs.com/Johny-zhao/p/18931339', title: 'CentOS Stream 8 高可用 Kuboard 部署方案' })">举报</a>
</div>
        