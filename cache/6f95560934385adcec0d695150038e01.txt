
		<h1 class="postTitle">
			<a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/aser1989/p/18814304" title="发布于 2025-04-08 13:03">
    <span role="heading" aria-level="2">从零散笔记到结构化知识库：我的文档网站建设之路</span>
    

</a>

		</h1>
		<div class="clear"></div>
		<div class="postBody">
			<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>我一直有记录笔记的习惯，无论是在工作还是学习中。但随着近年来更换笔记软件、频繁迁移数据，笔记内容逐渐变得零散、分散，缺乏系统性与整体性。为了更好地沉淀和复用这些知识，我决定搭建一个文档网站，对过往的笔记进行梳理与整合，逐步构建一套结构清晰、内容完整的知识资料库。</p>
<p>下面是我在这个过程中所做的一些尝试与实践。<br>
<br></p>
<h2 id="k8s不务正业地搭了个集群">K8s：不务正业地搭了个集群</h2>
<p>在一次“手痒”的驱使下，我在服务器上部署了一个 K8s 集群（有兴趣的朋友可以看看这篇：<a href="https://www.cnblogs.com/aser1989/p/18797001" target="_blank">用99元买的服务器搭一套CI/CD系统</a>）。虽然这并不是搭建文档网站的必要步骤，因为作为一个静态网站，其实用 <code>httpd</code> 或 <code>IIS</code> 就足够了。在服务器上部署K8s主要是为了了解更多K8s相关的知识。</p>
<p>目前我的集群由两台服务器组成：一台是阿里云 99 元/年的 ECS（Master），另一台是华为云的轻量应用服务器（原来的腾讯云体验版已到期）。两台服务器配置均为 2 核 2G，组成了一个跨公网的集群。需要注意的是，这种架构在访问速度上会受到明显影响，尤其是在带宽不理想的情况下。如果有条件，推荐使用同一家云服务商的主机，以减少网络延迟。</p>
<p>主力运行节点其实是华为云的那台服务器。虽然使用 <code>K3s</code> 构建的集群中 Server 既是 Master 也是 Worker，但由于我在集群上部署了 <code>Argo CD</code>，再加上本来就紧张的内存资源，导致运行相当吃力。后来关闭了 <code>kdump</code>，勉强挤出约 200MB 的内存，才算稳定运行。<br>
<br></p>
<h2 id="argo-cd轻量好用的-gitops-实现">Argo CD：轻量好用的 GitOps 实现</h2>
<p>考虑到我并不需要完整的 DevOps 平台，也没有企业级资源，于是选择了开源、口碑不错的 GitOps 工具 —— <code>Argo CD</code>。它的主要作用是自动化部署文档网站：每次更新文档并推送至 Git 仓库后，CI 流程完成构建，<code>Argo CD</code> 会自动拉取新版本并部署。</p>
<p>虽然配置初期略有学习成本，但上手之后带来的便利是非常明显的：部署自动化、版本回滚、配置追踪，一应俱全。就目前的效果而言，我个人是相当满意的，每次添加了文档后推送到Git仓库就不管了，程序会在CI执行完成后自动更新部署。</p>
<br>
<h2 id="github-actions免费的自动构建工具">Github Actions：免费的自动构建工具</h2>
<p>我最初使用的是 <code>Harness CI</code>，不过由于网站源码托管在 GitHub 上，直接使用 <code>Github Actions</code> 代替了原来的 <code>Harness CI</code>。这里有个小惊喜 —— 对于前端项目，<code>GitHub Actions</code> 在安装 <code>node_modules</code> 方面的效率极高。而且它运行在 <strong>GitHub</strong> 的托管环境中，我也不需要担心服务器内存不够的问题，毕竟只是闹着玩，再多折腾点就要玩不下去了。</p>
<p>CI 的核心流程如下：</p>
<ol>
<li>安装依赖并构建静态资源；</li>
<li>将构建结果打包成 <code>Docker</code> 镜像；</li>
<li>推送镜像到阿里云容器仓库；</li>
<li>更新部署配置中的镜像版本号，触发 <code>Argo CD</code> 自动部署。</li>
</ol>
<p>整体运行平稳，唯一不足在于<strong>Github</strong>的访问不太稳定，导致 <code>Argo CD</code> 有时无法拉取到最新的配置。不过，这并不影响整体使用，因为我对线上文档更新的实时性要求不高，而且通常几分钟内就能恢复正常。</p>
<br>
<h2 id="docusaurus开源文档框架">Docusaurus：开源文档框架</h2>
<p>为了整理这些笔记，我选择了由 Facebook开发的开源文档框架 <code>Docusaurus</code>。它是一个基于<code>Markdown</code> 和 <code>React</code> 的静态网站生成器，专为构建文档网站设计，既简洁易用，又可高度定制。相比 <code>VuePress</code>，我更喜欢 <code>Docusaurus</code> 在自定义页面开发方面的灵活性，它默认支持 MDX，允许在 <code>Markdown</code> 中直接使用 <code>React</code> 组件，这为前端开发者带来了极大的便利。</p>
<p>同时，<code>Docusaurus</code> 提供了一些官方插件和功能模块，如：</p>
<ul>
<li>搜索（相关插件数量应该是最多的）</li>
<li>国际化（i18n）</li>
<li>PWA 支持</li>
<li>多版本文档</li>
<li>博客系统</li>
</ul>
<p>虽然插件生态不如 <code>VuePress</code> 丰富，但核心功能已经非常完善，尤其适合做结构化、系统化的技术知识整理。</p>
<br>
<h2 id="性能优化措施">性能优化措施</h2>
<p>为了提升网站的访问速度，在资源有限的条件下，我主要做了两件优化工作：</p>
<ul>
<li><strong>配置 HTTPS</strong>：这是启用 HTTP/2 的前提。使用 HTTP/2 主要是为了突破浏览器的并发连接限制，从而提升网站加载速度。</li>
<li><strong>启用内容压缩</strong>：通过 <code>Traefik</code> 中间件实现内容压缩。在带宽受限的情况下，启用压缩能够显著加快内容的传输速度。</li>
</ul>
<br>
<h2 id="最后">最后</h2>
<p>网站已经部署一段时间，当前已完成部分文档的整理。如果感兴趣，可以访问 <a href="https://www.aser1989.cn/" target="_blank" rel="noopener nofollow">aser1989.cn</a> 查看相关内容。</p>

</div>
<div class="clear"></div>

		</div>
		<div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.21587144489930554" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-08 13:07">2025-04-08 13:03</span>&nbsp;
<a href="https://www.cnblogs.com/aser1989">ASER_1989</a>&nbsp;
阅读(<span id="post_view_count">285</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18814304" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18814304);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18814304', targetLink: 'https://www.cnblogs.com/aser1989/p/18814304', title: '从零散笔记到结构化知识库：我的文档网站建设之路' })">举报</a>
</div>
	