
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/token-ai/p/18876966" title="发布于 2025-05-15 02:40">
    <span role="heading" aria-level="2">使用离线部署32B模型实现OpenDeepWiki项目代码自动分析与文档生成</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="背景介绍">背景介绍</h2>
<p>在企业环境中，我们经常需要对公司项目代码进行分析和文档生成。然而，考虑到代码的保密性，将代码上传至公共AI平台存在安全隐患。为解决这一问题，我们可以在公司内部GPU服务器上部署强大的大语言模型（如<code>qwen2.5:32b-instruct-fp16</code>），并结合OpenDeepWiki工具，实现安全、高效的代码仓库分析与文档自动生成。</p>
<h2 id="环境需求">环境需求</h2>
<ul>
<li><strong>硬件</strong>: 支持<code>qwen2.5:32b-instruct-fp16</code>模型运行的GPU服务器（推荐配置：4*RTX 3090）</li>
<li><strong>软件</strong>: Ollama（用于部署模型）、Docker和Docker Compose环境</li>
<li><strong>网络</strong>: 内部网络环境，确保安全性</li>
</ul>
<h2 id="部署步骤">部署步骤</h2>
<h3 id="1-部署opendeepwiki">1. 部署OpenDeepWiki</h3>
<p>在服务器上创建并配置必要文件：</p>
<p><strong>docker-compose.yml</strong>:</p>
<pre><code class="language-yml">services:
  koalawiki:
    image: crpi-j9ha7sxwhatgtvj4.cn-shenzhen.personal.cr.aliyuncs.com/koala-ai/koala-wiki
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TASK_MAX_SIZE_PER_USER=5 # 每个用户AI处理文档生成的最大数量
      - REPAIR_MERMAID=1 # 是否进行Mermaid修复，1修复，其余不修复
      - CHAT_MODEL=qwen2.5:32b-instruct-fp16 # 必须要支持function的模型
      - ANALYSIS_MODEL=qwen2.5:32b-instruct-fp16 # 分析模型，用于生成仓库目录结构，这个很重要，模型越强，生成的目录结构越好，为空则使用ChatModel
      - CHAT_API_KEY=sk- #您的APIkey
      - LANGUAGE=简体中文 # 设置生成语言默认为"中文"
      - ENDPOINT=http://您的Ollamaip:11434/v1
      - DB_TYPE=sqlite
      - DB_CONNECTION_STRING=Data Source=/data/KoalaWiki.db
      - UPDATE_INTERVAL=5 # 仓库增量更新间隔，单位天
      - EnableSmartFilter=true # 是否启用智能过滤，这可能影响AI得到仓库的文件目录
      - PARALLEL_COUNT=1 # The warehouse processes the quantity in parallel
    volumes:
      - ./repositories:/app/repositories
      - ./data:/data
      
  koalawiki-web:
    image: crpi-j9ha7sxwhatgtvj4.cn-shenzhen.personal.cr.aliyuncs.com/koala-ai/koala-wiki-web
    environment:
      - NEXT_PUBLIC_API_URL=http://koalawiki:8080 # 用于提供给server的地址
      
  nginx: # 需要nginx将前端和后端代理到一个端口
    image: crpi-j9ha7sxwhatgtvj4.cn-shenzhen.personal.cr.aliyuncs.com/koala-ai/nginx:alpine
    ports:
      - 8090:80
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - koalawiki
      - koalawiki-web
</code></pre>
<p><strong>nginx.conf</strong>:</p>
<pre><code class="language-nginx">server {
    listen 80;
    server_name localhost;

    # 设置上传文件大小限制为 100MB
    client_max_body_size 100M;

    # 日志配置
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # 代理所有 /api/ 请求到后端服务
    location /api/ {
        proxy_pass http://koalawiki:8080/api/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }

    # 其他所有请求转发到前端服务
    location / {
        proxy_pass http://koalawiki-web:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}
</code></pre>
<h3 id="2-启动服务">2. 启动服务</h3>
<p>创建好上述文件后，在同级目录下执行以下命令：</p>
<ol>
<li>
<p>拉取必要的镜像：</p>
<pre><code class="language-bash">docker-compose pull
</code></pre>
</li>
<li>
<p>启动容器：</p>
<pre><code class="language-bash">docker-compose up -d
</code></pre>
</li>
<li>
<p>等待服务初始化完成（通常需要几分钟）</p>
</li>
</ol>
<h3 id="3-访问opendeepwiki平台">3. 访问OpenDeepWiki平台</h3>
<p>在浏览器中访问 <code>http://[服务器IP]:8090</code>，即可看到OpenDeepWiki的界面：<br>
<img src="https://img2024.cnblogs.com/blog/3578564/202505/3578564-20250515023959565-2063848380.png" alt="" loading="lazy"></p>
<h2 id="使用指南">使用指南</h2>
<h3 id="添加代码仓库进行分析">添加代码仓库进行分析</h3>
<ol>
<li>
<p>从以下地址获取OpenDeepWiki源码（推荐国内用户使用Gitee）：</p>
<ul>
<li>GitHub: <a href="https://github.com/AIDotNet/OpenDeepWiki" target="_blank" rel="noopener nofollow">https://github.com/AIDotNet/OpenDeepWiki</a></li>
<li>Gitee: <a href="https://gitee.com/AIDotNet/OpenDeepWiki" target="_blank" rel="noopener nofollow">https://gitee.com/AIDotNet/OpenDeepWiki</a></li>
</ul>
</li>
<li>
<p>下载源码的ZIP压缩包</p>
</li>
<li>
<p>在OpenDeepWiki平台点击"添加新仓库"：</p>
</li>
</ol>
<p><img src="https://img2024.cnblogs.com/blog/3578564/202505/3578564-20250515023953325-633511532.png" alt="" loading="lazy"></p>
<ol start="4">
<li>选择"上传压缩包"，填写组织名称和仓库名称（这些字段必填，将影响前端路由显示），然后提交：</li>
</ol>
<p><img src="https://img2024.cnblogs.com/blog/3578564/202505/3578564-20250515023949852-721637043.png" alt="" loading="lazy"></p>
<ol start="5">
<li>上传完成后，系统将开始处理仓库（处理时间约为3-5分钟）。处理中的仓库会显示在列表中：</li>
</ol>
<p><img src="https://img2024.cnblogs.com/blog/3578564/202505/3578564-20250515023944445-57983962.png" alt="" loading="lazy"></p>
<ol start="6">
<li>处理完成后，点击仓库名称即可查看由<code>qwen2.5:32b-instruct-fp16</code>模型自动生成的文档：</li>
</ol>
<p><img src="https://img2024.cnblogs.com/blog/3578564/202505/3578564-20250515023940731-386459166.png" alt="" loading="lazy"></p>
<h2 id="系统优势">系统优势</h2>
<ul>
<li><strong>安全可控</strong>：所有代码分析和文档生成过程都在内部环境完成，确保代码安全</li>
<li><strong>高质量文档</strong>：借助强大的<code>qwen2.5:32b-instruct-fp16</code>模型，生成的文档结构清晰、内容全面</li>
<li><strong>一键操作</strong>：简单的上传流程，无需复杂配置</li>
<li><strong>可扩展性</strong>：支持多种代码仓库格式，适用于不同项目需求</li>
</ul>
<h2 id="结语">结语</h2>
<p>通过部署OpenDeepWiki与<code>qwen2.5:32b-instruct-fp16</code>模型，我们可以安全、高效地为公司代码仓库生成完整文档，大幅提升项目理解和开发效率。</p>
<p>如果您对OpenDeepWiki感兴趣，欢迎访问以下地址并给项目点个Star：</p>
<ul>
<li>GitHub: <a href="https://github.com/AIDotNet/OpenDeepWiki" target="_blank" rel="noopener nofollow">https://github.com/AIDotNet/OpenDeepWiki</a></li>
<li>Gitee: <a href="https://gitee.com/AIDotNet/OpenDeepWiki" target="_blank" rel="noopener nofollow">https://gitee.com/AIDotNet/OpenDeepWiki</a></li>
</ul>
<p><strong>在线体验地址</strong>：<a href="https://opendeep.wiki/" target="_blank" rel="noopener nofollow">https://opendeep.wiki/</a><br>
目前已有500+仓库加入！您也可以将您的开源仓库添加进来。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.06606236898842592" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-05-15 02:40">2025-05-15 02:40</span>&nbsp;
<a href="https://www.cnblogs.com/token-ai">239573049</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18876966);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18876966', targetLink: 'https://www.cnblogs.com/token-ai/p/18876966', title: '使用离线部署32B模型实现OpenDeepWiki项目代码自动分析与文档生成' })">举报</a>
</div>
        