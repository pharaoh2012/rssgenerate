
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xiaobaiysf/p/18790813" title="发布于 2025-03-25 10:22">
    <span role="heading" aria-level="2">MaxKB+Ollama 离线部署</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>主题：在 Centos7 环境部署 MaxKB 以及 Ollama 实现基于离线大模型的的小助手调用。<br>
选择离线部署的原因：原计划是打算直接使用 1Panel 进行 MaxKB 和 Ollama 一键部署的，但是两者都会出现 Docker 远程拉取镜像超时的问题，于是选择了离线部署。</p>
<h1 id="一maxkb-的离线部署">一、MaxKB 的离线部署</h1>
<p>先下载对应的 MaxKB 离线安装包 ：<a href="https://community.fit2cloud.com/#/products/maxkb/downloads" target="_blank" rel="noopener nofollow">https://community.fit2cloud.com/#/products/maxkb/downloads</a></p>
<p>将安装包上传到机器上后 执行以下命令进行安装包的解压和安装</p>
<pre><code># 解压
tar -zxvf maxkb-v1.2.0-offline.tar.gz

# 进入安装包解压缩后目录
 cd maxkb-v1.2.0-offline

# 执行安装命令即可 
bash install.sh
</code></pre>
<p>参考网址 ：<a href="https://maxkb.cn/docs/installation/offline_installtion/" target="_blank" rel="noopener nofollow">https://maxkb.cn/docs/installation/offline_installtion/</a></p>
<p>ps 也可运行以下命令可以成功拉取镜像并运行容器</p>
<p><code>docker run -d --name=maxkb -p 8080:8080 -v ~/.maxkb:/var/lib/postgresql/data cr2.fit2cloud.com/1panel/maxkb</code></p>
<h1 id="二部署-ollama">二、部署 Ollama</h1>
<p>执行命令</p>
<p><code>curl -fsSL https://ollama.com/install.sh | sh</code></p>
<p>参考 ： <a href="https://github.com/ollama/ollama" target="_blank" rel="noopener nofollow">https://github.com/ollama/ollama</a> （上面提供各类操作系统的安装指导）</p>
<p>执行成功后会出现以下图样：</p>
<p>其中红框显示的是当前部署的 Ollama 的 API 调用地址<br>
<img src="https://img2024.cnblogs.com/blog/3600464/202503/3600464-20250325101019803-500412985.png" alt="" loading="lazy"></p>
<p>可以执行一下命令查看 Ollama 当前的状态</p>
<pre><code>#安装好后查看当前 Ollama 下拥有的模型（由于当前还没有拉取，所以目录为空）
[root@iZ7xvigag1tcx13yaa7cmhZ opt]# ollama list
NAME    ID      SIZE    MODIFIED 

#查看当前 Ollama 的版本
[root@iZ7xvigag1tcx13yaa7cmhZ opt]# ollama -v
Ollama version is 0.3.3

#Ollama 的运行状态
[root@iZ7xvigag1tcx13yaa7cmhZ opt]# systemctl status ollama
● ollama.service - Ollama Service
Loaded: loaded (/etc/systemd/system/ollama.service; enabled; vendor preset: disabled)
Active: active (running) since Sun 2024-08-04 01:02:47 CST; 36min ago
Main PID: 14453 (ollama)
Tasks: 10
Memory: 999.3M
</code></pre>
<p>最后将 Ollama 的 API 调用地址填写到MaxKB的配置 Ollama 模型 API 域名的位置</p>
<p><img src="https://img2024.cnblogs.com/blog/3600464/202503/3600464-20250325101232679-954892676.png" alt="" loading="lazy"></p>
<p>这里要特别注意：<br>
如果直接填写上图中的 127.0.0.1 的路径，点击添加会出现 API 域名无效的提示，以下是当时遇到该问题的解决过程：</p>
<pre><code>先验证当前 Ollama 的 API 是可以访问的

[root@iZ7xvigag1tcx13yaa7cmhZ opt]# curl http://127.0.0.1:11434/
Ollama is running

然后进入 /etc/systemd/system 目录 修改 ollama.service 文件

[root@iZ7xvigag1tcx13yaa7cmhZ opt]# cd /etc/systemd/system/

将其中的 Environment="PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin"
改为 Environment="OLLAMA_HOST=0.0.0.0"
修改其监听地址为 0.0.0.0

#重启加载配置文件及重启 Ollama
[root@iZ7xvigag1tcx13yaa7cmhZ system]# sudo systemctl daemon-reload
[root@iZ7xvigag1tcx13yaa7cmhZ system]# sudo systemctl restart ollama

#进入 MaxKB 的 Docker 容器中测试是否可以根据该地址访问到 Ollama
[root@iZ7xvigag1tcx13yaa7cmhZ system]# docker exec -it maxkb bash
root@f5be799b5776:/opt/maxkb/app# curl http://ip:11434/ （这里的 IP 是本机对应的ip地址，可以通过命令 ip addr 查询）
Ollama is runningroot@f5be799b5776:/opt/maxkb/app#
 
出现 Ollama is running 即可

然后将该地址配置到 API 域名上即可
</code></pre>
<p>解决方法参考：<a href="https://bbs.fit2cloud.com/t/topic/4165/20" target="_blank" rel="noopener nofollow">https://bbs.fit2cloud.com/t/topic/4165/20</a> （在 MaxKB 论坛中发现）</p>
<p>由于本次部署仅尝试整个部署流程，未配置独显，所以大部分独显的大模型是无法运行的。机器配置为 2C4G，有问题或者疑问欢迎一起讨论~</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.02055072909837963" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-03-25 10:29">2025-03-25 10:22</span>&nbsp;
<a href="https://www.cnblogs.com/xiaobaiysf">小白跃升坊</a>&nbsp;
阅读(<span id="post_view_count">13</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18790813" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18790813);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18790813', targetLink: 'https://www.cnblogs.com/xiaobaiysf/p/18790813', title: 'MaxKB+Ollama 离线部署' })">举报</a>
</div>
        