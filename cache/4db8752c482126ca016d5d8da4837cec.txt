
    <a name="top"></a>
    <h2><a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/jyzhao/p/18700202/shou-ba-shou-jiao-ni-bu-shu-deepseek-ben-de-mo-xin" title="发布于 2025-02-05 21:48">
    <span role="heading" aria-level="2">手把手教你部署 DeepSeek 本地模型</span>
    

</a>
</h2>
    <small>
<span id="post-date" data-last-update-days="20.114583333333332" data-date-updated="2025-02-26 00:33">2025-02-05 21:48</span>&nbsp;
<a href="https://www.cnblogs.com/jyzhao">AlfredZhao</a>&nbsp;
阅读(<span id="post_view_count">110941</span>)&nbsp;
评论(<span id="post_comment_count">20</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18700202);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18700202', targetLink: 'https://www.cnblogs.com/jyzhao/p/18700202/shou-ba-shou-jiao-ni-bu-shu-deepseek-ben-de-mo-xin', title: '手把手教你部署 DeepSeek 本地模型' })">举报</a>
</small>
    <div class="entry">
        <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>本文目标：部署 DeepSeek 本地模型，并通过 Ollama 提供 API 支持，Chatbox 提供 UI 界面。<br>
原则：不搞那些高深的玩法，让小白也能理解并真正的上手实践。</p>
<ul>
<li>1.下载Ollama并安装运行DeepSeek</li>
<li>2.下载Chatbox并配置为本地DeepSeek</li>
<li>3.无需联网也能和DeepSeek畅快聊天</li>
</ul>
<p><img alt="ds" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811347-1748069224.png" class="lazyload"></p>
<h1 id="1下载ollama并安装运行deepseek">1.下载Ollama并安装运行DeepSeek</h1>
<p>从Ollama官方网站下载Ollama：</p>
<ul>
<li><a href="https://ollama.com/" target="_blank" rel="noopener nofollow">https://ollama.com/</a></li>
</ul>
<p>进入Ollama官方网站后，可以看到Ollama已经支持DeepSeek-R1的部署：</p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811504-1044867574.jpg" class="lazyload"></p>
<p>点击<code>DeepSeek-R1</code>的链接可以看到有关deepseek-r1的详细介绍：</p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811490-2042520916.jpg" class="lazyload"><br>
目前deepseek-r1模型大小提供了7个选择：1.5b、7b、8b、14b、32b、70b、671b。<br>
因为我笔记本的显卡配置较低，所以这里只能选择最小的1.5b模型来做演示：</p>
<p><img alt="config" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811300-1394297426.png" class="lazyload"><br>
你可以根据你的硬件情况选择，通常模型大小（参数量）越大，模型的理解和生成能力越强，但也会消耗更多的计算资源。</p>
<p>点击<code>Download</code>按钮下载符合自己平台的Ollama：<br>
<img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811318-1394039628.jpg" class="lazyload"></p>
<p>我这里选择macOS，点击下载。<br>
下载文件大小不到200M，文件名为：<code>Ollama-darwin.zip</code>。</p>
<p>解压后打开Ollama应用程序，提示：</p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811583-278407829.jpg" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811365-1800220886.jpg" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811347-1089004642.jpg" class="lazyload"></p>
<p>点击<code>Install</code>安装ollama。</p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811550-1406760993.jpg" class="lazyload"></p>
<p>按照提示，打开终端，使用 Command + Space 快捷键调用 <code>terminal</code>：<br>
<img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811638-1754988517.jpg" class="lazyload"></p>
<p>这里Ollama默认给出的例子是下载/运行llama3.2大模型，<br>
我们这里不使用这个llama3.2模型，直接下载/运行deepseek，参数选择最小的1.5b，在终端窗口运行下面命令：</p>
<pre><code>ollama run deepseek-r1:1.5b
</code></pre>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811333-987684367.jpg" class="lazyload"></p>
<pre><code>jingyuzhao@jingyuzhao-mac ~ % ollama run deepseek-r1:1.5b
pulling manifest 
pulling manifest 
pulling manifest 
pulling manifest 
pulling manifest 
pulling manifest 
pulling aabd4debf0c8... 100% ▕████████████████████████████████████████▏ 1.1 GB                         
pulling 369ca498f347... 100% ▕████████████████████████████████████████▏  387 B                         
pulling 6e4c38e1172f... 100% ▕████████████████████████████████████████▏ 1.1 KB                         
pulling f4d24e9138dd... 100% ▕████████████████████████████████████████▏  148 B                         
pulling a85fe2a2e58e... 100% ▕████████████████████████████████████████▏  487 B                         
verifying sha256 digest 
writing manifest 
success 
&gt;&gt;&gt; Send a message (/? for help)
</code></pre>
<p>这里就直接可以和DeepSeek对话了：</p>
<pre><code>&gt;&gt;&gt; Hi! Who are you?
&lt;think&gt;

&lt;/think&gt;

Hi! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service 
and would be delighted to assist you with any inquiries or tasks you may have.

&gt;&gt;&gt; 你好，你是谁？
&lt;think&gt;

&lt;/think&gt;

你好！我是DeepSeek-R1，一个由深度求索公司开发的智能助手。我擅长通过思考来帮您解答复杂的数学，代码和
逻辑推理等理工类问题。 Feel free to ask me anything you'd like me to know! 

&gt;&gt;&gt; Send a message (/? for help)
</code></pre>
<h1 id="2下载chatbox并配置为本地deepseek">2.下载Chatbox并配置为本地DeepSeek</h1>
<p>Chatbox官方网站：</p>
<ul>
<li><a href="https://chatboxai.app/en" target="_blank" rel="noopener nofollow">https://chatboxai.app/en</a></li>
</ul>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811332-1649700781.jpg" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811497-153873065.jpg" class="lazyload"></p>
<p>我这里还是Intel-based的MAC，</p>
<p>下载的<code>Chatbox-1.9.7.dmg</code>，大小100M多点，点击安装，按下面提示拖到Applications内：</p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811430-1994164741.jpg" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811672-607665982.jpg" class="lazyload"></p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811352-1480779039.jpg" class="lazyload"></p>
<p>注意，这里我故意选错成DeepSeek API，这也是初学者经常会选错的，实际上，若选择这个你就找不到你本地的DeepSeek模型。</p>
<p>实际正确应该选择OLLAMA API，然后就可以看到我们上一步安装好的<code>deepseek-r1:1.5b</code>。</p>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811628-681728965.jpg" class="lazyload"></p>
<h1 id="3无需联网也能和deepseek畅快聊天">3.无需联网也能和DeepSeek畅快聊天</h1>
<p>配置好DeepSeek本地模型之后，就可以实现在断网情况下自由问答了，比如，此刻我正在写这篇文章，于是就问他帮我想几个备选的标题：</p>
<pre><code>我正在写一篇文章，我起的名字是“手把手教你部署 DeepSeek 本地模型”。请你帮我重新生成10个吸引眼球的标题供我选择。
</code></pre>
<p><img alt="" loading="lazy" data-src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250205214811688-60256533.jpg" class="lazyload"></p>
<p>他真的迅速给我起了10个吸引眼球的标题，还提供了它思考的过程，而且在我这4年前的电脑上跑起来都很迅速。<br>
嗯，真的很赞！不过我还是决定用自己最初想的朴实标题，不做标题党了。</p>

</div>
<div id="MySignature" role="contentinfo">
    AlfredZhao©版权所有「从Oracle起航，领略精彩的IT技术。」
</div>
<div class="clear"></div>

        <div class="clear"></div>
        
</div>
    <ul class="postmetadata">
        <vc:categories-tags blog-app="jyzhao" blog-id="186567" post-id="18700202"></vc:categories-tags>
    </ul>
