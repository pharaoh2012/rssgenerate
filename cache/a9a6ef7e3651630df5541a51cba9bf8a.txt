
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/TW-NLP/p/18756992" title="发布于 2025-03-07 09:36">
    <span role="heading" aria-level="2">开源最强中文纠错大模型，超越华为17个点！</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<span data-cke-copybin-start="1"><span data-cke-copybin-start="1">​</span></span>
<p>项目地址：<span class="cke_widget_wrapper cke_widget_inline cke_widget_csdnlink cke_widget_selected" data-cke-display-name="a" data-cke-filter="off" data-cke-widget-id="9" data-cke-widget-wrapper="1"><a class="cke_widget_editable cke_widget_element" title="GitHub - TW-NLP/ChineseErrorCorrector: 中文拼写错误和语法错误纠正" href="https://github.com/TW-NLP/ChineseErrorCorrector" data-cke-enter-mode="2" data-cke-saved-href="https://github.com/TW-NLP/ChineseErrorCorrector" data-cke-widget-data="%7B%22url%22%3A%22https%3A%2F%2Fgithub.com%2FTW-NLP%2FChineseErrorCorrector%22%2C%22text%22%3A%22GitHub%20-%20TW-NLP%2FChineseErrorCorrector%3A%20%E4%B8%AD%E6%96%87%E6%8B%BC%E5%86%99%E9%94%99%E8%AF%AF%E5%92%8C%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF%E7%BA%A0%E6%AD%A3%22%2C%22desc%22%3A%22%22%2C%22icon%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22isCard%22%3Afalse%2C%22hasResquest%22%3Atrue%2C%22iconDefault%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22id%22%3A%22s5CgeU-1741311166253%22%2C%22classes%22%3Anull%7D" data-cke-widget-editable="text" data-cke-widget-keep-attr="0" data-cke-widget-upcasted="1" data-link-icon="https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7" data-link-title="GitHub - TW-NLP/ChineseErrorCorrector: 中文拼写错误和语法错误纠正" data-widget="csdnlink" rel="noopener nofollow">GitHub - TW-NLP/ChineseErrorCorrector: 中文拼写错误和语法错误纠正</a></span></p>
<h2>&nbsp;</h2>
<p>文本纠错任务在审查、写作任务中至关重要，以前的纠错大多采用小模型进行训练，例如BART、T5、BERT等，但是小模型的泛化性较差，需要在不同领域训练不同的小模型进行纠错，为此我们使用200万数据进行大模型的训练，经过验证我们在<span class="cke_widget_wrapper cke_widget_inline cke_widget_csdnlink cke_widget_selected" data-cke-display-name="a" data-cke-filter="off" data-cke-widget-id="8" data-cke-widget-wrapper="1"><a class="cke_widget_editable cke_widget_element" title="GitHub - masr2000/NaCGEC" href="https://github.com/masr2000/NaCGEC" data-cke-enter-mode="2" data-cke-saved-href="https://github.com/masr2000/NaCGEC" data-cke-widget-data="%7B%22url%22%3A%22https%3A%2F%2Fgithub.com%2Fmasr2000%2FNaCGEC%22%2C%22text%22%3A%22GitHub%20-%20masr2000%2FNaCGEC%22%2C%22desc%22%3A%22%22%2C%22icon%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22isCard%22%3Afalse%2C%22hasResquest%22%3Atrue%2C%22iconDefault%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22id%22%3A%22w64Mza-1741311166252%22%2C%22classes%22%3Anull%7D" data-cke-widget-editable="text" data-cke-widget-keep-attr="0" data-cke-widget-upcasted="1" data-link-icon="https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7" data-link-title="GitHub - masr2000/NaCGEC" data-widget="csdnlink" rel="noopener nofollow">GitHub - masr2000/NaCGEC</a>数据集上，F1值比华为高10个点，遥遥领先，下面从三个方面进行详细的技术说明：数据集（涵盖业界所有的开源数据）、评估结果、使用方法，欢迎star，后续会持续更新纠错模型。</span></p>
<p>&nbsp;</p>
<h2>1、数据集</h2>
<table>
<thead>
<tr><th>数据集名称</th><th>数据链接</th><th>数据量和类别说明</th><th>描述</th></tr>
</thead>
<tbody>
<tr>
<td>CSC（拼写纠错数据集）</td>
<td><span class="cke_widget_wrapper cke_widget_inline cke_widget_csdnlink cke_widget_selected" data-cke-display-name="a" data-cke-filter="off" data-cke-widget-id="7" data-cke-widget-wrapper="1"><a class="cke_widget_editable cke_widget_element" title="twnlp/csc_data" href="https://huggingface.co/datasets/twnlp/csc_data" data-cke-enter-mode="2" data-cke-saved-href="https://huggingface.co/datasets/twnlp/csc_data" data-cke-widget-data="%7B%22url%22%3A%22https%3A%2F%2Fhuggingface.co%2Fdatasets%2Ftwnlp%2Fcsc_data%22%2C%22text%22%3A%22twnlp%2Fcsc_data%22%2C%22desc%22%3A%22%22%2C%22icon%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22isCard%22%3Afalse%2C%22hasResquest%22%3Atrue%2C%22iconDefault%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22id%22%3A%220wQ0XN-1741311166252%22%2C%22classes%22%3Anull%7D" data-cke-widget-editable="text" data-cke-widget-keep-attr="0" data-cke-widget-upcasted="1" data-link-icon="https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7" data-link-title="twnlp/csc_data" data-widget="csdnlink" rel="noopener nofollow">twnlp/csc_data</a></span></td>
<td>W271K：279,816 条，Medical：39,303 条，Lemon：22,259 条，ECSpell：6,688 条，CSCD：35,001 条</td>
<td>中文拼写纠错的数据集</td>
</tr>
<tr>
<td>CGC（语法纠错数据集）</td>
<td><span class="cke_widget_wrapper cke_widget_inline cke_widget_csdnlink cke_widget_selected" data-cke-display-name="a" data-cke-filter="off" data-cke-widget-id="6" data-cke-widget-wrapper="1"><a class="cke_widget_editable cke_widget_element" title="twnlp/cgc_data" href="https://huggingface.co/datasets/twnlp/cgc_data" data-cke-enter-mode="2" data-cke-saved-href="https://huggingface.co/datasets/twnlp/cgc_data" data-cke-widget-data="%7B%22url%22%3A%22https%3A%2F%2Fhuggingface.co%2Fdatasets%2Ftwnlp%2Fcgc_data%22%2C%22text%22%3A%22twnlp%2Fcgc_data%22%2C%22desc%22%3A%22%22%2C%22icon%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22isCard%22%3Afalse%2C%22hasResquest%22%3Atrue%2C%22iconDefault%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22id%22%3A%22brpZrk-1741311166252%22%2C%22classes%22%3Anull%7D" data-cke-widget-editable="text" data-cke-widget-keep-attr="0" data-cke-widget-upcasted="1" data-link-icon="https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7" data-link-title="twnlp/cgc_data" data-widget="csdnlink" rel="noopener nofollow">twnlp/cgc_data</a></span></td>
<td>CGED：20449 条，FCGEC：37354 条，MuCGEC：2467 条，NaSGEC：7568条</td>
<td>中文语法纠错的数据集</td>
</tr>
<tr>
<td>Lang8+HSK（百万语料-拼写和语法错误混合数据集）</td>
<td><span class="cke_widget_wrapper cke_widget_inline cke_widget_csdnlink cke_widget_selected" data-cke-display-name="a" data-cke-filter="off" data-cke-widget-id="5" data-cke-widget-wrapper="1"><a class="cke_widget_editable cke_widget_element" title="twnlp/lang8_hsk" href="https://huggingface.co/datasets/twnlp/lang8_hsk" data-cke-enter-mode="2" data-cke-saved-href="https://huggingface.co/datasets/twnlp/lang8_hsk" data-cke-widget-data="%7B%22url%22%3A%22https%3A%2F%2Fhuggingface.co%2Fdatasets%2Ftwnlp%2Flang8_hsk%22%2C%22text%22%3A%22twnlp%2Flang8_hsk%22%2C%22desc%22%3A%22%22%2C%22icon%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22isCard%22%3Afalse%2C%22hasResquest%22%3Atrue%2C%22iconDefault%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22id%22%3A%22Xc9e2c-1741311166251%22%2C%22classes%22%3Anull%7D" data-cke-widget-editable="text" data-cke-widget-keep-attr="0" data-cke-widget-upcasted="1" data-link-icon="https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7" data-link-title="twnlp/lang8_hsk" data-widget="csdnlink" rel="noopener nofollow">twnlp/lang8_hsk</a></span></td>
<td>1568885条</td>
<td>中文拼写和语法数据集</td>
</tr>
</tbody>
</table>
<p>项目包含三个部分的数据集，分别为CSC、CGC和Lang8+HSK，涵盖了所有开源高质量的拼写纠错和语法纠错的数据集，也是我们分阶段训练的数据。</p>
<h2>2、评估结果</h2>
<table>
<thead>
<tr><th>Model Name</th><th>Model Link</th><th>Prec</th><th>Rec</th><th>F0.5</th></tr>
</thead>
<tbody>
<tr>
<td>twnlp/ChineseErrorCorrector2-7B</td>
<td><span class="cke_widget_wrapper cke_widget_inline cke_widget_csdnlink cke_widget_selected" data-cke-display-name="a" data-cke-filter="off" data-cke-widget-id="4" data-cke-widget-wrapper="1"><a class="cke_widget_editable cke_widget_element" title="https://huggingface.co/twnlp/ChineseErrorCorrector2-7B" href="https://huggingface.co/twnlp/ChineseErrorCorrector2-7B" data-cke-enter-mode="2" data-cke-saved-href="https://huggingface.co/twnlp/ChineseErrorCorrector2-7B" data-cke-widget-data="%7B%22url%22%3A%22https%3A%2F%2Fhuggingface.co%2Ftwnlp%2FChineseErrorCorrector2-7B%22%2C%22text%22%3A%22https%3A%2F%2Fhuggingface.co%2Ftwnlp%2FChineseErrorCorrector2-7B%22%2C%22desc%22%3A%22%22%2C%22icon%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22isCard%22%3Afalse%2C%22hasResquest%22%3Atrue%2C%22iconDefault%22%3A%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fblog_editor_html%2Frelease2.3.8%2Fckeditor%2Fplugins%2FCsdnLink%2Ficons%2Ficon-default.png%3Ft%3DP1C7%22%2C%22id%22%3A%22vN2OgC-1741311166251%22%2C%22classes%22%3Anull%7D" data-cke-widget-editable="text" data-cke-widget-keep-attr="0" data-cke-widget-upcasted="1" data-link-icon="https://csdnimg.cn/release/blog_editor_html/release2.3.8/ckeditor/plugins/CsdnLink/icons/icon-default.png?t=P1C7" data-link-title="https://huggingface.co/twnlp/ChineseErrorCorrector2-7B" data-widget="csdnlink" rel="noopener nofollow">https://huggingface.co/twnlp/ChineseErrorCorrector2-7B</a></span></td>
<td>0.6233</td>
<td>0.6228</td>
<td>0.6232</td>
</tr>
<tr>
<td>HW_TSC_nlpcc2023_cgec(华为)</td>
<td>未开源</td>
<td>0.5095</td>
<td>0.3129</td>
<td>0.4526</td>
</tr>
<tr>
<td>鱼饼啾啾Plus</td>
<td>未开源</td>
<td>0.5708</td>
<td>0.1294</td>
<td>0.3394</td>
</tr>
<tr>
<td>CUHK_SU</td>
<td>未开源</td>
<td>0.3882</td>
<td>0.1558</td>
<td>0.2990</td>
</tr>
<tr>
<td>CGEC++</td>
<td>未开源</td>
<td>0.2414</td>
<td>0.0735</td>
<td>0.1657</td>
</tr>
<tr>
<td>zhao_jia</td>
<td>未开源</td>
<td>0.1719</td>
<td>0.1478</td>
<td>0.1665</td>
</tr>
</tbody>
</table>
<p>我们在NaCGEC数据集上，比最高的华为要高17个点，实测效果也很不错，强力推荐！</p>
<h1><br>
<strong>3、使用方法</strong></h1>
<h3>transformers</h3>
<p>通过 <code>transformers</code> 库，您可以方便地加载和使用中文拼写纠错模型：</p>
<div class="cke_widget_wrapper cke_widget_block cke_widget_codeSnippet cke_widget_selected" data-cke-display-name="代码段" data-cke-filter="off" data-cke-widget-id="3" data-cke-widget-wrapper="1">
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 安装 transformers 库</span>
pip install transformers</pre>
</div>
<p>&nbsp;</p>
<span class="cke_reset cke_widget_drag_handler_container"><img src="https://img2024.cnblogs.com/blog/3317889/202503/3317889-20250307093601229-1078229256.gif" width="15" height="15" class="cke_reset cke_widget_drag_handler" title="点击并拖拽以移动" data-cke-widget-drag-handler="1"></span></div>
<p>以下是使用模型进行拼写纠错的代码示例：</p>
<div class="cke_widget_wrapper cke_widget_block cke_widget_codeSnippet cke_widget_selected" data-cke-display-name="代码段" data-cke-filter="off" data-cke-widget-id="2" data-cke-widget-wrapper="1">
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> pip install transformers</span>
<span style="color: rgba(0, 0, 255, 1)">from</span> transformers <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> AutoModelForCausalLM, AutoTokenizer
checkpoint </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">twnlp/ChineseErrorCorrector2-7B</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">

device </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cuda</span><span style="color: rgba(128, 0, 0, 1)">"</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> for GPU usage or "cpu" for CPU usage</span>
tokenizer =<span style="color: rgba(0, 0, 0, 1)"> AutoTokenizer.from_pretrained(checkpoint)
model </span>=<span style="color: rgba(0, 0, 0, 1)"> AutoModelForCausalLM.from_pretrained(checkpoint).to(device)

input_content </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">你是一个文本纠错专家，纠正输入句子中的语法错误，并输出正确的句子，输入句子为：\n少先队员因该为老人让坐。</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">

messages </span>= [{<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">role</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">user</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">content</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">: input_content}]
input_text</span>=tokenizer.apply_chat_template(messages, tokenize=<span style="color: rgba(0, 0, 0, 1)">False)

</span><span style="color: rgba(0, 0, 255, 1)">print</span><span style="color: rgba(0, 0, 0, 1)">(input_text)

inputs </span>= tokenizer.encode(input_text, return_tensors=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">pt</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">).to(device)
outputs </span>= model.generate(inputs, max_new_tokens=1024, temperature=0, do_sample=False, repetition_penalty=1<span style="color: rgba(0, 0, 0, 1)">)

</span><span style="color: rgba(0, 0, 255, 1)">print</span>(tokenizer.decode(outputs[0]))</pre>
</div>
<p>&nbsp;</p>
<span class="cke_reset cke_widget_drag_handler_container"><img src="https://img2024.cnblogs.com/blog/3317889/202503/3317889-20250307093601229-1078229256.gif" width="15" height="15" class="cke_reset cke_widget_drag_handler" title="点击并拖拽以移动" data-cke-widget-drag-handler="1"></span></div>
<h3>VLLM</h3>
<p>使用 <code>VLLM</code> 进行推理，支持快速高效地生成文本：</p>
<div class="cke_widget_wrapper cke_widget_block cke_widget_codeSnippet cke_widget_selected" data-cke-display-name="代码段" data-cke-filter="off" data-cke-widget-id="1" data-cke-widget-wrapper="1">
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 安装 VLLM</span>
pip install vllm</pre>
</div>
<p>&nbsp;</p>
<span class="cke_reset cke_widget_drag_handler_container"><img src="https://img2024.cnblogs.com/blog/3317889/202503/3317889-20250307093601229-1078229256.gif" width="15" height="15" class="cke_reset cke_widget_drag_handler" title="点击并拖拽以移动" data-cke-widget-drag-handler="1"></span></div>
<p>以下是 <code>VLLM</code> 示例代码：</p>
<div class="cke_widget_wrapper cke_widget_block cke_widget_codeSnippet cke_widget_selected" data-cke-display-name="代码段" data-cke-filter="off" data-cke-widget-id="0" data-cke-widget-wrapper="1">
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 255, 1)">from</span> transformers <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> AutoTokenizer
</span><span style="color: rgba(0, 0, 255, 1)">from</span> vllm <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> LLM, SamplingParams

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Initialize the tokenizer</span>
tokenizer = AutoTokenizer.from_pretrained(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">twnlp/ChineseErrorCorrector2-7B</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Pass the default decoding hyperparameters of twnlp/ChineseErrorCorrector-7B</span><span style="color: rgba(0, 128, 0, 1)">
#</span><span style="color: rgba(0, 128, 0, 1)"> max_tokens is for the maximum length for generation.</span>
sampling_params = SamplingParams(seed=42, max_tokens=512<span style="color: rgba(0, 0, 0, 1)">)

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Input the model name or path. Can be GPTQ or AWQ models.</span>
llm = LLM(model=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">twnlp/ChineseErrorCorrector2-7B</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Prepare your prompts</span>
prompt = <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">少先队员因该为老人让坐。</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">
messages </span>=<span style="color: rgba(0, 0, 0, 1)"> [
    {</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">role</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">user</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">content</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">你是一个文本纠错专家，纠正输入句子中的语法错误，并输出正确的句子，输入句子为：</span><span style="color: rgba(128, 0, 0, 1)">"</span>+<span style="color: rgba(0, 0, 0, 1)">prompt}
]
text </span>=<span style="color: rgba(0, 0, 0, 1)"> tokenizer.apply_chat_template(
    messages,
    tokenize</span>=<span style="color: rgba(0, 0, 0, 1)">False,
    add_generation_prompt</span>=<span style="color: rgba(0, 0, 0, 1)">True
)

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> generate outputs</span>
outputs =<span style="color: rgba(0, 0, 0, 1)"> llm.generate([text], sampling_params)

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Print the outputs.</span>
<span style="color: rgba(0, 0, 255, 1)">for</span> output <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> outputs:
    prompt </span>=<span style="color: rgba(0, 0, 0, 1)"> output.prompt
    generated_text </span>=<span style="color: rgba(0, 0, 0, 1)"> output.outputs[0].text
    </span><span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Prompt: {prompt!r}, Generated text: {generated_text!r}</span><span style="color: rgba(128, 0, 0, 1)">"</span>) </pre>
</div>
<p>&nbsp;</p>
<pre class="cke_widget_element" data-cke-widget-data="%7B%22lang%22%3A%22python%22%2C%22code%22%3A%22from%20transformers%20import%20AutoTokenizer%5Cnfrom%20vllm%20import%20LLM%2C%20SamplingParams%5Cn%5Cn%23%20Initialize%20the%20tokenizer%5Cntokenizer%20%3D%20AutoTokenizer.from_pretrained(%5C%22twnlp%2FChineseErrorCorrector2-7B%5C%22)%5Cn%5Cn%23%20Pass%20the%20default%20decoding%20hyperparameters%20of%20twnlp%2FChineseErrorCorrector-7B%5Cn%23%20max_tokens%20is%20for%20the%20maximum%20length%20for%20generation.%5Cnsampling_params%20%3D%20SamplingParams(seed%3D42%2C%20max_tokens%3D512)%5Cn%5Cn%23%20Input%20the%20model%20name%20or%20path.%20Can%20be%20GPTQ%20or%20AWQ%20models.%5Cnllm%20%3D%20LLM(model%3D%5C%22twnlp%2FChineseErrorCorrector2-7B%5C%22)%5Cn%5Cn%23%20Prepare%20your%20prompts%5Cnprompt%20%3D%20%5C%22%E5%B0%91%E5%85%88%E9%98%9F%E5%91%98%E5%9B%A0%E8%AF%A5%E4%B8%BA%E8%80%81%E4%BA%BA%E8%AE%A9%E5%9D%90%E3%80%82%5C%22%5Cnmessages%20%3D%20%5B%5Cn%20%20%20%20%7B%5C%22role%5C%22%3A%20%5C%22user%5C%22%2C%20%5C%22content%5C%22%3A%20%5C%22%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99%E4%B8%93%E5%AE%B6%EF%BC%8C%E7%BA%A0%E6%AD%A3%E8%BE%93%E5%85%A5%E5%8F%A5%E5%AD%90%E4%B8%AD%E7%9A%84%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF%EF%BC%8C%E5%B9%B6%E8%BE%93%E5%87%BA%E6%AD%A3%E7%A1%AE%E7%9A%84%E5%8F%A5%E5%AD%90%EF%BC%8C%E8%BE%93%E5%85%A5%E5%8F%A5%E5%AD%90%E4%B8%BA%EF%BC%9A%5C%22%2Bprompt%7D%5Cn%5D%5Cntext%20%3D%20tokenizer.apply_chat_template(%5Cn%20%20%20%20messages%2C%5Cn%20%20%20%20tokenize%3DFalse%2C%5Cn%20%20%20%20add_generation_prompt%3DTrue%5Cn)%5Cn%5Cn%23%20generate%20outputs%5Cnoutputs%20%3D%20llm.generate(%5Btext%5D%2C%20sampling_params)%5Cn%5Cn%23%20Print%20the%20outputs.%5Cnfor%20output%20in%20outputs%3A%5Cn%20%20%20%20prompt%20%3D%20output.prompt%5Cn%20%20%20%20generated_text%20%3D%20output.outputs%5B0%5D.text%5Cn%20%20%20%20print(f%5C%22Prompt%3A%20%7Bprompt!r%7D%2C%20Generated%20text%3A%20%7Bgenerated_text!r%7D%5C%22)%20%22%2C%22classes%22%3Anull%7D" data-cke-widget-keep-attr="0" data-cke-widget-upcasted="1" data-widget="codeSnippet"><code class="language-python hljs"><span class="hljs-keyword">&nbsp;</span></code></pre>
<span class="cke_reset cke_widget_drag_handler_container"><img src="https://img2024.cnblogs.com/blog/3317889/202503/3317889-20250307093601229-1078229256.gif" width="15" height="15" class="cke_reset cke_widget_drag_handler" title="点击并拖拽以移动" data-cke-widget-drag-handler="1"></span></div>
<h2>总结</h2>
<p><code>ChineseErrorCorrector</code>&nbsp;是一个强大的中文拼写和语法纠错工具，开箱即用，后面会不断的跟进前沿的纠错方法和数据，不断更新开源模型。</p>
<span data-cke-copybin-start="1"><span data-cke-copybin-end="1">​</span></span>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.05643260621990741" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-03-07 09:36">2025-03-07 09:36</span>&nbsp;
<a href="https://www.cnblogs.com/TW-NLP">TW-NLP</a>&nbsp;
阅读(<span id="post_view_count">60</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18756992" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18756992);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18756992', targetLink: 'https://www.cnblogs.com/TW-NLP/p/18756992', title: '开源最强中文纠错大模型，超越华为17个点！' })">举报</a>
</div>
        