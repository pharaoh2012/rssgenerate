
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/fengyun2019/p/19018067" title="发布于 2025-08-02 10:03">
    <span role="heading" aria-level="2">LangChain框架入门04：10分钟优雅接入主流大模型</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>一个 AI 应用的核心就是它所依赖的大语言模型，LangChain 框架本身不内置任何大模型，但它通过定义统一的接口规范，可以将各种第三方大语言模型接入进来。本文将详细介绍如何在 LangChain 中接入大语言模型，以及如何使用不同的大语言模型。</p>
<h2 id="一model的分类">一、Model的分类</h2>
<p>LangChain中将大语言模型分为：<strong>文本生成模型（LLMs）</strong>和支持多轮对话的<strong>聊天模型（Chat models）</strong>。</p>
<p><strong>聊天模型</strong>：接受消息输入，并且输出消息，返回的消息封装为不同类型的 <code>BaseMessage</code> 实例， LangChain 也允许聊天模型以字符串作为输入。这样做可以轻松地用聊天模型代替 LLMs，当以字符串作为输入时，该字符串会被转换为 <code>HumanMessage</code> ，然后传递给底层聊天模型。</p>
<p><strong>文本生成模型</strong>：接受字符串输入，并且输出字符串，LangChain 也允许文本模型也以“消息”作为输入，从而与聊天模型的接口保持一致。当以消息作为输入时，这些消息会在传递给LLM之前被转换为字符串。</p>
<p>在 LangChain 的类结构中，顶层基类是 <code>BaseLanguageModel</code>，用于定义模型的通用接口。它分为两支：<code>BaseChatModel</code> 和 <code>BaseLLM</code>。接入聊天模型时需继承 <code>BaseChatModel</code>，如常用的 <code>ChatOpenAI</code>；而文本生成模型则继承 <code>BaseLLM</code>，如 <code>OpenAI</code>。</p>
<p><img alt="image-20250721075719115" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1495546/202508/1495546-20250802100117146-2146964061.png" class="lazyload"></p>
<h2 id="二chat-model聊天模型">二、Chat Model聊天模型</h2>
<p>在构建聊天模型时，有一些标准化参数：</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>参数含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>model</td>
<td>指定使用的大语言模型名称（如 <code>"gpt-4"</code>、<code>"gpt-3.5-turbo"</code> 等）</td>
</tr>
<tr>
<td>temperature</td>
<td>温度，温度越高，输出内容越<strong>随机</strong>；温度越低，输出内容越<strong>确定</strong></td>
</tr>
<tr>
<td>timeout</td>
<td>请求超时时间</td>
</tr>
<tr>
<td>max_tokens</td>
<td>生成内容的最大token数</td>
</tr>
<tr>
<td>stop</td>
<td>模型在生成时遇到这些“停止词”将立刻停止生成，常用于控制输出的边界。</td>
</tr>
<tr>
<td>max_retries</td>
<td>最大重试请求次数</td>
</tr>
<tr>
<td>api_key</td>
<td>大模型供应商提供的API秘钥</td>
</tr>
<tr>
<td>base_url</td>
<td>大模型供应商API 请求地址</td>
</tr>
</tbody>
</table>
<p>以上的标准参数，也只是适用于部分的大语言模型，有些参数在特定模型中可能是无效的，这些标准化参数仅对 LangChain 官方提供集成包的模型（如 <code>langchain-openai</code>、<code>langchain-anthropic</code>）生效，在langchain-community包中的第三方模型，则不需要遵守这些标准化参数的规则。</p>
<p>ChatOpenAI完整示例：</p>
<pre><code class="language-python">import dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# 读取env配置
dotenv.load_dotenv()

# 1.构建提示词
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个资深的Python开发工程师"),
    ("human", "{question}")
])

# 2.创建模型
llm = ChatOpenAI()

# 3.生成提示词
prompt_value = prompt.invoke({"question": "请你帮我写一个求最大公约数方法"})

# 4.大模型接受promptValue，输出AI消息
aiMessage = llm.invoke(prompt_value)

# 5.打印AI消息和AI消息内容
print(aiMessage.content)

</code></pre>
<p>执行结果如下：</p>
<pre><code class="language-python">好的！求最大公约数（GCD）可以用欧几里得算法，这是一种高效的算法。下面是用 Python 实现的代码：

```python
def gcd(a, b):
    while b:
        a, b = b, a % b
    return a
```

### 解释：
- 这个方法使用了 **欧几里得算法**，通过反复取模来缩小问题的规模，直到 `b` 为 0。
- 当 `b` 为 0 时，`a` 就是两个数的最大公约数。

你可以用这个函数来求两个数的最大公约数。例如：

```python
print(gcd(56, 98))  # 输出：14
```

这种方法的时间复杂度是 \(O(\log(\min(a, b)))\)，非常高效。
</code></pre>
<h2 id="三llm文本生成模型">三、LLM文本生成模型</h2>
<p>LLM文本生成模型使用方式如下：</p>
<pre><code class="language-python">import dotenv
from langchain_core.prompts import PromptTemplate
from langchain_openai import OpenAI

# 读取env配置
dotenv.load_dotenv()

# 1.构建提示词
prompt = PromptTemplate.from_template("{question}")

# 2.创建模型
llm = OpenAI()

prompt_value = prompt.invoke({"question": "请完整输出悯农这首诗"})

# 3.文本生成模型接受promptValue，并输出结果
print(llm.invoke(prompt_value))
</code></pre>
<p>执行结果：</p>
<pre><code class="language-python">《悯农》是唐代诗人李绅创作的一首诗，原文如下：

**悯农**

锄禾日当午，  
汗滴禾下土。  
谁知盘中餐，  
粒粒皆辛苦。

这首诗通过描写农民在烈日下辛勤耕作的情景，表达了对农民劳动的同情与敬意。
</code></pre>
<h2 id="四message组件">四、Message组件</h2>
<p>在之前介绍聊天模型ChatOpenAI的案例中，调用模型后返回了一条AI消息，在LangChain中，消息有几种不同的类型。所有消息都有 <code>type</code> 、 <code>content</code> 、 <code>response_metadata</code> 等属性。</p>
<p>下面是这几个属性的作用：</p>
<table>
<thead>
<tr>
<th>属性名</th>
<th>属性作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>type</td>
<td><code>type</code> 描述了是哪个类型的消息，包含类型有"user"、"ai"、"system" 和 "tool"</td>
</tr>
<tr>
<td>content</td>
<td>通常是字符串，有些情况下可能是字典列表，这个字典列表用于大模型的多模态输出。</td>
</tr>
<tr>
<td>name</td>
<td>用来区分当消息类型相同，对消息进行区分，但不是所有模型都支持这一功能。</td>
</tr>
<tr>
<td>response_metadata</td>
<td>AI消息才会包含的属性，大语言模型的响应中附加元数据，根据不同模型会有不同，如可能会包含本次 token 使用量等信息。</td>
</tr>
<tr>
<td>tool_calls</td>
<td>AI消息才会包含的属性，当大语言模型决定调用工具时，在 <code>AIMessage</code> 中就会包含这个属性，可以通过 <code>.tool_calls</code> 属性进行获取该属性返回一个 <code>ToolCall</code> 列表，每个 <code>ToolCall</code> 是一个字典，包含以下字段：                                                                                 <code>name</code> : 应调用的工具名称                                                                                                                                                                                <code>args</code> : 调用工具的参数                                                                                                                                                                                      <code>id</code> : 工具调用的唯一标识 ID</td>
</tr>
</tbody>
</table>
<p>根据消息类型的不同， Message组件被分为：</p>
<p><code>HumanMessage</code>：人类消息，type为"user"</p>
<p><code>AIMessage</code>： AI 消息，type为"ai"</p>
<p><code>SystemMessage</code>：系统消息，type为"system"，告诉大模型当前的背景是什么，应该如何做，并不是所有模型提供商都支持这个消息类型</p>
<p><code>ToolMessage</code>：工具消息，type为"tool"</p>
<p><code>FunctionMessage</code>：旧的函数调用消息类型，现已被 ToolMessage 取代。</p>
<h2 id="五使用其他大语言模型">五、使用其他大语言模型</h2>
<p>除了使用OpenAI的大语言模型之外，LangChain还可以使用很多的大语言模型，下面我们以接入阿里巴巴的通义千问聊天模型为例。</p>
<p>首先，申请阿里云百炼平台API KEY：</p>
<p><img alt="image-20250720230056442" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1495546/202508/1495546-20250802100152121-1088239111.png" class="lazyload"></p>
<p>在.env文件中，加入阿里云百炼平台的API Key</p>
<pre><code class="language-properties"># 阿里云百炼平台API KEY
DASHSCOPE_API_KEY=sk-***********************
</code></pre>
<p>安装依赖包</p>
<pre><code class="language-bash">pip install dashscope
</code></pre>
<p>调用通义千问模型示例如下：</p>
<pre><code class="language-python">import dotenv
from langchain_community.chat_models import ChatTongyi
from langchain_core.prompts import PromptTemplate
# 读取env配置
dotenv.load_dotenv()

# 1.构建提示词
prompt = PromptTemplate.from_template("{question}")

# 2.构建通义模型
tongyi_chat = ChatTongyi(
    model="qwen-turbo-2025-04-28"
)

prompt_value = prompt.invoke({"question": "请完整输出短歌行"})

# 3.文本生成模型接受promptValue，并输出结果
print(tongyi_chat.invoke(prompt_value).content)

</code></pre>
<p>执行结果：</p>
<pre><code class="language-python">《短歌行》是东汉末年曹操所作的一首乐府诗，全诗如下：

---

**短歌行**  
**曹操**

对酒当歌，人生几何！  
譬如朝露，去日苦多。  
慨当以慷，忧思难忘。  
何以解忧？唯有杜康。  

青青子衿，悠悠我心。  
但为君故，沉吟至今。  
呦呦鹿鸣，食野之苹。  
我有嘉宾，鼓瑟吹笙。  

明明如月，何时可掇？  
忧从中来，不可断绝。  
越陌度阡，枉用相存。  
契阔谈讌，心念旧恩。  

月明星稀，乌鹊南飞。  
绕树三匝，何枝可依？  
山不厌高，海不厌深。  
周公吐哺，天下归心。

---

这首诗表达了诗人对人生短暂的感慨、对贤才的渴求以及统一天下的雄心壮志。
</code></pre>
<p>接入更多模型的文档在LangChain官网的Integrations中</p>
<p><img alt="image-20250721080003483" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1495546/202508/1495546-20250802100208230-1951555359.png" class="lazyload"></p>
<p>在 LangChain Integrations 页面点击“More”进行查找</p>
<p><img alt="image-20250721080146433" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1495546/202508/1495546-20250802100223775-1921814244.png" class="lazyload"></p>
<p>找到阿里巴巴</p>
<p><img alt="image-20250721080252688" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1495546/202508/1495546-20250802100233755-845939317.png" class="lazyload"></p>
<p>在这里就可以看到接入ChatTongyi等模型的文档了，点击API Reference，查看具体文档。</p>
<p><img alt="image-20250721080345572" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1495546/202508/1495546-20250802100243858-977848147.png" class="lazyload"></p>
<p>开发者可以根据文档说明，快速集成各类主流和国产大语言模型。</p>
<p><img alt="image-20250721080639482" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1495546/202508/1495546-20250802100255253-549554019.png" class="lazyload"></p>
<h2 id="六总结">六、总结</h2>
<p>本文详细介绍了 LangChain 中模型组件（Model）的使用方法与设计思路，首先从模型的分类开始，分析了文本生成模型和聊天模型的区别，接下来通过具体的代码示例，来演示聊天模型ChatOpenAI和文本生成模型OpenAI的基本用法。</p>
<p>我们还学习了聊天模型输入输出都要用到的Message组件，了解了 Message 组件的几种类型（如 <code>HumanMessage</code>、<code>AIMessage</code>、<code>SystemMessage</code>、<code>ToolMessage</code>），最后，我们以接入阿里巴巴的通义千问的聊天模型为例，展示如何在LangChain中接入其他第三方模型。</p>
<p><strong>总的来说</strong>，LangChain 在模型接入方面做了大量抽象，可以灵活支持 OpenAI、Anthropic、阿里通义千问、百度文心一言等主流模型。通过本文，相信你已经理解Model组件的设计思想和使用方法，后续将继续深入介绍LangChain的核心模块和高级用法，敬请期待。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-02 10:03">2025-08-02 10:03</span>&nbsp;
<a href="https://www.cnblogs.com/fengyun2019">大志说编程</a>&nbsp;
阅读(<span id="post_view_count">69</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19018067);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19018067', targetLink: 'https://www.cnblogs.com/fengyun2019/p/19018067', title: 'LangChain框架入门04：10分钟优雅接入主流大模型' })">举报</a>
</div>
        