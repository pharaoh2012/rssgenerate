
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/dinosauria/p/19030512" title="发布于 2025-08-10 10:20">
    <span role="heading" aria-level="2">文声图防御框架原理笔记：Interpret then Deactivate(ItD)</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><code>Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models</code> 这篇论文提出了一种名为<strong>Interpret then Deactivate (ItD)</strong> 的框架，旨在文本到图像（T2I）扩散模型中实现精准、可扩展的概念擦除（即移除不想要的概念，如有害内容、特定名人等），同时不影响正常概念的生成。以下从思路、方法原理、数学公式推导三方面详细总结：</p>
<h3 id="一核心思路">一、核心思路</h3>
<p>现有概念擦除方法存在两大局限：1）微调模型参数会导致正常概念生成质量下降；2）集成定制模块泛化能力弱且需额外训练。为此，ItD框架通过“解释-停用”两步解决问题：</p>
<ol>
<li><strong>解释（Interpret）</strong>：用稀疏自编码器（SAE）将概念分解为稀疏特征的线性组合，明确概念的特征构成；</li>
<li><strong>停用（Deactivate）</strong>：仅停用目标概念特有的特征（排除与正常概念共享的特征），实现精准擦除，同时保留正常概念的生成能力。</li>
</ol>
<p>此外，SAE被复用为零样本分类器，可判断输入是否包含目标概念，仅在必要时应用擦除，进一步减少对正常概念的影响。</p>
<h3 id="二方法原理">二、方法原理</h3>
<h4 id="1-稀疏自编码器sae的训练">1. 稀疏自编码器（SAE）的训练</h4>
<p>SAE的作用是将文本编码器的语义信息（残差流输出）分解为稀疏特征的组合，为概念“解释”提供基础。</p>
<ul>
<li><strong>训练对象</strong>：文本编码器中transformer块的残差流输出（即token嵌入 <span class="math inline">\(e_l^h\)</span>)，其中 <span class="math inline">\(l\)</span>为层索引，<span class="math inline">\(h\)</span>为token索引）。</li>
<li><strong>模型选择</strong>：采用K-稀疏自编码器（KSAE），强制每次重构仅保留K个最大激活特征，确保稀疏性。</li>
<li><strong>核心目标</strong>：使SAE能将输入的token嵌入 <span class="math inline">\(e\)</span>重构为稀疏特征的线性组合，即 <span class="math inline">\(e \approx \sum_{\rho=1}^{d_{hid}} z^\rho f_\rho\)</span>（<span class="math inline">\(z^\rho\)</span>为特征激活值，<span class="math inline">\(f_\rho\)</span>为解码器矩阵的列向量，即特征向量）。</li>
</ul>
<h4 id="2-特征选择定位目标概念的特有特征">2. 特征选择：定位目标概念的“特有特征”</h4>
<p>为避免擦除正常概念的特征，需筛选出目标概念特有的特征：</p>
<ul>
<li><strong>步骤1：收集目标概念的相关特征</strong><br>
对目标概念的每个token，通过SAE获取特征激活值，取每个特征在所有token中的最大激活值，筛选出前 <span class="math inline">\(K_{sel}\)</span>个高激活特征，构成目标特征集 <span class="math inline">\(F_{tar}\)</span>。</li>
<li><strong>步骤2：排除与正常概念共享的特征</strong><br>
用正常概念集（retain set）的特征集 <span class="math inline">\(F_{retain}\)</span>与 <span class="math inline">\(F_{tar}\)</span>对比，移除两者共有的特征，得到目标概念特有特征集 <span class="math inline">\(\hat{F}_{tar} = F_{tar} \setminus \bigcup F_{retain}\)</span>。</li>
<li><strong>多概念擦除</strong>：对多个目标概念，取其特有特征集的并集 <span class="math inline">\(F_{erase} = \bigcup \hat{F}_{tar}\)</span>。</li>
</ul>
<h4 id="3-概念擦除机制">3. 概念擦除机制</h4>
<p>通过调整目标特征的激活值，移除文本嵌入中目标概念的语义信息：</p>
<ul>
<li><strong>编码与调整</strong>：文本嵌入经SAE编码为特征激活 <span class="math inline">\(s\)</span>后，将 <span class="math inline">\(F_{erase}\)</span>中的特征激活值缩放（如乘以小系数 <span class="math inline">\(\tau\)</span>），削弱其影响；</li>
<li><strong>解码重构</strong>：调整后的激活经SAE解码器重构为新的文本嵌入，该嵌入不再包含目标概念的信息，从而阻止扩散模型生成相关图像。</li>
</ul>
<h4 id="4-零样本分类器选择性擦除">4. 零样本分类器：选择性擦除</h4>
<p>利用SAE的重构损失判断输入是否包含目标概念，仅在包含时应用擦除，减少对正常概念的干扰：</p>
<ul>
<li>若输入文本嵌入 <span class="math inline">\(e\)</span>包含目标概念，其经SAE重构后的误差 <span class="math inline">\(\|e - \hat{e}\|\)</span>较小（因目标特征被调整）；</li>
<li>若为正常概念，重构误差较大。通过阈值 <span class="math inline">\(\tau\)</span>区分：<span class="math inline">\(G(e) = 1\)</span>（含目标概念，应用擦除）若 <span class="math inline">\(\|e - \hat{e}\|^2 &lt; \tau\)</span>，否则为0（不擦除）。</li>
</ul>
<h3 id="三数学公式原理推导">三、数学公式原理推导</h3>
<h4 id="1-sae的编码器与解码器">1. SAE的编码器与解码器</h4>
<ul>
<li>
<p><strong>编码器</strong>：将输入token嵌入 <span class="math inline">\(e\)</span>转换为稀疏特征激活 <span class="math inline">\(z\)</span></p>
<p></p><div class="math display">\[z = \text{TopK}(W_{enc}(e - b_{pre}))
\]</div><p></p><p>其中，<span class="math inline">\(W_{enc} \in \mathbb{R}^{d_{hid} \times d_{in}}\)</span>为编码器权重，<span class="math inline">\(b_{pre}\)</span>为偏置，<span class="math inline">\(\text{TopK}\)</span>保留前K个最大激活值（其余置0），确保稀疏性。</p>
</li>
<li>
<p><strong>解码器</strong>：将特征激活 <span class="math inline">\(z\)</span>重构为嵌入 <span class="math inline">\(\hat{e}\)</span></p>
<p></p><div class="math display">\[\hat{e} = W_{dec} z + b_{pre}
\]</div><p></p><p>其中，<span class="math inline">\(W_{dec} \in \mathbb{R}^{d_{in} \times d_{hid}}\)</span>为解码器权重，每列 <span class="math inline">\(f_\rho\)</span>为特征向量。</p>
</li>
</ul>
<h4 id="2-sae的训练损失函数">2. SAE的训练损失函数</h4>
<p>目标是最小化重构误差并保证特征稀疏性，损失函数为：</p>
<p></p><div class="math display">\[\mathcal{L}(e) = \|e - \hat{e}\|_2^2 + \alpha \mathcal{L}_{aux}
\]</div><p></p><ul>
<li>第一项 <span class="math inline">\(\|e - \hat{e}\|_2^2\)</span>：L2重构损失，确保输入与输出接近；</li>
<li>第二项 <span class="math inline">\(\alpha \mathcal{L}_{aux}\)</span>：辅助损失，防止“死特征”（即极少激活的特征）。<span class="math inline">\(\mathcal{L}_{aux}\)</span>定义为使用前 <span class="math inline">\(K_{aux}\)</span>（<span class="math inline">\(K_{aux} &gt; K\)</span>）个特征的重构误差，<span class="math inline">\(\alpha\)</span>为权重系数。</li>
</ul>
<h4 id="3-特征选择公式">3. 特征选择公式</h4>
<ul>
<li>
<p>目标概念特征集 <span class="math inline">\(F_{tar}\)</span>：</p>
<p></p><div class="math display">\[F_{tar} = \{\rho \mid s_C^\rho \in \text{TopK}(s_C^1, ..., s_C^{d_{hid}})\}
\]</div><p></p><p>其中 <span class="math inline">\(s_C^\rho = \max(s_1^\rho, ..., s_H^\rho)\)</span>，<span class="math inline">\(s_h^\rho\)</span>为第h个token的第<span class="math inline">\(\rho\)</span>个特征激活值，<span class="math inline">\(H\)</span>为目标概念的token数。</p>
</li>
<li>
<p>特有特征集 <span class="math inline">\(\hat{F}_{tar}\)</span>：</p>
<p></p><div class="math display">\[\hat{F}_{tar} = F_{tar} \setminus \bigcup_{C_r \in C_{retain}} F_{C_r}
\]</div><p></p><p>其中 <span class="math inline">\(C_{retain}\)</span>为正常概念集，<span class="math inline">\(F_{C_r}\)</span>为正常概念的特征集。<br>
当需要擦除多个目标概念时，总擦除特征集为各目标特有特征集的并集：</p>
</li>
</ul>
<p></p><div class="math display">\[F_{erase} = \bigcup_{C \in \mathcal{C}_{tar}} \hat{F}_C
\]</div><p></p><p>其中<span class="math inline">\(\mathcal{C}_{tar}\)</span>为所有目标概念的集合，该式确保一次擦除多个概念且无需额外训练。</p>
<h4 id="4-概念擦除的激活调整">4. 概念擦除的激活调整</h4>
<p>对特征激活 <span class="math inline">\(s\)</span>进行调整，削弱目标特征的影响：</p>
<p></p><div class="math display">\[\hat{s}^\rho = \begin{cases} 
s^\rho \cdot \tau &amp; \text{if } \rho \in F_{erase} \\
s^\rho &amp; \text{otherwise}
\end{cases}
\]</div><p></p><p>其中 <span class="math inline">\(\tau\)</span>为缩放系数（如 <span class="math inline">\(\tau &lt; 1\)</span>，削弱激活），调整后通过解码器重构为 <span class="math inline">\(\hat{e} = W_{dec} \hat{s} + b_{pre}\)</span>。</p>
<h4 id="5-零样本分类器的判断公式">5. 零样本分类器的判断公式</h4>
<p>基于重构损失判断是否包含目标概念：</p>
<p></p><div class="math display">\[G(e) = \begin{cases} 
1 &amp; \text{if } \|e - \hat{e}\|^2 &lt; \tau \\
0 &amp; \text{otherwise}
\end{cases}
\]</div><p></p><p>其中 <span class="math inline">\(\tau\)</span>为阈值，<span class="math inline">\(G(e)=1\)</span>时应用擦除，否则直接输出原嵌入。</p>
<h3 id="四总结">四、总结</h3>
<p>ItD框架通过SAE将概念分解为稀疏特征，结合对比特征选择和选择性擦除，实现了精准、可扩展的概念擦除。数学公式确保了SAE的稀疏性、特征的特异性及擦除的针对性，解决了现有方法对正常概念生成的干扰问题，同时通过零样本分类器进一步提升了鲁棒性。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-10 10:21">2025-08-10 10:20</span>&nbsp;
<a href="https://www.cnblogs.com/dinosauria">永是珞珈一恐龙</a>&nbsp;
阅读(<span id="post_view_count">24</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19030512);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19030512', targetLink: 'https://www.cnblogs.com/dinosauria/p/19030512', title: '文声图防御框架原理笔记：Interpret then Deactivate(ItD)' })">举报</a>
</div>
        