
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/songmin/p/18908585/video-2channel-review-and-ocr-on-ohos" title="发布于 2025-06-03 15:36">
    <span role="heading" aria-level="2">【拥抱鸿蒙】HarmonyOS NEXT实现双路预览并识别文字</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        <img src="https://img2024.cnblogs.com/blog/3652266/202506/3652266-20250603153549673-798292475.png" alt="【拥抱鸿蒙】HarmonyOS NEXT实现双路预览并识别文字" class="desc_img">
        我们在许多其他平台看到过OCR功能的应用，那么HarmonyOS在这方面的支持如何呢？我们如何能快速使用这一能力呢？使用这一能力需要注意的点有哪些呢？就让我们一起来探究吧~
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<blockquote>
<p>我们在许多其他平台看到过OCR功能的应用，那么HarmonyOS在这方面的支持如何呢？我们如何能快速使用这一能力呢？使用这一能力需要注意的点有哪些呢？就让我们一起来探究吧~</p>
</blockquote>
<p>【开发环境】</p>
<ul>
<li>版本规则号：HarmonyOS NEXT</li>
<li>版本类型：Developer Preview2</li>
<li>OpenHarmony API Version：11 Release</li>
<li>compileSdkVersion：4.1.0(11)</li>
<li>IDE：DevEco Studio 4.1.3.700（Mac）</li>
</ul>
<h2 id="实现目标">实现目标</h2>
<p>通过对Core Vision Kit的基础功能的实现，完成相册图片获取、OCR、相机预览，图片格式转换等功能，熟悉ArkTS的开发流程和细节，加深对HarmonyOS中各类基础库的理解。</p>
<h2 id="名词解释">名词解释</h2>
<ul>
<li>Core Vision Kit：基础视觉服务</li>
<li>Camera Kit：相机服务</li>
<li>Core File Kit：文件基础服务</li>
<li>OCR：Optical Character Recognition，通用文字识别或光学字符识别</li>
<li>URI: Uniform Resource Identifier，资源标识符，本文中URI指图片资源的访问路径</li>
</ul>
<h2 id="核心功能">核心功能</h2>
<p>本篇所涉及的核心功能就是通用文字识别（OCR）。</p>
<p>OCR是通过拍照、扫描等光学输入方式，把各种票据、卡证、表格、报刊、书籍等印刷品文字转化为图像信息，再利用文字识别技术将图像信息转化为计算机等设备可以使用的字符信息的技术。</p>
<p>首先，我们实现从相册选取一张图片，并识别图片上的文字的功能。这一功能的实现基于系统提供的Core Vision Kit中的OCR能力。</p>
<ol>
<li>创建一个<code>ImageOCRUtil</code>类，用于封装OCR相关功能。<br>
从<code>CoreVisionKit</code>中导入<code>textRecognition</code>模块，声明一个名为<code>ImageOCRUtil</code>的类，并创建其<code>new()</code>方法。</li>
</ol>
<pre><code class="language-ts">import { textRecognition } from '@kit.CoreVisionKit';

export class ImageOCRUtil {}

export default new ImageOCRUtil();
</code></pre>
<ol start="2">
<li>在<code>ImageOCRUtil</code>中实现图片中文字识别功能。<br>
构建一个异步方法：<code>async recognizeText(image:  PixelMap | undefined, resultCallback: Function)</code>，其中<code>PixelMap</code>为图像像素类，用于读取或写入图像数据以及获取图像信息。目前pixelmap序列化大小最大128MB，超过会送显失败。大小计算方式为：宽 x 高 x 每像素占用字节数。</li>
</ol>
<pre><code class="language-ts">export class ImageOCRUtil {

  /**
   * 文字识别
   *
   * @param image 图片源数据
   * @param resultCallback 结果返回
   * @returns
   */
  static async recognizeText(image:  PixelMap | undefined, resultCallback: Function) {
    // 非空判断
    if (!image || image === undefined) {
      hilog.error(0x0000, 'OCR', 'the image is not existed');
      return;
    }

    let visionInfo: textRecognition.VisionInfo = {
      pixelMap: image
    };

    let textConfiguration: textRecognition.TextRecognitionConfiguration = {
      isDirectionDetectionSupported: false
    };

    textRecognition.recognizeText(visionInfo, textConfiguration, (error: BusinessError, data: textRecognition.TextRecognitionResult) =&gt; {
      // 识别成功，获取结果
      if (error.code == 0) {
        let recognitionRes = data.value.toString();
        // 将识别结果返回
        resultCallback(recognitionRes);
      }
    });
  }
}
</code></pre>
<ol start="3">
<li>在<code>ImageOCRUtil</code>中实现从相册获取图片URI功能。<br>
这里需用到Core File Kit，可借助图片选择器获取图片的存储路径。</li>
</ol>
<pre><code class="language-ts">import { picker } from '@kit.CoreFileKit';

/**
  * 打开相册选择图片
  * @returns 异步返回图片URI
  */
static openAlbum(): Promise&lt;string&gt; {
    return new Promise&lt;string&gt;((resolve, reject) =&gt; {
      let photoPicker = new picker.PhotoViewPicker;
      photoPicker.select({
        MIMEType: picker.PhotoViewMIMETypes.IMAGE_TYPE,
        maxSelectNumber: 1
      }).then((res: picker.PhotoSelectResult) =&gt; {
        resolve(res.photoUris[0]);
      }).catch((err: BusinessError) =&gt; {
        hilog.error(0x0000, "OCR", `Failed to get photo uri, code: ${err.code}, message: ${err.message}`)
        resolve('')
      })
    })
}
</code></pre>
<h2 id="ui与调用">UI与调用</h2>
<p>为了验证图片识别的效果，我们可以搭建简单的UI，提供从相册获取图片 -&gt; 文字识别 -&gt; 显示识别结果这一流程的UI与交互。</p>
<p>在<code>Index</code>页面中，UI相关的代码如下：</p>
<pre><code class="language-ts">import { image } from '@kit.ImageKit'
import { hilog } from '@kit.PerformanceAnalysisKit';
import { ImageOCRUtil } from '../common/utils/ImageOCRUtil';
import { CommonUtils } from '../common/utils/CommonUtils';
import { fileIo } from '@kit.CoreFileKit';

@Entry
@Component
struct Index {
  private imageSource: image.ImageSource | undefined = undefined;
  @State selectedImage: PixelMap | undefined = undefined;
  @State dataValues: string = '';

  build() {
    Column() {
      // 选中的图片
      Image(this.selectedImage)
        .objectFit(ImageFit.Fill)
        .height('60%')

      // 识别的内容
      Text(this.dataValues)
        .copyOption(CopyOptions.LocalDevice)
        .height('15%')
        .width('60%')
        .margin(10)

      // 选择图片按钮
      Button('选择图片')
        .type(ButtonType.Capsule)
        .fontColor(Color.White)
        .width('80%')
        .margin(10)
        .onClick(() =&gt; {
          this.selectImage();
        })

      Button('开始识别')
        .type(ButtonType.Capsule)
        .fontColor(Color.White)
        .alignSelf(ItemAlign.Center)
        .width('80%')
        .margin(10)
        .onClick(() =&gt; {
            // 点击“开始识别”
          });
        })
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center)
  }

  private async selectImage() {
    let uri = await ImageOCRUtil.openAlbum();
    if (uri === undefined) {
      hilog.error(0x0000, 'OCR', 'Failed to get the uri of photo.')
      return;
    }

    this.loadImage(uri);
  }

  loadImage(path: string) {
    setTimeout(async () =&gt; {
      let fileSource = await fileIo.open(path, fileIo.OpenMode.READ_ONLY);
      this.imageSource = image.createImageSource(fileSource.fd);
      this.selectedImage = await this.imageSource.createPixelMap();
    })
  }
}

</code></pre>
<p>在“开始识别”的按钮的点击事件中，我们调用<code>ImageOCRUtil</code>的<code>recognizeText</code>，并在其回调中显示识别结果。<br>
并对<code>imageSource</code>和<code>selectedImage</code>进行<code>release()</code>释放内存空间。</p>
<pre><code class="language-ts">ImageOCRUtil.recognizeText(this.selectedImage, (content: string) =&gt; {
  if (!CommonUtils.isEmpty(content)) {
    this.dataValues = content;
  }
  
  // 释放内存空间
  this.imageSource?.release();
  this.selectedImage?.release();
});
</code></pre>
<p>其实现效果如下所示：</p>
<p><img src="https://img2024.cnblogs.com/blog/3652266/202506/3652266-20250603153418866-1992286922.png" alt="6001" loading="lazy"></p>
<h2 id="双路预览">双路预览</h2>
<p>为了对文字识别这一功能进行扩展，我们可以结合相机的双路预览功能实时获取图片帧，并对图片帧进行文字识别。</p>
<p>我们创建一个<code>XComponentPage</code>的页面，添加一个相机预览视图。</p>
<ol>
<li>获取ImageReceiver组件的SurfaceId。</li>
</ol>
<pre><code class="language-ts">async getImageReceiverSurfaceId(receiver: image.ImageReceiver): Promise&lt;string | undefined&gt; {
    let ImageReceiverSurfaceId: string | undefined = undefined;
    if (receiver !== undefined) {
      console.info('receiver is not undefined');
      let ImageReceiverSurfaceId: string = await receiver.getReceivingSurfaceId();
      console.info(`ImageReceived id: ${ImageReceiverSurfaceId}`);
    } else {
      console.error('createImageReceiver failed');
    }
    return ImageReceiverSurfaceId;
  }
</code></pre>
<ol start="2">
<li>创建XComponent组件Surface。</li>
</ol>
<pre><code class="language-ts">XComponent({
        // 组件的唯一标识
        id: 'LOXComponent',
        // surface:EGL/OpenGLES和媒体数据写入  component:开发者定制绘制内容
        type: XComponentType.SURFACE,
        // 应用Native层编译输出动态库名称，仅XComponent类型为"surface"时有效
        libraryname: 'SingleXComponent',
        // 给组件绑定一个控制器，通过控制器调用组件方法，仅XComponent类型为"surface"时有效
        controller: this.mXComponentController
      })// 插件加载完成时回调事件
        .onLoad(() =&gt; {
          // 设置Surface宽高（1920*1080），预览尺寸设置参考前面 previewProfilesArray 获取的当前设备所支持的预览分辨率大小去设置
          // 预览流与录像输出流的分辨率的宽高比要保持一致
          this.mXComponentController.setXComponentSurfaceSize({ surfaceWidth: 1920, surfaceHeight: 1080 });
          // 获取Surface ID
          this.xComponentSurfaceId = this.mXComponentController.getXComponentSurfaceId();
        })// 插件卸载完成时回调事件
        .onDestroy(() =&gt; {

        })
        .width("100%")
        .height(display.getDefaultDisplaySync().width * 9 / 16)
</code></pre>
<ol start="3">
<li>实现双路预览。</li>
</ol>
<pre><code class="language-ts">import camera from '@ohos.multimedia.camera';


async createDualChannelPreview(cameraManager: camera.CameraManager, XComponentSurfaceId: string, receiver: image.ImageReceiver): Promise&lt;void&gt; {
    // 获取支持的相机设备对象
    let camerasDevices: Array&lt;camera.CameraDevice&gt; = cameraManager.getSupportedCameras();

    // 获取支持的模式类型
    let sceneModes: Array&lt;camera.SceneMode&gt; = cameraManager.getSupportedSceneModes(camerasDevices[0]);
    let isSupportPhotoMode: boolean = sceneModes.indexOf(camera.SceneMode.NORMAL_PHOTO) &gt;= 0;
    if (!isSupportPhotoMode) {
      console.error('photo mode not support');
      return;
    }

    // 获取profile对象
    let profiles: camera.CameraOutputCapability = cameraManager.getSupportedOutputCapability(camerasDevices[0], camera.SceneMode.NORMAL_PHOTO); // 获取对应相机设备profiles
    let previewProfiles: Array&lt;camera.Profile&gt; = profiles.previewProfiles;

    // 预览流1
    let previewProfilesObj: camera.Profile = previewProfiles[0];

    // 预览流2
    let previewProfilesObj2: camera.Profile = previewProfiles[0];

    // 创建 预览流1 输出对象
    let previewOutput: camera.PreviewOutput = cameraManager.createPreviewOutput(previewProfilesObj, XComponentSurfaceId);

    // 创建 预览流2 输出对象
    let imageReceiverSurfaceId: string = await receiver.getReceivingSurfaceId();
    let previewOutput2: camera.PreviewOutput = cameraManager.createPreviewOutput(previewProfilesObj2, imageReceiverSurfaceId);

    // 创建cameraInput对象
    let cameraInput: camera.CameraInput = cameraManager.createCameraInput(camerasDevices[0]);

    // 打开相机
    await cameraInput.open();

    // 会话流程
    let photoSession: camera.PhotoSession = cameraManager.createSession(camera.SceneMode.NORMAL_PHOTO) as camera.PhotoSession;

    // 开始配置会话
    photoSession.beginConfig();

    // 把CameraInput加入到会话
    photoSession.addInput(cameraInput);

    // 把 预览流1 加入到会话
    photoSession.addOutput(previewOutput);

    // 把 预览流2 加入到会话
    photoSession.addOutput(previewOutput2);

    // 提交配置信息
    await photoSession.commitConfig();

    // 会话开始
    await photoSession.start();
  }
</code></pre>
<ol start="4">
<li>通过ImageReceiver实时获取预览图像。</li>
</ol>
<pre><code class="language-ts">onImageArrival(receiver: image.ImageReceiver): void {
  receiver.on('imageArrival', () =&gt; {
    receiver.readNextImage((err: BusinessError, nextImage: image.Image) =&gt; {
      if (err || nextImage === undefined) {
        console.error('readNextImage failed');
        return;
      }
      nextImage.getComponent(image.ComponentType.JPEG, async (err: BusinessError, imgComponent: image.Component) =&gt; {
        if (err || imgComponent === undefined) {
          console.error('getComponent failed');
        }
        if (imgComponent &amp;&amp; imgComponent.byteBuffer as ArrayBuffer) {
          let imageArrayBuffer = imgComponent.byteBuffer as ArrayBuffer;
          console.log("得到图片数据:" + JSON.stringify(imageArrayBuffer))
          console.log("图片数据长度:" + imageArrayBuffer.byteLength)
          
          //TODO：OCR识别

        } else {
          console.error('byteBuffer is null');
        }
        nextImage.release();
      })
    })
  })
}
</code></pre>
<p>最后，我们对预览返回进行文字识别。预览返回的结果<code>imageArrayBuffer</code>的类型为<code>ArrayBuffer</code>，我们需要将其转换为<code>PixelMap</code>类，然后再调用<code>recognizeText()</code>识别。</p>
<pre><code class="language-ts">// 转换图片格式为PixelMap，并识别其中的文字
let opts: image.InitializationOptions = {
  editable: true,
  pixelFormat: 3,
  size: { height: 320, width: 320 }
}
image.createPixelMap(imageArrayBuffer, opts).then((pixelMap: image.PixelMap) =&gt; {
  console.info('Succeeded in creating pixelmap.');

  ImageOCRUtil.recognizeText(pixelMap, (res: string) =&gt; {
    console.info("识别结果:" + res);
  });
  }).catch((error: BusinessError) =&gt; {
    console.error('Failed to create pixelmap.');
})
</code></pre>
<p>这样，运行<code>XComponentPage</code>时，打开预览对准包含文字的物体，就可从Log中看到识别的文字信息。</p>
<p>完整代码见 -&gt; <a href="https://github.com/songminzh/hosgo/tree/main/projects/vision" target="_blank" rel="noopener nofollow">hosgo-vision</a></p>
<p>拥抱鸿蒙，拥抱未来，选择远方，风雨兼程。</p>
<p>参考</p>
<ul>
<li><a href="https://developer.huawei.com/consumer/cn/codelabsPortal/carddetails/tutorials_Next-CoreVisionKit" target="_blank" rel="noopener nofollow">机器学习-基础视觉服务（ArkTS）</a></li>
<li><a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/core-vision-introduction-0000001815834585" target="_blank" rel="noopener nofollow">指南-Core Vision Kit</a></li>
<li><a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/text-recognition-guidelines-0000001796771961" target="_blank" rel="noopener nofollow">通用文字识别</a></li>
<li><a href="https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/camera-dual-channel-preview-0000001820880033" target="_blank" rel="noopener nofollow">双路预览(ArkTS)</a></li>
</ul>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.20477392634375" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-06-03 15:36">2025-06-03 15:36</span>&nbsp;
<a href="https://www.cnblogs.com/songmin">郑知鱼</a>&nbsp;
阅读(<span id="post_view_count">74</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18908585);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18908585', targetLink: 'https://www.cnblogs.com/songmin/p/18908585/video-2channel-review-and-ocr-on-ohos', title: '【拥抱鸿蒙】HarmonyOS NEXT实现双路预览并识别文字' })">举报</a>
</div>
        