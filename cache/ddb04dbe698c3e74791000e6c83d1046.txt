
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/anai/p/18718130" title="发布于 2025-02-16 16:13">
    <span role="heading" aria-level="2">在windows主机本地快速部署使用deepseek-r1大模型</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>一台配备 Windows 操作系统、12GB 或以上显存的英伟达显卡、8GB 或以上内存，并能连接互联网的电脑可以继续阅读以下内容。</p>
<h3 id="简介">简介</h3>
<hr>
<h3 id="_"></h3>
<h3 id="ollama用于下载和启动大模型">Ollama（用于下载和启动大模型）</h3>
<p>Ollama 专注于本地大型语言模型（LLM）的快速、极简安装和使用，例如 LLaMA 3.3 和 DeepSeek-R1。它提供开箱即用的体验，适合个人开发者和小规模实验研究，但不适用于高可用性和高并发的生产环境。地址：<a href="https://ollama.com/" target="_blank" rel="noopener nofollow">https://ollama.com/</a></p>
<h4 id="open-webui用于提供一个交互友好的界面向指定的大模型提问">Open WebUI（用于提供一个交互友好的界面，向指定的大模型提问）</h4>
<p>Open WebUI 是一个可扩展、功能丰富且用户友好的自托管 AI 平台，旨在完全离线运行。它支持多种 LLM 运行器（如 Ollama）和与 OpenAI 兼容的 API，并内置 RAG 推理引擎，使其成为强大的 AI 部署解决方案。所谓“自托管”是指用户可以在自己的服务器或本地环境中运行和管理该平台。地址：<a href="https://openwebui.com/" target="_blank" rel="noopener nofollow">https://openwebui.com/</a></p>
<h4 id="deepseek-r1-distill-qwen-14b大模型介绍">DeepSeek-R1-Distill-Qwen-14B（大模型介绍）</h4>
<p>这里提到的大模型是 DeepSeek-R1-Distill-Qwen-14B，它是基于 Qwen2.5-14B 模型进行蒸馏微调后得到的，使用了 DeepSeek-R1 生成的样本。尽管蒸馏过程减小了模型大小，但运行此模型仍需要至少 30GB 的显存，这超出了大部分人的硬件条件。而 Ollama 提供了进一步量化的版本，将参数规模降至 14.8 亿，模型大小降至 9GB。</p>
<h3 id="开始">开始</h3>
<h4 id="下载安装ollamawindows">下载安装Ollama(windows)</h4>
<p>浏览器打开地址：<a href="https://ollama.com/" target="_blank" rel="noopener nofollow">https://ollama.com/</a> ，点击下载按钮</p>
<p><img src="https://img2024.cnblogs.com/blog/706195/202502/706195-20250216151814832-1178389683.png" alt="图片" loading="lazy"></p>
<p>下载后之后，双击安装即可，没有看到有什么可以自定义的配置。</p>
<h4 id="使用ollama下载指定的大模型">使用Ollama下载指定的大模型</h4>
<p>由于Ollama默认存储路径在C盘，而C盘空间有限，所以建议将模型文件保存在其他盘符或目录下。可以通过设置环境变量OLLAMA_MODELS来更改模型的下载路径:</p>
<p>1.首先，右键点击Windows桌面上的“此电脑”图标，选择“属性”以打开系统属性窗口。</p>
<p>2.在系统属性窗口右侧找到并点击“高级系统设置”，在弹出窗口上点击“高级-环境变量”</p>
<p>3.在“环境变量”窗口中，可以在“系统变量”新建一个名为OLLAMA_MODELS的环境变量，并在“变量值”文本框中输入你自己希望保存模型文件的新路径。由于大模型的文件都非常大，比如我们将要部署的模型文件大小就为9G左右，所以建议选择的路径所在的磁盘空间要比较大一些。</p>
<p><img src="https://img2024.cnblogs.com/blog/706195/202502/706195-20250216151814807-968599514.png" alt="图片" loading="lazy"></p>
<p>4.通过任务管理器结束Ollama进程，然后重新运行Ollama来使修改的环境变量生效。</p>
<p>5.上述过程完成后，打开powershell命令行工具，执行如下命令下载deepseek-r1:14b大模型，模型文件较大，需要等待一定时间。</p>
<pre><code>ollama pull deepseek-r1:14b
</code></pre>
<h4 id="查看ollama下载好的模型列表">查看Ollama下载好的模型列表</h4>
<p>下载完成后，可通过如下命令检查是否能看到下载好的模型</p>
<pre><code>ollama list
</code></pre>
<p>使用Ollama启动模型</p>
<pre><code>ollama run deepseek-r1:14b &nbsp; &nbsp;
</code></pre>
<p>该命令会启动 DeepSeek-R1 模型，并启动一个 REPL（交互式终端），你可以接着在命令行直接输入问题，模型会根据问题生成回答。</p>
<h4 id="安装open-webui">安装Open WebUI</h4>
<pre><code>pip install&nbsp;open-webui
</code></pre>
<p>运行Open WebUI</p>
<pre><code>open-webui serve
</code></pre>
<p>Open WebUI页面访问</p>
<pre><code>http://localhost:8080
</code></pre>
<p>查看Open WebUI的大模型配置</p>
<ul>
<li>
<p>点击右上角的用户头像图标，选择Settings;</p>
</li>
<li>
<p>在弹出的界面左侧菜单选择Admin Settings;</p>
</li>
<li>
<p>在打开的界面的导航栏选择Settings;</p>
</li>
<li>
<p>在左侧界面选择Models，如果你的ollama和open webui在同一台机器上，那么此时会看到已经自动识别到的deepseek-r1:14b模型。（可能是因为本地提前启动了ollama,毕竟open webui以前叫ollama webui嘛~）</p>
</li>
</ul>
<h4 id="_-1"></h4>
<h4 id="使用open-webui-向指定大模型提问">使用Open WebUI 向指定大模型提问</h4>
<p>笔者是24g显存的显卡，所以部署的是32b的deepseek-r1模型，此模型大约需要20g显存占用。</p>
<p><img src="https://img2024.cnblogs.com/blog/706195/202502/706195-20250216151814844-1600971560.png" alt="图片" loading="lazy"></p>
<p>直接在输入框输入你的问题，点击发送即可，可能会等待10到15秒时间给出回复。</p>
<h4 id="注意事项">注意事项</h4>
<p>如果在chrome上使用open webui 出现打字机效果相关的问题，导致内容被更改或显示不全，可以更换浏览器试试。此现象应该极少遇到，但是笔者遇到了，不知什么原因，更换为edge浏览器尝试是正常的。</p>

</div>
<div id="MySignature" role="contentinfo">
    <p>本文来自博客园，作者：<a href="https://www.cnblogs.com/anai/" target="_blank">AI粉嫩特攻队</a>，转载请注明原文链接：<a href="https://www.cnblogs.com/anai/p/18718130" target="_blank">https://www.cnblogs.com/anai/p/18718130</a></p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.05883703510069444" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-16 16:49">2025-02-16 16:13</span>&nbsp;
<a href="https://www.cnblogs.com/anai">AI粉嫩特攻队</a>&nbsp;
阅读(<span id="post_view_count">24</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18718130" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18718130);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18718130', targetLink: 'https://www.cnblogs.com/anai/p/18718130', title: '在windows主机本地快速部署使用deepseek-r1大模型' })">举报</a>
</div>
        