
    <a name="top"></a>
    <h2><a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/jyzhao/p/18705735/shou-ba-shou-jiao-ni-wei-yang-deepseek-ben-de-mo-x" title="发布于 2025-02-09 08:26">
    <span role="heading" aria-level="2">手把手教你喂养 DeepSeek 本地模型</span>
    

</a>
</h2>
    <small>
<span id="post-date" data-last-update-days="0.02519450660300926" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-09 08:27">2025-02-09 08:26</span>&nbsp;
<a href="https://www.cnblogs.com/jyzhao">AlfredZhao</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18705735" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18705735);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18705735', targetLink: 'https://www.cnblogs.com/jyzhao/p/18705735/shou-ba-shou-jiao-ni-wei-yang-deepseek-ben-de-mo-x', title: '手把手教你喂养 DeepSeek 本地模型' })">举报</a>
</small>
    <div class="entry">
        <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>上篇文章《<a href="https://mp.weixin.qq.com/s/AgQkyzV7cr-gUsfTqP7mFg?token=295441393&amp;lang=zh_CN" target="_blank" rel="noopener nofollow">手把手教你部署 DeepSeek 本地模型</a>》首发是在公众号，但截止目前只有500多人阅读量，而在<a href="https://www.cnblogs.com/jyzhao/p/18700202/shou-ba-shou-jiao-ni-bu-shu-deepseek-ben-de-mo-xin" target="_blank">自己博客园BLOG同步更新的文章</a>热度很高，目前已达到50000+的阅读量，流量是公众号的100倍。</p>
<p>不管怎样，看来大家还是更喜欢这种真正手把手的教学模式。</p>
<p>在高流量加持下，也得到了更多读者的反馈，从评论区看到大家部署成功后都很兴奋，普遍认为这类教程对新手的帮助很大。</p>
<p>但也有困惑，就是成功部署本地模型之后，除了能在断网模式下也可以和deepseek聊天之外，还有哪些优势呢？</p>
<p>其实从BLOG的评论区已经有读者指出，迫切的想知道下一步究竟该如何喂养这个本地模型，让它可以成为一个更有用的本地私密知识库。</p>
<p><img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637964-1861863258.png" alt="wxfm-ds2" loading="lazy"></p>
<p>下面就开始 DeepSeek 手把手系列第二篇：《手把手教你喂养 DeepSeek 本地模型》</p>
<ul>
<li>1.基本概念科普</li>
<li>2.下载 AnythingLLM 软件</li>
<li>3.配置 nomic-embed-text 模型</li>
<li>4.演示如何正确喂养个人数据</li>
<li>5.喂养前后效果对比和缺陷</li>
</ul>
<h1 id="1基本概念科普">1.基本概念科普</h1>
<p>这里先给AI小白简单科普一下基本概念，便于更好地理解本文中的动手操作。</p>
<p>为什么我这里叫“喂养”DeepSeek 本地模型，是因为大模型再强大也有它天然的局限性，比如训练数据不可能包含你的私域数据，而打造自己的本地私域知识库，就需要检索这些数据，具体采用的是RAG（检索增强生成）方法。</p>
<p>RAG，英文全称是Retrieval-Augmented Generation。简单来讲，采用RAG就需要把你的私域数据向量化，然后存储到向量数据库中，支持向量检索配合LLM大模型一起提供更专业的回复。</p>
<h1 id="2下载-anythingllm-软件">2.下载 AnythingLLM 软件</h1>
<p>官方网站：</p>
<ul>
<li><a href="https://anythingllm.com/desktop" target="_blank" rel="noopener nofollow">https://anythingllm.com/desktop</a></li>
</ul>
<p>下载符合你系统平台的软件，我这里是Apple Intel：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637385-492125126.png" alt="any1" loading="lazy"></p>
<p>下载好的<code>AnythingLLMDesktop.dmg</code>，dmg文件约300M多点，双击安装并拖至应用程序中：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637411-76663093.png" alt="any3" loading="lazy"></p>
<p>拖动时可以看到AnythingLLM安装程序有1G大小：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637291-332290119.png" alt="any4" loading="lazy"></p>
<p>然后打开AnythingLLM，欢迎界面如下：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637429-1903087189.png" alt="any6" loading="lazy"></p>
<p>点击<code>Get Started</code>配置首选LLM，这里我们选择上一篇文章已经教大家配置好的Ollama：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637459-1295671021.png" alt="any9" loading="lazy"></p>
<p>这里注意，需要确保你的Ollama正常运行，否则会报错找不到<code>provider endpoint</code>，如下图：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637437-2072169844.png" alt="any10" loading="lazy"></p>
<p>此时就需要检查你的ollama以及可用的本地模型：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637352-284858044.png" alt="any11" loading="lazy"></p>
<p>修复好之后就可以看到AnythingLLM已经可以正确识别到本地部署的模型：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637486-32889826.png" alt="any12" loading="lazy"></p>
<p>之后可以看到LLM模型选择了Ollama，Embedding默认是AnythingLLM的Embedder，Vector Database默认是LanceDB：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637413-1536870798.png" alt="any13" loading="lazy"></p>
<p>为了不给新手加难度，Embedding和Vector Database我这里都没有进行修改，直接先进入到下一步，是一个survey，笔者是个i人，实在没啥可说的，这里直接跳过了：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637387-423656625.png" alt="any14" loading="lazy"></p>
<p>下一步选择工作区名称，你可以随便起名字，我这里就用自己的英文名演示了：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637346-1931415386.png" alt="any15" loading="lazy"></p>
<p>然后就终于进入了主界面：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637474-960117475.png" alt="any17" loading="lazy"></p>
<p>呼呼，迫不及待的开始测试。<br>
我这里直接设计了一个大模型不可能知道的问题，就是拿我的中文名字去做测试，直接问他“赵靖宇是谁？”<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637404-375331455.png" alt="any18" loading="lazy"></p>
<p>果然，它不知道！</p>
<p>马上开始上传一段TXT文本<code>QA-Test.TXT</code>，其实就是简单包含了我之前在讲公开课时的一段个人介绍，全文也没几句话。开始期待它的表现，上传方式如下，可以看到上传后文件就会自动Embedded！<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637441-1990642552.png" alt="any19" loading="lazy"></p>
<p>可是…… 这里不太顺利，它居然还是不知道！呜呜呜，我都把小抄给你了你还说不知道，笔者已哭晕……<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637381-1556385045.png" alt="any20" loading="lazy"></p>
<p>此时只能转而troubleshooting，检索发现不少人都有遇到类似问题，有人甚至直接发结论说本地大模型的模式下，AnythingLLM根本无法识别上传的个人文件，甚至力劝大家别折腾了。。</p>
<h1 id="3配置-nomic-embed-text-模型">3.配置 nomic-embed-text 模型</h1>
<p>笔者属于不撞南墙不回头的类型，想深挖下问题到底出在哪里？开始逐一检查可能的配置：<br>
1）聊天设置模型选择肯定是没问题，本地大模型 DeepSeek：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637456-339993143.png" alt="any25" loading="lazy"></p>
<p>2）向量数据库默认的，向量数量为1：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637464-542860007.png" alt="any26" loading="lazy"></p>
<p>3）代理配置依然选择了本地大模型 DeepSeek：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637490-1182826280.png" alt="any27" loading="lazy"></p>
<p>笔者初步判断：</p>
<ul>
<li>1）本地大模型肯定没问题，因为上篇使用Chatbox调用都OK，AnythingLLM对应配置也再次确认了，均正确。</li>
<li>2）向量数据库虽然我有更好的选择，笔者就是从事数据库行业，但这里显然还没到那个阶段，默认的即便再拉跨也不至于一个这么简单的文本向量化都搞不定。</li>
<li>3）那就剩下 Embedding 用的模型，虽然开始也没怀疑过，但是这样排除下来就这个可能性最大了。要不，换一个试试？</li>
</ul>
<p>目前 Embedding 采用的是默认的 AnythingLLM Embedder：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637450-681682686.png" alt="any28" loading="lazy"></p>
<p>简单research了下，选了另一个Ollama下的<code>nomic-embed-text</code>Embedding 模型，官方网站：</p>
<ul>
<li><a href="https://ollama.com/library/nomic-embed-text" target="_blank" rel="noopener nofollow">https://ollama.com/library/nomic-embed-text</a></li>
</ul>
<p>我们可以在terminal下使用ollama直接拉取<code>ollama pull nomic-embed-text</code>：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637422-1842107533.png" alt="any30" loading="lazy"></p>
<p>然后再回到<code>Embedder首选项</code>，在嵌入引擎提供商，选择Ollama，然后在下面的Ollama Embedding Model选择刚刚下载的最新<code>nomic-embed-text:8192</code>，如下图：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637496-387389866.png" alt="any31" loading="lazy"></p>
<p>选择好之后点击蓝色的按钮<code>保存更改</code>，会弹出一个比较醒目的Warning，如下图：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637496-509134765.png" alt="any32" loading="lazy"></p>
<p>主要是警告你要做的这个更改Embedding模型的操作会重置先前所有embedded的文档，且不可逆转。我这之前的根本没效果，重置就重置，赶紧点击<code>Confirm</code>，迫不及待想看下这个新的Embedder是否有用？</p>
<h1 id="4演示如何正确喂养个人数据">4.演示如何正确喂养个人数据</h1>
<p>使用跟之前同样的操作方法，同样的问题<code>赵靖宇是谁？</code>，喂养文本<code>QA-Test.TXT</code>，终于起作用了！<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637385-847884078.png" alt="any33" loading="lazy"></p>
<p>于是兴奋地继续追问：<code>他有几年的工作经验？</code>，又不知道了，当然这个正常，因为我提供的信息里就没有明确提到，可以继续上传其他个人数据，比如说来份PDF格式的个人简历：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637415-2020950869.png" alt="any34" loading="lazy"></p>
<p>然后继续问些更细节的问题：<code>你知道他的博客地址是什么吗？</code>、<code>赵靖宇有公众号吗？</code><br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637478-778135277.png" alt="any35" loading="lazy"><br>
效果还是比较给力的，均给出了正确答案。明确说出我的公众号名称<code>赵靖宇</code>，以及Blog的url地址：<code>https://www.cnblogs.com/jyzhao/</code>，尤其是网址能准确给出还是比较惊喜的。</p>
<h1 id="5喂养前后效果对比和缺陷">5.喂养前后效果对比和缺陷</h1>
<p>上面已经看到了喂养后的效果显著，但这是否就高枕无忧了呢？</p>
<p>其实不是的，比如我继续测试时发现，当让它帮我总结下简历信息，就看到了较明显的缺陷：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637469-328529834.png" alt="any37" loading="lazy"></p>
<p>这里有两处明显的错误：而且有一个错误，还是之前单独问它时，回答正确的，具体如下图：<br>
<img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637510-49865465.png" alt="any38" loading="lazy"></p>
<p>其实这个回复中大部分信息都还OK，可瑕疵也是极为明显的，比如它居然说我是人工智能聊天机器人，然后把之前曾正确回答出的博客网址又给答错了。<br>
这些讹误和不稳定性，原因可能是受限于我本地部署的模型太小，本身能力不足，也可能是Embedding向量化的工作做的还不够好，但总体来说，对于我这台个人电脑能达到这样的效果，已经很是知足了。</p>
<p><img src="https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637964-1861863258.png" alt="wxfm-ds2" loading="lazy"></p>
<p>OK，到这里，就已经完成了 DeepSeek 手把手系列的第二篇教程《<a href="https://mp.weixin.qq.com/s/YcW4MDAj06W35TOtHVoB2Q?token=295441393&amp;lang=zh_CN" target="_blank" rel="noopener nofollow">手把手教你喂养 DeepSeek 本地模型</a>》，之前说感兴趣的读者们也抓紧hands-on起来吧！</p>

</div>
<div id="MySignature" role="contentinfo">
    AlfredZhao©版权所有「从Oracle起航，领略精彩的IT技术。」
</div>
<div class="clear"></div>

        <div class="clear"></div>
        
</div>
    <ul class="postmetadata">
        <vc:categories-tags blog-app="jyzhao" blog-id="186567" post-id="18705735"></vc:categories-tags>
    </ul>
