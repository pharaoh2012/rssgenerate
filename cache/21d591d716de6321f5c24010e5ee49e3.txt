
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/DOMLX/p/18831868" title="发布于 2025-04-17 23:18">
    <span role="heading" aria-level="2">pytorch 实战教程之路径聚合网络 PANet (Path Aggregation Network)代码实现            路径聚合网络PANet原理详解</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<p>原文作者：aircraft</p>
<p>原文链接：<a id="cb_post_title_url" class="postTitle2 vertical-middle" title="发布于 2025-04-17 23:18" href="https://www.cnblogs.com/DOMLX/p/18831868">pytorch 实战教程之路径聚合网络PANet(Path AggregationNetwork)代码实现 PANet原理详解&nbsp;<img src="https://www.cnblogs.com/images/visibility.svg" alt="审核中" class="text-tail-icon" title="审核中，审核通过后方可公开访问">&nbsp;</a></p>
<h1 class="postTitle">&nbsp;</h1>
<div>&nbsp;</div>
<div class="clear">&nbsp;</div>
<div class="postBody">&nbsp;</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>　　　　　　<span style="font-size: 16px">　学习YOLOv5前的准备就是学习DarkNet53网络，FPN特征金字塔网络，PANet路径聚合网络结构，（从SPP到SPPF）SPPF空间金字塔池化等。本篇讲PANet网络结构。。。</span></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">&nbsp;PANet原理详解什么介绍我本来是不想写的，看了一圈博客，感觉他们写的都无法让入门小白真正的去理解这个网络结构（感觉他们像个机器翻译人，论文翻译一下就结束了），所以我在他们的基础上稍微讲的详细一些。。。(代码在最下面，注释都打的比较详细了)</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h3><span style="font-size: 14pt">PANet（Path Aggregation Network）详解</span></h3>
<p><span style="font-size: 16px">PANet 是2018年提出的一种高效的目标检测与实例分割网络，核心思想是通过​<strong>​双向特征融合​</strong>​和​<strong>​自适应特征池化​</strong>​显著提升多尺度目标的检测能力。以下从设计动机、核心创新、网络结构、实验结果四个方面详细解析。</span></p>
<p>&nbsp;</p>
<h4><span style="font-size: 14pt">一、设计背景：FPN的局限性</span></h4>
<p><span style="font-size: 18px">​<strong>​FPN（Feature Pyramid Network）​</strong>​ 通过自顶向下的路径构建特征金字塔，但存在两个关键问题：</span></p>
<ol>
<li><span style="font-size: 16px">​<strong>​语义信息稀释​</strong>​：深层特征经过多次上采样传递到浅层时，丢失细节信息。</span></li>
<li><span style="font-size: 16px">​<strong>​定位精度不足​</strong>​：小目标依赖浅层特征，但浅层语义信息较弱。</span></li>
</ol>
<p><span style="font-size: 16px">​<strong>​示例问题​</strong>​：</span><br><span style="font-size: 16px">
在COCO数据集中，小目标（面积&lt;32²像素）的检测AP仅为26.9，远低于大目标（AP 53.6）。</span></p>
<p>&nbsp;</p>
<h4><span style="font-size: 14pt">二、核心创新</span></h4>
<p><span style="font-size: 18px">PANet 提出两大核心改进：</span></p>
<ol><ol>
<li><span style="font-size: 16px">​<strong>​自底向上路径增强（Bottom-Up Path Augmentation）​</strong>​</span><br><span style="font-size: 16px">
新增与FPN反向的路径，强化低层特征的定位能力。</span></li>
<li><span style="font-size: 16px">​<strong>​自适应特征池化（Adaptive Feature Pooling）​</strong>​</span><br><span style="font-size: 16px">
根据目标尺寸自动选择最优特征层级。</span></li>







</ol></ol>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h4><span style="font-size: 14pt">三、网络结构详解</span></h4>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417215313390-1582641457.png" alt="" loading="lazy"></p>
<p><span style="font-size: 18px">主要部分由（a）<strong><strong>FPN（特征金字塔网络），<strong>（b）</strong><strong><strong>自下而上的路径增强（Bottom-up Path Augmentation），<strong>（c）</strong><strong><strong>自适应特征池化（Adaptive Feature Pooling），<strong>（d）<strong>分类与框预测 ,<strong>（e）Mask掩膜分割 构成，详细如下：</strong></strong></strong></strong></strong></strong></strong></strong></strong></span></p>
<p><strong><strong>&nbsp;</strong></strong></p>
<p><span style="font-size: 18px"><strong>（一）.（a）<strong>FPN（特征金字塔网络）</strong> ：</strong></span></p>
<h4><span style="font-size: 16px"><strong>1. 核心思想​</strong>​</span></h4>
<p><span style="font-size: 16px">FPN 通过结合 ​<strong>​深层语义信息​</strong>​（高层特征）和 ​<strong>​浅层细节信息​</strong>​（低层特征），构建多尺度的特征金字塔，显著提升目标检测模型对不同尺寸目标的检测能力。</span></p>
<h4><span style="font-size: 16px"><strong>​2. 网络结构组成​</strong>​</span></h4>
<p><span style="font-size: 16px">FPN 由以下核心组件构成：</span></p>
<div class="hyc-common-markdown__table-wrapper">
<div class="table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">组件</span></th><th><span style="font-size: 16px">作用</span></th></tr>






</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">​<strong>​骨干网络​（自底向上C2-C5）</strong>​</span></td>
<td><span style="font-size: 16px">提取多尺度特征（如ResNet）</span></td>






</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​自顶向下路径​（P5-P2）</strong>​</span></td>
<td><span style="font-size: 16px">通过上采样传递高层语义信息</span></td>






</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​横向连接​</strong>​</span></td>
<td><span style="font-size: 16px">将不同层级的特征对齐通道后融合</span></td>






</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​特征平滑层​</strong>​</span></td>
<td><span style="font-size: 16px">消除上采样带来的混叠效应</span></td>






</tr>






</tbody>






</table>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">大致结构示意图：</span></p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417215928524-1640440099.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><strong>​3. 详细结构分解​</strong>​</span></h4>
<h5><span style="font-size: 16px">​<strong>​3.1 骨干网络（Bottom-Up Pathway）​</strong></span></h5>
<h5><span style="font-size: 16px">在这个过程中，特征图的分辨率逐渐降低，而语义信息逐渐丰富。每一层特征图都代表了输入图像在不同尺度上的抽象表示​</span></h5>
<ul>
<li><span style="font-size: 16px">​<strong>​作用​</strong>​：逐级提取特征，分辨率递减，语义信息递增</span></li>
<li><span style="font-size: 16px">​<strong>​典型实现​</strong>​：ResNet的四个阶段（C1-C5）</span></li>
<li><span style="font-size: 16px">​<strong>​输出特征图​</strong>​：</span>
<pre><span style="font-size: 16px"><code>C2: [H/4, W/4, 256]  （高分辨率，低层细节）
C3: [H/8, W/8, 512]
C4: [H/16, W/16, 1024]
C5: [H/32, W/32, 2048] （低分辨率，高层语义）</code></span></pre>
</li>
</ul>
</div>
</div>
<p>&nbsp;</p>
<p><span style="font-size: 16px"><strong>骨干网络(自底向上，从C2到C5)：</strong></span></p>
<p><span style="font-size: 16px"><strong>　　</strong>C2到C5代表不同的<a class="hl hl-1" href="https://so.csdn.net/so/search?q=ResNet&amp;spm=1001.2101.3001.7020" rel="noopener nofollow" target="_blank" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=ResNet&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;ResNet\&quot;}&quot;}" data-tit="ResNet" data-pretit="resnet">ResNet</a>卷积组，这些卷积组包含了多个Bottleneck结构，组内的特征图大小相同，组间大小递减。</span></p>
<p><span style="font-size: 16px">Bottleneck结构（瓶颈块）：包含三个卷积层，能够有效减少参数数量并提升性能。ResNet-18使用基础的块BasicBlock：两个3*3的卷积层，而ResNet-50使用Bottleneck块：一个1*1的卷积层降低通道数目，然后到3*3的卷积层融合特征，再到1*1的卷积层恢复通道数。</span></p>
<p><strong>​</strong></p>
<p><span style="font-size: 16px"><strong>方向特点​</strong>​：</span></p>
<ul>
<li><span style="font-size: 16px">​<strong>​<strong>自底向上</strong>路径​</strong>​：从深层特征（C5）开始，通过上采样逐步向浅层（C4→C3→C2）传播语义信息。</span></li>
<li><span style="font-size: 16px">​<strong>​横向连接​</strong>​：每个层级融合来自同尺度的骨干网络特征（C2-C5）和上采样后的高层特征。</span></li>
</ul>
<h4>&nbsp;</h4>
<h4><span style="font-size: 16px"><strong>P系列特征的信息特性​：</strong>​</span></h4>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">特征层</span></th><th><span style="font-size: 16px">来源</span></th><th><span style="font-size: 16px">语义信息</span></th><th><span style="font-size: 16px">空间细节</span></th><th><span style="font-size: 16px">特征图尺寸（输入512x512）</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">​<strong>​P5​</strong>​</span></td>
<td><span style="font-size: 16px">C5上采样</span></td>
<td><span style="font-size: 16px">最强（全局语义）</span></td>
<td><span style="font-size: 16px">最粗糙</span></td>
<td><span style="font-size: 16px">16x16（1/32分辨率）</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​P4​</strong>​</span></td>
<td><span style="font-size: 16px">C4 + P5上采样</span></td>
<td><span style="font-size: 16px">强</span></td>
<td><span style="font-size: 16px">较粗糙</span></td>
<td><span style="font-size: 16px">32x32（1/16分辨率）</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​P3​</strong>​</span></td>
<td><span style="font-size: 16px">C3 + P4上采样</span></td>
<td><span style="font-size: 16px">中等</span></td>
<td><span style="font-size: 16px">中等</span></td>
<td><span style="font-size: 16px">64x64（1/8分辨率）</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​P2​</strong>​</span></td>
<td><span style="font-size: 16px">C2 + P3上采样</span></td>
<td><span style="font-size: 16px">较弱</span></td>
<td><span style="font-size: 16px">最精细</span></td>
<td><span style="font-size: 16px">128x128（1/4分辨率）</span></td>
</tr>
</tbody>
</table>
</div>
<h4><span style="font-size: 16px"><strong>P系列携带高层语义信息：</strong>​</span></h4>
<p><span style="font-size: 16px">​<strong>​关键机制​</strong>​：</span></p>
<ol>
<li>
<p>​<strong>​语义信息逐级传递​</strong>​：</p>
<ul>
<li><span style="font-size: 16px">高层的C5特征经过多次卷积和下采样，已丢失细节但捕获了​<strong>​全局语义​</strong>​（如"这是一只狗"）。</span></li>
<li><span style="font-size: 16px">通过自顶向下的上采样路径，这些语义信息被传递到所有P层。</span></li>
</ul>
</li>
<li>
<p><span style="font-size: 16px">​<strong>​横向连接的局限性​</strong>​：</span></p>
<ul>
<li><span style="font-size: 16px">虽然C2-C5本身包含多尺度信息，但低层的C2-C4主要是​<strong>​局部细节​</strong>​（边缘、纹理）。</span></li>
<li><span style="font-size: 16px">横向连接（1x1卷积）只能做通道对齐，无法直接增强语义。</span></li>
</ul>
</li>
</ol>
<h5>&nbsp;</h5>
<h5><span style="font-size: 16px"><strong>3.2 自顶向下路径（Top-Down Pathway）​</strong>​<strong>（从P5-P2）</strong>：</span></h5>
<p><span style="font-size: 16px">为了解决高层特征图分辨率低、细节信息少的问题，FPN引入了自顶向下的特征融合路径。首先对C5进行1x1卷积降低通道数得到P5，然后依次进行双线性差值上采样后与C2-C4层横向连接过来的数据直接相加，分别得到P4-P2，P4,P3,P2在通过一个3*3的平滑卷积层使得数据融合输出。</span></p>
<p><span style="font-size: 16px"><strong>​流程​</strong>​：</span></p>
<ol>
<li><span style="font-size: 16px">​<strong>​顶层处理​</strong>​：C5 → 1x1卷积 → P5</span></li>
<li><span style="font-size: 16px">​<strong>​逐级上采样​</strong>​：P5 → 上采样 → 与C4融合 → P4 → 上采样 → 与C3融合 → P3 ...</span></li>
</ol>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)">P5 (高层语义)
  ↓ 上采样2x
P4 </span>= P5上采样 +<span style="color: rgba(0, 0, 0, 1)"> C4投影
  ↓ 上采样2x
P3 </span>= P4上采样 +<span style="color: rgba(0, 0, 0, 1)"> C3投影
  ↓ 上采样2x
P2 </span>= P3上采样 + C2投影</span></pre>
</div>
<p><span style="font-size: 16px"><strong>核心操作就是通过双线性上采样后的高层特征与浅层数据直接相加后续融合​</strong>​：&nbsp;</span></p>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)">def _upsample_add(self, x, y):
    _,_,H,W </span>=<span style="color: rgba(0, 0, 0, 1)"> y.size()
    </span><span style="color: rgba(0, 0, 255, 1)">return</span> F.interpolate(x, (H,W), mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">bilinear</span><span style="color: rgba(128, 0, 0, 1)">'</span>) + y  # 双线性上采样</span></pre>
</div>
<p>&nbsp;</p>
<p><span style="font-size: 16px">不同上采样方法的优缺点：</span></p>
<p><span style="font-size: 16px">双线性插值（Bilinear Interpolation）：</span><br><span style="font-size: 16px">优点：计算简单，易于实现。</span><br><span style="font-size: 16px">缺点：缺乏学习能力，可能对高层语义特征的细节有所损失。</span></p>
<p><span style="font-size: 16px">反卷积（Deconvolution）：</span><br><span style="font-size: 16px">优点：可学习上采样过程中的参数，更灵活。</span><br><span style="font-size: 16px">缺点：可能引入棋盘效应（Checkerboard Effect）。</span></p>
<p><span style="font-size: 16px">亚像素卷积（Sub-pixel Convolution）：</span><br><span style="font-size: 16px">优点：对特征细节恢复更精细。</span><br><span style="font-size: 16px">缺点：实现相对复杂，且计算开销稍高。</span></p>
<p><span style="font-size: 16px">实践建议</span></p>
<p><span style="font-size: 16px">根据任务需求权衡计算效率与性能。如果计算资源有限，优先选择双线性插值；在高精度任务中，可以尝试反卷积或亚像素卷积。</span></p>
<h5><span style="font-size: 16px"><strong>3.3 横向连接（Lateral Connections）​：</strong></span></h5>
<p><span style="font-size: 16px">目的是为了将上采样后的高语义特征与浅层的定位细节进行融合，实现多尺度特征融合​​（通过横向连接将浅层细节与深层语义结合），横向连接不仅有助于传递低层特征图的细节信息，还可以增强高层特征图的定位能力。高语义特征经过上采样后，其长宽与对应的浅层特征相同，而通道数固定为256。因此需要对特征C2——C4进行1x1卷积使得其通道数变为256.，然后两者进行逐元素相加得到P4、P3与P2。​</span></p>
<ul>
<li><span style="font-size: 16px">​<strong>​作用​</strong>​：将骨干网络特征与上采样特征对齐通道</span></li>
<li><span style="font-size: 16px">​<strong>​实现方式​</strong>​：1x1卷积（通道压缩/对齐）</span></li>






</ul>
<h4><span style="font-size: 16px"><strong>4. 输出特征金字塔​</strong>​</span></h4>
<div class="hyc-common-markdown__table-wrapper">
<div class="table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">特征层</span></th><th><span style="font-size: 16px">分辨率（相对于输入）</span></th><th><span style="font-size: 16px">通道数</span></th><th><span style="font-size: 16px">适用目标尺寸</span></th></tr>






</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">P2</span></td>
<td><span style="font-size: 16px">1/4</span></td>
<td><span style="font-size: 16px">256</span></td>
<td><span style="font-size: 16px">小目标（&lt;32x32像素）</span></td>






</tr>
<tr>
<td><span style="font-size: 16px">P3</span></td>
<td><span style="font-size: 16px">1/8</span></td>
<td><span style="font-size: 16px">256</span></td>
<td><span style="font-size: 16px">中等目标（32-96像素）</span></td>






</tr>
<tr>
<td><span style="font-size: 16px">P4</span></td>
<td><span style="font-size: 16px">1/16</span></td>
<td><span style="font-size: 16px">256</span></td>
<td><span style="font-size: 16px">大目标（&gt;96x96像素）</span></td>






</tr>
<tr>
<td><span style="font-size: 16px">P5</span></td>
<td><span style="font-size: 16px">1/32</span></td>
<td><span style="font-size: 16px">256</span></td>
<td><span style="font-size: 16px">极大目标/背景</span></td>






</tr>






</tbody>






</table>






</div>






</div>
<p><span style="font-size: 16px">&nbsp;</span></p>
<p><span style="font-size: 16px">&nbsp;</span></p>
<ul>
<li><span style="font-size: 16px">通过上述步骤，FPN构建了一个特征金字塔（feature pyramid）。这个金字塔包含了从底层到顶层的多个尺度的特征图，每个特征图都融合了不同层次的特征信息。</span></li>
<li><span style="font-size: 16px">特征金字塔的每一层都对应一个特定的尺度范围，使得模型能够同时处理不同大小的目标。</span></li>






</ul>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><strong>5. 设计优势​</strong>​</span></h4>
<ol>
<li><span style="font-size: 16px">​<strong>​多尺度预测​</strong>​：每个金字塔层都可独立用于目标检测</span></li>
<li><span style="font-size: 16px">​<strong>​参数共享​</strong>​：所有层级使用相同的检测头（Head）</span></li>
<li><span style="font-size: 16px">​<strong>​计算高效​</strong>​：横向连接仅使用轻量级的1x1卷积</span></li>
<li><span style="font-size: 16px">​<strong>​端到端训练​</strong>​：整个网络可联合优化</span></li>






</ol>
<p><span style="font-size: 16px">&nbsp;</span></p>
<h4><span style="font-size: 16px"><strong>6. 典型应用场景​</strong>​</span></h4>
<ol>
<li><span style="font-size: 16px">​<strong>​目标检测​</strong>​：Faster R-CNN、Mask R-CNN</span></li>
<li><span style="font-size: 16px">​<strong>​实例分割​</strong>​：Mask预测分支可附加到各金字塔层</span></li>
<li><span style="font-size: 16px">​<strong>​关键点检测​</strong>​：高分辨率特征层（如P2）适合精细定位</span></li>






</ol>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><strong>本文代码中对照实现的FPN部分：</strong></span></p>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)"># 特征金字塔网络（FPN）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> FPN(nn.Module):
    def __init__(self, block, num_blocks):
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        参数：
            block: 基础块类型（Bottleneck）
            num_blocks: 各层block数量（如ResNet50的[</span><span style="color: rgba(128, 0, 128, 1)">3</span>,<span style="color: rgba(128, 0, 128, 1)">4</span>,<span style="color: rgba(128, 0, 128, 1)">6</span>,<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">]）
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        super().__init__()
        self.in_planes </span>= <span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">  # 初始通道数
        
        # 初始卷积层（模仿ResNet）
        self.conv1 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">64</span>, <span style="color: rgba(128, 0, 128, 1)">7</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">3</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn1 </span>= nn.BatchNorm2d(<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">)
        self.maxpool </span>= nn.MaxPool2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span>)  # <span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(0, 0, 0, 1)">4下采样
        
        # 构建残差层（C2</span>-<span style="color: rgba(0, 0, 0, 1)">C5）
        self.layer1 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">64</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">0</span>], <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)   # C2
        self.layer2 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">128</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">1</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)  # C3
        self.layer3 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">256</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">2</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">) # C4
        self.layer4 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">512</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">3</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">) # C5
        
        # 特征金字塔横向连接（1x1卷积降维）
        self.toplayer </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">2048</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)   # 处理C5
        self.latlayer1 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">1024</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 处理C4
        self.latlayer2 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)    # 处理C3
        self.latlayer3 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)    # 处理C2
        
        # 权重参数初始化 
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> m <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> [self.toplayer, self.latlayer1, self.latlayer2, self.latlayer3]:
            nn.init.kaiming_normal_(m.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def _make_layer(self, block, planes, num_blocks, stride):
        </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">构建残差层</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
        layers </span>=<span style="color: rgba(0, 0, 0, 1)"> [block(self.in_planes, planes, stride)]  # 第一个block的stride如果大于1，可能有下采样
        self.in_planes </span>= planes *<span style="color: rgba(0, 0, 0, 1)"> block.expansion  # 更新输入通道数
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> _ <span style="color: rgba(0, 0, 255, 1)">in</span> range(<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">, num_blocks):
            layers.append(block(self.in_planes, planes, </span><span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">))  # 后续block无下采样

        </span><span style="color: rgba(128, 0, 0, 1)">'''</span><span style="color: rgba(128, 0, 0, 1)">最终结构：假如第一个stride为2自带下采样，后面为1正常输出：Sequential(</span>
                    Bottleneck1(<span style="color: rgba(128, 0, 128, 1)">256</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck2(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck3(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck4(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)
                        )</span><span style="color: rgba(128, 0, 0, 1)">'''
</span>        <span style="color: rgba(0, 0, 255, 1)">return</span> nn.Sequential(*<span style="color: rgba(0, 0, 0, 1)">layers)
    

    def _upsample_add(self, x, y):
        </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">上采样并相加（特征融合）</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
        # 使用双线性插值上采样到y的尺寸再加上y进行特征融合
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> F.interpolate(x, size=y.shape[<span style="color: rgba(128, 0, 128, 1)">2</span>:], mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">bilinear</span><span style="color: rgba(128, 0, 0, 1)">'</span>) +<span style="color: rgba(0, 0, 0, 1)"> y

    def forward(self, x):
        # 自底向上路径
        c1 </span>= F.relu(self.bn1(self.conv1(x)))  # [B,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">256</span><span style="color: rgba(0, 0, 0, 1)">]
        c1 </span>= self.maxpool(c1)  # [B,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        
        c2 </span>= self.layer1(c1)   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">] (C2)
        c3 </span>= self.layer2(c2)   # [B,<span style="color: rgba(128, 0, 128, 1)">512</span>,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">]   (C3)
        c4 </span>= self.layer3(c3)    # [B,<span style="color: rgba(128, 0, 128, 1)">1024</span>,<span style="color: rgba(128, 0, 128, 1)">32</span>,<span style="color: rgba(128, 0, 128, 1)">32</span><span style="color: rgba(0, 0, 0, 1)">]  (C4)
        c5 </span>= self.layer4(c4)    # [B,<span style="color: rgba(128, 0, 128, 1)">2048</span>,<span style="color: rgba(128, 0, 128, 1)">16</span>,<span style="color: rgba(128, 0, 128, 1)">16</span><span style="color: rgba(0, 0, 0, 1)">] (C5)
        
        # 自顶向下路径（特征金字塔构建）
        p5 </span>= self.toplayer(c5)               # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">16</span>,<span style="color: rgba(128, 0, 128, 1)">16</span><span style="color: rgba(0, 0, 0, 1)">]
        p4 </span>= self._upsample_add(p5, self.latlayer1(c4))  # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">32</span>,<span style="color: rgba(128, 0, 128, 1)">32</span><span style="color: rgba(0, 0, 0, 1)">]   self.latlayer代表连接层，将数据连接过来
        p3 </span>= self._upsample_add(p4, self.latlayer2(c3))   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">]
        p2 </span>= self._upsample_add(p3, self.latlayer3(c2))   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> p2, p3, p4, p5</span></pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><strong><strong>（二）</strong>.（b）<strong>自下而上的路径增强（Bottom-up Path Augmentation）</strong> ：</strong></span></p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417221058260-2069096829.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">这里要注意的是P2就是N2。</span></p>
<p><span style="font-size: 16px">N3：N2下采样后+P3的投影（下采样一般就是池化，P3的投影指的是P3的数据通过1*1的卷积修改通道数目后传输过来的数据）</span></p>
<p><span style="font-size: 16px">N4:&nbsp; &nbsp;N3下采样后+P4的投影</span></p>
<p><span style="font-size: 16px">N5:&nbsp; &nbsp;N4下采样后+P5的投影</span></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px"><strong>​自下向上路径的作用​</strong>​：</span></p>
<ul>
<li><span style="font-size: 16px">​<strong>​方向​</strong>​：从P2开始，通过下采样逐步向高层传递​<strong>​定位细节​</strong>​。</span></li>
<li><span style="font-size: 16px">​<strong>​信息流动​</strong>​：</span>
<pre><span style="font-size: 16px"><code>N2（P2级） → 下采样 + P3的投影 → N3 → 下采样 </code></span><span style="font-size: 16px"><code>+ P4的投影 </code></span><span style="font-size: 16px"><code>→ N4 → 下采样 + P5的投影 → N5</code></span></pre>
</li>
<li><span style="font-size: 16px">​<strong>​定位信息增强​</strong>​：</span>
<ul>
<li>低层特征（N2-N3）携带​<strong>​精确位置信息​</strong>​（如物体边缘）</li>
<li>通过路径传递，修正高层特征的定位误差</li>
</ul>
</li>
</ul>
<p>过程示意图：</p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417223319187-1668409950.bmp" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">​<strong>​<br></strong></span></p>
<p><span style="font-size: 16px"><strong>典型示例​</strong>​：</span></p>
<ul>
<li><span style="font-size: 16px">​<strong>​P5​</strong>​可能检测到"狗在图像某处"</span></li>
<li><span style="font-size: 16px">​<strong>​N5​</strong>​结合低层细节后，能更准确定位狗的具体位置</span></li>






</ul>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"># 进行特征融合（FPN与自底向上路径相加）多层级融合​​：每个尺度都获得全局+<span style="color: rgba(0, 0, 0, 1)">局部信息
        # N2</span>-N5 路径存在的意义主要传递的是增强后的定位信息  而P2-<span style="color: rgba(0, 0, 0, 1)">P5才是原有的丰富语义信息 
        # 高层的C5特征经过多次卷积和下采样，已丢失细节但捕获了​​全局语义​​（如</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">这是一只狗</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">）。
        # 通过自顶向下的上采样路径，这些语义信息被传递到所有P层。
        # 虽然C2</span>-C5本身包含多尺度信息，但低层的C2-<span style="color: rgba(0, 0, 0, 1)">C4主要是​​局部细节​​（边缘、纹理）。
        # 横向连接到对应P层（1x1卷积）只能做通道对齐，无法直接增强语义。
        # N2（P2级） → 下采样 → N3 → 下采样 → N4 → 下采样 → N5   
        # 低层特征（N2</span>-<span style="color: rgba(0, 0, 0, 1)">N3）携带​​精确位置信息​​（如物体边缘）通过路径传递，修正高层特征的定位误差 
        # P5​​可能检测到</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">狗在图像某处</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)"> N5​​结合低层细节后，能更准确定位狗的具体位置 
        # P5 </span>+<span style="color: rgba(0, 0, 0, 1)"> N5​​：增强高层语义的定位能力 
        # P2 </span>+ N2​​：为细节层补充语义理解</span></pre>
</div>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><br><br></span></p>
<p><span style="font-size: 18px">本文对照实现的大概代码：</span></p>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"># 自底向上增强路径（PANet核心） N2--<span style="color: rgba(0, 0, 0, 1)">N5
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> BottomUpPath(nn.Module):
    def __init__(self):
        super().__init__()
        # 横向连接卷积（特征融合）  创建个卷积List,存放四个卷积层
        self.lat_conv </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.ModuleList([
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span>) <span style="color: rgba(0, 0, 255, 1)">for</span> _ <span style="color: rgba(0, 0, 255, 1)">in</span> range(<span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)  # 每个金字塔层级一个卷积
        ])
        self.downsample </span>= nn.MaxPool2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 2倍下采样
        
        # 参数初始化
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> conv <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> self.lat_conv:
            nn.init.kaiming_normal_(conv.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def forward(self, features):
        p2, p3, p4, p5 </span>= features  # 来自FPN的特征  FPN将自己每层的数据传输过来经过1*<span style="color: rgba(0, 0, 0, 1)">1的卷积归一化通道数目后与降采样的数据直接相加完成特征连接
        
        # 自底向上增强路径（通过下采样和横向连接）
        n2 </span>= self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">0</span>](p2)                   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        n3 </span>= self.downsample(n2) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">](p3)  # 下采样后相加
        n4 </span>= self.downsample(n3) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">](p4)
        n5 </span>= self.downsample(n4) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">](p5)
        
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> [n2, n3, n4, n5]</span></pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><strong><strong>（三）</strong>.（c）<strong>自适应特征池化（Adaptive Feature Pooling）</strong> ：</strong></span></p>
<p><span style="font-size: 18px">&nbsp;</span></p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418082210408-901897357.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h3>PANet 自适应特征池化详解</h3>
<p><span style="font-size: 16px">自适应特征池化（Adaptive Feature Pooling）是 PANet 的核心创新之一，旨在解决传统特征金字塔网络（FPN）中 ​<strong>​ROI 特征与层级不匹配​</strong>​ 的问题。以下从原理、实现到优势进行完整解析。</span></p>
<h4><span style="font-size: 16px"><strong>​一、传统方法的局限性​</strong>​</span></h4>
<p><span style="font-size: 16px">在 FPN 中，特征金字塔的层级选择规则通常为：</span></p>
<p><span style="font-size: 16px"><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417224905507-584258096.png" alt="" loading="lazy"></span></p>
<p><span style="font-size: 16px">&nbsp;</span></p>
<p><span style="font-size: 16px">其中：</span></p>
<ul>
<li><span class="katex" style="font-size: 16px"><span class="strut"><span class="mord mathnormal">w<span class="mpunct">,<span class="mspace"><span class="mord mathnormal">h 是 ROI 的宽高</span></span></span></span></span></span></li>
<li><span class="katex" style="font-size: 16px"><span class="strut"><span class="mord"><span class="mord mathnormal">k<span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class="pstrut"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0<span class="vlist-s">​<span class="vlist-r"><span class="vlist"> 是基准层级（通常设为4，对应 P4）</span></span></span></span></span></span></span></span></span></span></span></span></span></span></li>
<li><span class="katex" style="font-size: 16px"><span class="strut"><span class="mord mathnormal">k 对应特征层级（P2-P5）</span></span></span></li>
</ul>
<p><span style="font-size: 16px"><strong>问题​</strong>​：</span></p>
<ol>
<li><span style="font-size: 16px">​<strong>​单一层级限制​</strong>​：每个 ROI 只能从一个层级提取特征，可能丢失关键信息。</span></li>
<li><span style="font-size: 16px">​<strong>​小目标敏感​</strong>​：小 ROI 被迫使用高分辨率但低语义的浅层特征（如 P2）。</span></li>
<li><span style="font-size: 16px">​<strong>​人工规则缺陷​</strong>​：固定的数学公式无法动态适应不同数据分布。</span></li>
</ol>
<h4><span style="font-size: 16px"><strong>​二、自适应特征池化原理​</strong>​</span></h4>
<p><span style="font-size: 16px">PANet 提出同时利用 ​<strong>​所有层级​</strong>​ 的特征，通过 ​<strong>​动态融合​</strong>​ 增强 ROI 特征表示。</span></p>
<h5><span style="font-size: 16px">​<strong>​1. 多层级特征提取​</strong>​</span></h5>
<ul>
<li><span style="font-size: 16px">​<strong>​输入​</strong>​：融合后的 PAN 特征（P2+N2, P3+N3, ..., P5+N5）---------------------这里要特别注意结构图上是没有直接显示的（但是这个操作严格符合论文中"Feature fusion by element-wise addition"的描述（见论文3.2节））</span></li>
</ul>
<div class="cnblogs_code">
<pre><span style="font-size: 16px">pan_features =<span style="color: rgba(0, 0, 0, 1)"> [
            p2 </span>+<span style="color: rgba(0, 0, 0, 1)"> n2,  # 增强后的P2特征
            p3 </span>+<span style="color: rgba(0, 0, 0, 1)"> n3,
            p4 </span>+<span style="color: rgba(0, 0, 0, 1)"> n4,
            p5 </span>+<span style="color: rgba(0, 0, 0, 1)"> n5
        ]</span></span></pre>
</div>
<ul>
<li>
<table>
<thead>
<tr><th><span style="font-size: 16px">方案</span></th><th><span style="font-size: 16px">mAP</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">仅FPN</span></td>
<td><span style="font-size: 16px">46.5</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">仅BUP</span></td>
<td><span style="font-size: 16px">46.3</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">FPN+BUP融合</span></td>
<td><span style="font-size: 16px">47.4</span></td>
</tr>
</tbody>
</table>
</li>
<li>
<pre><span style="font-size: 16px"><code>Original PANet结构：
FPN路径：P5 → P4 → P3 → P2
BUP路径：N2 → N3 → N4 → N5
Fusion方式：P2+N2 → P3+N3 → P4+N4 → P5+N5</code></span></pre>
</li>
<li><span style="font-size: 16px">​<strong>​操作​</strong>​：对每个 ROI 在 ​<strong>​所有层级​</strong>​ 进行 ROI Align&nbsp;</span></li>
</ul>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)"> # 然后进入 多层级ROI Align池化
        pooled </span>=<span style="color: rgba(0, 0, 0, 1)"> []
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> feat, name <span style="color: rgba(0, 0, 255, 1)">in</span> zip(pan_features, [<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p2</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p3</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p4</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p5</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]):
            # 对每个层级的特征进行ROI Align
            pooled.append(self.roi_align[name](feat, proposals))</span></span></pre>
</div>
<h5><span style="font-size: 16px"><strong>​2. 特征融合策略​</strong>​</span></h5>
<ul>
<li>
<p><span style="font-size: 16px">​<strong>​最大值融合（Max Fusion）​</strong>​：</span></p>
</li>
</ul>
<p><span style="font-size: 16px"><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417225219887-218143952.png" alt="" loading="lazy"></span></p>
<p><span style="font-size: 16px">&nbsp;</span></p>
<ul>
<li><span style="font-size: 16px">保留每个位置最显著的特征响应</span></li>
<li><span style="font-size: 16px">增强对小目标的敏感度</span></li>
</ul>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)"> # 特征融合（取各层级最大值）
        fused </span>= torch.max(torch.stack(pooled), dim=<span style="color: rgba(128, 0, 128, 1)">0</span>)[<span style="color: rgba(128, 0, 128, 1)">0</span>]  # [N,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">7</span>,<span style="color: rgba(128, 0, 128, 1)">7</span>]</span></pre>
</div>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><span style="font-size: 18px"><strong>三、实现细节​</strong></span>​</span></h4>
<h5><span style="font-size: 16px">​<strong>​1. ROI Align 参数​</strong></span>​</h5>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th>参数</th><th>值</th><th>说明</th></tr>
</thead>
<tbody>
<tr>
<td><code>output_size</code></td>
<td>7x7</td>
<td>输出特征图尺寸</td>
</tr>
<tr>
<td><code>sampling_ratio</code></td>
<td>2</td>
<td>每个区间采样点数</td>
</tr>
<tr>
<td><code>spatial_scale</code></td>
<td>层级相关</td>
<td>P2: 1/4, P3: 1/8, 以此类推</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
</div>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)"># ROI Align配置（不同层级的空间尺度） 自适应特征池化：对每个候选区域，在每个特征层上进行ROI Align池化，然后将不同层的特征图进行最大值融合 
        self.roi_align </span>=<span style="color: rgba(0, 0, 0, 1)"> {
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p2</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">4</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span>),  # <span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(0, 0, 0, 1)">4尺寸
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p3</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">8</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p4</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">16</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p5</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">32</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)
        }
        </span><span style="color: rgba(128, 0, 0, 1)">'''</span><span style="color: rgba(128, 0, 0, 1)"> RoIAlign与RoIPool的区别 参考博客：https://www.cnblogs.com/xiaochouk/p/15912972.html</span>
<span style="color: rgba(0, 0, 0, 1)">            RoIAlign与传统的RoIPool（区域兴趣池化）的主要区别在于处理边界的方式。
            RoIPool在进行池化操作时会对边界进行量化处理，这会导致精度损失。
            而RoIAlign则通过保持边界框内的采样点为浮点数坐标，
            并进行双线性插值来计算每个采样点的值，从而减少了量化误差，提高了精度。</span><span style="color: rgba(128, 0, 0, 1)">'''</span></span></pre>
</div>
<p>&nbsp;不同层的池化比例大小不同，最后得到同样大小的特征图。</p>
<h4><span style="font-size: 16px"><span style="font-size: 18px"><strong>四、优势分析​</strong></span>​</span></h4>
<h5><span style="font-size: 16px">​<strong>​1. 多层级信息互补​</strong>​</span></h5>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">特征层级</span></th><th><span style="font-size: 16px">优势特征</span></th><th><span style="font-size: 16px">对检测的帮助</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">​<strong>​P2​</strong>​</span></td>
<td><span style="font-size: 16px">高分辨率细节（边缘、纹理）</span></td>
<td><span style="font-size: 16px">提升小目标定位精度</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​P5​</strong>​</span></td>
<td><span style="font-size: 16px">强语义（物体类别）</span></td>
<td><span style="font-size: 16px">避免漏检模糊目标</span></td>
</tr>
</tbody>
</table>
</div>
<p>&nbsp;</p>
<h5><span style="font-size: 16px"><strong>​1. 多层级信息互补​</strong>​</span></h5>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">特征层级</span></th><th><span style="font-size: 16px">优势特征</span></th><th><span style="font-size: 16px">对检测的帮助</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">​<strong>​P2​</strong>​</span></td>
<td><span style="font-size: 16px">高分辨率细节（边缘、纹理）</span></td>
<td><span style="font-size: 16px">提升小目标定位精度</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​P5​</strong>​</span></td>
<td><span style="font-size: 16px">强语义（物体类别）</span></td>
<td><span style="font-size: 16px">避免漏检模糊目标</span></td>
</tr>
</tbody>
</table>
</div>
<h5><span style="font-size: 16px">​<strong>​2. 实验验证（COCO 数据集）​</strong>​</span></h5>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">方法</span></th><th><span style="font-size: 16px">mAP</span></th><th><span style="font-size: 16px">AP<sub>small</sub></span></th><th><span style="font-size: 16px">AP<sub>medium</sub></span></th><th><span style="font-size: 16px">AP<sub>large</sub></span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">FPN（单层级）</span></td>
<td><span style="font-size: 16px">36.2</span></td>
<td><span style="font-size: 16px">18.2</span></td>
<td><span style="font-size: 16px">39.0</span></td>
<td><span style="font-size: 16px">48.2</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">PANet（自适应池化）</span></td>
<td><span style="font-size: 16px">41.2</span></td>
<td><span style="font-size: 16px">​<strong>​23.8​</strong>​ (+31%)</span></td>
<td><span style="font-size: 16px">​<strong>​44.3​</strong>​</span></td>
<td><span style="font-size: 16px">​<strong>​52.5​</strong>​</span></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><span style="font-size: 16px">​<strong>​小目标检测提升显著​</strong>​：AP<sub>small</sub> 提升 5.6 个点</span></li>
<li><span style="font-size: 16px">​<strong>​计算代价可控​</strong>​：增加约 20% 的池化时间，但 mAP 提升 5%</span></li>
</ul>
<h4><span style="font-size: 16px"><span style="font-size: 18px"><strong>​五、与传统方法的对比​</strong></span>​</span></h4>
<table>
<thead>
<tr><th><span style="font-size: 16px">维度</span></th><th><span style="font-size: 16px">FPN</span></th><th><span style="font-size: 16px">PANet</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">特征来源</span></td>
<td><span style="font-size: 16px">单一层级</span></td>
<td><span style="font-size: 16px">多层级融合</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">规则灵活性</span></td>
<td><span style="font-size: 16px">固定数学公式</span></td>
<td><span style="font-size: 16px">数据驱动动态适应</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">小目标优化</span></td>
<td><span style="font-size: 16px">有限</span></td>
<td><span style="font-size: 16px">显著提升（+31%）</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">计算效率</span></td>
<td><span style="font-size: 16px">高</span></td>
<td><span style="font-size: 16px">中等（可接受）</span></td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h4><span style="font-size: 16px"><span style="font-size: 18px"><strong>​六、实际应用示例​</strong></span>​</span></h4>
<p><span style="font-size: 16px">假设检测两个目标：</span></p>
<ol>
<li><span style="font-size: 16px">​<strong>​小目标​</strong>​：20x20 像素的鸟</span></li>
<li><span style="font-size: 16px">​<strong>​大目标​</strong>​：300x300 像素的汽车</span></li>
</ol>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">目标类型</span></th><th><span style="font-size: 16px">FPN 选择的层级</span></th><th><span style="font-size: 16px">PANet 融合效果</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">小目标</span></td>
<td><span style="font-size: 16px">P2（1/4 分辨率）</span></td>
<td><span style="font-size: 16px">同时利用 P2 的细节和 P5 的语义，避免漏检</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">大目标</span></td>
<td><span style="font-size: 16px">P5（1/32 分辨率）</span></td>
<td><span style="font-size: 16px">融合 P5 的语义和 P2 的细节，边界更精确</span></td>
</tr>
</tbody>
</table>
</div>
<h4><span style="font-size: 16px"><strong>七、总结​</strong>​</span></h4>
<ul>
<li><span style="font-size: 16px">​<strong>​核心思想​</strong>​：打破单层级限制，通过多层级特征融合增强 ROI 表示。</span></li>
<li><span style="font-size: 16px">​<strong>​技术价值​</strong>​：​<strong>​行业影响​</strong>​：成为后续模型（如 Mask Scoring R-CNN）的标配组件。</span>
<ul>
<li><span style="font-size: 16px">为小目标提供高分辨率细节</span></li>
<li><span style="font-size: 16px">为大目标保留强语义特征</span></li>
<li><span style="font-size: 16px">动态适应不同尺度目标</span></li>
</ul>
</li>
<li></li>
</ul>
<p><span style="font-size: 16px">自适应特征池化使 PANet 在 COCO 等复杂场景数据集的检测精度显著提升，尤其为小目标检测提供了新的优化方向。</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><strong><strong>（四）</strong>.（d）分类与框预测 ：</strong></span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418082246809-484174803.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 18px">在这个网络结构部分里进行​<strong>​分类​</strong>​（判断物体类别）和​<strong>​回归​</strong>​（精确调整边界框）。<br></span></p>
<h4><span style="font-size: 16px"><strong>1. 模块定位与功能​</strong>​</span></h4>
<p><span style="font-size: 16px">在 PANet 的整体架构中，分类与边界框预测模块是网络的最终输出层，承担两个核心任务：</span></p>
<ul>
<li><span style="font-size: 16px">​<strong>​分类任务​</strong>​：预测 ROI 内物体的类别（如 COCO 的 80 类）</span></li>
<li><span style="font-size: 16px">​<strong>​回归任务​</strong>​：精调边界框坐标（Δx, Δy, Δw, Δh）</span></li>






</ul>
<p><span style="font-size: 18px"><strong><strong>结构设计：</strong></strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1)">graph TD
A[输入特征] </span>--&gt;<span style="color: rgba(0, 0, 0, 1)"> B[全连接层1]
B </span>--&gt;<span style="color: rgba(0, 0, 0, 1)"> C[ReLU]
C </span>--&gt;<span style="color: rgba(0, 0, 0, 1)"> D[全连接层2]
D </span>--&gt; E1[分类输出] &amp; E2[回归输出]</pre>
</div>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><strong><strong>模拟代码：</strong></strong></span></p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1)"># 分类头
        self.cls_head </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span>, <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">),  # ROI特征展平后输入
            nn.ReLU(),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">, num_classes)   # 输出类别分数
        )
        # 回归头
        self.reg_head </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span>, <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)  # 输出边界框偏移量  偏移量x,y,w,h
        )</span></pre>
</div>
<p><span style="font-size: 16px">PANet 的检测头通过 ​<strong>​多层级特征融合​</strong>​ 与 ​<strong>​路径增强​</strong>​，实现了：</span></p>
<ol>
<li><span style="font-size: 16px">​<strong>​分类精度提升​</strong>​：增强小目标语义理解</span></li>
<li><span style="font-size: 16px">​<strong>​定位精度优化​</strong>​：融合底层细节特征</span></li>
<li><span style="font-size: 16px">​<strong>​多尺度适应性​</strong>​：动态平衡不同尺寸目标需求</span></li>
</ol>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><strong><strong>（五）</strong>.（e）Mask掩膜分割 ：</strong></span></p>
<p>&nbsp;</p>
<p><span style="font-size: 18px"><strong>PANet最后一个贡献是提出了Fully-connected Fusion，这是对原有的分割支路(FCN)引入一个前景二分类的全连接支路，通过融合这两条支路的输出得到更加精确的分割结果。这个模块的具体实现如Figure4所示。</strong></span></p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417232755839-147763486.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">PANet提出了对FCN和全连接融合的结构。</span></p>
<p><span style="font-size: 16px">其主分支由4个连续的3*3卷积核一个上采样2倍的反卷积组成，它用来预测每个类别的mask分支。</span></p>
<p><span style="font-size: 16px">全连接融合的另一个分支是从conv3叉出的一个全连接层，它先通过两个3*3卷积进行降维，然后将其展开成一维向量，然后通过这个向量预测类别不可知的前景/背景的mask。</span></p>
<p><span style="font-size: 16px">最后再通过一个reshape操作将其还原为 28*28的Feature Map。</span></p>
<p><span style="font-size: 16px">这里一般只使用一个全连接层，因为两个以上的全连接会使空间特征遭到破坏。</span></p>
<p><span style="font-size: 16px">最后在单位加和一个sigmoid激活函数得到最终输出。</span><br><br></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 14pt"><strong>主要由两个分支组层：</strong></span></p>
<h4><span style="font-size: 16px">1. ​<strong>​主分支（FCN分支）​</strong>​</span></h4>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(128, 0, 0, 1)">"""
</span>输入形状：[N, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">14</span>, <span style="color: rgba(128, 0, 128, 1)">14</span><span style="color: rgba(0, 0, 0, 1)">]
流程：
</span><span style="color: rgba(128, 0, 128, 1)">1</span>. 4个3x3卷积 +<span style="color: rgba(0, 0, 0, 1)"> ReLU（保持尺寸）
</span><span style="color: rgba(128, 0, 128, 1)">2</span>. 反卷积2倍上采样 → [<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
</span><span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">. 1x1卷积生成类别相关掩膜
</span><span style="color: rgba(128, 0, 0, 1)">"""</span></span></pre>
</div>
<ul>
<li><span style="font-size: 16px"><strong>​通道守恒​</strong>​：所有卷积层保持256通道，避免信息损失</span></li>
<li><span style="font-size: 16px">​<strong>​上采样设计​</strong>​：使用转置卷积实现精确的2倍上采样</span></li>
</ul>
<h4>&nbsp;</h4>
<h4><span style="font-size: 16px">2. ​<strong>​全连接融合分支​</strong>​</span></h4>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(128, 0, 0, 1)">"""
</span>输入取自第3个卷积层输出：[N, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">14</span>, <span style="color: rgba(128, 0, 128, 1)">14</span><span style="color: rgba(0, 0, 0, 1)">]
流程：
</span><span style="color: rgba(128, 0, 128, 1)">1</span>. 2个3x3卷积降维 → [N,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">14</span>,<span style="color: rgba(128, 0, 128, 1)">14</span><span style="color: rgba(0, 0, 0, 1)">]
</span><span style="color: rgba(128, 0, 128, 1)">2</span>. 展平为向量 → [N, <span style="color: rgba(128, 0, 128, 1)">64</span> * <span style="color: rgba(128, 0, 128, 1)">14</span> * <span style="color: rgba(128, 0, 128, 1)">14</span><span style="color: rgba(0, 0, 0, 1)">]
</span><span style="color: rgba(128, 0, 128, 1)">3</span>. 单个全连接层 → [N, <span style="color: rgba(128, 0, 128, 1)">28</span> * <span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
</span><span style="color: rgba(128, 0, 128, 1)">4</span>. Reshape → [N,<span style="color: rgba(128, 0, 128, 1)">1</span>,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
</span><span style="color: rgba(128, 0, 128, 1)">5</span><span style="color: rgba(0, 0, 0, 1)">. 与主分支相加后Sigmoid
</span><span style="color: rgba(128, 0, 0, 1)">"""</span></span></pre>
</div>
<p>&nbsp;</p>
<ul>
<li><span style="font-size: 16px"><strong>​降维策略​</strong>​：通过两次3x3卷积将通道数降至64</span></li>
<li><span style="font-size: 16px">​<strong>​单全连接层​</strong>​：避免破坏空间结构，直接映射到目标尺寸</span></li>
</ul>
<p>&nbsp;</p>
<h4><span style="font-size: 16px">​<strong>​双路径信息互补​</strong></span>​</h4>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th>路径</th><th>信息类型</th><th>作用</th></tr>
</thead>
<tbody>
<tr>
<td>主分支 (FCN)</td>
<td><span style="font-size: 16px">局部细节</span></td>
<td><span style="font-size: 16px">捕捉物体边缘和纹理</span></td>
</tr>
<tr>
<td>全连接分支</td>
<td><span style="font-size: 16px">全局上下文</span></td>
<td><span style="font-size: 16px">增强语义一致性</span></td>
</tr>
</tbody>
</table>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h4>&nbsp;</h4>
<h3><span style="font-size: 14pt">性能对比实验：</span></h3>
<h4>&nbsp;</h4>
<p><span style="font-size: 16px">在 COCO 数据集上的消融实验结果：</span></p>
<h4>&nbsp;</h4>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">模型变体</span></th><th><span style="font-size: 16px">Mask AP</span></th><th><span style="font-size: 16px">参数量</span></th><th><span style="font-size: 16px">推理速度 (FPS)</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">基础 FCN 头</span></td>
<td><span style="font-size: 16px">33.1</span></td>
<td><span style="font-size: 16px">7.2M</span></td>
<td><span style="font-size: 16px">6.2</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">仅全连接分支</span></td>
<td><span style="font-size: 16px">32.8</span></td>
<td><span style="font-size: 16px">10.1M</span></td>
<td><span style="font-size: 16px">5.8</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">PANet 双分支融合</span></td>
<td><span style="font-size: 16px">36.9</span></td>
<td><span style="font-size: 16px">17.3M</span></td>
<td><span style="font-size: 16px">4.9</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">双全连接层 (替代单层)</span></td>
<td><span style="font-size: 16px">35.2</span></td>
<td><span style="font-size: 16px">24.6M</span></td>
<td><span style="font-size: 16px">4.1</span></td>
</tr>
</tbody>
</table>
</div>
<h4>&nbsp;</h4>
<p><span style="font-size: 16px">​<strong>​结论​</strong>​：</span></p>
<h4>&nbsp;</h4>
<ul>
<li><span style="font-size: 16px">双分支结构带来 ​<strong>​+3.8 AP​</strong>​ 提升</span></li>
<li><span style="font-size: 16px">单全连接层比双全连接层节省 ​<strong>​30%​</strong>​ 参数</span></li>
<li><span style="font-size: 16px">速度下降在可接受范围内（4.9 FPS → 实时性仍较好）</span></li>
</ul>
<h4><span style="font-size: 16px"><strong>&nbsp;</strong></span></h4>
<p>&nbsp;</p>
<p><span style="font-size: 16px">大致模拟代码：</span></p>
<p>&nbsp;</p>
<div class="cnblogs_code">
<pre><span style="font-size: 16px"><span style="color: rgba(0, 0, 0, 1)">import torch
import torch.nn </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> nn
import torch.nn.functional </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> F

</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> PANetMaskHead(nn.Module):
    def __init__(self, in_channels</span>=<span style="color: rgba(128, 0, 128, 1)">256</span>, num_classes=<span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">):
        super().__init__()
        
        # </span>----------------- 主分支 -----------------<span style="color: rgba(0, 0, 0, 1)">
        self.main_branch </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Conv2d(in_channels, </span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),  # 从此层分叉
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.ConvTranspose2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">2</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),  # 上采样2倍
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, num_classes, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 类别相关掩膜
        )
        
        # </span>----------------- 全连接融合分支 -----------------<span style="color: rgba(0, 0, 0, 1)">
        self.fc_branch </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            # 从第3个卷积层分叉输入（in_channels</span>=<span style="color: rgba(128, 0, 128, 1)">256</span><span style="color: rgba(0, 0, 0, 1)">）
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">128</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">128</span>, <span style="color: rgba(128, 0, 128, 1)">64</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Flatten(),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">64</span> * <span style="color: rgba(128, 0, 128, 1)">14</span> * <span style="color: rgba(128, 0, 128, 1)">14</span>, <span style="color: rgba(128, 0, 128, 1)">28</span> * <span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">),  # 仅一个全连接层
            nn.Unflatten(</span><span style="color: rgba(128, 0, 128, 1)">1</span>, (<span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(128, 0, 128, 1)">28</span>, <span style="color: rgba(128, 0, 128, 1)">28</span>)) # Reshape为[N,<span style="color: rgba(128, 0, 128, 1)">1</span>,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        )
        
        # </span>----------------- 融合后处理 -----------------<span style="color: rgba(0, 0, 0, 1)">
        self.sigmoid </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sigmoid()

    def forward(self, x):
        # 主分支前向
        main_out </span>= self.main_branch(x)  # [N,C,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 全连接分支前向
        fc_out </span>= self.fc_branch(x)      # [N,<span style="color: rgba(128, 0, 128, 1)">1</span>,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 特征融合与输出
        fused </span>= main_out +<span style="color: rgba(0, 0, 0, 1)"> fc_out       # 逐元素相加
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> self.sigmoid(fused)      # [N,C,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span>]</span></pre>
</div>
<h3><span style="font-size: 16px">总结</span></h3>
<p><span style="font-size: 16px">通过双分支结构实现了：</span></p>
<ol>
<li><span style="font-size: 16px">​<strong>​局部-全局特征互补​</strong>​：FCN分支捕捉细节，全连接分支整合语义</span></li>
<li><span style="font-size: 16px">​<strong>​参数效率优化​</strong>​：单全连接层平衡性能与计算成本</span></li>
<li><span style="font-size: 16px">​<strong>​多类别支持​</strong>​：每个类别独立预测掩膜</span></li>
</ol>
<p><span style="font-size: 16px">这种设计使得 PANet 在实例分割任务中实现了 SOTA 性能，也为后续的 Mask2Former 等模型提供了重要参考。实际部署时可通过 TensorRT 量化进一步优化推理速度。</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h4>&nbsp;</h4>
<h4><span style="font-size: 14pt">四、关键实验结果（COCO数据集）</span></h4>
<div class="hyc-common-markdown__table-wrapper">
<table>
<thead>
<tr><th><span style="font-size: 16px">方法</span></th><th><span style="font-size: 16px">mAP</span></th><th><span style="font-size: 16px">AP_small</span></th><th><span style="font-size: 16px">AP_medium</span></th><th><span style="font-size: 16px">AP_large</span></th></tr>
</thead>
<tbody>
<tr>
<td><span style="font-size: 16px">FPN（Baseline）</span></td>
<td><span style="font-size: 16px">36.2</span></td>
<td><span style="font-size: 16px">18.2</span></td>
<td><span style="font-size: 16px">39.0</span></td>
<td><span style="font-size: 16px">48.2</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">PANet</span></td>
<td><span style="font-size: 16px">41.2</span></td>
<td><span style="font-size: 16px">23.8</span></td>
<td><span style="font-size: 16px">44.3</span></td>
<td><span style="font-size: 16px">52.5</span></td>
</tr>
<tr>
<td><span style="font-size: 16px">​<strong>​提升幅度​</strong>​</span></td>
<td><span style="font-size: 16px">+5.0</span></td>
<td><span style="font-size: 16px">+5.6</span></td>
<td><span style="font-size: 16px">+5.3</span></td>
<td><span style="font-size: 16px">+4.3</span></td>
</tr>
</tbody>
</table>
</div>
<p><span style="font-size: 16px">​<strong>​结论​</strong>​：</span></p>
<ul>
<li><span style="font-size: 16px">小目标检测（AP_small）提升最显著（+5.6）</span></li>
<li><span style="font-size: 16px">所有尺度目标均有明显提升</span></li>
</ul>
<h4><span style="font-size: 14pt">五、PANet的拓展应用</span></h4>
<ol>
<li>​<strong>​实例分割​</strong>​<br>
在Mask R-CNN基础上集成PANet，边界精度提升3.4%。</li>
<li>​<strong>​实时检测​</strong>​<br>
与轻量级主干（如MobileNetV3）结合，在1080Ti上达到32 FPS。</li>
<li>​<strong>​跨领域适配​</strong>​<br>
在医疗影像（细胞检测）、遥感图像中表现优异。</li>








</ol>
<h4><span style="font-size: 14pt">六、总结：PANet的核心贡献</span></h4>
<ol>
<li><span style="font-size: 16px">​<strong>​双向特征融合​</strong>​：</span><br><span style="font-size: 16px">
同时保留高层语义与低层定位信息，解决特征金字塔的“信息隔离”问题。</span></li>
<li><span style="font-size: 16px">​<strong>​动态特征选择​</strong>​：</span><br><span style="font-size: 16px">
根据目标尺寸自适应选择特征层级，提升多尺度检测鲁棒性。</span></li>
<li><span style="font-size: 16px">​<strong>​简单高效​</strong>​：</span><br><span style="font-size: 16px">
仅增加约15%计算量，却能带来5%以上的mAP提升。</span></li>








</ol>
<p><span style="font-size: 16px">PANet的设计理念启发了后续许多工作（如NAS-FPN、BiFPN），成为目标检测领域的重要里程碑。</span></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><span style="font-size: 16px">本文模拟虚拟数据pytorch实现PANet实例代码（可直接复制运行---------少了MASK掩膜分割部分，有兴趣的自己实现一下加进去）:</span></p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250417232137476-445543455.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1)"># 导入必要的库
import torch
import torch.nn </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> nn
import torch.nn.functional </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> F
</span><span style="color: rgba(0, 0, 255, 1)">from</span><span style="color: rgba(0, 0, 0, 1)"> torchvision.ops import RoIAlign  # ROI对齐操作

# </span>-------------------- 设备配置 --------------------<span style="color: rgba(0, 0, 0, 1)">
# 检测可用设备，优先使用GPU
device </span>= torch.device(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cuda</span><span style="color: rgba(128, 0, 0, 1)">"</span> <span style="color: rgba(0, 0, 255, 1)">if</span> torch.cuda.is_available() <span style="color: rgba(0, 0, 255, 1)">else</span> <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cpu</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)

# </span>-------------------- 数据预处理 --------------------<span style="color: rgba(0, 0, 0, 1)">
# 自定义数据整理函数，用于处理包含字典的批次数据
def coco_collate(batch):
    </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">处理包含字典的批次数据</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
    images </span>= [item[<span style="color: rgba(128, 0, 128, 1)">0</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> item <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> batch]  # 提取所有图像
    targets </span>= [item[<span style="color: rgba(128, 0, 128, 1)">1</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> item <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> batch]  # 提取所有标注数据
    </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> torch.stack(images), targets  # 将图像堆叠为张量，保持标注为列表

# 虚拟COCO数据集生成器（带归一化）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> FakeCOCODataset(torch.utils.data.Dataset):
    def __init__(self, num_samples</span>=<span style="color: rgba(128, 0, 128, 1)">100</span><span style="color: rgba(0, 0, 0, 1)">):
        self.num_samples </span>=<span style="color: rgba(0, 0, 0, 1)"> num_samples  # 样本数量
        self.classes </span>= <span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">  # COCO数据集类别数
        self.img_size </span>= <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">  # 图像尺寸
    
    def __len__(self):
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> self.num_samples  # 返回数据集大小
    
    def __getitem__(self, idx):
        # 生成虚拟图像 [</span><span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>]，值范围[<span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]
        # 生成3通道的随机图像张量，模拟512x512大小的图片（值范围[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]）
        # 形状：(</span><span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>) -&gt;<span style="color: rgba(0, 0, 0, 1)"> [channels, height, width]
        img </span>= torch.rand(<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">, self.img_size, self.img_size)

        # 生成5个边界框的元数据
        num_boxes </span>= <span style="color: rgba(128, 0, 128, 1)">5</span><span style="color: rgba(0, 0, 0, 1)">  # 每张图片生成5个随机框

        # 生成边界框中心坐标（归一化比例）
        # torch.rand生成[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span>)均匀分布，*<span style="color: rgba(128, 0, 128, 1)">0.8</span>+<span style="color: rgba(128, 0, 128, 1)">0</span>.1后范围[<span style="color: rgba(128, 0, 128, 1)">0.1</span>,<span style="color: rgba(128, 0, 128, 1)">0.9</span><span style="color: rgba(0, 0, 0, 1)">)
        # 示例结果：tensor([[</span><span style="color: rgba(128, 0, 128, 1)">0.3</span>, <span style="color: rgba(128, 0, 128, 1)">0.7</span>], [<span style="color: rgba(128, 0, 128, 1)">0.5</span>,<span style="color: rgba(128, 0, 128, 1)">0.5</span><span style="color: rgba(0, 0, 0, 1)">], ...])（5行2列）
        centers </span>= torch.rand(num_boxes, <span style="color: rgba(128, 0, 128, 1)">2</span>) * <span style="color: rgba(128, 0, 128, 1)">0.8</span> + <span style="color: rgba(128, 0, 128, 1)">0.1</span><span style="color: rgba(0, 0, 0, 1)">

        # 生成边界框尺寸（归一化比例）
        # 范围[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">0.3</span>)，确保最大尺寸不超过图像的30%<span style="color: rgba(0, 0, 0, 1)">
        # 示例结果：tensor([[</span><span style="color: rgba(128, 0, 128, 1)">0.2</span>, <span style="color: rgba(128, 0, 128, 1)">0.15</span>], [<span style="color: rgba(128, 0, 128, 1)">0.25</span>,<span style="color: rgba(128, 0, 128, 1)">0.1</span><span style="color: rgba(0, 0, 0, 1)">], ...])
        sizes </span>= torch.rand(num_boxes, <span style="color: rgba(128, 0, 128, 1)">2</span>) * <span style="color: rgba(128, 0, 128, 1)">0.3</span><span style="color: rgba(0, 0, 0, 1)">

        # 初始化边界框容器（xyxy格式）
        # 创建形状为[</span><span style="color: rgba(128, 0, 128, 1)">5</span>,<span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">]的全零张量
        boxes </span>= torch.zeros(num_boxes, <span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)

        # 计算左上角坐标（x1,y1）
        # (中心x </span>- 宽度/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> 图像尺寸 → 实际像素坐标
        # 示例：中心x</span>=<span style="color: rgba(128, 0, 128, 1)">0.3</span>，宽度=<span style="color: rgba(128, 0, 128, 1)">0.2</span> → (<span style="color: rgba(128, 0, 128, 1)">0.3</span>-<span style="color: rgba(128, 0, 128, 1)">0.1</span>)=<span style="color: rgba(128, 0, 128, 1)">0.2</span> → <span style="color: rgba(128, 0, 128, 1)">0.2</span> * <span style="color: rgba(128, 0, 128, 1)">512</span>=<span style="color: rgba(128, 0, 128, 1)">102.4</span><span style="color: rgba(0, 0, 0, 1)">
        boxes[:, </span><span style="color: rgba(128, 0, 128, 1)">0</span>:<span style="color: rgba(128, 0, 128, 1)">2</span>] = (centers - sizes/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> self.img_size

        # 计算右下角坐标（x2,y2）
        # (中心x </span>+ 宽度/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> 图像尺寸 → 实际像素坐标
        # 示例：中心x</span>=<span style="color: rgba(128, 0, 128, 1)">0.3</span>，宽度=<span style="color: rgba(128, 0, 128, 1)">0.2</span> → (<span style="color: rgba(128, 0, 128, 1)">0.3</span>+<span style="color: rgba(128, 0, 128, 1)">0.1</span>)=<span style="color: rgba(128, 0, 128, 1)">0.4</span> → <span style="color: rgba(128, 0, 128, 1)">0.4</span> * <span style="color: rgba(128, 0, 128, 1)">512</span>=<span style="color: rgba(128, 0, 128, 1)">204.8</span><span style="color: rgba(0, 0, 0, 1)">
        boxes[:, </span><span style="color: rgba(128, 0, 128, 1)">2</span>:<span style="color: rgba(128, 0, 128, 1)">4</span>] = (centers + sizes/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> self.img_size

        # 坐标边界约束（防止越界）
        # 将坐标限制在[</span><span style="color: rgba(128, 0, 128, 1)">0</span>, <span style="color: rgba(128, 0, 128, 1)">511</span>]范围内（假设img_size=<span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">）
        # 示例：若计算结果为</span>-<span style="color: rgba(128, 0, 128, 1)">10</span><span style="color: rgba(0, 0, 0, 1)"> → 修正为0，若520 → 修正为511
        boxes </span>= boxes.clamp(<span style="color: rgba(128, 0, 128, 1)">0</span>, self.img_size-<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)

        # 归一化处理（用于回归任务）
        # 将像素坐标转换为[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]范围内的比例
        # 示例：x1</span>=<span style="color: rgba(128, 0, 128, 1)">102.4</span> → <span style="color: rgba(128, 0, 128, 1)">102.4</span>/<span style="color: rgba(128, 0, 128, 1)">512</span>=<span style="color: rgba(128, 0, 128, 1)">0.2</span><span style="color: rgba(0, 0, 0, 1)">
        norm_boxes </span>= boxes /<span style="color: rgba(0, 0, 0, 1)"> self.img_size

        # 生成随机类别标签（假设classes</span>=<span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">）
        # 生成1</span>-79的整数（不包括80），形状[<span style="color: rgba(128, 0, 128, 1)">5</span><span style="color: rgba(0, 0, 0, 1)">,]
        # 示例结果：tensor([</span><span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">45</span>, <span style="color: rgba(128, 0, 128, 1)">23</span>, <span style="color: rgba(128, 0, 128, 1)">67</span>, <span style="color: rgba(128, 0, 128, 1)">12</span><span style="color: rgba(0, 0, 0, 1)">])
        labels </span>= torch.randint(<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">, self.classes, (num_boxes,))
                
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> img, {
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">: boxes,      # 原始坐标用于RoIAlign
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">norm_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">: norm_boxes, # 归一化坐标用于训练
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">: labels
        }

# </span>-------------------- 模型组件 --------------------<span style="color: rgba(0, 0, 0, 1)">
# Bottleneck模块（ResNet基础块）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> Bottleneck(nn.Module):
    expansion </span>= <span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">  # 输出通道扩展倍数
    
    def __init__(self, in_planes, planes, stride</span>=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">):
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        参数：
            in_planes: 输入通道数
            planes: 中间层通道数
            stride: 卷积步长
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        super().__init__()
        # 1x1卷积降维
        self.conv1 </span>= nn.Conv2d(in_planes, planes, <span style="color: rgba(128, 0, 128, 1)">1</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn1 </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.BatchNorm2d(planes)
        # 3x3卷积
        self.conv2 </span>= nn.Conv2d(planes, planes, <span style="color: rgba(128, 0, 128, 1)">3</span>, stride, padding=<span style="color: rgba(128, 0, 128, 1)">1</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn2 </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.BatchNorm2d(planes)
        # 1x1卷积升维
        self.conv3 </span>= nn.Conv2d(planes, planes*self.expansion, <span style="color: rgba(128, 0, 128, 1)">1</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn3 </span>= nn.BatchNorm2d(planes*<span style="color: rgba(0, 0, 0, 1)">self.expansion)

        # 快捷连接（当维度不匹配时）
        self.shortcut </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential()
        </span><span style="color: rgba(0, 0, 255, 1)">if</span> stride != <span style="color: rgba(128, 0, 128, 1)">1</span> or in_planes != self.expansion*<span style="color: rgba(0, 0, 0, 1)">planes:
            self.shortcut </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
                nn.Conv2d(in_planes, self.expansion</span>*planes, <span style="color: rgba(128, 0, 128, 1)">1</span>, stride, bias=<span style="color: rgba(0, 0, 0, 1)">False),
                nn.BatchNorm2d(self.expansion</span>*<span style="color: rgba(0, 0, 0, 1)">planes)
            )
            
        # 参数初始化（He初始化） nn.init.kaiming_normal_（）函数</span>--<span style="color: rgba(0, 0, 0, 1)">  避免引起一些梯度爆炸问题（初始参数太大或者太小之类的） 
        # 参考博客：https:</span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">blog.csdn.net/m0_48241022/article/details/137057738</span>
        nn.init.kaiming_normal_(self.conv1.weight, mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
        nn.init.kaiming_normal_(self.conv2.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
        nn.init.kaiming_normal_(self.conv3.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def forward(self, x):
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> = F.relu(self.bn1(self.conv1(x)))  # 卷积+BN+<span style="color: rgba(0, 0, 0, 1)">ReLU
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> = F.relu(self.bn2(self.conv2(<span style="color: rgba(0, 0, 255, 1)">out</span><span style="color: rgba(0, 0, 0, 1)">)))
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> = self.bn3(self.conv3(<span style="color: rgba(0, 0, 255, 1)">out</span><span style="color: rgba(0, 0, 0, 1)">))  # 最后一个BN前不加ReLU
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> +=<span style="color: rgba(0, 0, 0, 1)"> self.shortcut(x)  # 残差连接
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> F.relu(<span style="color: rgba(0, 0, 255, 1)">out</span><span style="color: rgba(0, 0, 0, 1)">)  # 合并后激活

# 特征金字塔网络（FPN）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> FPN(nn.Module):
    def __init__(self, block, num_blocks):
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        参数：
            block: 基础块类型（Bottleneck）
            num_blocks: 各层block数量（如ResNet50的[</span><span style="color: rgba(128, 0, 128, 1)">3</span>,<span style="color: rgba(128, 0, 128, 1)">4</span>,<span style="color: rgba(128, 0, 128, 1)">6</span>,<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">]）
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        super().__init__()
        self.in_planes </span>= <span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">  # 初始通道数
        
        # 初始卷积层（模仿ResNet）
        self.conv1 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">64</span>, <span style="color: rgba(128, 0, 128, 1)">7</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">3</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn1 </span>= nn.BatchNorm2d(<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">)
        self.maxpool </span>= nn.MaxPool2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span>)  # <span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(0, 0, 0, 1)">4下采样
        
        # 构建残差层（C2</span>-<span style="color: rgba(0, 0, 0, 1)">C5）
        self.layer1 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">64</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">0</span>], <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)   # C2
        self.layer2 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">128</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">1</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)  # C3
        self.layer3 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">256</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">2</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">) # C4
        self.layer4 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">512</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">3</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">) # C5
        
        # 特征金字塔横向连接（1x1卷积降维）
        self.toplayer </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">2048</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)   # 处理C5
        self.latlayer1 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">1024</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 处理C4
        self.latlayer2 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)    # 处理C3
        self.latlayer3 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)    # 处理C2
        
        # 权重参数初始化 
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> m <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> [self.toplayer, self.latlayer1, self.latlayer2, self.latlayer3]:
            nn.init.kaiming_normal_(m.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def _make_layer(self, block, planes, num_blocks, stride):
        </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">构建残差层</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
        layers </span>=<span style="color: rgba(0, 0, 0, 1)"> [block(self.in_planes, planes, stride)]  # 第一个block的stride如果大于1，可能有下采样
        self.in_planes </span>= planes *<span style="color: rgba(0, 0, 0, 1)"> block.expansion  # 更新输入通道数
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> _ <span style="color: rgba(0, 0, 255, 1)">in</span> range(<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">, num_blocks):
            layers.append(block(self.in_planes, planes, </span><span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">))  # 后续block无下采样

        </span><span style="color: rgba(128, 0, 0, 1)">'''</span><span style="color: rgba(128, 0, 0, 1)">最终结构：假如第一个stride为2自带下采样，后面为1正常输出：Sequential(</span>
                    Bottleneck1(<span style="color: rgba(128, 0, 128, 1)">256</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck2(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck3(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck4(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)
                        )</span><span style="color: rgba(128, 0, 0, 1)">'''
</span>        <span style="color: rgba(0, 0, 255, 1)">return</span> nn.Sequential(*<span style="color: rgba(0, 0, 0, 1)">layers)
    

    def _upsample_add(self, x, y):
        </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">上采样并相加（特征融合）</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
        # 使用双线性插值上采样到y的尺寸再加上y进行特征融合
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> F.interpolate(x, size=y.shape[<span style="color: rgba(128, 0, 128, 1)">2</span>:], mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">bilinear</span><span style="color: rgba(128, 0, 0, 1)">'</span>) +<span style="color: rgba(0, 0, 0, 1)"> y

    def forward(self, x):
        # 自底向上路径
        c1 </span>= F.relu(self.bn1(self.conv1(x)))  # [B,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">256</span><span style="color: rgba(0, 0, 0, 1)">]
        c1 </span>= self.maxpool(c1)  # [B,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        
        c2 </span>= self.layer1(c1)   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">] (C2)
        c3 </span>= self.layer2(c2)   # [B,<span style="color: rgba(128, 0, 128, 1)">512</span>,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">]   (C3)
        c4 </span>= self.layer3(c3)    # [B,<span style="color: rgba(128, 0, 128, 1)">1024</span>,<span style="color: rgba(128, 0, 128, 1)">32</span>,<span style="color: rgba(128, 0, 128, 1)">32</span><span style="color: rgba(0, 0, 0, 1)">]  (C4)
        c5 </span>= self.layer4(c4)    # [B,<span style="color: rgba(128, 0, 128, 1)">2048</span>,<span style="color: rgba(128, 0, 128, 1)">16</span>,<span style="color: rgba(128, 0, 128, 1)">16</span><span style="color: rgba(0, 0, 0, 1)">] (C5)
        
        # 自顶向下路径（特征金字塔构建）
        p5 </span>= self.toplayer(c5)               # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">16</span>,<span style="color: rgba(128, 0, 128, 1)">16</span><span style="color: rgba(0, 0, 0, 1)">]
        p4 </span>= self._upsample_add(p5, self.latlayer1(c4))  # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">32</span>,<span style="color: rgba(128, 0, 128, 1)">32</span><span style="color: rgba(0, 0, 0, 1)">]   self.latlayer代表连接层，将数据连接过来
        p3 </span>= self._upsample_add(p4, self.latlayer2(c3))   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">]
        p2 </span>= self._upsample_add(p3, self.latlayer3(c2))   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> p2, p3, p4, p5

# 自底向上增强路径（PANet核心） N2</span>--<span style="color: rgba(0, 0, 0, 1)">N5
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> BottomUpPath(nn.Module):
    def __init__(self):
        super().__init__()
        # 横向连接卷积（特征融合）  创建个卷积List,存放四个卷积层
        self.lat_conv </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.ModuleList([
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span>) <span style="color: rgba(0, 0, 255, 1)">for</span> _ <span style="color: rgba(0, 0, 255, 1)">in</span> range(<span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)  # 每个金字塔层级一个卷积
        ])
        self.downsample </span>= nn.MaxPool2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 2倍下采样
        
        # 参数初始化
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> conv <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> self.lat_conv:
            nn.init.kaiming_normal_(conv.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def forward(self, features):
        p2, p3, p4, p5 </span>= features  # 来自FPN的特征  FPN将自己每层的数据传输过来经过1*<span style="color: rgba(0, 0, 0, 1)">1的卷积归一化通道数目后与降采样的数据直接相加完成特征连接
        
        # 自底向上增强路径（通过下采样和横向连接）
        n2 </span>= self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">0</span>](p2)                   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        n3 </span>= self.downsample(n2) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">](p3)  # 下采样后相加
        n4 </span>= self.downsample(n3) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">](p4)
        n5 </span>= self.downsample(n4) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">](p5)
        
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> [n2, n3, n4, n5]

# PANet完整网络
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> PANet(nn.Module):
    def __init__(self, num_classes</span>=<span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">):
        super().__init__()
        # 特征金字塔网络（基于ResNet50的FPN）
        self.fpn </span>= FPN(Bottleneck, [<span style="color: rgba(128, 0, 128, 1)">3</span>,<span style="color: rgba(128, 0, 128, 1)">4</span>,<span style="color: rgba(128, 0, 128, 1)">6</span>,<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">])  # ResNet50结构
        
        # 自底向上增强路径
        self.bottom_up </span>=<span style="color: rgba(0, 0, 0, 1)"> BottomUpPath()
        
        # ROI Align配置（不同层级的空间尺度） 自适应特征池化：对每个候选区域，在每个特征层上进行ROI Align池化，然后将不同层的特征图进行最大值融合
        self.roi_align </span>=<span style="color: rgba(0, 0, 0, 1)"> {
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p2</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">4</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span>),  # <span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(0, 0, 0, 1)">4尺寸
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p3</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">8</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p4</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">16</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p5</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">32</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)
        }
        </span><span style="color: rgba(128, 0, 0, 1)">'''</span><span style="color: rgba(128, 0, 0, 1)"> RoIAlign与RoIPool的区别 参考博客：https://www.cnblogs.com/xiaochouk/p/15912972.html</span>
<span style="color: rgba(0, 0, 0, 1)">            RoIAlign与传统的RoIPool（区域兴趣池化）的主要区别在于处理边界的方式。
            RoIPool在进行池化操作时会对边界进行量化处理，这会导致精度损失。
            而RoIAlign则通过保持边界框内的采样点为浮点数坐标，
            并进行双线性插值来计算每个采样点的值，从而减少了量化误差，提高了精度。</span><span style="color: rgba(128, 0, 0, 1)">'''
</span><span style="color: rgba(0, 0, 0, 1)">        # 分类头
        self.cls_head </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span>, <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">),  # ROI特征展平后输入
            nn.ReLU(),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">, num_classes)   # 输出类别分数
        )
        # 回归头
        self.reg_head </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span>, <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)  # 输出边界框偏移量  偏移量x,y,w,h
        )
        
        # 参数初始化（Xavier初始化）
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> head <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> [self.cls_head, self.reg_head]:
            </span><span style="color: rgba(0, 0, 255, 1)">for</span> m <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> head.modules():
                </span><span style="color: rgba(0, 0, 255, 1)">if</span><span style="color: rgba(0, 0, 0, 1)"> isinstance(m, nn.Linear):
                    nn.init.normal_(m.weight, mean</span>=<span style="color: rgba(128, 0, 128, 1)">0</span>, std=<span style="color: rgba(128, 0, 128, 1)">0.01</span><span style="color: rgba(0, 0, 0, 1)">)  # 小随机数初始化
                    nn.init.constant_(m.bias, </span><span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">)  # 偏置初始化为0

    def forward(self, x, proposals):
        # 特征提取
        p2, p3, p4, p5 </span>=<span style="color: rgba(0, 0, 0, 1)"> self.fpn(x)  # FPN输出四个阶段，也可以理解为四层的数据
        
        # 自底向上增强路径处理  将FPN的数据经过自底向上增强路径融合连接后得到n2, n3, n4, n5
        n2, n3, n4, n5 </span>=<span style="color: rgba(0, 0, 0, 1)"> self.bottom_up([p2, p3, p4, p5])
        
        # 之后再进行特征融合（FPN与自底向上路径相加）多层级融合​​：每个尺度都获得全局</span>+<span style="color: rgba(0, 0, 0, 1)">局部信息
        # N2</span>-N5 路径存在的意义主要传递的是增强后的定位信息  而P2-<span style="color: rgba(0, 0, 0, 1)">P5才是原有的丰富语义信息 
        # 高层的C5特征经过多次卷积和下采样，已丢失细节但捕获了​​全局语义​​（如</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">这是一只狗</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">）。
        # 通过自顶向下的上采样路径，这些语义信息被传递到所有P层。
        # 虽然C2</span>-C5本身包含多尺度信息，但低层的C2-<span style="color: rgba(0, 0, 0, 1)">C4主要是​​局部细节​​（边缘、纹理）。
        # 横向连接到对应P层（1x1卷积）只能做通道对齐，无法直接增强语义。
        # N2（P2级） → 下采样 → N3 → 下采样 → N4 → 下采样 → N5   
        # 低层特征（N2</span>-<span style="color: rgba(0, 0, 0, 1)">N3）携带​​精确位置信息​​（如物体边缘）通过路径传递，修正高层特征的定位误差 
        # P5​​可能检测到</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">狗在图像某处</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)"> N5​​结合低层细节后，能更准确定位狗的具体位置 
        # P5 </span>+<span style="color: rgba(0, 0, 0, 1)"> N5​​：增强高层语义的定位能力 
        # P2 </span>+<span style="color: rgba(0, 0, 0, 1)"> N2​​：为细节层补充语义理解   
        pan_features </span>=<span style="color: rgba(0, 0, 0, 1)"> [
            p2 </span>+<span style="color: rgba(0, 0, 0, 1)"> n2,  # 增强后的P2特征
            p3 </span>+<span style="color: rgba(0, 0, 0, 1)"> n3,
            p4 </span>+<span style="color: rgba(0, 0, 0, 1)"> n4,
            p5 </span>+<span style="color: rgba(0, 0, 0, 1)"> n5
        ]
        
        # 然后进入 多层级ROI Align池化
        pooled </span>=<span style="color: rgba(0, 0, 0, 1)"> []
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> feat, name <span style="color: rgba(0, 0, 255, 1)">in</span> zip(pan_features, [<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p2</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p3</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p4</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p5</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]):
            # 对每个层级的特征进行ROI Align
            pooled.append(self.roi_align[name](feat, proposals))
            
        # 特征融合（取各层级最大值）
        fused </span>= torch.max(torch.stack(pooled), dim=<span style="color: rgba(128, 0, 128, 1)">0</span>)[<span style="color: rgba(128, 0, 128, 1)">0</span>]  # [N,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">7</span>,<span style="color: rgba(128, 0, 128, 1)">7</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 展平特征用于全连接层
        flattened </span>= fused.flatten(<span style="color: rgba(128, 0, 128, 1)">1</span>)  # [N, <span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 预测输出
        cls_logits </span>=<span style="color: rgba(0, 0, 0, 1)"> self.cls_head(flattened)  # 分类分数
        reg_preds </span>=<span style="color: rgba(0, 0, 0, 1)"> self.reg_head(flattened)   # 回归偏移量
        
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> cls_logits, reg_preds

# </span>-------------------- 训练验证代码 --------------------
<span style="color: rgba(0, 0, 255, 1)">if</span> __name__ == <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">__main__</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">:
    # 超参数设置
    batch_size </span>= <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">
    num_epochs </span>= <span style="color: rgba(128, 0, 128, 1)">5</span><span style="color: rgba(0, 0, 0, 1)">
    num_classes </span>= <span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">
    
    # 数据加载
    dataset </span>=<span style="color: rgba(0, 0, 0, 1)"> FakeCOCODataset()
    dataloader </span>=<span style="color: rgba(0, 0, 0, 1)"> torch.utils.data.DataLoader(
        dataset,
        batch_size</span>=<span style="color: rgba(0, 0, 0, 1)">batch_size,
        collate_fn</span>=<span style="color: rgba(0, 0, 0, 1)">coco_collate  # 使用自定义整理函数
    )
    
    # 模型初始化并转移到设备
    model </span>=<span style="color: rgba(0, 0, 0, 1)"> PANet(num_classes).to(device)
    
    # 优化器（Adam优化器）
    optimizer </span>= torch.optim.Adam(model.parameters(), lr=<span style="color: rgba(128, 0, 128, 1)">0.001</span><span style="color: rgba(0, 0, 0, 1)">)
    
    # 损失函数
    cls_criterion </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.CrossEntropyLoss().to(device)  # 分类损失
    reg_criterion </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.SmoothL1Loss().to(device)     # 回归损失（对异常值更鲁棒）

    # 训练循环
    </span><span style="color: rgba(0, 0, 255, 1)">for</span> epoch <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> range(num_epochs):
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> batch_idx, (images, targets) <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> enumerate(dataloader):
            # 数据转移到设备
            images </span>=<span style="color: rgba(0, 0, 0, 1)"> images.to(device)
            
            # 生成proposals（将标注框作为候选框）
            proposals </span>=<span style="color: rgba(0, 0, 0, 1)"> []
            </span><span style="color: rgba(0, 0, 255, 1)">for</span> i, t <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> enumerate(targets):
                # 构造proposal格式：[batch_index, x1, y1, x2, y2]
                batch_indices </span>= torch.full((len(t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span>]),<span style="color: rgba(128, 0, 128, 1)">1</span>), i, device=<span style="color: rgba(0, 0, 0, 1)">device)
                raw_boxes </span>= t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">].to(device)
                proposal </span>= torch.cat([batch_indices, raw_boxes], dim=<span style="color: rgba(128, 0, 128, 1)">1</span>).<span style="color: rgba(0, 0, 255, 1)">float</span><span style="color: rgba(0, 0, 0, 1)">()
                proposals.append(proposal)
                
            proposals_tensor </span>= torch.cat(proposals, dim=<span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">)  # 合并所有proposals
            
            # 前向传播
            cls_out, reg_out </span>=<span style="color: rgba(0, 0, 0, 1)"> model(images, proposals_tensor)
            
            # 准备标签数据
            gt_labels </span>= torch.cat([t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">'</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span> targets]).<span style="color: rgba(0, 0, 255, 1)">long</span><span style="color: rgba(0, 0, 0, 1)">().to(device)
            gt_boxes </span>= torch.cat([t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">norm_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> targets]).to(device)
            
            # 计算损失
            cls_loss </span>=<span style="color: rgba(0, 0, 0, 1)"> cls_criterion(cls_out, gt_labels)
            reg_loss </span>=<span style="color: rgba(0, 0, 0, 1)"> reg_criterion(reg_out, gt_boxes)
            total_loss </span>= cls_loss +<span style="color: rgba(0, 0, 0, 1)"> reg_loss  # 总损失为两者之和
            
            # 反向传播与优化
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
            
            # 每10个batch打印日志
            </span><span style="color: rgba(0, 0, 255, 1)">if</span> batch_idx % <span style="color: rgba(128, 0, 128, 1)">10</span> == <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">:
                print(f</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx}/{len(dataloader)}]</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
                print(f</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">分类损失: {cls_loss.item():.4f} 回归损失: {reg_loss.item():.4f}</span><span style="color: rgba(128, 0, 0, 1)">'</span>)</pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>增加了mask分割后的代码 分类损失和掩膜损失有点问题(有兴趣的话 帮我找一下问题在哪里)：</p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/1251892/202504/1251892-20250418004640382-136036035.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1)"># 导入必要的库
import torch
import torch.nn </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> nn
import torch.nn.functional </span><span style="color: rgba(0, 0, 255, 1)">as</span><span style="color: rgba(0, 0, 0, 1)"> F
</span><span style="color: rgba(0, 0, 255, 1)">from</span><span style="color: rgba(0, 0, 0, 1)"> torchvision.ops import RoIAlign  # ROI对齐操作

# </span>-------------------- 设备配置 --------------------<span style="color: rgba(0, 0, 0, 1)">
# 检测可用设备，优先使用GPU
device </span>= torch.device(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cuda</span><span style="color: rgba(128, 0, 0, 1)">"</span> <span style="color: rgba(0, 0, 255, 1)">if</span> torch.cuda.is_available() <span style="color: rgba(0, 0, 255, 1)">else</span> <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cpu</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)

# </span>-------------------- 数据预处理 --------------------<span style="color: rgba(0, 0, 0, 1)">
# 自定义数据整理函数，用于处理包含字典的批次数据
def coco_collate(batch):
    </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">处理包含字典的批次数据</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
    images </span>= [item[<span style="color: rgba(128, 0, 128, 1)">0</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> item <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> batch]  # 提取所有图像
    targets </span>= [item[<span style="color: rgba(128, 0, 128, 1)">1</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> item <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> batch]  # 提取所有标注数据



    # 需要合并所有需要批量处理的数据
    collated </span>=<span style="color: rgba(0, 0, 0, 1)"> {
        </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">masks</span><span style="color: rgba(128, 0, 0, 1)">'</span>: torch.cat([t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">masks</span><span style="color: rgba(128, 0, 0, 1)">'</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span> targets]),  # [N,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span>: [t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> targets],      # 保持列表结构
        </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">norm_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span>: [t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">norm_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> targets],
        </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">'</span>: [t[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">'</span>] <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> targets]
    }
    </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> torch.stack(images), collated

# 虚拟COCO数据集生成器（带归一化）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> FakeCOCODataset(torch.utils.data.Dataset):
    def __init__(self, num_samples</span>=<span style="color: rgba(128, 0, 128, 1)">100</span><span style="color: rgba(0, 0, 0, 1)">):
        self.num_samples </span>=<span style="color: rgba(0, 0, 0, 1)"> num_samples  # 样本数量
        self.classes </span>= <span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">  # COCO数据集类别数
        self.img_size </span>= <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">  # 图像尺寸
    
    def __len__(self):
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> self.num_samples  # 返回数据集大小
    
    def __getitem__(self, idx):
        # 生成虚拟图像 [</span><span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>]，值范围[<span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]
        # 生成3通道的随机图像张量，模拟512x512大小的图片（值范围[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]）
        # 形状：(</span><span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">512</span>) -&gt;<span style="color: rgba(0, 0, 0, 1)"> [channels, height, width]
        img </span>= torch.rand(<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">, self.img_size, self.img_size)

        # 生成5个边界框的元数据
        num_boxes </span>= <span style="color: rgba(128, 0, 128, 1)">5</span><span style="color: rgba(0, 0, 0, 1)">  # 每张图片生成5个随机框

        # 生成边界框中心坐标（归一化比例）
        # torch.rand生成[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span>)均匀分布，*<span style="color: rgba(128, 0, 128, 1)">0.8</span>+<span style="color: rgba(128, 0, 128, 1)">0</span>.1后范围[<span style="color: rgba(128, 0, 128, 1)">0.1</span>,<span style="color: rgba(128, 0, 128, 1)">0.9</span><span style="color: rgba(0, 0, 0, 1)">)
        # 示例结果：tensor([[</span><span style="color: rgba(128, 0, 128, 1)">0.3</span>, <span style="color: rgba(128, 0, 128, 1)">0.7</span>], [<span style="color: rgba(128, 0, 128, 1)">0.5</span>,<span style="color: rgba(128, 0, 128, 1)">0.5</span><span style="color: rgba(0, 0, 0, 1)">], ...])（5行2列）
        centers </span>= torch.rand(num_boxes, <span style="color: rgba(128, 0, 128, 1)">2</span>) * <span style="color: rgba(128, 0, 128, 1)">0.8</span> + <span style="color: rgba(128, 0, 128, 1)">0.1</span><span style="color: rgba(0, 0, 0, 1)">

        # 生成边界框尺寸（归一化比例）
        # 范围[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">0.3</span>)，确保最大尺寸不超过图像的30%<span style="color: rgba(0, 0, 0, 1)">
        # 示例结果：tensor([[</span><span style="color: rgba(128, 0, 128, 1)">0.2</span>, <span style="color: rgba(128, 0, 128, 1)">0.15</span>], [<span style="color: rgba(128, 0, 128, 1)">0.25</span>,<span style="color: rgba(128, 0, 128, 1)">0.1</span><span style="color: rgba(0, 0, 0, 1)">], ...])
        sizes </span>= torch.rand(num_boxes, <span style="color: rgba(128, 0, 128, 1)">2</span>) * <span style="color: rgba(128, 0, 128, 1)">0.3</span><span style="color: rgba(0, 0, 0, 1)">

        # 初始化边界框容器（xyxy格式）
        # 创建形状为[</span><span style="color: rgba(128, 0, 128, 1)">5</span>,<span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">]的全零张量
        boxes </span>= torch.zeros(num_boxes, <span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)

        # 计算左上角坐标（x1,y1）
        # (中心x </span>- 宽度/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> 图像尺寸 → 实际像素坐标
        # 示例：中心x</span>=<span style="color: rgba(128, 0, 128, 1)">0.3</span>，宽度=<span style="color: rgba(128, 0, 128, 1)">0.2</span> → (<span style="color: rgba(128, 0, 128, 1)">0.3</span>-<span style="color: rgba(128, 0, 128, 1)">0.1</span>)=<span style="color: rgba(128, 0, 128, 1)">0.2</span> → <span style="color: rgba(128, 0, 128, 1)">0.2</span> * <span style="color: rgba(128, 0, 128, 1)">512</span>=<span style="color: rgba(128, 0, 128, 1)">102.4</span><span style="color: rgba(0, 0, 0, 1)">
        boxes[:, </span><span style="color: rgba(128, 0, 128, 1)">0</span>:<span style="color: rgba(128, 0, 128, 1)">2</span>] = (centers - sizes/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> self.img_size

        # 计算右下角坐标（x2,y2）
        # (中心x </span>+ 宽度/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> 图像尺寸 → 实际像素坐标
        # 示例：中心x</span>=<span style="color: rgba(128, 0, 128, 1)">0.3</span>，宽度=<span style="color: rgba(128, 0, 128, 1)">0.2</span> → (<span style="color: rgba(128, 0, 128, 1)">0.3</span>+<span style="color: rgba(128, 0, 128, 1)">0.1</span>)=<span style="color: rgba(128, 0, 128, 1)">0.4</span> → <span style="color: rgba(128, 0, 128, 1)">0.4</span> * <span style="color: rgba(128, 0, 128, 1)">512</span>=<span style="color: rgba(128, 0, 128, 1)">204.8</span><span style="color: rgba(0, 0, 0, 1)">
        boxes[:, </span><span style="color: rgba(128, 0, 128, 1)">2</span>:<span style="color: rgba(128, 0, 128, 1)">4</span>] = (centers + sizes/<span style="color: rgba(128, 0, 128, 1)">2</span>) *<span style="color: rgba(0, 0, 0, 1)"> self.img_size

        # 坐标边界约束（防止越界）
        # 将坐标限制在[</span><span style="color: rgba(128, 0, 128, 1)">0</span>, <span style="color: rgba(128, 0, 128, 1)">511</span>]范围内（假设img_size=<span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">）
        # 示例：若计算结果为</span>-<span style="color: rgba(128, 0, 128, 1)">10</span><span style="color: rgba(0, 0, 0, 1)"> → 修正为0，若520 → 修正为511
        boxes </span>= boxes.clamp(<span style="color: rgba(128, 0, 128, 1)">0</span>, self.img_size-<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)

        # 归一化处理（用于回归任务）
        # 将像素坐标转换为[</span><span style="color: rgba(128, 0, 128, 1)">0</span>,<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">]范围内的比例
        # 示例：x1</span>=<span style="color: rgba(128, 0, 128, 1)">102.4</span> → <span style="color: rgba(128, 0, 128, 1)">102.4</span>/<span style="color: rgba(128, 0, 128, 1)">512</span>=<span style="color: rgba(128, 0, 128, 1)">0.2</span><span style="color: rgba(0, 0, 0, 1)">
        norm_boxes </span>= boxes /<span style="color: rgba(0, 0, 0, 1)"> self.img_size

        # 生成随机类别标签（假设classes</span>=<span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">）
        # 生成1</span>-79的整数（不包括80），形状[<span style="color: rgba(128, 0, 128, 1)">5</span><span style="color: rgba(0, 0, 0, 1)">,]
        # 示例结果：tensor([</span><span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">45</span>, <span style="color: rgba(128, 0, 128, 1)">23</span>, <span style="color: rgba(128, 0, 128, 1)">67</span>, <span style="color: rgba(128, 0, 128, 1)">12</span><span style="color: rgba(0, 0, 0, 1)">])
        labels </span>= torch.randint(<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">, self.classes, (num_boxes,))
                
        #  生成有意义掩膜标签（基于边界框）
        masks </span>=<span style="color: rgba(0, 0, 0, 1)"> []
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> box <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> boxes:
            # 创建全零矩阵
            mask </span>=<span style="color: rgba(0, 0, 0, 1)"> torch.zeros(self.img_size, self.img_size)
            x1, y1, x2, y2 </span>= box.<span style="color: rgba(0, 0, 255, 1)">int</span><span style="color: rgba(0, 0, 0, 1)">()
            mask[y1:y2, x1:x2] </span>= <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">  # 边界框内为1
            masks.append(mask)
            


        # 修复维度处理
        masks_tensor </span>= torch.stack(masks)  # [<span style="color: rgba(128, 0, 128, 1)">5</span>,<span style="color: rgba(128, 0, 128, 1)">512</span>,<span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">]
        small_masks </span>=<span style="color: rgba(0, 0, 0, 1)"> F.interpolate(
            masks_tensor.unsqueeze(</span><span style="color: rgba(128, 0, 128, 1)">1</span>),  # 添加通道维度 [<span style="color: rgba(128, 0, 128, 1)">5</span>,<span style="color: rgba(128, 0, 128, 1)">1</span>,<span style="color: rgba(128, 0, 128, 1)">512</span>,<span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">]
            size</span>=<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">,
            mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">nearest</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">
        ).squeeze(</span><span style="color: rgba(128, 0, 128, 1)">1</span>)  # 下采样后移除通道维度 [<span style="color: rgba(128, 0, 128, 1)">5</span>,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> img, {
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">: boxes,       # 保持每个样本的原始结构
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">norm_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">: norm_boxes,
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">: labels,
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">masks</span><span style="color: rgba(128, 0, 0, 1)">'</span>: small_masks      # [<span style="color: rgba(128, 0, 128, 1)">5</span>,<span style="color: rgba(128, 0, 128, 1)">28</span>,<span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        }

# </span>-------------------- 模型组件 --------------------<span style="color: rgba(0, 0, 0, 1)">
# Bottleneck模块（ResNet基础块）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> Bottleneck(nn.Module):
    expansion </span>= <span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">  # 输出通道扩展倍数
    
    def __init__(self, in_planes, planes, stride</span>=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">):
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        参数：
            in_planes: 输入通道数
            planes: 中间层通道数
            stride: 卷积步长
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        super().__init__()
        # 1x1卷积降维
        self.conv1 </span>= nn.Conv2d(in_planes, planes, <span style="color: rgba(128, 0, 128, 1)">1</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn1 </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.BatchNorm2d(planes)
        # 3x3卷积
        self.conv2 </span>= nn.Conv2d(planes, planes, <span style="color: rgba(128, 0, 128, 1)">3</span>, stride, padding=<span style="color: rgba(128, 0, 128, 1)">1</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn2 </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.BatchNorm2d(planes)
        # 1x1卷积升维
        self.conv3 </span>= nn.Conv2d(planes, planes*self.expansion, <span style="color: rgba(128, 0, 128, 1)">1</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn3 </span>= nn.BatchNorm2d(planes*<span style="color: rgba(0, 0, 0, 1)">self.expansion)

        # 快捷连接（当维度不匹配时）
        self.shortcut </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential()
        </span><span style="color: rgba(0, 0, 255, 1)">if</span> stride != <span style="color: rgba(128, 0, 128, 1)">1</span> or in_planes != self.expansion*<span style="color: rgba(0, 0, 0, 1)">planes:
            self.shortcut </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
                nn.Conv2d(in_planes, self.expansion</span>*planes, <span style="color: rgba(128, 0, 128, 1)">1</span>, stride, bias=<span style="color: rgba(0, 0, 0, 1)">False),
                nn.BatchNorm2d(self.expansion</span>*<span style="color: rgba(0, 0, 0, 1)">planes)
            )
            
        # 参数初始化（He初始化） nn.init.kaiming_normal_（）函数</span>--<span style="color: rgba(0, 0, 0, 1)">  避免引起一些梯度爆炸问题（初始参数太大或者太小之类的） 
        # 参考博客：https:</span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">blog.csdn.net/m0_48241022/article/details/137057738</span>
        nn.init.kaiming_normal_(self.conv1.weight, mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
        nn.init.kaiming_normal_(self.conv2.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
        nn.init.kaiming_normal_(self.conv3.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def forward(self, x):
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> = F.relu(self.bn1(self.conv1(x)))  # 卷积+BN+<span style="color: rgba(0, 0, 0, 1)">ReLU
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> = F.relu(self.bn2(self.conv2(<span style="color: rgba(0, 0, 255, 1)">out</span><span style="color: rgba(0, 0, 0, 1)">)))
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> = self.bn3(self.conv3(<span style="color: rgba(0, 0, 255, 1)">out</span><span style="color: rgba(0, 0, 0, 1)">))  # 最后一个BN前不加ReLU
        </span><span style="color: rgba(0, 0, 255, 1)">out</span> +=<span style="color: rgba(0, 0, 0, 1)"> self.shortcut(x)  # 残差连接
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> F.relu(<span style="color: rgba(0, 0, 255, 1)">out</span><span style="color: rgba(0, 0, 0, 1)">)  # 合并后激活

# 特征金字塔网络（FPN）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> FPN(nn.Module):
    def __init__(self, block, num_blocks):
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        参数：
            block: 基础块类型（Bottleneck）
            num_blocks: 各层block数量（如ResNet50的[</span><span style="color: rgba(128, 0, 128, 1)">3</span>,<span style="color: rgba(128, 0, 128, 1)">4</span>,<span style="color: rgba(128, 0, 128, 1)">6</span>,<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">]）
        </span><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">        super().__init__()
        self.in_planes </span>= <span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">  # 初始通道数
        
        # 初始卷积层（模仿ResNet）
        self.conv1 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">64</span>, <span style="color: rgba(128, 0, 128, 1)">7</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">3</span>, bias=<span style="color: rgba(0, 0, 0, 1)">False)
        self.bn1 </span>= nn.BatchNorm2d(<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">)
        self.maxpool </span>= nn.MaxPool2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span>)  # <span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(0, 0, 0, 1)">4下采样
        
        # 构建残差层（C2</span>-<span style="color: rgba(0, 0, 0, 1)">C5）
        self.layer1 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">64</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">0</span>], <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)   # C2
        self.layer2 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">128</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">1</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)  # C3
        self.layer3 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">256</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">2</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">) # C4
        self.layer4 </span>= self._make_layer(block, <span style="color: rgba(128, 0, 128, 1)">512</span>, num_blocks[<span style="color: rgba(128, 0, 128, 1)">3</span>], <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">) # C5
        
        # 特征金字塔横向连接（1x1卷积降维）
        self.toplayer </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">2048</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)   # 处理C5
        self.latlayer1 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">1024</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 处理C4
        self.latlayer2 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)    # 处理C3
        self.latlayer3 </span>= nn.Conv2d(<span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)    # 处理C2
        
        # 权重参数初始化 
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> m <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> [self.toplayer, self.latlayer1, self.latlayer2, self.latlayer3]:
            nn.init.kaiming_normal_(m.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def _make_layer(self, block, planes, num_blocks, stride):
        </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">构建残差层</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
        layers </span>=<span style="color: rgba(0, 0, 0, 1)"> [block(self.in_planes, planes, stride)]  # 第一个block的stride如果大于1，可能有下采样
        self.in_planes </span>= planes *<span style="color: rgba(0, 0, 0, 1)"> block.expansion  # 更新输入通道数
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> _ <span style="color: rgba(0, 0, 255, 1)">in</span> range(<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">, num_blocks):
            layers.append(block(self.in_planes, planes, </span><span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">))  # 后续block无下采样

        </span><span style="color: rgba(128, 0, 0, 1)">'''</span><span style="color: rgba(128, 0, 0, 1)">最终结构：假如第一个stride为2自带下采样，后面为1正常输出：Sequential(</span>
                    Bottleneck1(<span style="color: rgba(128, 0, 128, 1)">256</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck2(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck3(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
                    Bottleneck4(</span><span style="color: rgba(128, 0, 128, 1)">512</span>-&gt;<span style="color: rgba(128, 0, 128, 1)">512</span>, stride=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)
                        )</span><span style="color: rgba(128, 0, 0, 1)">'''
</span>        <span style="color: rgba(0, 0, 255, 1)">return</span> nn.Sequential(*<span style="color: rgba(0, 0, 0, 1)">layers)
    

    def _upsample_add(self, x, y):
        </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">上采样并相加（特征融合）</span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
        # 使用双线性插值上采样到y的尺寸再加上y进行特征融合
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> F.interpolate(x, size=y.shape[<span style="color: rgba(128, 0, 128, 1)">2</span>:], mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">bilinear</span><span style="color: rgba(128, 0, 0, 1)">'</span>) +<span style="color: rgba(0, 0, 0, 1)"> y

    def forward(self, x):
        # 自底向上路径
        c1 </span>= F.relu(self.bn1(self.conv1(x)))  # [B,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">256</span><span style="color: rgba(0, 0, 0, 1)">]
        c1 </span>= self.maxpool(c1)  # [B,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        
        c2 </span>= self.layer1(c1)   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">] (C2)
        c3 </span>= self.layer2(c2)   # [B,<span style="color: rgba(128, 0, 128, 1)">512</span>,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">]   (C3)
        c4 </span>= self.layer3(c3)    # [B,<span style="color: rgba(128, 0, 128, 1)">1024</span>,<span style="color: rgba(128, 0, 128, 1)">32</span>,<span style="color: rgba(128, 0, 128, 1)">32</span><span style="color: rgba(0, 0, 0, 1)">]  (C4)
        c5 </span>= self.layer4(c4)    # [B,<span style="color: rgba(128, 0, 128, 1)">2048</span>,<span style="color: rgba(128, 0, 128, 1)">16</span>,<span style="color: rgba(128, 0, 128, 1)">16</span><span style="color: rgba(0, 0, 0, 1)">] (C5)
        
        # 自顶向下路径（特征金字塔构建）
        p5 </span>= self.toplayer(c5)               # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">16</span>,<span style="color: rgba(128, 0, 128, 1)">16</span><span style="color: rgba(0, 0, 0, 1)">]
        p4 </span>= self._upsample_add(p5, self.latlayer1(c4))  # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">32</span>,<span style="color: rgba(128, 0, 128, 1)">32</span><span style="color: rgba(0, 0, 0, 1)">]   self.latlayer代表连接层，将数据连接过来
        p3 </span>= self._upsample_add(p4, self.latlayer2(c3))   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">64</span>,<span style="color: rgba(128, 0, 128, 1)">64</span><span style="color: rgba(0, 0, 0, 1)">]
        p2 </span>= self._upsample_add(p3, self.latlayer3(c2))   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> p2, p3, p4, p5

# 自底向上增强路径（PANet核心） N2</span>--<span style="color: rgba(0, 0, 0, 1)">N5
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> BottomUpPath(nn.Module):
    def __init__(self):
        super().__init__()
        # 横向连接卷积（特征融合）  创建个卷积List,存放四个卷积层
        self.lat_conv </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.ModuleList([
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">1</span>) <span style="color: rgba(0, 0, 255, 1)">for</span> _ <span style="color: rgba(0, 0, 255, 1)">in</span> range(<span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)  # 每个金字塔层级一个卷积
        ])
        self.downsample </span>= nn.MaxPool2d(<span style="color: rgba(128, 0, 128, 1)">3</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 2倍下采样
        
        # 参数初始化
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> conv <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> self.lat_conv:
            nn.init.kaiming_normal_(conv.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)

    def forward(self, features):
        p2, p3, p4, p5 </span>= features  # 来自FPN的特征  FPN将自己每层的数据传输过来经过1 *<span style="color: rgba(0, 0, 0, 1)"> 1的卷积归一化通道数目后与降采样的数据直接相加完成特征连接
        
        # 自底向上增强路径（通过下采样和横向连接）
        n2 </span>= self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">0</span>](p2)                   # [B,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">128</span>,<span style="color: rgba(128, 0, 128, 1)">128</span><span style="color: rgba(0, 0, 0, 1)">]
        n3 </span>= self.downsample(n2) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">](p3)  # 下采样后相加
        n4 </span>= self.downsample(n3) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">](p4)
        n5 </span>= self.downsample(n4) + self.lat_conv[<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">](p5)
        
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> [n2, n3, n4, n5]

# 🆕 掩膜预测头（对应论文图1(e)）
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> MaskHead(nn.Module):
    def __init__(self, in_channels</span>=<span style="color: rgba(128, 0, 128, 1)">256</span>, num_classes=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">):
        super().__init__()
        # 主分支：4个3x3卷积 </span>+<span style="color: rgba(0, 0, 0, 1)"> 反卷积
        self.main_branch </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Conv2d(in_channels, </span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.ConvTranspose2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">2</span>, stride=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, num_classes, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)  # 输出通道数改为1
        )
        
        # 全连接融合分支
        self.fc_branch </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">128</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),  # 从主分支第三个卷积层分叉
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Conv2d(</span><span style="color: rgba(128, 0, 128, 1)">128</span>, <span style="color: rgba(128, 0, 128, 1)">64</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, padding=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(inplace</span>=<span style="color: rgba(0, 0, 0, 1)">True),
            nn.Flatten(),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">64</span> * <span style="color: rgba(128, 0, 128, 1)">14</span> * <span style="color: rgba(128, 0, 128, 1)">14</span>, <span style="color: rgba(128, 0, 128, 1)">28</span> * <span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">),       # 单全连接层保持空间结构
            nn.Unflatten(</span><span style="color: rgba(128, 0, 128, 1)">1</span>, (<span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(128, 0, 128, 1)">28</span>, <span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">))       # 重塑为空间特征
        )
        
        self.sigmoid </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sigmoid()

        </span><span style="color: rgba(0, 0, 255, 1)">for</span> m <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> self.modules():
            </span><span style="color: rgba(0, 0, 255, 1)">if</span><span style="color: rgba(0, 0, 0, 1)"> isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode</span>=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">fan_out</span><span style="color: rgba(128, 0, 0, 1)">'</span>, nonlinearity=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">relu</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, </span><span style="color: rgba(128, 0, 128, 1)">0</span>, <span style="color: rgba(128, 0, 128, 1)">0.01</span><span style="color: rgba(0, 0, 0, 1)">)
                nn.init.constant_(m.bias, </span><span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">)

    def forward(self, x):
        # 主分支前向
        main_out </span>= self.main_branch(x)  # [N, C, <span style="color: rgba(128, 0, 128, 1)">28</span>, <span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 全连接分支前向
        fc_out </span>= self.fc_branch(x)      # [N, <span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(128, 0, 128, 1)">28</span>, <span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 特征融合与输出
        fused </span>= main_out +<span style="color: rgba(0, 0, 0, 1)"> fc_out       # 逐元素相加
        </span><span style="color: rgba(0, 0, 255, 1)">return</span> self.sigmoid(fused)      # [N, C, <span style="color: rgba(128, 0, 128, 1)">28</span>, <span style="color: rgba(128, 0, 128, 1)">28</span><span style="color: rgba(0, 0, 0, 1)">]

# PANet完整网络
</span><span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> PANet(nn.Module):
    def __init__(self, num_classes</span>=<span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">):
        super().__init__()
        # 特征金字塔网络（基于ResNet50的FPN）
        self.fpn </span>= FPN(Bottleneck, [<span style="color: rgba(128, 0, 128, 1)">3</span>,<span style="color: rgba(128, 0, 128, 1)">4</span>,<span style="color: rgba(128, 0, 128, 1)">6</span>,<span style="color: rgba(128, 0, 128, 1)">3</span><span style="color: rgba(0, 0, 0, 1)">])  # ResNet50结构
        
        # 自底向上增强路径
        self.bottom_up </span>=<span style="color: rgba(0, 0, 0, 1)"> BottomUpPath()
        
        # ROI Align配置（不同层级的空间尺度） 自适应特征池化：对每个候选区域，在每个特征层上进行ROI Align池化，然后将不同层的特征图进行最大值融合
        self.roi_align </span>=<span style="color: rgba(0, 0, 0, 1)"> {
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p2</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">4</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span>),  # <span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(0, 0, 0, 1)">4尺寸
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p3</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">8</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p4</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">16</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">),
            </span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p5</span><span style="color: rgba(128, 0, 0, 1)">'</span>: RoIAlign(<span style="color: rgba(128, 0, 128, 1)">7</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">32</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)
        }
        </span><span style="color: rgba(128, 0, 0, 1)">'''</span><span style="color: rgba(128, 0, 0, 1)"> RoIAlign与RoIPool的区别 参考博客：https://www.cnblogs.com/xiaochouk/p/15912972.html</span>
<span style="color: rgba(0, 0, 0, 1)">            RoIAlign与传统的RoIPool（区域兴趣池化）的主要区别在于处理边界的方式。
            RoIPool在进行池化操作时会对边界进行量化处理，这会导致精度损失。
            而RoIAlign则通过保持边界框内的采样点为浮点数坐标，
            并进行双线性插值来计算每个采样点的值，从而减少了量化误差，提高了精度。</span><span style="color: rgba(128, 0, 0, 1)">'''
</span>        self.mask_roi_align = RoIAlign(<span style="color: rgba(128, 0, 128, 1)">14</span>, spatial_scale=<span style="color: rgba(128, 0, 128, 1)">1</span>/<span style="color: rgba(128, 0, 128, 1)">4</span>., sampling_ratio=<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">)
        # 🆕 添加掩膜预测头
        self.mask_head </span>= MaskHead(num_classes=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)
        
        # 分类头
        self.cls_head </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span>, <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">),  # ROI特征展平后输入
            nn.ReLU(),
            nn.Dropout(</span><span style="color: rgba(128, 0, 128, 1)">0.5</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">, num_classes)   # 输出类别分数
        )
        # 回归头
        self.reg_head </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span>, <span style="color: rgba(128, 0, 128, 1)">512</span><span style="color: rgba(0, 0, 0, 1)">),
            nn.ReLU(),
            nn.Linear(</span><span style="color: rgba(128, 0, 128, 1)">512</span>, <span style="color: rgba(128, 0, 128, 1)">4</span><span style="color: rgba(0, 0, 0, 1)">)  # 输出边界框偏移量  偏移量x,y,w,h
        )
        
        # 参数初始化（Xavier初始化）
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> head <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> [self.cls_head, self.reg_head]:
            </span><span style="color: rgba(0, 0, 255, 1)">for</span> m <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> head.modules():
                </span><span style="color: rgba(0, 0, 255, 1)">if</span><span style="color: rgba(0, 0, 0, 1)"> isinstance(m, nn.Linear):
                    nn.init.normal_(m.weight, mean</span>=<span style="color: rgba(128, 0, 128, 1)">0</span>, std=<span style="color: rgba(128, 0, 128, 1)">0.01</span><span style="color: rgba(0, 0, 0, 1)">)  # 小随机数初始化
                    nn.init.constant_(m.bias, </span><span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">)  # 偏置初始化为0

    def forward(self, x, proposals):
        # 特征提取
        p2, p3, p4, p5 </span>=<span style="color: rgba(0, 0, 0, 1)"> self.fpn(x)  # FPN输出四个阶段，也可以理解为四层的数据
        
        # 自底向上增强路径处理  将FPN的数据经过自底向上增强路径融合连接后得到n2, n3, n4, n5
        n2, n3, n4, n5 </span>=<span style="color: rgba(0, 0, 0, 1)"> self.bottom_up([p2, p3, p4, p5])
        
        # 之后再进行特征融合（FPN与自底向上路径相加）多层级融合：每个尺度都获得全局</span>+<span style="color: rgba(0, 0, 0, 1)">局部信息
        # N2</span>-N5 路径存在的意义主要传递的是增强后的定位信息  而P2-<span style="color: rgba(0, 0, 0, 1)">P5才是原有的丰富语义信息 
        # 高层的C5特征经过多次卷积和下采样，已丢失细节但捕获了全局语义（如</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">这是一只狗</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">）。
        # 通过自顶向下的上采样路径，这些语义信息被传递到所有P层。
        # 虽然C2</span>-C5本身包含多尺度信息，但低层的C2-<span style="color: rgba(0, 0, 0, 1)">C4主要是局部细节（边缘、纹理）。
        # 横向连接到对应P层（1x1卷积）只能做通道对齐，无法直接增强语义。
        # N2（P2级） → 下采样 → N3 → 下采样 → N4 → 下采样 → N5   
        # 低层特征（N2</span>-<span style="color: rgba(0, 0, 0, 1)">N3）携带精确位置信息（如物体边缘）通过路径传递，修正高层特征的定位误差 
        # P5可能检测到</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">狗在图像某处</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)"> N5结合低层细节后，能更准确定位狗的具体位置 
        # P5 </span>+<span style="color: rgba(0, 0, 0, 1)"> N5：增强高层语义的定位能力 
        # P2 </span>+<span style="color: rgba(0, 0, 0, 1)"> N2：为细节层补充语义理解   
        pan_features </span>=<span style="color: rgba(0, 0, 0, 1)"> [
            p2 </span>+<span style="color: rgba(0, 0, 0, 1)"> n2,  # 增强后的P2特征
            p3 </span>+<span style="color: rgba(0, 0, 0, 1)"> n3,
            p4 </span>+<span style="color: rgba(0, 0, 0, 1)"> n4,
            p5 </span>+<span style="color: rgba(0, 0, 0, 1)"> n5
        ]
        
        # 然后进入 多层级ROI Align池化
        pooled </span>=<span style="color: rgba(0, 0, 0, 1)"> []
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> feat, name <span style="color: rgba(0, 0, 255, 1)">in</span> zip(pan_features, [<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p2</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p3</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p4</span><span style="color: rgba(128, 0, 0, 1)">'</span>,<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">p5</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]):
            # 对每个层级的特征进行ROI Align
            pooled.append(self.roi_align[name](feat, proposals))
            
        # 特征融合（取各层级最大值）
        fused </span>= torch.max(torch.stack(pooled), dim=<span style="color: rgba(128, 0, 128, 1)">0</span>)[<span style="color: rgba(128, 0, 128, 1)">0</span>]  # [N,<span style="color: rgba(128, 0, 128, 1)">256</span>,<span style="color: rgba(128, 0, 128, 1)">7</span>,<span style="color: rgba(128, 0, 128, 1)">7</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 🆕 掩膜预测分支
        mask_rois </span>= [self.mask_roi_align(pan_features[<span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">], proposals)]  # 使用14x14的ROI Align
        mask_feat </span>= torch.cat(mask_rois, dim=<span style="color: rgba(128, 0, 128, 1)">0</span>)  # [N, <span style="color: rgba(128, 0, 128, 1)">256</span>, <span style="color: rgba(128, 0, 128, 1)">14</span>, <span style="color: rgba(128, 0, 128, 1)">14</span><span style="color: rgba(0, 0, 0, 1)">]
        mask_pred </span>=<span style="color: rgba(0, 0, 0, 1)"> self.mask_head(mask_feat)
        
        # 展平特征用于全连接层
        flattened </span>= fused.flatten(<span style="color: rgba(128, 0, 128, 1)">1</span>)  # [N, <span style="color: rgba(128, 0, 128, 1)">256</span> * <span style="color: rgba(128, 0, 128, 1)">7</span> * <span style="color: rgba(128, 0, 128, 1)">7</span><span style="color: rgba(0, 0, 0, 1)">]
        
        # 预测输出
        cls_logits </span>=<span style="color: rgba(0, 0, 0, 1)"> self.cls_head(flattened)  # 分类分数
        reg_preds </span>=<span style="color: rgba(0, 0, 0, 1)"> self.reg_head(flattened)   # 回归偏移量
        
        # 🆕 返回新增的掩膜预测结果
        </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> cls_logits, reg_preds, mask_pred

# </span>-------------------- 训练验证代码 --------------------
<span style="color: rgba(0, 0, 255, 1)">if</span> __name__ == <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">__main__</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">:
    # 超参数设置
    batch_size </span>= <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">
    num_epochs </span>= <span style="color: rgba(128, 0, 128, 1)">5</span><span style="color: rgba(0, 0, 0, 1)">
    num_classes </span>= <span style="color: rgba(128, 0, 128, 1)">80</span><span style="color: rgba(0, 0, 0, 1)">
    
    # 数据加载
    dataset </span>=<span style="color: rgba(0, 0, 0, 1)"> FakeCOCODataset()
    dataloader </span>=<span style="color: rgba(0, 0, 0, 1)"> torch.utils.data.DataLoader(
        dataset,
        batch_size</span>=<span style="color: rgba(0, 0, 0, 1)">batch_size,
        collate_fn</span>=<span style="color: rgba(0, 0, 0, 1)">coco_collate  # 使用自定义整理函数
    )
    
    # 模型初始化并转移到设备
    model </span>=<span style="color: rgba(0, 0, 0, 1)"> PANet(num_classes).to(device)
    
    # 修改优化器配置（添加学习率衰减）
    optimizer </span>= torch.optim.Adam(model.parameters(), lr=<span style="color: rgba(128, 0, 128, 1)">0.001</span><span style="color: rgba(0, 0, 0, 1)">)
    scheduler </span>= torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span style="color: rgba(128, 0, 128, 1)">3</span>, gamma=<span style="color: rgba(128, 0, 128, 1)">0.1</span><span style="color: rgba(0, 0, 0, 1)">)
    
    # 损失函数
    cls_criterion </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.CrossEntropyLoss().to(device)  # 分类损失
    reg_criterion </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.SmoothL1Loss().to(device)     # 回归损失（对异常值更鲁棒）
    #  添加掩膜损失（二元交叉熵）
    mask_criterion </span>=<span style="color: rgba(0, 0, 0, 1)"> nn.BCELoss().to(device)

    # 训练循环
    </span><span style="color: rgba(0, 0, 255, 1)">for</span> epoch <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> range(num_epochs):
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> batch_idx, (images, collated) <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> enumerate(dataloader):
           
            proposals </span>=<span style="color: rgba(0, 0, 0, 1)"> []
            </span><span style="color: rgba(0, 0, 255, 1)">for</span> i <span style="color: rgba(0, 0, 255, 1)">in</span> range(len(collated[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">])):
                raw_boxes </span>= collated[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">raw_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">][i].to(device)  # 从collated获取数据
                batch_indices </span>= torch.full((len(raw_boxes),<span style="color: rgba(128, 0, 128, 1)">1</span>), i, device=<span style="color: rgba(0, 0, 0, 1)">device)
                proposals.append(torch.cat([batch_indices, raw_boxes], dim</span>=<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">))
            
            proposals_tensor </span>= torch.cat(proposals, dim=<span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">)
            # 前向传播
            cls_out, reg_out, mask_pred </span>=<span style="color: rgba(0, 0, 0, 1)"> model(images.to(device), proposals_tensor)
            
           # 准备标签数据
            gt_labels </span>= torch.cat(collated[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]).to(device)     # 直接从collated获取
            gt_boxes </span>= torch.cat(collated[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">norm_boxes</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]).to(device)
            gt_masks </span>= collated[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">masks</span><span style="color: rgba(128, 0, 0, 1)">'</span>].to(device).unsqueeze(<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">)      # 添加通道维度
                    
            # 计算损失
            cls_loss </span>=<span style="color: rgba(0, 0, 0, 1)"> cls_criterion(cls_out, gt_labels)
            reg_loss </span>=<span style="color: rgba(0, 0, 0, 1)"> reg_criterion(reg_out, gt_boxes)
            mask_loss </span>=<span style="color: rgba(0, 0, 0, 1)"> mask_criterion(mask_pred, gt_masks)
            total_loss </span>= cls_loss + reg_loss + <span style="color: rgba(128, 0, 128, 1)">2</span>*<span style="color: rgba(0, 0, 0, 1)">mask_loss
            
            # 反向传播
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
            
            
            # 每10个batch打印日志
            </span><span style="color: rgba(0, 0, 255, 1)">if</span> batch_idx % <span style="color: rgba(128, 0, 128, 1)">10</span> == <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">:
                print(f</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx}/{len(dataloader)}]</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
                print(f</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">分类损失: {cls_loss.item():.4f} 回归损失: {reg_loss.item():.4f} 掩膜损失: {mask_loss.item():.4f}</span><span style="color: rgba(128, 0, 0, 1)">'</span>)  # 🆕 添加掩膜损失显示</pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>参考博客：https://blog.csdn.net/a8039974/article/details/142340236</p>
<p>　　　　　https://cloud.tencent.com/developer/article/1592997</p>
<p>论文：https://arxiv.org/pdf/1803.01534</p>
</div>
<div id="MySignature" role="contentinfo">
    转发和使用本文，请注明作者信息和原文地址---本文原作者为aircraft

---大家好我是徐飞机，有没有大佬们的公司招c++开发/图像处理/opengl/opencv/halcon实习的啊，带上我一个呗QAQ。。。hhhhhh  想要免费获取前端，后端，c/c++,matlab，Python，opencv，机器学习，深度学习，安卓，java，等等全套视频教程请关注机器视觉开发公众号，转发集赞28即可百度云获得hhhhhhhh
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.029801157440972222" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-18 08:25">2025-04-17 23:18</span>&nbsp;
<a href="https://www.cnblogs.com/DOMLX">aircraft</a>&nbsp;
阅读(<span id="post_view_count">19</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18831868);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18831868', targetLink: 'https://www.cnblogs.com/DOMLX/p/18831868', title: 'pytorch 实战教程之路径聚合网络 PANet (Path Aggregation Network)代码实现            路径聚合网络PANet原理详解' })">举报</a>
</div>
        