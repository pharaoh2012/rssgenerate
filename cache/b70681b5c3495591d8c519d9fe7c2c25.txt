
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/1312mn/p/18729302" title="发布于 2025-02-25 10:21">
    <span role="heading" aria-level="2">C# 集成 DeepSeek 模型实现 AI 私有化（本地部署与 API 调用教程）</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h2 class="md-end-block md-heading"><span class="md-plain md-expand" style="font-size: 16px">前言</span></h2>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">自从 DeepSeek 大模型火了以来，网络上出现了许多关于本地部署的教程和方法。然而，要真正深入了解其功能和应用，还是需要自己动手进行一次本地部署。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">DeepSeek 作为一个高效的自然语言处理模型，其本地部署能力为大家提供了灵活的应用场景。不管是开发私有化的 AI 应用，还是集成到现有的系统中，DeepSeek 都能提供强大的支持。</span></p>
<p class="md-end-block md-p md-focus"><span class="md-plain md-expand" style="font-size: 16px">本文将详细介绍如何快速部署 DeepSeek 模型，并通过 C# 调用其 API 接口，从而搭建高效的私有 AI 服务。我们将从环境准备、本地部署、API 客户端配置到实际调用接口，完成整个过程。</span></p>
<h2 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">搭建基础环境</span></h2>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">Ollama 是一个轻量级AI模型运行框架，支持 macOS、Linux 和 Windows 跨平台运行，并兼容包括 Llama 3.3、DeepSeek-R1、Phi-4 和 Gemma 2 在内的 54 种主流开源模型。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">它简化了模型的下载、安装和使用过程，提供了统一的操作界面，能够方便地在本地环境中运行和测试不同的语言模型，简单的说就是相当于一个容器。</span></p>
<h3 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">1、安装 Ollama</span></h3>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">首先先下载 Ollama，进入官网，根据大家当前的操作系统选择安装包（Windows/Linux/macOS）。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">官网下载地址：<span class="md-link md-pair-s"><a href="https://ollama.com/download" rel="noopener nofollow">https://ollama.com/download</a></span></span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224162713920-1727065777.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">如上图所示点击 Download 下载安装包，然后直接安装就可以。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">注意：Ollama默认安装是在C盘的以及下载的大模型数据包也是默认在C盘，所以一定要注意自己C盘的存储空间够用，</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">当然我们也有方式改变他的安装路径的。如果不想折腾的可以直接点击安装就可以了。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">本文示例是修改了安装路径，具体步骤如下：</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">首先在目标路径（如 D:\Ollaman）创建一个新文件夹并放置 Ollama 安装包</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">然后在该路径下打开命令窗口并输入 OllamaSetup.exe /DIR=D:\Ollama，接着在安装界面点击 "Install"，即可将 Ollama 安装到指定目录，大模型数据包也会默认下载到该目录中。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224162807938-50852975.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">Ollama 安装好了就会自动启动。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">查看是否安装成功 Windows+R，输入CMD进入命令窗口，输入：ollama -v有版本号就说明安装好了，在任务栏右下角有个羊驼的图标。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224162830170-1699184926.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<h3 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">2、下载 DeepSeek R1 模型 </span></h3>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">在 Ollama 官网点击 Models，选择deepseek-r1</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224162909798-1775212850.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">选择对应的模型，可以看到模型的相信介绍、各种参数的模型。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224162930879-1438125611.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">普通用户：选择 8B 版本，适合日常对话、写作等</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">高性能显卡用户（显存 16GB 以上）：可选 16B 版本，体验更强大性能</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">各个版本模型对硬件要求，官方没有明确的说明，根据网友分享的大概整理如下，大家可以根据自己的电脑配置选择模型。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224162949507-77974559.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">选择要下载的模型，复制指令。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163010097-1604254265.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">打开命令窗口，粘贴运行指令。等待下载完成。下载过程中，会显示下载进度和速度等信息。由于模型文件较大，下载时间可能会较长，需要耐心等待。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163032389-125730732.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">至此，已经可以与DeepSeek进行会话。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">同时在浏览器访问：<span class="md-link md-pair-s"><a href="http://127.0.0.1:11434" rel="noopener nofollow">http://127.0.0.1:11434</a><span class="md-plain">，有如下提示也代表启动成功了。</span></span></span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163054869-706114047.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<h2 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">客户端 ChatBox AI接入 DeepSeek</span></h2>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">Chatbox AI 是一款 AI 客户端应用和智能助手，支持众多先进的 AI 模型和 API，可在 Windows、MacOS、Android、iOS、Linux 和网页版上使用。</span></p>
<h3 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">1、下载 ChatBox AI</span></h3>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">浏览器中访问 Chatbox AI的官方网站（<span class="md-link md-pair-s"><a href="https://chatboxai.app/zh" rel="noopener nofollow">https://chatboxai.app/zh</a><span class="md-plain">），下载安装。</span></span></span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163119553-1027575435.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<h3 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">2、配置环境变量</span></h3>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">添加两个环境变量，允许外部访问，填写：0.0.0.0，代表允许任何电脑访问。</span></p>
<div class="cnblogs_code">
<pre>OLLAMA_HOST：<span style="color: rgba(128, 0, 128, 1)">0.0</span>.<span style="color: rgba(128, 0, 128, 1)">0.0</span><span style="color: rgba(0, 0, 0, 1)">
OLLAMA_ORIGING：</span>*</pre>
</div>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">点击我的电脑，右键属性-&gt;高级系统设置-&gt;环境变量。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163154484-716000315.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">注意：设置完环境变量后退出一下 Ollama，然后重新启动下Ollama。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163215297-1959259392.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<h3 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">3、Chatbox AI 连接本地模型</span></h3>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">启动 Chatbox AI 软件，选择 Ollama API后，然后选择下载的 DeepSeek模型，如果大家还有其他模型也可以选择对应的模型。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163236909-461437010.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">模型设置</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">选择API类型：Ollama API</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">模型名称：deepseek-r1:8b</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">点击检查连接，如果状态正常，可以开始使用了。</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163304661-850154449.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">以上设置完成。我们就可以在客户端使用AI聊天了，</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163322951-1591498180.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<h2 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">C# 调用 DeepSeek API </span></h2>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">Ollama 还提供了 API 接口功能，使得自定义客户端开发或集成到应用系统变得非常方便。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">其相关生态系统也非常完善，使用 C# 版本的 Ollama SDK（如 OllamaSharp）可以快速进行开发。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">下面通过一个简单的例子来演示如何使用 Ollama：</span></p>
<h3 class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">1、安装依赖包</span></h3>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">首先，安装 OllamaSharp 依赖包：</span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163352748-1886317136.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<h3 class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">2、示例代码</span></h3>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">新建一个 OllamaApiExampleController控制器，添加如下代码：</span></p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 255, 1)">using</span><span style="color: rgba(0, 0, 0, 1)"> Microsoft.AspNetCore.Mvc;
</span><span style="color: rgba(0, 0, 255, 1)">using</span><span style="color: rgba(0, 0, 0, 1)"> Microsoft.Extensions.AI;
</span><span style="color: rgba(0, 0, 255, 1)">using</span><span style="color: rgba(0, 0, 0, 1)"> OllamaSharp;
​
</span><span style="color: rgba(0, 0, 255, 1)">namespace</span><span style="color: rgba(0, 0, 0, 1)"> DotNetCore.DeepSeekApi.Controllers
{
    </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;summary&gt;</span>
    <span style="color: rgba(128, 128, 128, 1)">///</span><span style="color: rgba(0, 128, 0, 1)"> OllamaApi示例控制器
    </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;/summary&gt;</span>
<span style="color: rgba(0, 0, 0, 1)">    [ApiController]
    [Route(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">api/[controller]</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)]
    </span><span style="color: rgba(0, 0, 255, 1)">public</span> <span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> OllamaApiExampleController : ControllerBase
    {
        </span><span style="color: rgba(0, 0, 255, 1)">private</span> <span style="color: rgba(0, 0, 255, 1)">readonly</span> Uri _modelEndpoint = <span style="color: rgba(0, 0, 255, 1)">new</span> Uri(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">http://localhost:11434</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">);
        </span><span style="color: rgba(0, 0, 255, 1)">private</span> <span style="color: rgba(0, 0, 255, 1)">readonly</span> <span style="color: rgba(0, 0, 255, 1)">string</span> _modelName = <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">deepseek-r1:1.5b</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">;
​
        </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;summary&gt;</span>
        <span style="color: rgba(128, 128, 128, 1)">///</span><span style="color: rgba(0, 128, 0, 1)"> 初始化
        </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;/summary&gt;</span>
        <span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;param name="httpClient"&gt;&lt;/param&gt;</span>
        <span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;param name="configuration"&gt;&lt;/param&gt;</span>
        <span style="color: rgba(0, 0, 255, 1)">public</span><span style="color: rgba(0, 0, 0, 1)"> OllamaApiExampleController(){}
​
        </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;summary&gt;</span>
        <span style="color: rgba(128, 128, 128, 1)">///</span><span style="color: rgba(0, 128, 0, 1)"> 提问接口
        </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;/summary&gt;</span>
        <span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;param name="request"&gt;&lt;/param&gt;</span>
        <span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;returns&gt;&lt;/returns&gt;</span>
        [HttpPost(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ask</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)]
        </span><span style="color: rgba(0, 0, 255, 1)">public</span> <span style="color: rgba(0, 0, 255, 1)">async</span> Task&lt;IActionResult&gt;<span style="color: rgba(0, 0, 0, 1)"> AskQuestion([FromBody] AskRequest request)
        {
            </span><span style="color: rgba(0, 0, 255, 1)">var</span> chatClient = <span style="color: rgba(0, 0, 255, 1)">new</span><span style="color: rgba(0, 0, 0, 1)"> OllamaApiClient(_modelEndpoint, _modelName);
            </span><span style="color: rgba(0, 0, 255, 1)">var</span> question =<span style="color: rgba(0, 0, 0, 1)"> request.Question;
​
            </span><span style="color: rgba(0, 0, 255, 1)">if</span> (<span style="color: rgba(0, 0, 255, 1)">string</span><span style="color: rgba(0, 0, 0, 1)">.IsNullOrEmpty(question))
            {
                </span><span style="color: rgba(0, 0, 255, 1)">return</span> BadRequest(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">请输入您的问题？</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">);
            }
            </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 使用 await foreach 遍历每个 ChatResponseUpdate</span>
            <span style="color: rgba(0, 0, 255, 1)">var</span> responseBuilder = <span style="color: rgba(0, 0, 255, 1)">new</span> List&lt;<span style="color: rgba(0, 0, 255, 1)">string</span>&gt;<span style="color: rgba(0, 0, 0, 1)">();
            </span><span style="color: rgba(0, 0, 255, 1)">await</span> <span style="color: rgba(0, 0, 255, 1)">foreach</span> (<span style="color: rgba(0, 0, 255, 1)">var</span> update <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> chatClient.GetStreamingResponseAsync(question))
            {
                responseBuilder.Add(update.ToString());
            }
            </span><span style="color: rgba(0, 0, 255, 1)">var</span> response = <span style="color: rgba(0, 0, 255, 1)">string</span>.Join(<span style="color: rgba(128, 0, 0, 1)">""</span><span style="color: rgba(0, 0, 0, 1)">, responseBuilder);
            </span><span style="color: rgba(0, 0, 255, 1)">return</span> Ok(<span style="color: rgba(0, 0, 255, 1)">new</span> { Response =<span style="color: rgba(0, 0, 0, 1)"> response });
        }
    }
​
    </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;summary&gt;</span>
    <span style="color: rgba(128, 128, 128, 1)">///</span><span style="color: rgba(0, 128, 0, 1)"> 实体类
    </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;/summary&gt;</span>
    <span style="color: rgba(0, 0, 255, 1)">public</span> <span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> AskRequest
    {
        </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;summary&gt;</span>
        <span style="color: rgba(128, 128, 128, 1)">///</span><span style="color: rgba(0, 128, 0, 1)"> 问题
        </span><span style="color: rgba(128, 128, 128, 1)">///</span> <span style="color: rgba(128, 128, 128, 1)">&lt;/summary&gt;</span>
        <span style="color: rgba(0, 0, 255, 1)">public</span> <span style="color: rgba(0, 0, 255, 1)">string</span> Question { <span style="color: rgba(0, 0, 255, 1)">get</span>; <span style="color: rgba(0, 0, 255, 1)">set</span><span style="color: rgba(0, 0, 0, 1)">; }
    }
}</span></pre>
</div>
<h3><span class="md-plain" style="font-size: 16px">3、运行结果</span></h3>
<p><img src="https://img2024.cnblogs.com/blog/576536/202502/576536-20250224163440979-1075119048.png" width="700" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">Ollama 相关的API接口，可以查看官方文档。</span></p>
<p class="md-end-block md-p"><span class="md-link md-pair-s" style="font-size: 16px"><a href="https://github.com/ollama/ollama/blob/main/docs/api.md" rel="noopener nofollow">https://github.com/ollama/ollama/blob/main/docs/api.md</a></span></p>
<h2 class="md-end-block md-heading"><span class="md-plain" style="font-size: 16px">总结</span></h2>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">通过本文简单的学习实现了DeepSeek 的本地部署和本地调用API接口。</span></p>
<p class="md-end-block md-p"><span class="md-plain" style="font-size: 16px">能够掌握 DeepSeek 的本地部署方法，还能学会如何在 C# 项目中集成并调用 DeepSeek 提供的强大功能。</span></p>
<p class="md-end-block md-p"><span class="md-plain md-expand" style="font-size: 16px">希望这些内容能够帮助大家在实际项目中顺利应用 DeepSeek，提升开发效率和项目质量。</span></p>
<h2><span class="md-plain md-expand" style="font-size: 16px">最后</span></h2>
<p><span style="font-size: 16px">如果你觉得这篇文章对你有帮助，不妨点个赞支持一下！你的支持是我继续分享知识的动力。如果有任何疑问或需要进一步的帮助，欢迎随时留言。</span></p>
<p><span style="font-size: 16px">也可以加入微信公众号<strong>[DotNet技术匠]</strong>&nbsp;社区，与其他热爱技术的同行一起交流心得，共同成长！<strong>优秀是一种习惯，欢迎大家留言学习！</strong></span></p>
<p><img src="https://img2024.cnblogs.com/blog/576536/202408/576536-20240814113403514-910171896.png" alt="" style="display: block; margin-left: auto; margin-right: auto"></p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="4.49915237531713" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-25 10:21">2025-02-25 10:21</span>&nbsp;
<a href="https://www.cnblogs.com/1312mn">小码编匠</a>&nbsp;
阅读(<span id="post_view_count">1562</span>)&nbsp;
评论(<span id="post_comment_count">1</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18729302" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18729302);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18729302', targetLink: 'https://www.cnblogs.com/1312mn/p/18729302', title: 'C# 集成 DeepSeek 模型实现 AI 私有化（本地部署与 API 调用教程）' })">举报</a>
</div>
        