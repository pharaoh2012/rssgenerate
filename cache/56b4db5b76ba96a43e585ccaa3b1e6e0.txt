
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/jinjiangongzuoshi/p/18710936" title="发布于 2025-02-12 09:27">
    <span role="heading" aria-level="2">自己如何在本地电脑从零搭建DeepSeek！手把手教学，快来看看！ (建议收藏)</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>在人工智能飞速发展的今天，大语言模型的应用越来越广泛。DeepSeek 作为近期爆火的一款大语言模型，受到了众多开发者的青睐。</p>
<p>今天这篇内容，就来聊聊，如何在本地自己的电脑上部署DeepSeek。</p>
<h3 id="1哪些场景适合将大模型部署在自己电脑上">1、哪些场景适合将大模型部署在自己电脑上？</h3>
<p><strong>先说结论：</strong> 虽说将大模型部署在自己的电脑上，有很多好处，但万不得已，并不推荐个人搞本地部署（钱多或企业除外）。对于普通用户来讲，只是日常简单的使用AI，直接使用市面上主流的云AI工具就足够了。</p>
<p>那在哪些情况下，需要或者适合将大模型（如DeepSeek）部署在自己的电脑上呢？</p>
<h4 id="1追求极致数据隐私与安全性">1、追求极致数据隐私与安全性</h4>
<ul>
<li>当处理高度敏感的数据，如医疗记录、商业机密或个人隐私信息时，将大模型部署在本地电脑，可确保数据不会传输到外部服务器，从根本上保障数据的安全性和隐私性。例如，医疗研究人员在分析患者的基因数据时，本地部署能避免数据泄露风险。</li>
<li><strong>保护敏感数据：</strong> 本地部署可以确保所有数据的处理和存储都在本地完成，不会上传到云端，从而有效避免数据在传输和云端存储过程中可能带来的隐私泄露风险。</li>
<li><strong>完全掌控数据：</strong> 用户可以完全控制数据的使用和存储，确保数据不被未经授权的访问或用于其他目的。</li>
</ul>
<h4 id="2个性化定制需求强烈高度定制灵活性">2、个性化定制需求强烈（高度定制、灵活性）</h4>
<ul>
<li>对于一些专业领域，如特定行业的知识问答、代码生成等，开发者可以基于本地部署的大模型进行微调，使其更好地满足特定场景需求。例如，软件开发团队可以针对自身的代码规范和业务逻辑，对大模型进行优化，提升代码生成的准确性和实用性。</li>
<li><strong>自定义知识库训练：</strong> 用户可以根据自己的需求对模型进行自定义知识库训练，进一步提升模型在特定领域的性能。</li>
<li><strong>灵活调整模型参数</strong>： 本地部署允许用户根据业务需求灵活调整模型参数和功能，满足不同场景下的个性化需求。</li>
<li><strong>开源灵活性：</strong> 开源模型（如DeepSeek）允许用户无限制地进行微调或将其集成到自己的项目中</li>
</ul>
<h4 id="3成本与资源优化适合企业内">3、成本与资源优化（适合企业内）</h4>
<ul>
<li><strong>成本可控：</strong> 长期使用本地部署比持续使用云服务更具成本效益，尤其适合高频调用场景。</li>
<li><strong>硬件友好：</strong> DeepSeek等大模型对硬件资源要求较低，可在较少GPU或高级CPU集群上运行，资源效率显著。</li>
</ul>
<h4 id="4个人兴趣与学习研究目的">4、个人兴趣与学习、研究目的</h4>
<ul>
<li>
<p>学生、研究人员想要深入了解大模型的运行机制、进行算法实验或者开展模型优化研究，本地部署提供了一个可以自由探索和调试的环境。通过在自己电脑上部署模型，能够更直观地观察模型的运行过程，为学术研究提供便利。</p>
</li>
<li>
<p><strong>技术探索：</strong> 对于技术爱好者和研究人员来说，本地部署可以提供一个更自由的实验环境，方便进行模型的测试和优化。</p>
</li>
<li>
<p><strong>教育用途：</strong> 教育机构可以利用本地部署的大模型进行教学和研究，无需依赖外部服务。</p>
</li>
</ul>
<p>总之，本地部署大模型适合那些对数据隐私、定制化、成本控制有较高要求的用户和企业。</p>
<h2 id="2准备工作">2、准备工作</h2>
<p>1、电脑配置：确保你的电脑具备一定的硬件性能，至少拥有 8GB 及以上的运行内存和足够的硬盘空间。如果有英伟达显卡，部署和运行会更加流畅。</p>
<p>2、下载 ollama：你可以在 ollama 的官方网站（<code>https://ollama.ai/</code>）上找到对应你操作系统（Windows、MacOS 或 Linux）的安装包，下载并安装。</p>
<p>简单来说，如果你的电脑配置满足最低要求（如8GB内存以上），就可以通过工具（如Ollama）轻松实现本地部署<code>DeepSeek</code>。</p>
<p>实践是检验真理的唯一标准，话不多说，开干。</p>
<h2 id="3本地电脑部署deepseek大模型具体步骤">3、本地电脑部署DeepSeek大模型具体步骤</h2>
<h4 id="1安装ollama">1、安装ollama</h4>
<p>1、本地部署首先要安装ollama，<code>ollama</code> 是一个用于在本地运行大语言模型的工具，它能让你在自己的电脑上轻松部署和使用各类模型。你可以把它理解为，一个装AI的盒子，把AI装在盒子里，方便管理。</p>
<p>访问<code>ollama</code>下载地址:<code>https://ollama.com/download</code></p>
<p><img src="https://files.mdnice.com/user/3808/71874308-fcae-4396-9de6-7b0eff4b1a53.png" alt="" loading="lazy"></p>
<p>根据自己的电脑类型，选择不同版本。</p>
<p>2、接下来以Windows为例，下载好安装后，双击安装。（傻瓜式安装即可）</p>
<p><img src="https://files.mdnice.com/user/3808/b689881b-4e82-4021-bfb7-01bf162fcff4.png" alt="" loading="lazy"></p>
<p>安装完成后，ollama会在后台运行，任务栏会出现一个类似羊驼的图标。<br>
<img src="https://files.mdnice.com/user/3808/658fc2cf-5c03-45ed-a874-f9ce90acaf29.png" alt="" loading="lazy"></p>
<h4 id="2选择要安装的模型">2、选择要安装的模型</h4>
<p>1、访问<code>https://ollama.com/search</code>,选择要安装的模型</p>
<p><img src="https://files.mdnice.com/user/3808/5f9df3c9-169f-4de4-aacc-9ae50d3c8c3b.png" alt="" loading="lazy"></p>
<p>2、点击选择<code>deepseek-r1</code>，进入模型参数界面</p>
<p><img src="https://files.mdnice.com/user/3808/78819f9a-9dd0-4538-90b3-35afb479dd72.png" alt="" loading="lazy"></p>
<p>这里的数字越大，参数越多，性能越强，所需要的配置也就越高，1.5b代表模型具备15亿参数。</p>
<p>例如，若要运行14b参数模型，需要大约11.5G显存。也就是你的电脑显卡最好要达到16G。</p>
<p>若个人学习用途，一般建议安装最小的1.5b版本即可。大多数的个人电脑配置都能跑的起来。具体大家可以根据自己的电脑性能选择。</p>
<p>3、以<code>1.5b</code>参数为例，选择1.5b参数后，复制红框中的命令<code>ollama run deepseek-r1:1.5b</code>。</p>
<p><img src="https://files.mdnice.com/user/3808/655e795b-1c30-4cb7-9a05-a825331c6026.png" alt="" loading="lazy"></p>
<p>详细地址: <code>https://ollama.com/library/deepseek-r1:1.5b</code></p>
<h4 id="3安装模型">3、安装模型</h4>
<p>1、打开命令行，在命令行中输入:<code>ollama run deepseek-r1:1.5b</code></p>
<p><img src="https://files.mdnice.com/user/3808/020ed518-3f8d-4089-85d0-89cdec1b3faf.png" alt="" loading="lazy"></p>
<p>2、下载成功后，就可以与模型对话啦。<br>
<img src="https://files.mdnice.com/user/3808/8fd331a5-2172-43be-8b12-5469f68220f5.png" alt="" loading="lazy"></p>
<p>此时大模型安装在你的电脑上，就算断网也可以继续用，再也不用担心数据泄露了。</p>
<h4 id="4使用模型">4、使用模型</h4>
<p>安装好模型后，此时我们可以通过命令行的方式，在命令行中发送消息来与DeepSeek 大模型对话。</p>
<p>1、例如我的第一个问题是："世界上是先有鸡还是先有蛋？"</p>
<p><img src="https://files.mdnice.com/user/3808/4f1f660e-ea99-4da5-aee1-fa525319f638.png" alt="" loading="lazy"><br>
对于这个问题，回答的还可以，果然是推理型模型，思考的过程也给我们列出来了。</p>
<p>2、我的第二个问题是：”你是如何看待DeepSeek爆火的原因“？</p>
<p><img src="https://files.mdnice.com/user/3808/f7c9e382-7789-4a49-8735-edafe6993fb2.png" alt="" loading="lazy"></p>
<p>这个问题，回答的就太过于敷衍了，直接将DeepSeek的公司背书给出来了，当然也可以理解，毕竟DeepSeek的投喂数据都是几个月前的，那时，它还并没有爆火出圈，而且我们下载的还是最小阉割版模型。</p>
<p>3、这里还有一个问题，当你关闭电脑后，下次若再想使用本地模型时，只需要启动了<code>ollama</code>，<br>
同时打开命令行界面，输入<code>ollama run deepseek-r1:1.5b</code> 即可。因为你之前已经下载过，这次无需下载，可以直接和模型聊天。</p>
<p><img src="https://files.mdnice.com/user/3808/15ec3dd0-3cab-475f-b35d-d60376ee5406.png" alt="" loading="lazy"></p>
<h4 id="5为本地模型搭建ui界面">5、为本地模型搭建UI界面</h4>
<p>1、使用命令行方式来和模型对话，对于不会编程的小伙伴来说，太难受了。不过没关系，我们有很多方案可以为你的本地模型搭建UI界面，比如<code>Open-WebUI</code>、<code>Chatbox AI</code>等。</p>
<p>2、这里我们以ChatBox AI为例，访问:<code>https://chatboxai.app/zh</code></p>
<p><img src="https://files.mdnice.com/user/3808/b08455e4-9ae0-4fc4-946c-ddfd245d6877.png" alt="" loading="lazy"><br>
选择对应的版本，下载安装。</p>
<p>3、选择使用自己的 API  Key 或者本地模型：</p>
<p><img src="https://files.mdnice.com/user/3808/fe5f6c40-656a-4f78-8b1b-143f9755a3d3.png" alt="" loading="lazy"></p>
<p>4、选择本地跑的 <code>deepseek-r1:1.5b</code>模型：</p>
<p><img src="https://files.mdnice.com/user/3808/8cdb824c-cf78-4fdd-a01a-309378139684.png" alt="" loading="lazy"></p>
<p>Ollama 默认使用 端口11434 提供本地服务。当你在本地运行 Ollama 时，可以通过以下地址访问其 API 服务：<br>
<code>http://localhost:11434</code><br>
如果你需要更改默认端口，可以通过设置环境变量 <code>OLLAMA_HOST</code> 来指定新的端口。</p>
<p>5、在ChatBox对话框中，输入：”先有鸡还是先有蛋“，即可调用本地模型，生成答案</p>
<p><img src="https://files.mdnice.com/user/3808/7ce75a01-a0aa-42f5-a57a-78cb26de66ae.png" alt="" loading="lazy"></p>
<p>至此，简单几步，在你的本地电脑上就安装运行起来了 <code>DeepSeek R1</code>。</p>
<p>好了，今天先就分享到这里，下一篇我们来好好聊一聊关于<code>ollama</code>是个啥。</p>
<p>另，组建了两个知识星球：<strong>「DeepSeek创智研习社」、「AI副业俱乐部」</strong>，专注于AI领域，一个是<strong>永久免费开放</strong>，分享AI 领域的前沿资讯、工具、资料与DeepSeek使用技巧，一个需要门票（一杯春天的奶茶），专注<strong>AI+创作×提效×商业变现闭环</strong>，欢迎在研究或在实践的你，一起交流共创，添加作者微信762357658，备注【加入知识星球】或公众号后台回复「AI」邀请加入。</p>

</div>
<div id="MySignature" role="contentinfo">
    技术改变世界！
         --狂诗绝剑
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.053170023075231485" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-12 09:28">2025-02-12 09:27</span>&nbsp;
<a href="https://www.cnblogs.com/jinjiangongzuoshi">狂师</a>&nbsp;
阅读(<span id="post_view_count">319</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18710936" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18710936);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18710936', targetLink: 'https://www.cnblogs.com/jinjiangongzuoshi/p/18710936', title: '自己如何在本地电脑从零搭建DeepSeek！手把手教学，快来看看！ (建议收藏)' })">举报</a>
</div>
        