
        <h2>
            <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/milton/p/18813440" title="发布于 2025-04-07 20:37">
    <span role="heading" aria-level="2">图像处理中的 Gaussina Blur 和 SIFT 算法</span>
    

</a>

        </h2>
        <div class="postbody">
                <div id="cnblogs_post_description" style="display: none">
        
        SIFT(Scale-Invariant Feature Transform)算法是一种用于图像处理中的局部特征提取方法, 具有尺度、旋转和光照不变性, 通过对图像进行不同尺度的高斯模糊生成多组图像并从中提取特征实现
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="gaussina-blur-高斯模糊">Gaussina Blur 高斯模糊</h1>
<h2 id="高斯模糊的数学定义">高斯模糊的数学定义</h2>
<p>高斯模糊是通过 <strong>高斯核(Gaussian Kernel)</strong> 对图像进行卷积操作实现的. 二维高斯函数定义为</p>
<p></p><div class="math display">\[G(x, y, \sigma) = \frac{1}{2\pi \sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}}
\]</div><p></p><p>其中：</p>
<ul>
<li><span class="math inline">\((x, y)\)</span> 是像素点的坐标</li>
<li><span class="math inline">\(\sigma\)</span> 是高斯核的标准差, 控制模糊程度<span class="math inline">\(\sigma\)</span> 越大, 图像越模糊</li>
</ul>
<h2 id="高斯模糊计算的-python-实现">高斯模糊计算的 Python 实现</h2>
<p>以下是使用 OpenCV 计算不同尺度高斯模糊的代码</p>
<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# 读取图像
img = cv2.imread('00001.jpg', cv2.IMREAD_COLOR_RGB)

# 定义高斯核的尺度（σ值）
sigma_values = [1.0, 1.6, 2.0, 2.5, 3.0]  # 示例σ值

# 对每个σ值进行高斯模糊
blurred_images = []
for sigma in sigma_values:
    # 高斯核大小（通常根据σ自动计算，如 ksize=(0,0)）
    blurred = cv2.GaussianBlur(img, (0, 0), sigmaX=sigma, sigmaY=sigma)
    blurred_images.append(blurred)

# 显示结果
plt.figure(figsize=(15, 8))
# 原图
plt.subplot(2, 3, 1)
plt.imshow(img)
plt.title('original')
plt.axis('off')
# 模糊处理过的图
for i, (sigma, blurred) in enumerate(zip(sigma_values, blurred_images)):
    plt.subplot(2, 3, i+2)
    plt.imshow(blurred, cmap='gray')
    plt.title(f'σ={sigma}')
    plt.axis('off')
plt.tight_layout()
plt.show()
</code></pre>
<ul>
<li><code>cv2.GaussianBlur(img, ksize, sigmaX)</code>
<ul>
<li><code>ksize=(0,0)</code> 时, OpenCV 会根据 <span class="math inline">\(\sigma\)</span> 自动计算核大小, 通常为 <span class="math inline">\(6\sigma + 1\)</span></li>
<li><code>sigmaX</code> 和 <code>sigmaY</code> 是高斯核在 X 和 Y 方向的标准差, 通常设为相同值</li>
</ul>
</li>
</ul>
<h2 id="高斯核矩阵">高斯核矩阵</h2>
<p>在实际计算中, 高斯核需要离散化为一个二维矩阵. 例如, 当 <span class="math inline">\(\sigma = 1.0\)</span> 时, 一个 3×3 的高斯核可能如下</p>
<p></p><div class="math display">\[K = \frac{1}{16}
\begin{bmatrix}
1 &amp; 2 &amp; 1 \\
2 &amp; 4 &amp; 2 \\
1 &amp; 2 &amp; 1 \\
\end{bmatrix}
\]</div><p></p><p><strong>手动计算高斯核的示例</strong></p>
<pre><code class="language-python">import cv2
import numpy as np

# 生成二维高斯核
def gaussian_kernel(size, sigma):
    kernel = np.zeros((size, size))
    # // 是整数除法运算符, 会将结果向下取整到最接近的整数
    center = size // 2
    for x in range(size):
        for y in range(size):
            dx, dy = x - center, y - center
            kernel[x, y] = np.exp(-(dx**2 + dy**2) / (2 * sigma**2))
    kernel /= kernel.sum()  # 归一化
    return kernel

# 生成 σ=1.5 的 5x5 高斯核
kernel = gaussian_kernel(5, 1.5)
print(kernel)
</code></pre>
<p>矩阵中各元素的数值构成了一个三维高斯曲面, 中心点最高, 呈钟形向四周降低</p>
<h1 id="siftscale-invariant-feature-transform算法">SIFT(Scale-Invariant Feature Transform)算法</h1>
<p>SIFT(Scale-Invariant Feature Transform)算法是一种用于图像处理中的局部特征提取方法, 具有尺度、旋转和光照不变性, 因为其结果稳定性和较高的精度在图像匹配中广泛应用. SIFT的缺点是计算复杂度较高, 在一些需要实时处理的场景被快速算法如SURF, ORB等替代. 在 COLMAP 中, 提取特征量和匹配基于的就是 SIFT 算法.</p>
<h2 id="1-尺度空间极值检测scale-space-extrema-detection">1. 尺度空间极值检测(Scale-Space Extrema Detection)</h2>
<p><strong>目的</strong>: 在多尺度空间中寻找关键点(潜在的特征点)</p>
<ul>
<li>构建高斯金字塔
<ul>
<li>对图像进行不同尺度的高斯模糊(通过高斯卷积核 $ G(x,y,\sigma) $), 生成多组(Octave)图像. 每组包含多层(Interval), 尺度按 $ k\sigma $ 递增(如 $ \sigma, k\sigma, k^2\sigma $).
<ul>
<li>不同尺度的高斯模糊是通过对图像应用不同标准差 <span class="math inline">\(\sigma\)</span> 的高斯核进行卷积计算得到的</li>
</ul>
</li>
<li>下一组的图像由上一组降采样(如尺寸减半)得到.</li>
</ul>
</li>
<li>构建高斯差分金字塔(DoG)
<ul>
<li>对同一组内相邻尺度的高斯图像相减, 得到 $ D(x,y,\sigma) = L(x,y,k\sigma) - L(x,y,\sigma) $</li>
<li>DoG用于近似拉普拉斯算子(LoG), 效率更高.</li>
</ul>
</li>
<li>检测极值点
<ul>
<li>每个像素与同一层相邻的8个像素及上下相邻层的18个像素(共26个)比较, 判断是否为局部极大/极小值.</li>
</ul>
</li>
</ul>
<h2 id="2-关键点定位keypoint-localization">2. 关键点定位(Keypoint Localization)</h2>
<p><strong>目的</strong>: 精确定位关键点, 去除低对比度或边缘响应点</p>
<ul>
<li>泰勒展开精确定位
<ul>
<li>通过泰勒展开拟合DoG函数, 找到极值点的亚像素级位置(偏移量 $ \hat{x} $)</li>
<li>若 $ |D(\hat{x})| $ 小于阈值(如0.03), 则视为低对比度点, 剔除</li>
</ul>
</li>
<li>边缘响应剔除
<ul>
<li>利用Hessian矩阵计算曲率, 剔除边缘响应强的点(主曲率比值大的点)</li>
<li>若 $ \frac{\text{Tr}(H)^2}{\text{Det}(H)} &gt; \frac{(r+1)^2}{r} $(通常 $ r=10 $), 则剔除</li>
</ul>
</li>
</ul>
<h2 id="3-方向分配orientation-assignment">3. 方向分配(Orientation Assignment)</h2>
<p><strong>目的</strong>: 将关键点方向归一化处理, 以实现旋转不变性</p>
<ul>
<li>计算梯度幅值和方向
<ul>
<li>在关键点所在高斯尺度图像上, 计算邻域窗口内像素的梯度:<p></p><div class="math display">\[m(x,y) = \sqrt{(L(x+1,y)-L(x-1,y))^2 + (L(x,y+1)-L(x,y-1))^2}
\]</div><p></p><p></p><div class="math display">\[\theta(x,y) = \tan^{-1}\left( \frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)} \right)
\]</div><p></p></li>
</ul>
</li>
<li>生成方向直方图
<ul>
<li>将360°分为36柱(每柱10°), 加权统计梯度幅值(权重为高斯窗口和梯度幅值).</li>
<li>取主峰(最高峰值)和80%以上主峰的次峰作为关键点方向.</li>
</ul>
</li>
</ul>
<h2 id="4-关键点描述符descriptor-generation">4. 关键点描述符(Descriptor Generation)</h2>
<p><strong>目的</strong>: 在方向归一化处理后, 通过划分子块生成关键点的特征向量</p>
<ul>
<li><strong>旋转坐标轴</strong>: 将邻域窗口旋转至关键点主方向.</li>
<li><strong>划分子区域</strong>: 将16×16的窗口分为4×4的子块(共16块).</li>
<li><strong>计算子块梯度直方图</strong>:
<ul>
<li>每个子块内计算8方向的梯度直方图(共8维).</li>
<li>16个子块 × 8方向 = 128维特征向量.</li>
</ul>
</li>
<li><strong>归一化处理</strong>:
<ul>
<li>对特征向量归一化, 减少光照影响, 并截断大于0.2的值以增强鲁棒性.</li>
</ul>
</li>
</ul>
<h2 id="5-关键点匹配">5. 关键点匹配</h2>
<ul>
<li>通过欧氏距离(如最近邻算法)比较两幅图像的SIFT描述符</li>
<li>使用最近邻距离比(NNDR, 如 $ \frac{d_1}{d_2} &lt; 0.8 $)筛选匹配点, 提升匹配精度.</li>
</ul>
<h1 id="在python代码中通过opencv使用sift算法">在Python代码中通过OpenCV使用SIFT算法</h1>
<h2 id="提取关键点">提取关键点</h2>
<pre><code class="language-python">import cv2
import matplotlib.pyplot as plt

# 读取图像（转为灰度图）
img = cv2.imread('00001.jpg', cv2.IMREAD_GRAYSCALE)

# 初始化 SIFT 检测器
sift = cv2.SIFT_create()

# 检测关键点并计算描述符
keypoints, descriptors = sift.detectAndCompute(img, None)

# 绘制关键点
img_with_keypoints = cv2.drawKeypoints(
    img, 
    keypoints, 
    None, 
    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
)

# 显示结果
plt.figure(figsize=(10, 6))
plt.imshow(img_with_keypoints, cmap='gray')
plt.title('SIFT Keypoints')
plt.axis('off')
plt.show()
</code></pre>
<h2 id="双图关键点匹配">双图关键点匹配</h2>
<pre><code class="language-python">import cv2
import matplotlib.pyplot as plt

# 读取两张图像
img1 = cv2.imread('00001.jpg', cv2.IMREAD_GRAYSCALE)
img2 = cv2.imread('00006.jpg', cv2.IMREAD_GRAYSCALE)

# 初始化 SIFT
sift = cv2.SIFT_create()

# 计算关键点和描述符
kp1, desc1 = sift.detectAndCompute(img1, None)
kp2, desc2 = sift.detectAndCompute(img2, None)

# 使用 BFMatcher（Brute-Force 匹配器）
bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)
matches = bf.match(desc1, desc2)

# 按距离排序，取最优匹配
matches = sorted(matches, key=lambda x: x.distance)

# 绘制前 50 个匹配点
matched_img = cv2.drawMatches(
    img1, kp1, 
    img2, kp2, 
    matches[:10], 
    None, 
    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
)

# 显示匹配结果
plt.figure(figsize=(15, 8))
plt.imshow(matched_img, cmap='gray')
plt.title('SIFT Feature Matching')
plt.axis('off')
plt.show()
</code></pre>

</div>
<div class="clear"></div>

        </div>
        <p class="postfoot">
            posted on 
<span id="post-date" data-last-update-days="0.2387960923599537" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-07 20:37">2025-04-07 20:37</span>&nbsp;
<a href="https://www.cnblogs.com/milton">Milton</a>&nbsp;
阅读(<span id="post_view_count">14</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18813440" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18813440);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18813440', targetLink: 'https://www.cnblogs.com/milton/p/18813440', title: '图像处理中的 Gaussina Blur 和 SIFT 算法' })">举报</a>

        </p>
    