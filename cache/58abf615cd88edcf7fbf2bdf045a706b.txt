
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/jellyai/p/18738187" title="发布于 2025-02-26 12:03">
    <span role="heading" aria-level="2">Featurewiz-Polars：一种强大且可扩展的特征选择解决方案，适用于XGBoost</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><img src="https://img2024.cnblogs.com/blog/3524016/202502/3524016-20250226120220926-1052822666.png" alt="" loading="lazy"></p>
<p>前言：“Featurewiz-Polars”是一个用于特征工程的 Python 库，结合了特征选择和特征生成的功能。它基于“Polars”，这是一个高性能的 DataFrame 库，用于处理大型数据集，具有类似 Pandas 的 API 但更高效，尤其在处理大数据时。Featurewiz-Polars 专注于通过自动化方式，快速从数据中提取出最有意义的特征，帮助机器学习模型提高性能。</p>
<p>特征选择是构建高效机器学习模型的关键步骤。</p>
<p>我通过艰难的经验学到了这一点。</p>
<p>有一个项目至今让我难以忘怀：我曾在一家金融科技初创公司做信用风险模型的工作。我们拥有了一切——交易历史、社交媒体信号、替代信用评分——并将所有这些输入到模型中，期待它能给我们提供最佳的预测。</p>
<p>刚开始看起来很有希望，但一旦部署，审批变得不可预测，更糟糕的是，高风险借款人开始悄悄溜过。经过数周的调试，问题变得异常明显：模型在无关和冗余特征中迷失了自己，过度拟合噪音而非实际的风险模式。</p>
<p>这次经历让我踏上了特征选择的漫长探索之路——反复试验、无数实验，以及对在简洁性和性能之间找到最佳平衡的执着。</p>
<p>在这个过程中，我从手工制作的领域启发到自动化选择方法都进行了尝试。现在，经历了所有这些痛苦的教训后，我想分享一个真正有效的方法。</p>
<p>介绍Featurewiz</p>
<p>如果你是Featurewiz的新手，这里是它的亮点：</p>
<p>• 只需三行代码即可自动化特征选择。</p>
<p>• 广泛的特征工程——它不仅选择特征；它还能自动生成数百个特征并挑选出最佳的。</p>
<p>• 最受认可的mRMR（最小冗余、最大相关性）实现之一，这是特征选择的黄金标准算法。</p>
<p>Featurewiz多年来一直是人们的首选解决方案，拥有超过600个GitHub星标和140多个Google Scholar引用。</p>
<p>现在，随着Featurewiz-Polars的发布，这个库已经发展得更快、更可扩展、更可靠，特别适用于大规模数据集。</p>
<p>如何将Featurewiz用作Scikit-Learn转换器</p>
<p>将Featurewiz用作兼容Scikit-Learn的转换器非常简单：</p>
<ol>
<li>安装Featurewiz</li>
</ol>
<p>import featurewiz as fw</p>
<ol start="2">
<li>创建Transformer</li>
</ol>
<p>wiz = fw.FeatureWiz(verbose=1)</p>
<ol start="3">
<li>拟合并转换数据集</li>
</ol>
<p>在这个例子中，我们将使用来自Featurewiz GitHub仓库的汽车销售数据集。加载到Pandas DataFrame后，并将其拆分为训练集和测试集，我们可以将其输入到Featurewiz中，以识别最重要的特征：</p>
<p>X_train, y_train = wiz.fit_transform(train[preds], train[target])</p>
<p>X_test = wiz.transform(test[preds])</p>
<p>目标是什么？使用km_driven、fuel、seller_type、transmission、owner、mileage、engine、max_power和seats等变量预测汽车销售价格。</p>
<p>特征选择真的能提高性能吗？</p>
<p>为了验证这一点，我们训练了两个模型：</p>
<p>• 一个使用所有特征</p>
<p>• 一个仅使用Featurewiz选择的最重要特征</p>
<p><img src="https://img2024.cnblogs.com/blog/3524016/202502/3524016-20250226120237395-1951591629.png" alt="" loading="lazy"></p>
<p>图1：注意到使用Featurewiz选择的变量（右侧）的模型，比使用所有特征（左侧）的模型表现更好。</p>
<p>但是，为什么使用更少特征的模型表现更好呢？有两个关键原因：</p>
<ol>
<li>
<p>更简单的模型能更好地泛化——减少特征复杂性有助于防止过拟合。</p>
</li>
<li>
<p>更快的训练和推理——更少的变量意味着更快的训练和预测，这在实际应用中至关重要。</p>
</li>
</ol>
<p>你可以在GitHub上找到这篇博客的完整笔记本和数据集。</p>
<p>Featurewiz的工作原理：递归XGBoost特征选择</p>
<p>Featurewiz的特征选择依赖于递归XGBoost排名，逐步精炼特征集。具体过程如下：</p>
<ol>
<li>
<p>从一切开始——将整个数据集输入到选择过程。</p>
</li>
<li>
<p>XGBoost特征排名——训练XGBoost模型以评估特征的重要性。</p>
</li>
<li>
<p>选择关键特征——根据重要性评分提取最显著的特征。</p>
</li>
<li>
<p>修剪并重复——仅保留排名最高的特征，并在精细化的子集上重新运行过程。</p>
</li>
<li>
<p>迭代直到最佳——继续循环，直到满足停止标准（如稳定性或收益递减）。</p>
</li>
<li>
<p>完成特征集——合并所有循环中选择的特征，去除重复项，形成最终优化的特征集。</p>
</li>
</ol>
<p>这种方法确保只有最相关、最不冗余的特征被选中，从而提高模型性能和效率。</p>
<p>下一步：使用Split-Driven递归XGBoost的Featurewiz-Polars</p>
<p>原始的Featurewiz方法非常强大，但也有一些权衡——它可能容易过拟合，并且缺乏内建的泛化机制评估。正是在这种情况下，最新版本的Featurewiz-Polars应运而生。</p>
<p>有什么新变化？Split-Driven递归XGBoost</p>
<p>这种改进的方法引入了基于验证的特征选择，利用Polars实现了速度和效率。具体过程如下：</p>
<ol>
<li>
<p>为验证分割数据——将数据集分为训练集和验证集。</p>
</li>
<li>
<p>XGBoost特征排名（带验证）——在训练集上评估特征的重要性，并在验证集上评估性能。</p>
</li>
<li>
<p>选择关键特征（带验证）——根据特征的重要性和它们的泛化能力选择特征。</p>
</li>
<li>
<p>使用新分割重复——在不同的训练/验证集分割下重复这个过程。</p>
</li>
<li>
<p>最终、稳定的特征集——合并所有运行中的选择特征，去除重复项，从而得出更强大、可靠的选择结果。</p>
</li>
</ol>
<p>与现有库的基准比较</p>
<p>我们将Featurewiz-Polars与mRMR特征选择库进行了测试，使用其Polars实现进行公平比较。</p>
<p>测试1：克利夫兰心脏病数据集</p>
<p>• 原始数据集：14个特征。</p>
<p>• Featurewiz-Polars仅选择了3个特征，达到了91%的平衡准确率。</p>
<p>• mRMR选择了10个特征，但只达到了89%的平衡准确率。</p>
<p><img src="https://img2024.cnblogs.com/blog/3524016/202502/3524016-20250226120252916-2033208785.png" alt="" loading="lazy"></p>
<p>Featurewiz-Polars在使用更少特征的情况下表现更好——提高了泛化能力并减少了复杂性。</p>
<p><img src="https://img2024.cnblogs.com/blog/3524016/202502/3524016-20250226120307856-1702810230.png" alt="" loading="lazy"></p>
<p>以下是实际比较的截图</p>
<p>测试2：加州住房数据集（回归任务）</p>
<p>• 原始数据集：13个特征。</p>
<p>• Featurewiz-Polars选择了7个特征，RMSE为0.50。</p>
<p>• 竞争的mRMR库选择了8个特征，但RMSE稍微差一点。</p>
<p><img src="https://img2024.cnblogs.com/blog/3524016/202502/3524016-20250226120319473-880839644.png" alt="" loading="lazy"></p>
<p>同样，Featurewiz-Polars在使用更少特征的情况下提供了更优的性能。</p>
<p><img src="https://img2024.cnblogs.com/blog/3524016/202502/3524016-20250226120329206-1007211769.png" alt="" loading="lazy"></p>
<p>安装指南</p>
<p>Featurewiz-Polars尚未发布到PyPI，但你可以从源码安装：</p>
<p>cd &lt;new_folder_destination&gt;</p>
<p>git clone <a href="https://github.com/AutoViML/featurewiz_polars.git" target="_blank" rel="noopener nofollow">https://github.com/AutoViML/featurewiz_polars.git</a></p>
<p>pip install -r requirements.txt</p>
<p>cd examples</p>
<p>python fs_test.py</p>
<p>或者直接从GitHub安装：</p>
<p>pip install git+https://github.com/AutoViML/featurewiz_polars.git</p>
<p>或者下载并解压：</p>
<p><a href="https://github.com/AutoViML/featurewiz_polars/archive/master.zip" target="_blank" rel="noopener nofollow">https://github.com/AutoViML/featurewiz_polars/archive/master.zip</a></p>
<p>最后的想法</p>
<p>Featurewiz-Polars运行得更快，选择的特征更少，并且比竞争的mRMR实现提供了更好的模型性能。</p>
<p>如果你正在进行特征选择，试试看，自己比较一下结果吧！你可以从GitHub获取fs_test.py模块并运行你自己的基准测试。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.010292939989583333" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-26 12:04">2025-02-26 12:03</span>&nbsp;
<a href="https://www.cnblogs.com/jellyai">果冻人工智能</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18738187" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18738187);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18738187', targetLink: 'https://www.cnblogs.com/jellyai/p/18738187', title: 'Featurewiz-Polars：一种强大且可扩展的特征选择解决方案，适用于XGBoost' })">举报</a>
</div>
        