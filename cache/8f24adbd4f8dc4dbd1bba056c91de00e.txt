
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/deali/p/18695132" title="发布于 2025-01-30 13:12">
    <span role="heading" aria-level="2">DeepSeek火爆全网，官网宕机？本地部署一个随便玩「LLM探索」</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="前言">前言</h2>
<p>最近 DeepSeek 狠狠刷了一波屏，国产大模型真的越来越厉害了👍，官方的服务器已经爆满了，以至于频繁出现反应迟缓甚至宕机的情况，和两年多之前 ChatGPT 的遭遇颇为相似。</p>
<p>我已经好久没有本地部署模型了（现在各厂商的模型都便宜量大），这次正好来试试 DeepSeek 开源模型的效果。</p>
<h3 id="关于ai大模型的扩展阅读">关于AI大模型的扩展阅读</h3>
<ul>
<li><a href="https://www.cnblogs.com/deali/p/llm-1.html" target="_blank">LLM探索：环境搭建与模型本地部署</a></li>
<li><a href="https://www.cnblogs.com/deali/p/llm-2.html" target="_blank">LLM探索：GPT类模型的几个常用参数 Top-k, Top-p, Temperature</a></li>
<li><a href="https://www.cnblogs.com/deali/p/17275651.html" target="_blank">快来玩AI画图！StableDiffusion模型搭建与使用入门~</a></li>
<li><a href="https://www.cnblogs.com/deali/p/18359353" target="_blank">使用Django-Channels实现websocket通信+大模型对话</a></li>
<li><a href="https://www.cnblogs.com/deali/p/17553214.html" target="_blank">项目完成小结：使用Blazor和gRPC开发大模型客户端</a></li>
</ul>
<h2 id="安装-ollama">安装 ollama</h2>
<p><a href="https://ollama.com/download/linux" target="_blank" rel="noopener nofollow">https://ollama.com/download/linux</a></p>
<p>我是在 Linux 服务器上安装的，一行命令就可以。如果是 Windows 的话，可能是下载安装包就行。</p>
<pre><code class="language-bash">curl -fsSL https://ollama.com/install.sh | sh
</code></pre>
<p>我安装的时候似乎遇到网络问题</p>
<p>改成先下载</p>
<pre><code class="language-bash">wget https://ollama.com/install.sh
</code></pre>
<p>然后手动执行安装，就可以了</p>
<pre><code class="language-bash">sh ./install.sh
</code></pre>
<h2 id="配置-ollama-监听地址">配置 ollama 监听地址</h2>
<p>ollama 安装后默认监听 127.0.0.1, 为了方便使用，要么修改监听地址，要么用 SSH 转发，这里我选择了修改地址</p>
<pre><code class="language-bash">sudo systemctl edit ollama
</code></pre>
<p>它会自动在 <code>/etc/systemd/system/ollama.service.d/override.conf</code> 中存储你添加或修改的配置。</p>
<p>在里面添加配置</p>
<pre><code class="language-ini">[Service]
Environment="OLLAMA_HOST=0.0.0.0:11434"
</code></pre>
<p>即可覆盖主服务文件里对 <code>OLLAMA_HOST</code> 的设置，其他环境变量（如 <code>PATH</code> 等）则仍保留主服务文件里的值。</p>
<h3 id="验证">验证</h3>
<p>先重启以下</p>
<pre><code class="language-bash">sudo systemctl daemon-reload
sudo systemctl restart ollama
</code></pre>
<p>然后执行以下命令验证</p>
<pre><code class="language-bash">sudo systemctl show ollama | grep Environment
</code></pre>
<p>你会看到系统最终为该服务设置的所有环境变量。其中如果存在同名变量，就会以最后写入（即 override 配置）的值为准。</p>
<h2 id="搜索模型">搜索模型</h2>
<p><a href="https://ollama.com/search?q" target="_blank" rel="noopener nofollow">https://ollama.com/search?q</a> = deepseek</p>
<p>目前最火的 DeepSeek-R1 排在显眼位置</p>
<p>这里根据显存选择合适的模型，我选了 14b 的模型</p>
<p>右侧有安装命令，点击按钮复制</p>
<h2 id="安装">安装</h2>
<p>接着执行命令</p>
<pre><code class="language-bash">ollama run deepseek-r1:14b
</code></pre>
<p>开始下载，14b 的模型大小是 9GB</p>
<h2 id="使用">使用</h2>
<p>在命令行可以直接使用</p>
<p><img src="https://img2024.cnblogs.com/blog/866942/202501/866942-20250130130835448-574157211.png" alt="" loading="lazy"></p>
<h2 id="安装-open-webui">安装 Open WebUI</h2>
<p><a href="https://github.com/open-webui/open-webui" target="_blank" rel="noopener nofollow">https://github.com/open-webui/open-webui</a></p>
<h3 id="pip-安装">pip 安装</h3>
<pre><code class="language-bash">conda create -n open-webui python=3.11
</code></pre>
<p>切换环境</p>
<pre><code class="language-bash">conda activate open-webui
</code></pre>
<p>安装</p>
<pre><code class="language-bash">pip install open-webui
</code></pre>
<p>启动</p>
<pre><code class="language-bash">open-webui serve
</code></pre>
<h3 id="docker">docker</h3>
<p>官方只提供了 docker 命令</p>
<pre><code class="language-bash">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre>
<p>我改成了 docker-compose 配置</p>
<pre><code class="language-yaml">services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: always
    ports:
      - "3000:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - "./open-webui:/app/backend/data"

</code></pre>
<h2 id="ssh-转发">SSH 转发</h2>
<p>在本机执行以下命令，将服务器的端口转发到本机</p>
<pre><code class="language-bash">ssh -L 3000:localhost:3000 用户名@服务器地址 -p 端口
</code></pre>
<p>这样就可以在本机的浏览器打开 <code>http://localhost:3000</code> 访问到 webui 了</p>
<h2 id="使用-webui">使用 webui</h2>
<p>很简单，第一次打开会需要创建管理员账号</p>
<p>进入之后界面与 ChatGPT 有点相似</p>
<p><img src="https://img2024.cnblogs.com/blog/866942/202501/866942-20250130130813308-507392736.png" alt="" loading="lazy"></p>
<p>和 DeepSeek 模型对话，这个14b的模型就感觉效果已经不错了，如果完整版模型就更好，真的未来可期啊！</p>
<p><img src="https://img2024.cnblogs.com/blog/866942/202501/866942-20250130130821042-2060900524.png" alt="" loading="lazy"></p>
<h2 id="后记">后记</h2>
<p>据说 DeepSeek 的代码能力很强，可惜现在官网的 API 服务进不去。</p>
<p>下一篇文章我来试试拿本地部署的 DeepSeek 来写代码，看看效果如何。</p>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="https://mp.weixin.qq.com/s/JUe73lGnnXv-13B8oME_Rg" target="_blank" rel="noopener nofollow">DeepSeek-R1本地部署，再也不怕宕机，还有语音功能！</a></li>
<li><a href="https://www.bilibili.com/video/BV18qcweJE7X" target="_blank" rel="noopener nofollow">DeepSeek 3大用法！再见ChatGPT/cursor</a></li>
</ul>

</div>
<div id="MySignature" role="contentinfo">
    微信公众号：「程序设计实验室」
专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.5457471664664352" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-01-30 13:13">2025-01-30 13:12</span>&nbsp;
<a href="https://www.cnblogs.com/deali">程序设计实验室</a>&nbsp;
阅读(<span id="post_view_count">422</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18695132" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18695132);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18695132', targetLink: 'https://www.cnblogs.com/deali/p/18695132', title: 'DeepSeek火爆全网，官网宕机？本地部署一个随便玩「LLM探索」' })">举报</a>
</div>
        