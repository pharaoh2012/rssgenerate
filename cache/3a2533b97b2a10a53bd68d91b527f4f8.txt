
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xiao987334176/p/18891735" title="发布于 2025-05-23 10:29">
    <span role="heading" aria-level="2">ComfyUI+通义万相 Wan2.1系列生成视频教程</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h1>一、Wan2.1系列</h1>
<p>Wan2.1 系列是阿里巴巴通义实验室推出的开源视频生成模型套件，共有 4 个模型，包括文生视频的 Wan2.1-T2V-1.3B 和 Wan2.1-T2V-14B，以及图生视频的 Wan2.1-I2V-14B</p>
<p>在权威评测集 VBench 中，Wan2.1 以总分 86.22% 的成绩登上榜首位置，大幅领先了 Sora、Minimax、Luma、Gen3、Pika 等国内外视频生成模型</p>
<p data-pid="zO8PZUBN">具体来说，Wan2.1开源了文生视频和图生视频两种模型。</p>
<p data-pid="nosc9IM3">其中，文生视频模型有1.3B和14B两种大小，图生视频模型大小都是14B，不过，一个是480P，另一个是720P。</p>
<p data-pid="nosc9IM3"><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523100811897-1608313957.jpg" alt=""></p>
<p data-pid="OGPTv_5w">大尺寸14B版本主打高性能，但1.3B小版本适合消费级显卡，只需要 8.2GB 显存就可以生成 480P 高质量视频。</p>
<p data-pid="HRLNuiJN">也即是说，只要你有一张4060显卡（8G显存），就能跑得动这个模型，并且可以在大约4分钟以内生成5秒的480p视频。</p>
<p data-pid="YPT-Xz6M">刚好，ComfyUI官方也支持了Wan2.1模型，所以，这篇文章就带大家一步一步在本地部署Wan2.1模型。</p>
<h1>二、ComfyUI</h1>
<p>ComfyUI 和大家熟知的 WebUI 一样，都是 Stable Diffusion 的一种用户界面，可以实现文生图、图生图、图像处理、AI 视频生成等操作。但 ComfyUI 是节点式模块化的界面，需要用户自己搭建工作流，而且各方面的资源比较松散，需要自己安装部署，因此入门难度较高，不适合零基础的 AI 绘画小白，一般都推荐大家先掌握 Stable Diffusion WebUI 的用法，再学习 ComfyUI。</p>
<p>ComfyUI 越来越受欢迎，是因为用户可以按需要搭建自定义工作流，高效完成各种图像生成任务，很多最新的 AI 技术比如 SVD、InstantID 发布没多久就能在 ComfyUI 中用上，这点是 WebUI 做不到的；ComfyUI 会将图像生成流程保存为工作流（workflow）文件，下次使用时直接拖入界面加载就行，这样不仅方便自己复用已有工作流，还能轻松借用大神的生成作品；而且 ComfyUI 对低显存用户也更友好，在 WebUI 中容易爆显存生成任务在 ComfyUI 中可以顺利完成。</p>
<h2>下载</h2>
<p>夸克网盘<br>链接：https://pan.quark.cn/s/fed0656eb3f1</p>
<p>打开链接，只需要下载ComfyUI-aki-V202504版-无需密码.zip，其他文件不需要下载。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522173010511-164905125.png" alt="" loading="lazy"></p>
<h2>安装</h2>
<p>解压zip文件，得到文件夹ComfyUI-aki-V202504版-无需密码，进入目录ComfyUI-aki-V202504版</p>
<p>双击文件，绘世启动器.exe</p>
<p>第一次打开，会提示安装组件windowsdesktop-runtime，安装提示下载安装即可。</p>
<p>安装完成，首页效果如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522173928765-2143980860.png" alt="" loading="lazy"></p>
<p>&nbsp;点击左侧的高级选项--&gt;环境维护--&gt;安装PyTorch，选择最新版本CUDA 12.8，点击安装。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522173847081-59780197.png" alt="" loading="lazy"></p>
<p>安装需要一点时间，请耐心等待</p>
<p>&nbsp;</p>
<p>点击版本管理，更新到最新版本</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522174950273-1643381127.png" alt="" loading="lazy"></p>
<h1>三、ComfyUI模型文件下载</h1>
<h2>clip_vision下载</h2>
<p data-pid="gr0CC_YY">打开下面这个页面，下载clip_vision：</p>
<p data-pid="gr0CC_YY"><a href="https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/clip_vision" target="_blank" rel="noopener nofollow">https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/clip_vision</a></p>
<p>下载文件</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522180758213-950323860.png" alt="" loading="lazy"></p>
<p>&nbsp;下载到本地后，移到下载到本地后，移到ComfyUI整合包的ComfyUI\models\clip_vision目录下。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522181015277-1072539522.png" alt="" loading="lazy"></p>
<h2>diffusion_models下载</h2>
<p data-pid="L1Y76s8v">打开下面这个页面，下载diffusion_model：<a class=" external" href="https://link.zhihu.com/?target=https%3A//huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/diffusion_models" rel="noopener nofollow" target="_blank" data-za-detail-view-id="1043"><span class="invisible"><br></span></a></p>
<p data-pid="L1Y76s8v"><a href="https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/diffusion_models" target="_blank" rel="noopener nofollow">https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/diffusion_models</a></p>
<p data-pid="e_75JzcS">Wan2.1模型支持文生视频和图生视频两种方式，每种方式下又有14B和1.3B两种尺寸的模型，其中：</p>
<ul>
<li data-pid="lNJI01MF">文生视频</li>
<ul>
<li data-pid="o5_QHXjv">wan2.1_t2v_1.3B的模型，最大只支持生成832×480像素视频</li>
<li data-pid="7BIZkHj0">wan2.1_t2v_14B的模型，支持1280×720像素和832×480像素视频</li>



</ul>
<li data-pid="HjIOcY6A">图生视频</li>
<ul>
<li data-pid="RCalf-iQ">wan2.1_i2v_480p_14B的模型，最大支持生成832×480像素视频</li>
<li data-pid="JxhKLd1j">wan2.1_i2v_720p_14B的模型，最大支持生成1280×720像素视频</li>



</ul>



</ul>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522181200946-739138191.png" alt=""></p>
<p>同时，每个尺寸的模型下也有多个模型，根据生成质量的优劣，按照如下原则选择（质量等级从高到低）：</p>
<p><span style="color: rgba(255, 0, 0, 1)"><strong>fp16 &gt; bf16 &gt; fp8_scaled &gt; fp8_e4m3fn</strong></span></p>
<p>结合自己的显存大小，我选择这两个模型下载到本地：</p>
<p>文生视频：wan2.1_t2v_1.3B_fp16.safetensors<br>图生视频：wan2.1_i2v_480p_14B_fp8_scaled.safetensors</p>
<p>&nbsp;</p>
<p>然后移到ComfyUI-aki-V202504版\ComfyUI\models\diffusion_models目录下面。</p>
<h2>text_encoders下载</h2>
<p data-pid="JK1b4S1r">打开下面这个页面，下载text_encoders：</p>
<p data-pid="8lu9G1nI"><a class=" external" href="https://link.zhihu.com/?target=https%3A//huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/text_encoders" rel="noopener nofollow" target="_blank" data-za-detail-view-id="1043"><span class="invisible">https://<span class="visible">huggingface.co/Comfy-Or<span class="invisible">g/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/text_encoders</span></span></span></a></p>
<ul>
<li data-pid="sS5uMvpq">如果显存 &gt;= 12G，选择第一个text_encoder<code>下载</code></li>
<li data-pid="zW5Jx2H2">如果显存 &lt; 12G，选择第二个text_encoder<code>下载</code></li>



</ul>
<p>选择第一个下载</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522181818812-1458497942.png" alt="" loading="lazy"></p>
<p>&nbsp;下载到本地后，移到下载到本地后，移到ComfyUI整合包的ComfyUI\models\text_encoders目录下。</p>
<h2>vae下载</h2>
<p data-pid="SpWR4vdC">打开下面这个页面，下载vae：</p>
<p data-pid="SpWR4vdC"><a href="https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/vae" target="_blank" rel="noopener nofollow">https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/vae</a></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522182001690-1128479729.png" alt="" loading="lazy"></p>
<p>&nbsp;下载到本地后，移到下载到本地后，移到ComfyUI整合包的ComfyUI\models\vae目录下。</p>
<h1>四、工作流下载</h1>
<p data-pid="u4H4pMS4">打开下面这个页面，下载工作流：</p>
<p data-pid="u4H4pMS4"><a href="https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/example%20workflows_Wan2.1" target="_blank" rel="noopener nofollow">https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/example%20workflows_Wan2.1</a></p>
<p data-pid="KxXOvU0h">我们根据第三步下载的diffusion_model，相对应地选择第一个和第三个工作流下载：</p>
<p data-pid="KxXOvU0h"><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522182125286-1088351547.png" alt=""></p>
<p>下载到本地后，移到下载到本地后，移到ComfyUI整合包的ComfyUI\user\default\workflows目录下。</p>
<h1>五、文生视频</h1>
<p data-pid="WfJ0Mwq_">第一步，打开秋叶启动器，确保是最新版本，点击左上角，一键启动。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522182404729-1697765502.png" alt="" loading="lazy"></p>
<p>启动完成后，会自动打开网页：&nbsp;http://127.0.0.1:8188/</p>
<p>&nbsp;</p>
<p>第二步，点击左边侧栏，打开文生视频工作流。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522182742247-296118470.png" alt="" loading="lazy"></p>
<p>&nbsp;第三步，调整diffusion_model、text_encoder和vae的配置，选择之前下载好的模型。</p>
<p>&nbsp;</p>
<p><span style="color: rgba(255, 0, 0, 1)"><strong>注意必须要手动选择，umt5 xxl fp16.safetensors</strong></span></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523101431378-1770947539.png" alt="" loading="lazy"></p>
<p><span style="color: rgba(255, 0, 0, 1)"><strong>注意必须要手动选择，这里选择wan2.1 t2v 1.3B fp16.safetensors</strong></span></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523101517484-339120113.png" alt="" loading="lazy"></p>
<p><span style="color: rgba(255, 0, 0, 1)"><strong>注意必须要手动选择，wan 2.1 vae.safetensors</strong></span></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523101615796-1117831247.png" alt="" loading="lazy"></p>
<p>第四步，在CLIP文本编码器框输入正向提示词</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523101702797-1006973524.png" alt="" loading="lazy"></p>
<p>这里的提示词如下：</p>
<div class="cnblogs_code">
<pre>阳光明媚的草原上，一位年轻的中国美女正在欢快地散步，镜头采用中景拍摄，完美捕捉到她全身的曼妙姿态。她有着标志性的可爱脸型，瓜子脸搭配长发自然卷，淡妆之下，笑起来时左右脸颊上绽放出两个浅浅的酒窝，尽显青春活力与甜美气质。淡蓝色连衣裙上点缀着白色与淡黄色小花，领口微微敞开，裙摆轻柔垂落至脚踝，随着微风轻轻摆动，展现出玲珑有致的身材曲线，健康优雅。她脚蹬一双舒适凉鞋，漫步绿草如茵的草地，阳光温柔洒落，为她披上一层柔和金辉，她时而轻笑，时而低头细嗅青草芬芳，满溢轻松愉悦。广袤草原延伸至远方，黄、红、紫等各色野花星星点点，蓝天白云高远澄净，共同勾勒出清新自然的夏日画卷，映衬着她活力四溢的年轻身姿。</pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;完整流程如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523101837953-1961519836.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>最后点执行按钮，开始生成视频。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523101856621-2130548459.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>注意看，左上角会显示进度，中间顶部会显示CPU，内存，GPU的使用率</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523102227119-1044610932.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>生成过程中，GPU使用率会很高</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250522170334798-1989217585.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>不过不用担心，大概2分钟左右，就可以完成了。</p>
<p>&nbsp;</p>
<p>生成完成后，左下角，会播放效果</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523102419654-1012964485.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>生成的图片，会保存在目录ComfyUI-aki-V202504版\ComfyUI\output</p>
<p>会出现一个ComfyUI_00001_.webp文件，打开文件，效果如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523102727376-995863647.webp" alt=""></p>
<p>这是1.3b的效果，花草有点模糊，人物还是比较清晰的。</p>
<p>&nbsp;</p>
<h1>六、图生视频</h1>
<p>第一步，点击左边侧栏，打开图生视频工作流。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523131511188-1150334422.png" alt="" loading="lazy"></p>
<p>第二步，调整diffusion_model、text_encoder、clip_vision和vae的配置，选择之前下载好的模型。</p>
<p>&nbsp;</p>
<p><span style="color: rgba(255, 0, 0, 1)"><strong>注意必须要手动选择，umt5 xxl fp16.safetensors</strong></span></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523131546732-1925726653.png" alt="" loading="lazy"></p>
<p><strong><span style="color: rgba(255, 0, 0, 1)">&nbsp;注意必须要手动选择，这里是wan2.1i2v 480p 14B fp8 scaled.safetensors</span></strong></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523131641613-2023075862.png" alt="" loading="lazy"></p>
<p><span style="color: rgba(255, 0, 0, 1)"><strong>&nbsp;注意必须要手动选择，wan 2.1 vae.safetensors</strong></span></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523131732170-1023382157.png" alt="" loading="lazy"></p>
<p><strong><span style="color: rgba(255, 0, 0, 1)">&nbsp;注意必须要手动选择，clip vision h.safetensors</span></strong></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523131855703-1828959220.png" alt="" loading="lazy"></p>
<p>第三步，上传图片</p>
<p>点击upload，上传本地图片</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523132020540-1876140086.png" alt="" loading="lazy"></p>
<p>图片下载地址为：<a href="https://img2.baidu.com/it/u=3946513537,3753906297&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=800&amp;h=1200" target="_blank" rel="noopener nofollow">https://img2.baidu.com/it/u=3946513537,3753906297&amp;fm=253&amp;fmt=auto&amp;app=138&amp;f=JPEG?w=800&amp;h=1200</a></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523132222158-630604463.jpg" alt=""></p>
<p>&nbsp;</p>
<p>在CLIP文本编码器框输入正向提示词</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523132246949-2105366983.png" alt="" loading="lazy"></p>
<p>文本内容：</p>
<div class="cnblogs_code">
<pre>一位年轻美丽的女性，她面带灿烂的微笑，眼神明亮而温柔。她端着一盆色彩鲜艳、水果种类丰富的水果沙拉。她迈着轻快而优雅的步伐向我走来，仿佛带着满满的活力与清新之感。</pre>
</div>
<p>&nbsp;</p>
<p>修改图片尺寸，因为图片是800x1200的，所以保存的图像，尺寸也要和原始图片一致才行。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523132635154-1630342632.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>图生视频的工作流，完整如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523132413351-335779711.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p data-pid="rzOxuseV">从上图可以看到，图生视频的工作流相比文生视频，有两个主要的区别：</p>
<p data-pid="RBIoWnEK">1、多了一个clip_vision的节点；</p>
<p data-pid="WIVP8Uoo">2、diffusion_model换成了图生视频的模型。</p>
<p>&nbsp;</p>
<p>最后点执行按钮</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523132452865-1119326592.png" alt="" loading="lazy"></p>
<p>开始生成视频。</p>
<p>&nbsp;</p>
<p>注意：耗时会比较长，因为用的是14b模型，16GB显存有点吃力。</p>
<p>整个过程，大概持续了35分钟，最后看一下效果图。</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202505/1341090-20250523132810220-2105794288.webp" alt=""></p>
<p>&nbsp;</p>
<p>我噻，效果还是比较惊艳了，尤其是她笑的笑容，我沦陷了...</p>
<p>&nbsp;</p>
<p>本文参考链接：</p>
<p>https://zhuanlan.zhihu.com/p/30647063188</p>
<p>https://blog.csdn.net/weixin_59486588/article/details/147836457</p>
<p>&nbsp;</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.6985217037326389" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-05-23 13:29">2025-05-23 10:29</span>&nbsp;
<a href="https://www.cnblogs.com/xiao987334176">肖祥</a>&nbsp;
阅读(<span id="post_view_count">348</span>)&nbsp;
评论(<span id="post_comment_count">4</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18891735);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18891735', targetLink: 'https://www.cnblogs.com/xiao987334176/p/18891735', title: 'ComfyUI+通义万相 Wan2.1系列生成视频教程' })">举报</a>
</div>
        