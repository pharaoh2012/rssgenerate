<!----> <meta itemprop="headline" content="自己跑 AI 模型和知识库，永远免费用！"> <meta itemprop="keywords" content="前端,JavaScript,OpenAI"> <meta itemprop="datePublished" content="2024-11-23T13:02:38.000Z"> <meta itemprop="image" content="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-assets/icon/icon-128.png~tplv-t2oaga2asx-image.image"> <div itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="name" content="zxg_神说要有光"> <meta itemprop="url" content="https://juejin.cn/user/2788017216685118"></div> <div itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="掘金"> <div itemprop="logo" itemscope="itemscope" itemtype="https://schema.org/ImageObject"><meta itemprop="url" content="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-assets/icon/icon-white-180.png~tplv-t2oaga2asx-image.image"> <meta itemprop="width" content="180"> <meta itemprop="height" content="180"></div></div> <h1 class="article-title" data-v-7cdd11fb="">
            自己跑 AI 模型和知识库，永远免费用！
            <!----> <!----></h1> <div class="author-info-block block-hidden" data-v-7cdd11fb=""><div class="author-info-box" data-v-7cdd11fb=""><div class="author-name" data-v-7cdd11fb=""><a href="/user/2788017216685118/posts" target="_blank" rel="" class="jj-link username username ellipsis" data-v-65b50b51="" data-v-1800aadb="" data-v-7cdd11fb=""><span class="name" style="max-width:160px;" data-v-65b50b51="" data-v-1800aadb="">
    zxg_神说要有光
  </span> <!----> <!----> <!----> </a></div> <div class="meta-box" data-v-7cdd11fb=""><time datetime="2024-11-23T13:02:38.000Z" title="Sat Nov 23 2024 13:02:38 GMT+0000 (Coordinated Universal Time)" class="time" data-v-7cdd11fb="">
                    2024-11-23
                  </time> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" class="read-icon" data-v-7cdd11fb=""><path d="M7.90078 2.80078C4.49278 2.80078 1.74745 6.11672 0.800781 7.77469C1.74745 9.58339 4.49278 13.2008 7.90078 13.2008C11.3088 13.2008 14.0541 9.58339 15.0008 7.77469C14.0541 6.11672 11.3088 2.80078 7.90078 2.80078Z" stroke="currentColor" data-v-7cdd11fb=""></path><circle cx="7.89922" cy="8.00078" r="2.2" stroke="currentColor" data-v-7cdd11fb=""></circle></svg> <span class="views-count" data-v-7cdd11fb="">
                    16,712
                  </span> <span class="read-time" data-v-7cdd11fb=""><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-7cdd11fb=""><rect width="16" height="16" fill="none" data-v-7cdd11fb=""></rect><circle cx="8" cy="8" r="5.65625" stroke="#8A919F" data-v-7cdd11fb=""></circle><path d="M7.69141 5.18652V8.30924H10.8141" stroke="#8A919F" stroke-linecap="round" stroke-linejoin="round" data-v-7cdd11fb=""></path></svg>
                    阅读10分钟
                  </span> <!----></div></div> <div style="flex:1;" data-v-7cdd11fb=""></div> <!----> <!----></div> <!----> <!----> <!----> <div id="article-root" itemprop="articleBody" class="main" data-v-7cdd11fb=""><div class="article-viewer markdown-body result"><p>我们经常会问 AI 一些问题，大多数情况下，它会综合各种资料，给我们想要的回答。</p>
<p>但有的时候就不行了：</p>
<p>比如我写了 10 年的日记，这些都是私密信息，没有公开。</p>
<p>那让 AI 给我总结下我的一些经历，是不是就做不到了？</p>
<p>那如何在不把这些信息公开到互联网的情况下，让 AI 给我总结下呢？</p>
<p>这时候我们就需要搭建本地的知识库了。</p>
<p>而且搭了本地知识库也不行，用线上的 AI 模型的时候，万一它把我的日记记下来了呢？</p>
<p>如果我想绝对的安全那就也不能用这些线上模型。</p>
<p>这时候就需要跑本地 AI 模型了。</p>
<p>所以，这篇文章我们就来学习下本地知识库 + 本地模型。</p>
<p>除了上面说的安全外，它们还不用花一分钱！</p>
<p>首先，我们先用下线上的 AI 模型。</p>
<p>国内用国外的模型一般都要找个代理商来用。</p>
<p>这种代理挺多的，我这里用的 <a href="https://link.juejin.cn?target=https%3A%2F%2Fgpt302.saaslink.net%2Fbzgo6g" target="_blank" title="https://gpt302.saaslink.net/bzgo6g" ref="nofollow noopener noreferrer">302.ai</a>，你也可以用别的</p>
<p>这种代理都是给你对接好了国内、国外各种模型，可以直接用。</p>
<p>充值后，生成一个 API KEY：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b0f21134da794007971d552e35e8bdcd~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2580&amp;h=1340&amp;s=274617&amp;e=png&amp;b=ffffff" alt="" loading="lazy"></p>
<p>接下来就可以调用 openai 的接口了。</p>
<p>我们创建个项目：</p>
<pre><code class="hljs language-perl" lang="perl"><span class="hljs-keyword">mkdir</span> <span class="hljs-keyword">my</span>-ai-test
cd <span class="hljs-keyword">my</span>-ai-test
npm init -<span class="hljs-keyword">y</span>
</code></pre>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9a2b9dbe838e46bea1dec4a915e70db2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=892&amp;h=678&amp;s=87470&amp;e=png&amp;b=010101" alt="image.png" loading="lazy"></p>
<p>进入项目，安装 openai 的 sdk：</p>
<pre><code class="hljs language-css" lang="css">npm install <span class="hljs-attr">--save</span> openai
</code></pre>
<p>然后创建 index.mjs（.mjs 的后缀是告诉 node 这个文件是 es module 的）</p>
<pre><code class="hljs language-javascript" lang="javascript"><span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span> <span class="hljs-keyword">from</span> <span class="hljs-string">'openai'</span>;

<span class="hljs-keyword">const</span> client = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>({
    <span class="hljs-attr">apiKey</span>: <span class="hljs-string">'你的 API KEY'</span>,
    <span class="hljs-attr">baseURL</span>: <span class="hljs-string">'https://api.302.ai/v1'</span>
});

<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span> <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) {
  <span class="hljs-keyword">const</span> stream = <span class="hljs-keyword">await</span> client.<span class="hljs-property">chat</span>.<span class="hljs-property">completions</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">model</span>: <span class="hljs-string">"gpt-4"</span>,
    <span class="hljs-attr">messages</span>: [
      { <span class="hljs-attr">role</span>: <span class="hljs-string">'user'</span>, <span class="hljs-attr">content</span>: <span class="hljs-string">'今天晚上吃什么，给我一些推荐一些清淡点的菜'</span> },
    ],
    <span class="hljs-attr">stream</span>: <span class="hljs-literal">true</span>
  });

  <span class="hljs-keyword">for</span> <span class="hljs-keyword">await</span> (<span class="hljs-keyword">const</span> chunk <span class="hljs-keyword">of</span> stream) {
    process.<span class="hljs-property">stdout</span>.<span class="hljs-title function_">write</span>(chunk.<span class="hljs-property">choices</span>[<span class="hljs-number">0</span>]?.<span class="hljs-property">delta</span>?.<span class="hljs-property">content</span> || <span class="hljs-string">''</span>);
  }
}

<span class="hljs-title function_">main</span>();
</code></pre>
<p>跑一下：</p>
<pre><code class="hljs language-bash" lang="bash">node ./src/index.mjs
</code></pre>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/25031421eae94a1c976667ffe370d93b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1864&amp;h=998&amp;s=155094&amp;e=gif&amp;f=59&amp;b=1a1a1a" alt="" loading="lazy"></p>
<p>如果问它我的日记里的一些东西，他就不知道了：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ae4fd839c5dd47a4b8e06ce8ce270f07~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2136&amp;h=652&amp;s=158496&amp;e=png&amp;b=1d1d1d" alt="image.png" loading="lazy"></p>
<p>这时候就需要搭建一个知识库了。</p>
<p>我这里用的是 <a href="https://link.juejin.cn?target=https%3A%2F%2Fmaxkb.cn%2F" target="_blank" title="https://maxkb.cn/" ref="nofollow noopener noreferrer">maxkb</a>，一个开源的知识库</p>
<p>用 docker 跑一下：</p>
<p>首先没安装 docker 的话去官网下载下桌面端 <a href="https://link.juejin.cn?target=https%3A%2F%2Fwww.docker.com%2F" target="_blank" title="https://www.docker.com/" ref="nofollow noopener noreferrer">www.docker.com/</a></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6478ee495cc04028a5ce4586f4364842~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2264&amp;h=1052&amp;s=180680&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>跑起来后，可以看到镜像列表：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1db2ce29f879468488c11da3d53b09f2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2096&amp;h=1178&amp;s=270255&amp;e=png&amp;b=f6f6f8" alt="image.png" loading="lazy"></p>
<p>镜像跑起来的容器列表：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b8f3a30432c448d68f7c4cd21ab1ca77~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2106&amp;h=1078&amp;s=295037&amp;e=png&amp;b=f6f6f8" alt="image.png" loading="lazy"></p>
<p>我们搜索下 maxkb 的镜像（这步可能需要科学上网）：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/635687b987ae418b8628c5a311ef05f3~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1846&amp;h=1132&amp;s=227729&amp;e=png&amp;b=f2f3f7" alt="image.png" loading="lazy"></p>
<p>点击 run，它会下载镜像，然后让你填入参数来跑：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cd14b097cf3547448610ae2a54d874ee~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1200&amp;h=1308&amp;s=166106&amp;e=png&amp;b=fefefe" alt="image.png" loading="lazy"></p>
<p>输入容器名、映射的端口号、挂载的数据卷</p>
<p>映射端口的意思是你把本地的 8080 端口映射到容器里的 8080 端口，这样你就能通过本地的 8080 端口访问容器里的服务了。</p>
<p>挂载数据卷也是这个意思，把本地的 /Users/guang/.maxkb（这个目录是随便的，windows 下就是 c://xxx ） 目录挂载到容器里的 /var/lib/postgresql/data（这个目录是固定的）</p>
<p>还需要挂载本地的另一个目录到容器里的 /opt/maxkb/app/sandbox/python-packages</p>
<p>接下来点击 run，把容器跑起来：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e5d7c96813b94bee828c8aca091fec11~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1648&amp;h=1180&amp;s=276688&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>跑起来之后访问 <a href="https://link.juejin.cn?target=http%3A%2F%2Flocalhost%3A8080" target="_blank" title="http://localhost:8080" ref="nofollow noopener noreferrer">http://localhost:8080</a> 就好了。</p>
<p>登录页面是这样的：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/47a3f19269a24adcaad68b7d62d46edb~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2376&amp;h=1256&amp;s=2004435&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>初始用户名和密码是： admin、MaxKB@123..</p>
<p>点击创建知识库：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0d9066fb18f749708a8b3ee9d8e59ee5~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1402&amp;h=804&amp;s=110869&amp;e=png&amp;b=f3f5f8" alt="image.png" loading="lazy"></p>
<p>这个知识库是放我的看过的小说：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/197a5d982c8f46738b7e29f6cbaa36e2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1432&amp;h=1102&amp;s=113579&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>点击上传文档：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0030563c13fb4fe8afa469603bf2bd74~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1696&amp;h=602&amp;s=85268&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>文档可以是文本的 txt、markdown 等，也可以是表格的 excel、csv 等：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bf2e4119a9cb4f019a65443bfe0e7e73~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1582&amp;h=828&amp;s=99770&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>把这个小说上传上去</p>
<p>秋日的秘密.txt</p>
<pre><code class="hljs language-txt" lang="txt">秋天的午后，阳光透过金黄的树叶洒在小镇的石板路上，给人一种温暖而宁静的感觉。艾米莉提着一篮苹果，沿着小路走向镇外的森林。她的步伐轻快，心中充满了期待，因为她正准备去见一个不为人知的秘密朋友。

在森林的深处，有一片隐蔽的空地，那里有一座古老的石亭，几乎被藤蔓和苔藓覆盖。艾米莉第一次发现这个地方是在一个月前，她偶然间走得太远，结果误入了这片神秘的区域。自那以后，她每周都会来这里，和她的新朋友见面。

她的朋友是一个名叫卢卡斯的年轻画家，他有着一头卷曲的黑发和一双总是带着微笑的眼睛。卢卡斯在镇上并不为人所知，因为他总是躲在森林里，专注于他的画作。他的画布上充满了色彩斑斓的秋景，每一幅都像是一个梦境。

“艾米莉！”卢卡斯的声音从亭子里传来，他正站在一幅未完成的画作前，手中握着调色板。

“我带了些苹果来，”艾米莉微笑着回应，将篮子放在石桌上。“你今天画了什么？”

卢卡斯指了指画布，上面是一片金色的树林，阳光透过树叶，形成斑驳的光影。“这是我今天早上看到的景象。秋天总是充满了灵感。”

艾米莉仔细端详着画，心中不由得感叹卢卡斯的才华。“如果你把这些画拿去镇上展出，一定会大受欢迎的。”

卢卡斯笑了笑，摇摇头。“我更喜欢这里的安静。我画画是为了自己，而不是为了展示。”

两人聊了一会儿，直到太阳开始西沉，空气中弥漫着一丝凉意。艾米莉知道是时候回家了，她不想让父母担心。

“明天见，卢卡斯。”她挥了挥手，准备离开。

“明天见，艾米莉。”卢卡斯微笑着回应，目送她的身影消失在树林间。

然而，第二天，当艾米莉再次来到石亭时，卢卡斯却没有出现。她等了很久，心中开始有些不安。她在森林里四处寻找，但卢卡斯仿佛从未存在过一样，消失得无影无踪。

接下来的几天，艾米莉依然没有见到卢卡斯，她开始担心是不是发生了什么事情。她决定去镇上的画廊打听，因为她记得卢卡斯曾提到过他有一个朋友在那里工作。

画廊的老板是一个和蔼的老人，他听完艾米莉的描述后，露出了一个神秘的微笑。“你说的卢卡斯，是不是有一头卷曲的黑发？”

艾米莉点点头，心中燃起一丝希望。

“那可能是我年轻时的一个朋友，”老人说道，眼中闪烁着怀旧的光芒。“他是个天才画家，但很久以前就离开了这里。听说他去了一个遥远的地方。”

艾米莉愣住了，她不知道该如何理解这些话。她开始怀疑自己是否在森林中遇见的卢卡斯只是一个幻影，或者是她自己的想象。

但当她回到石亭时，发现桌上多了一幅画，那是她和卢卡斯在一起的情景。画中的两人笑得那么真实，仿佛在告诉她，那个秋日的秘密确实存在过。

艾米莉小心翼翼地拿起画，心中充满了温暖。也许卢卡斯真的去了一个遥远的地方，但他留下的画作和回忆，将永远伴随着她。

从那以后，艾米莉每年秋天都会去石亭，带上一篮苹果，静静地坐在那儿，仿佛卢卡斯还在她身边，继续讲述着那些关于秋天的秘密。
</code></pre>
<p>这个小说绝对是网上搜不到的，因为我是让 AI 写的：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/310ec0632ca94e22b3e3b6317578589f~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1732&amp;h=880&amp;s=196272&amp;e=png&amp;b=fafafa" alt="image.png" loading="lazy"></p>
<p>不信你可以问下试试：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3f730b42c523409c9d5f41d725a0b22b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1996&amp;h=748&amp;s=169456&amp;e=png&amp;b=1d1d1d" alt="image.png" loading="lazy"></p>
<p>上传这个文档：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0a3ec3387fc478089db53517da2e3e0~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2174&amp;h=1176&amp;s=141206&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>这样，知识库里就有了一个文档：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dab68d2a49514996b1dcb009c358cd46~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1230&amp;h=596&amp;s=68618&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>然后点击创建一个应用：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f6b1bf82a1e0493da8b1610cd287d8c5~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1390&amp;h=676&amp;s=103599&amp;e=png&amp;b=f2f5f8" alt="image.png" loading="lazy"></p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/117e9e0b62664c718e3bd9142cc9f09b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1444&amp;h=1002&amp;s=113541&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>配置应用前，我们先要配置下线上的模型：</p>
<p>点击系统管理 &gt; 模型设置 &gt; 添加模型：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/158c31d1a1894256a92f070de26f85c6~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2188&amp;h=972&amp;s=255432&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>添加一个 openai 的模型，填入刚才我们用的代理商的 api key 和 base url</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/777c591bd93446ab8c6369a334456527~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1840&amp;h=1202&amp;s=235130&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>点击添加：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/35e641b8eea34257a8f581fefb6d381d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1874&amp;h=1414&amp;s=268516&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c39640f85544cd6ab7add8e597492bf~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2194&amp;h=744&amp;s=142304&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>然后回过头来继续配置应用：</p>
<p>选择刚才创建的模型：</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5f9022a93e394ba3837970590925c673~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1060&amp;h=966&amp;s=105715&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>关联上小说的知识库：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a46db398b9ff45a79afba15dc87349ae~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2696&amp;h=1346&amp;s=3025869&amp;e=gif&amp;f=48&amp;b=fefefe" alt="2024-11-23 20.01.55.gif" loading="lazy"></p>
<p>点击右上角的保存并发布。</p>
<p>之后就可以在概览里看到 base url 和 api key 了：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3c5278b4bbf9409e974563bb10d28cb4~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2258&amp;h=576&amp;s=120319&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cff6f5cf61474244ab960b38d2252b31~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1604&amp;h=538&amp;s=59053&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>把它复制出来，替换 index.mjs 里的配置：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/57a5d68adc4b41e7aaa122b230f67e3c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1628&amp;h=242&amp;s=62515&amp;e=png&amp;b=1f1f1f" alt="image.png" loading="lazy"></p>
<p>这时候就可以问这本小说的问题了：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b54453905fca4e59bcab428d04859a09~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2112&amp;h=798&amp;s=307437&amp;e=png&amp;b=1b1b1b" alt="image.png" loading="lazy"></p>
<p>我们多问点问题试试：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/57cbc33b569a4de0ae4d149b8e3e1027~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2138&amp;h=394&amp;s=114686&amp;e=png&amp;b=1c1c1c" alt="image.png" loading="lazy"></p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fd0a8ca4bafc48cb84023a6ab6d70b7b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2140&amp;h=360&amp;s=115873&amp;e=png&amp;b=1c1c1c" alt="image.png" loading="lazy"></p>
<p>回答的都挺好的。</p>
<p>当然，这个小说内容比较少，你完全可以找一个内容更多的知识库，来让 AI 解读。</p>
<p>这就是知识库的作用！</p>
<p>我们企业内部的一些私有组件库，就可以把信息整理一下，做成知识库告诉 AI。</p>
<p>这样，它再生成的代码就是基于内部组件库的了。</p>
<p>那再看下第二个问题，虽然知识库是本地部署的，但是用的模型是线上的啊</p>
<p>这样可能有安全问题，所以我们要自己部署个本地模型。</p>
<p>我们用 ollama 来安装本地模型。</p>
<p>在 ollama 官网 <a href="https://link.juejin.cn?target=https%3A%2F%2Follama.com%2F" target="_blank" title="https://ollama.com/" ref="nofollow noopener noreferrer">ollama.com/</a> 下载：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fc605d1b8d4e4595a0aa8aa044e1e68c~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2346&amp;h=1232&amp;s=155010&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>安装后就可以用  ollama 命令了。</p>
<p>我们跑下 qwen 这个模型，它是中文开源模型：</p>
<pre><code class="hljs language-arduino" lang="arduino">ollama run qwen2<span class="hljs-number">.5</span>:<span class="hljs-number">1.5b</span>
</code></pre>
<p>从 0.5b 到 72b 是参数多少不同，消耗计算资源不同：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/27ec252628db446fbaa593bb76cf1f52~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2002&amp;h=1196&amp;s=174876&amp;e=png&amp;b=fefefe" alt="image.png" loading="lazy"></p>
<p>我们这里下个小的来测试：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a80beed3c4e24192b8a56b70805f7a10~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1376&amp;h=808&amp;s=191801&amp;e=png&amp;b=010101" alt="image.png" loading="lazy"></p>
<p>下载后问了下问题，可以看到，大模型跑起来了。</p>
<p>这个窗口不要关掉，再开一个窗口调用下 api：</p>
<pre><code class="hljs language-vbnet" lang="vbnet">curl http://localhost:<span class="hljs-number">11434</span>/api/chat -d <span class="hljs-comment">'{</span>
  <span class="hljs-string">"model"</span>: <span class="hljs-string">"qwen2.5:1.5b"</span>,
  <span class="hljs-string">"messages"</span>: [
    { <span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"介绍下西游记"</span> }
  ]
}<span class="hljs-comment">'</span>
</code></pre>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d8d8f272050646e18eabc141c8e28441~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1154&amp;h=744&amp;s=165483&amp;e=png&amp;b=020202" alt="image.png" loading="lazy"></p>
<p>上面是流式返回的内容。</p>
<p>可以看到 API 也是通的。</p>
<p>接下来就可以把这个本地模型配到 maxkb 了。</p>
<p>添加 Ollama 模型：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/06a4babf748d4283acdbbeecdc2322fa~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2010&amp;h=1060&amp;s=193442&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d95feaa4d18741d68fde060d0db18112~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1322&amp;h=1402&amp;s=170200&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>填下名字、模型名、API 域名和 API Key</p>
<p>这里模型名填和本地一样的</p>
<p>API 域名用 <a href="https://link.juejin.cn?target=http%3A%2F%2Fhost.docker.internal%3A11434" target="_blank" title="http://host.docker.internal:11434" ref="nofollow noopener noreferrer">host.docker.internal:11434</a> （就是容器内的 locahost）</p>
<p>API Key 填啥都行</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4366773ba19f41cca7fd9edbd2e2fe39~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2106&amp;h=892&amp;s=130762&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>然后改下小说助手的设置，换成本地的 Ollama 模型，点击保存：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d4c9c3cda8294d958acb00442e56021f~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1498&amp;h=802&amp;s=89383&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>为了证明我这次用的是本地的模型，我把线上 AI 的所有 API Key 都禁用掉了：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f23f0d0b02a44718d88b6e6a67fa816~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=2742&amp;h=1172&amp;s=263772&amp;e=png&amp;b=ffffff" alt="image.png" loading="lazy"></p>
<p>然后我让它给续写一段故事：</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f33226ec9f3b44aa8e9d8d364b2e8d38~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1752&amp;h=1150&amp;s=398199&amp;e=png&amp;b=1a1a1a" alt="image.png" loading="lazy"></p>
<p>你仔细看下，写的还真挺好的。</p>
<p>本地用的这个 qwen2.5 模型真不错，一般情况下不用花钱去买线上的模型用了。</p>
<p>用本地知识库放一些私有的信息，然后交给本地的 AI 模型去解读，完全不用花一分钱，效果也足够用。</p>
<h2 data-id="heading-0">总结</h2>
<p>今天我们学了本地知识库、本地 AI 模型，并用它来做了一个阅读小说的助手。</p>
<p>AI 模型只知道公开的信息，如果想让它对一些你的私有信息做解读，就需要用到知识库了。</p>
<p>我们用 docker 跑了 maxkb 这个开源知识库，完全免费用，数据都是存在本地的相当安全。</p>
<p>你可以用它接入线上 AI 模型来用，但如果担心这样不安全，也可以用 Ollma 跑个本地 AI 模型。</p>
<p>我们试了下本地 Ollama 跑的 qwen2.5 模型，然后搭配小说知识库里的一篇小说，续写啥的完全不成问题，解读也很到位。</p>
<p>当然，这些不是前端领域的应用。</p>
<p>对前端来说，最有价值的是把内部的组件库、文档等做成知识库，让 AI 生成的代码用内部组件库来写，也可以让它来做文档查询助手。</p>
<p>本地的 AI 模型 + 本地的知识库，完全不用花一分钱，但效果也足够用。</p>
<blockquote>
<p>更多内容可以看我的小册<a href="https://juejin.cn/book/7408937821752262665" target="_blank" title="https://juejin.cn/book/7408937821752262665">《Node.js CLI 通关秘籍》</a></p>
</blockquote></div></div>