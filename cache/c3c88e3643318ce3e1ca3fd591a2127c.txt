
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/ludangxin/p/18913321" title="发布于 2025-06-05 23:33">
    <span role="heading" aria-level="2">1. LangChain4j 初识，想使用Java开发AI应用？</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="1-简介">1. 简介</h2>
<p><strong>LangChain4j</strong> 是一个基于 Java 的开源框架，用于开发 <strong>人工智能驱动的应用程序</strong>，尤其是涉及 <strong>大语言模型（LLM）交互</strong> 的场景。它的设计目标是简化开发者与大语言模型的集成过程，提供一套工具和组件来处理复杂的 LLM 应用逻辑，例如对话管理、提示工程、工具调用等。</p>
<h3 id="核心功能与特点">核心功能与特点</h3>
<ol>
<li><strong>大语言模型集成</strong>
<ul>
<li>支持多种 LLM 接入方式，包括：
<ul>
<li>本地运行的开源模型（如 Llama 2、ChatGLM 等）。</li>
<li>第三方 API 模型（如 OpenAI 的 GPT 系列、Anthropic 的 Claude 等）。</li>
</ul>
</li>
<li>通过统一的接口抽象，降低模型切换的成本。</li>
</ul>
</li>
<li><strong>提示工程工具</strong>
<ul>
<li>提供模板化的提示构建器，帮助开发者结构化输入（如填充变量、管理上下文历史）。</li>
<li>支持动态组合提示链（Prompt Chain），例如根据用户问题逐步调用不同的提示模板。</li>
</ul>
</li>
<li><strong>对话状态管理</strong>
<ul>
<li>维护多轮对话的上下文，支持记忆管理（如设置上下文窗口大小、选择性遗忘旧信息）。</li>
<li>可集成外部知识库（如向量数据库）实现长期记忆。</li>
</ul>
</li>
<li><strong>工具调用能力</strong>
<ul>
<li>支持调用外部工具（如计算器、数据库查询、API 接口等），并将工具返回结果整合到 LLM 的回答中。</li>
<li>提供工具调用的决策逻辑（如判断何时需要调用工具、如何解析工具返回结果）。</li>
</ul>
</li>
<li><strong>链式流程编排</strong>
<ul>
<li>通过 <strong>Chain</strong> 机制编排多个组件（如提示生成、工具调用、结果处理），形成复杂的工作流。</li>
<li>典型场景：问答系统中先调用搜索引擎获取实时数据，再用 LLM 生成回答。</li>
</ul>
</li>
<li><strong>扩展性与生态</strong>
<ul>
<li>基于 Java 生态，可轻松与 Spring框架集成。</li>
<li>支持自定义组件（如自定义提示策略、工具适配器），灵活适配业务需求。</li>
</ul>
</li>
</ol>
<h2 id="2-话不多说直接展示">2. 话不多说，直接展示</h2>
<p>本章主要通过单元测试的方式展示LangChain4j的各项功能，后续会出通过<code>LangChain4j Starter</code>的方式快速集成SpringBoot。</p>
<p>使用SDK版本信息如下：</p>
<p>​	Java: 21</p>
<p>​	SpringBoot: 3.4.5</p>
<p>​	LangChain4j: 1.0.1</p>
<p>AI 模型主要使用的是阿里的百炼平台免费的token，需要<code>ApiKey</code>的可以自行去申请, 平台地址如下：</p>
<p><a href="https://bailian.console.aliyun.com/?tab=model#/model-market" target="_blank" rel="noopener nofollow">https://bailian.console.aliyun.com/?tab=model#/model-market</a></p>
<h2 id="3-maven">3. Maven</h2>
<pre><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;3.4.5&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.ldx&lt;/groupId&gt;
    &lt;artifactId&gt;langchain-test&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;langchain-test&lt;/name&gt;
    &lt;description&gt;langchain-test&lt;/description&gt;

    &lt;properties&gt;
        &lt;java.version&gt;21&lt;/java.version&gt;
        &lt;langchain4j.version&gt;1.0.1&lt;/langchain4j.version&gt;
        &lt;guava.version&gt;33.0.0-jre&lt;/guava.version&gt;
    &lt;/properties&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
                &lt;artifactId&gt;langchain4j-bom&lt;/artifactId&gt;
                &lt;version&gt;${langchain4j.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
            &lt;artifactId&gt;langchain4j&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
            &lt;artifactId&gt;guava&lt;/artifactId&gt;
            &lt;version&gt;${guava.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
            &lt;artifactId&gt;langchain4j-open-ai&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
            &lt;artifactId&gt;langchain4j-reactor&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
<h2 id="4-构建模型对象">4. 构建模型对象</h2>
<pre><code class="language-java">// 普通的对话模型
private static ChatModel chatModel;

// 流式对话的模型（可以模拟gpt的打字机效果）
private static StreamingChatModel streamingChatModel;

@BeforeAll
public static void init_chat_model() {
    chatModel = OpenAiChatModel
            .builder()
            // apikey 通过环境变量的方式注入，大家可以使用自己的apikey
            .apiKey(System.getenv("LLM_API_KEY"))
            .modelName("qwen-plus")
            .baseUrl("https://dashscope.aliyuncs.com/compatible-mode/v1")
            .build();
    streamingChatModel = OpenAiStreamingChatModel
            .builder()
            .apiKey(System.getenv("LLM_API_KEY"))
            .modelName("qwen-plus")
            .baseUrl("https://dashscope.aliyuncs.com/compatible-mode/v1")
            .build();
}
</code></pre>
<h2 id="5-返回字符串">5. 返回字符串</h2>
<pre><code class="language-java">@Test
public void should_return_str_when_use_normal_chat() {
    String q = "你是谁";
    String content = chatModel.chat(q);
    log.info("call ai q: {}\na: {}", q, content);
}
</code></pre>
<blockquote>
<p>测试结果如下：</p>
</blockquote>
<pre><code>22:12:37.807 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- call ai q: 你是谁
a: 我是通义千问，阿里巴巴集团旗下的超大规模语言模型。我能够回答问题、创作文字，比如写故事、公文、邮件、剧本等，还能进行逻辑推理、编程，甚至表达观点和玩游戏。我在多国语言上都有很好的掌握，能为你提供多样化的帮助。有什么我可以帮到你的吗？
</code></pre>
<h2 id="6-返回流">6. 返回流</h2>
<blockquote>
<p>这里使用flux对象接收流式返回的结果</p>
<p>如果想流式的返回给前端，也可以使用SSE的方式返回（代码注释的部分）</p>
</blockquote>
<pre><code class="language-java">@Test
public void should_return_stream_when_use_stream_model() {
    Sinks.Many&lt;String&gt; sinks = Sinks
        .many()
        .multicast()
        .onBackpressureBuffer();
    Flux&lt;String&gt; flux = sinks.asFlux();
    StreamingChatResponseHandler streamingChatResponseHandler = new StreamingChatResponseHandler() {
        @Override
        public void onPartialResponse(String s) {
            sinks.tryEmitNext(s);
        }

        @Override
        public void onCompleteResponse(ChatResponse chatResponse) {
            sinks.tryEmitComplete();
        }

        @Override
        public void onError(Throwable throwable) {
            sinks.tryEmitError(throwable);
        }
    };
//        SseEmitter sse = new SseEmitter();
//        final StreamingChatResponseHandler streamingChatResponseHandler = LambdaStreamingResponseHandler.onPartialResponseAndError(s -&gt; {
//            try {
//                log.info("ai response stream data: {}", s);
//                sse.send(s);
//            } catch (IOException e) {
//                throw new RuntimeException(e);
//            }
//        }, e -&gt; sse.complete());
    streamingChatModel.chat("你是谁", streamingChatResponseHandler);
    flux
        .toStream()
        .forEach(partial -&gt; log.info("ai response stream data: {}", partial));
}
</code></pre>
<blockquote>
<p>测试结果如下:</p>
</blockquote>
<pre><code>22:45:26.442 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 我是
22:45:26.444 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 通
22:45:26.444 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 义
22:45:26.541 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 千问，阿里巴巴
22:45:26.771 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 集团旗下的通义
22:45:26.790 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 实验室自主研发的超
22:45:26.949 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 大规模语言模型。
22:45:27.103 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 我能够回答问题
22:45:27.199 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 、创作文字，
22:45:27.320 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 比如写故事、
22:45:27.482 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 写公文、
22:45:27.586 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 写邮件、写
22:45:27.789 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 剧本、逻辑推理
22:45:27.863 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 、编程等等，
22:45:27.982 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 还能表达观点，
22:45:28.435 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 玩游戏等。如果你
22:45:28.453 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 有任何问题或需要
22:45:28.576 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 帮助，欢迎随时
22:45:28.665 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ai response stream data: 告诉我！
</code></pre>
<h2 id="7-提示词模板">7. 提示词/模板</h2>
<pre><code class="language-java">@Test
public void should_return_prompt_content_when_use_prompt() {
    // 申明系统提示词
    // SystemMessage systemMessage = Prompt.from("你是一名java专家，请协助用户解决相应的专业性问题").toSystemMessage();
    // 申明提示词模板
    final PromptTemplate promptTemplate = new PromptTemplate("""
            👉 将文本改写成类似小红书的 Emoji 风格。
            请使用 Emoji 风格编辑以下段落，该风格以引人入胜的标题、每个段落中包含表情符号和在末尾添加相关标签为特点。请确保保持原文的意思。
            用户的提问信息如下:
            {{question}}
            """);                                  
    final UserMessage userMessage = promptTemplate
            .apply(Map.of("question", "你是谁"))
            .toUserMessage();
    ChatResponse chatResponse = chatModel.chat(userMessage);
    String content = chatResponse
            .aiMessage()
            .text();
    log.info("call ai q: {}\na: {}", userMessage.singleText(), content);
}
</code></pre>
<blockquote>
<p>测试结果如下：</p>
</blockquote>
<pre><code>22:46:36.572 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- call ai q: 👉 将文本改写成类似小红书的 Emoji 风格。
请使用 Emoji 风格编辑以下段落，该风格以引人入胜的标题、每个段落中包含表情符号和在末尾添加相关标签为特点。请确保保持原文的意思。
用户的提问信息如下:
你是谁

a: ✨你是谁？来认识一下我吧！💬

嗨，亲爱的朋友们！我是通义千问，阿里巴巴集团旗下的超大规模语言模型🤖。我可以通过学习海量文本数据，帮你回答问题、创作文字，甚至玩游戏哦～是不是很酷呢？🔥  

如果你有任何问题或需要帮助，尽管告诉我！我会尽力为你提供支持和支持❤️。让我们一起开启有趣的探索之旅吧！🌍  

#人工智能 #聊天机器人 #新知探索 #科技生活
</code></pre>
<h2 id="8-聊天记忆">8. 聊天记忆</h2>
<blockquote>
<p>中心逻辑其实就是：将最近的聊天内容存储起来，然后一股脑扔给AI😓</p>
</blockquote>
<pre><code class="language-java">@Test
public void should_return_memory_content_when_use_memory_chat() {
    String id = "zhangtieniu_01";
    String q1 = "你是谁";
    ChatMemory chatMemory = MessageWindowChatMemory
            .builder()
            // 会话隔离（不同用户的聊天信息互不干扰）
            .id(id)
            // 最大存储最近的5条聊天内容（存储太多影响性能&amp;token）
            .maxMessages(5)
            .build();
    // 将聊天内容放入记忆对象中
    chatMemory.add(UserMessage.from(q1));
    // SystemMessage 始终保存在messages中 且占用maxMessage名额
    chatMemory.add(SystemMessage.from("""
            👉 将文本改写成类似小红书的 Emoji 风格。
            请使用 Emoji 风格编辑以下段落，该风格以引人入胜的标题、每个段落中包含表情符号和在末尾添加相关标签为特点。请确保保持原文的意思。
            """));
    final ChatResponse chatResponse = chatModel.chat(chatMemory.messages());
    // 将ai的返回结果放入记忆对象中                                  
    chatMemory.add(chatResponse.aiMessage());
    String q2 = "我刚刚问了啥";
    chatMemory.add(UserMessage.from(q2));
    final ChatResponse chatResponse2 = chatModel.chat(chatMemory.messages());

    log.info("call ai q1: {}\na1: {}", q1, chatResponse
            .aiMessage()
            .text());
    log.info("==========================分隔符==========================");
    log.info("call ai q2: {}\na2: {}", q2, chatResponse2
            .aiMessage()
            .text());
}
</code></pre>
<blockquote>
<p>测试结果如下：</p>
</blockquote>
<pre><code>22:54:58.965 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- call ai q1: 你是谁
a1: 🌟 你好呀，让我来介绍一下自己！ 👋 我是通义千问，阿里巴巴集团旗下的超大规模语言模型。我不仅能陪你聊天，还能帮你写故事、邮件、剧本等等，甚至可以表达观点、玩游戏呢！🎮📖  

💡 无论你想聊生活中的小确幸 🍵 还是工作学习中的难题 📚，我都会尽力帮助你！希望我能成为你的贴心小伙伴～ ❤️  

#人工智能 #聊天伙伴 #创作助手 #日常分享
22:54:58.968 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- ==========================分隔符==========================
22:54:58.969 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- call ai q2: 我刚刚问了啥
a2: 🤔 呃... 让我查查！哦对！你刚刚问的是：“我是谁？” 这个问题让我有机会用小红书风格重新介绍自己呢！ 😊  

✨ 作为通义千问，我最喜欢的就是通过对话帮助别人啦！如果你还有其他问题或者需要灵感，随时可以问我哦～👇  

#回忆对话 #人工智能 #问答时间 #互动分享
</code></pre>
<h2 id="9-聊天内容持久化">9. 聊天内容持久化</h2>
<h3 id="91-store-handler">9.1 store handler</h3>
<blockquote>
<p>这里简单的使用map存储会话内容</p>
</blockquote>
<pre><code class="language-java">package com.ldx.langchaintest.store;

import com.google.common.collect.ArrayListMultimap;
import dev.langchain4j.data.message.ChatMessage;
import dev.langchain4j.store.memory.chat.ChatMemoryStore;

import java.util.List;

public class PersistentChatMemoryStoreTest implements ChatMemoryStore {
    public final ArrayListMultimap&lt;Object, ChatMessage&gt; messagesStore = ArrayListMultimap.create();

    @Override
    public List&lt;ChatMessage&gt; getMessages(Object memoryId) {
        return messagesStore.get(memoryId);
    }

    @Override
    public void updateMessages(Object memoryId, List&lt;ChatMessage&gt; messages) {
        messagesStore.put(memoryId, messages.getLast());
    }

    @Override
    public void deleteMessages(Object memoryId) {
        messagesStore.removeAll(memoryId);
    }
}
</code></pre>
<h3 id="92-实现">9.2 实现</h3>
<pre><code class="language-java">@Test
public void should_return_memory_content_when_use_store_chat() {
    String id = "zhangtieniu_01";
    String q1 = "张铁牛是一个高富帅，你是张铁牛的助手";
    PersistentChatMemoryStoreTest store = new PersistentChatMemoryStoreTest();
    ChatMemory chatMemory = MessageWindowChatMemory
            .builder()
            .id(id)
            .chatMemoryStore(store)
            .maxMessages(5)
            .build();
    chatMemory.add(UserMessage.from(q1));
    final ChatResponse chatResponse = chatModel.chat(chatMemory.messages());
    chatMemory.add(chatResponse.aiMessage());
    String q2 = "张铁牛是谁";
    chatMemory.add(UserMessage.from(q2));
    final ChatResponse chatResponse2 = chatModel.chat(chatMemory.messages());
    chatMemory.add(chatResponse2.aiMessage());
    
    // 获取当前会话的存储内容并打印
    List&lt;ChatMessage&gt; chatMessages = store.messagesStore.get(id);
    for (ChatMessage chatMessage : chatMessages) {
        log.info("session id: {}, message type: {}, message: {}", id, chatMessage.type(), chatMessage);
    }
}
</code></pre>
<blockquote>
<p>测试结果如下：</p>
</blockquote>
<pre><code>23:09:08.086 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- session id: zhangtieniu_01, message type: USER, message: UserMessage { name = null contents = [TextContent { text = "张铁牛是一个高富帅，你是张铁牛的助手" }] }
23:09:08.089 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- session id: zhangtieniu_01, message type: AI, message: AiMessage { text = "您好，我是张铁牛先生的助手。张铁牛先生确实是一位优秀的人士，他不仅外貌出众、家境优渥，而且非常有才华。作为他的助手，我会帮助他处理各种事务，确保他的生活和工作都井井有条。如果您有任何需要帮忙的事情，或者想了解张铁牛先生的相关信息，只要是我职责范围内的，我都会尽力提供帮助。请问有什么我可以为您服务的呢？" toolExecutionRequests = [] }
23:09:08.090 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- session id: zhangtieniu_01, message type: USER, message: UserMessage { name = null contents = [TextContent { text = "张铁牛是谁" }] }
23:09:08.090 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- session id: zhangtieniu_01, message type: AI, message: AiMessage { text = "张铁牛先生是一位非常杰出的人物。他出身于一个成功的企业家庭，拥有优越的教育资源和广泛的商业人脉。除了在商业领域的卓越成就外，他还以阳光、正直的形象受到周围人的喜爱。

作为一位“高富帅”，张铁牛先生不仅注重个人修养，还热衷于公益事业，经常参与慈善活动来回馈社会。同时，他对生活充满热情，兴趣爱好广泛，比如健身、旅行以及收藏艺术品等。

不过，请允许我提醒您，虽然他是公众眼中的完美人物，但他更希望被当作普通人来尊重，注重隐私保护。如果您有关于他的正面问题或需要安排相关事务，我很乐意为您提供帮助！" toolExecutionRequests = [] }
</code></pre>
<h2 id="10-function-call">10. function call</h2>
<h3 id="101-user-svc">10.1 user svc</h3>
<blockquote>
<p>声明一个自定义的user svc， 让ai去调用我们的业务方法</p>
</blockquote>
<pre><code class="language-java">import dev.langchain4j.agent.tool.P;
import dev.langchain4j.agent.tool.Tool;

public class UserServiceTest {
    @Tool("根据用户的名称获取对应的code")
    public String getUserCodeByUsername(@P("用户名称") String username) {
        if ("张铁牛".equals(username)) {
            return "003";
        }

        return "000";
    }
}
</code></pre>
<h3 id="102-实现">10.2 实现</h3>
<pre><code class="language-java">@Test
public void should_return_func_content_when_use_function_call() {
    final String q = "张铁牛的code是多少";
    List&lt;ChatMessage&gt; chatMessages = new ArrayList&lt;&gt;();
    chatMessages.add(UserMessage.from(q));
    final UserServiceTest userServiceTest = new UserServiceTest();
    final ChatRequest chatRequest = ChatRequest
            .builder()
            .messages(UserMessage.from(q))
            // 将工具类注入到上下文中
            .toolSpecifications(ToolSpecifications.toolSpecificationsFrom(userServiceTest))
            .build();
    final ChatResponse chatResponse = chatModel.chat(chatRequest);
    final AiMessage aiMessage = chatResponse.aiMessage();
    chatMessages.add(aiMessage);
    String a = aiMessage.text();

    // 在响应结果中判断是否有tool请求
    if (aiMessage.hasToolExecutionRequests()) {
        // 遍历tool req
        for (ToolExecutionRequest toolExecutionRequest : aiMessage.toolExecutionRequests()) {
            // 申明执行器 其实就是通过tool name 反射调用userServiceTest的方法
            ToolExecutor userToolExecutor = new DefaultToolExecutor(userServiceTest, toolExecutionRequest);
            final String uuid = UUID
                    .randomUUID()
                    .toString();
            final String executeResult = userToolExecutor.execute(toolExecutionRequest, uuid);
            log.info("execute user tool, name: {}, param:{}, result: {} ", toolExecutionRequest.name(), toolExecutionRequest.arguments(), executeResult);
            final ToolExecutionResultMessage toolExecutionResultMessages = ToolExecutionResultMessage.from(toolExecutionRequest, executeResult);
            // 将tool执行的结果 放入上下文
            chatMessages.add(toolExecutionResultMessages);
        }
        // 再次请求ai
        a = chatModel
                .chat(chatMessages)
                .aiMessage()
                .text();
    }

    log.info("call ai q:{}\na:{}", q, a);
}
</code></pre>
<blockquote>
<p>测试结果如下：</p>
</blockquote>
<pre><code>23:18:53.710 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- execute user tool, name: getUserCodeByUsername, param:{"username": "张铁牛"}, result: 003 
23:18:55.482 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- call ai q:张铁牛的code是多少
a:根据您的问题，张铁牛的代码是 **003**。如果还有其他相关信息需要补充或查询，请告诉我！
</code></pre>
<h2 id="11-dynamic-function-call">11. dynamic function call</h2>
<blockquote>
<p>因为有的时候我们使用已有的svc时，我们可能无法直接给目标方法标注对应的注解让AI来识别方法（比如第三方包里的方法）</p>
<p>所以就需要动态的创建tool的描述类，如下</p>
</blockquote>
<pre><code class="language-java">@Test
public void should_return_func_content_when_use_dynamic_function_call() {
    final String q = "张铁牛的code是多少";
    final List&lt;ChatMessage&gt; chatMessages = new ArrayList&lt;&gt;();
    chatMessages.add(UserMessage.from(q));
    final UserServiceTest userServiceTest = new UserServiceTest();
    final ToolSpecification toolSpecification = ToolSpecification
            .builder()
            .name("getUserCodeByUsername")
            .description("根据用户的名称获取对应的code")
            .parameters(JsonObjectSchema
                    .builder()
                    .addStringProperty("username", "用户姓名")
                    .build())
            .build();

    final ChatRequest chatRequest = ChatRequest
            .builder()
            .messages(UserMessage.from(q))
            .toolSpecifications(toolSpecification)
            .build();
    final ChatResponse chatResponse = chatModel.chat(chatRequest);
    AiMessage aiMessage = chatResponse.aiMessage();
    chatMessages.add(aiMessage);
    String a = aiMessage.text();

    if (aiMessage.hasToolExecutionRequests()) {
        for (ToolExecutionRequest toolExecutionRequest : aiMessage.toolExecutionRequests()) {
            ToolExecutor userToolExecutor = new DefaultToolExecutor(userServiceTest, toolExecutionRequest);
            final String uuid = UUID
                    .randomUUID()
                    .toString();
            final String executeResult = userToolExecutor.execute(toolExecutionRequest, uuid);
            log.info("execute user tool, name: {}, param:{}, result: {} ", toolExecutionRequest.name(), toolExecutionRequest.arguments(), executeResult);
            final ToolExecutionResultMessage toolExecutionResultMessages = ToolExecutionResultMessage.from(toolExecutionRequest, executeResult);
            chatMessages.add(toolExecutionResultMessages);
        }

        a = chatModel
                .chat(chatMessages)
                .aiMessage()
                .text();
    }

    log.info("call ai q:{}\na:{}", q, a);
}
</code></pre>
<blockquote>
<p>测试结果如下：</p>
</blockquote>
<pre><code>23:22:53.626 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- execute user tool, name: getUserCodeByUsername, param:{"username": "张铁牛"}, result: 003 
23:22:55.065 [main] INFO com.ldx.langchaintest.lowapi.AiChatTest -- call ai q:张铁牛的code是多少
a:根据您的问题，张铁牛的代码是 **003**。如果还有其他相关信息需要补充，请告诉我！
</code></pre>
<h2 id="12-小结">12. 小结</h2>
<p>本章使用了<code>LangChain4j</code>一些比较底层的（原生的）api来请求大模型， 展示了AI服务中常见的使用方法，下一章我们将使用<code>LangChain4j</code>的<code>AI Service</code>功能来展示<code>LangChain4j</code>高阶用法。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.5342487190243056" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-06-05 23:33">2025-06-05 23:33</span>&nbsp;
<a href="https://www.cnblogs.com/ludangxin">张铁牛</a>&nbsp;
阅读(<span id="post_view_count">171</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18913321);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18913321', targetLink: 'https://www.cnblogs.com/ludangxin/p/18913321', title: '1. LangChain4j 初识，想使用Java开发AI应用？' })">举报</a>
</div>
        