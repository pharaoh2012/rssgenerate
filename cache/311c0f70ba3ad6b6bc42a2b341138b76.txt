
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/dechinphy/p/18740207/cycuda-gather" title="发布于 2025-02-27 10:20">
    <span role="heading" aria-level="2">Cython与CUDA之Gather</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        <img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250227101855972-1341902839.png" alt="Cython与CUDA之Gather" class="desc_img">
        本文使用了Cython作为封装函数，封装一个CUDA C实现的Gather算子，然后通过Python去调用，用这种方法实现一个比较Pythonic的CUDA Gather函数的实现和调用。
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="技术背景">技术背景</h1>
<p>Cython是Python的一个超集，可以使用Pythonic的语法写出接近于C语言的性能，可以用于将Python编程过程中遇到的Bottleneck模块改写成Cython以达到加速的效果。前面写过一些关于<a href="https://www.cnblogs.com/dechinphy/p/18320419/cython-osc" target="_blank">Cython加速计算</a>的文章。又因为Cython编译过程中会先转为C语言代码，然后再编译为动态链接库或者可执行文件，所以很自然的可以在<a href="https://www.cnblogs.com/dechinphy/p/18323048/cython-c" target="_blank">Cython中调用C语言</a>函数。用这种方法，还可以直接<a href="https://www.cnblogs.com/dechinphy/p/18338355/cython-cuda" target="_blank">调用CUDA C函数</a>。在这篇文章中，我们要使用Cython结合CUDA C的方法来实现一个CUDA版本的Gather函数，从一个数组中根据索引数组，输出对应的数组。相当于numpy中的<code>result=source[index]</code>。</p>
<h1 id="接口头文件">接口头文件</h1>
<p>我们定义一个<code>cuda_index.cuh</code>的头文件，用于指定C函数接口形式：</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

extern "C" int Gather(float *source, int *index, float *res, int N, int M);
</code></pre>
<p>其中source是原始数组，index是索引数组，res是结果数组，N是索引的维度，M是原始数组的维度。</p>
<h1 id="异常捕获头文件">异常捕获头文件</h1>
<p>这里使用的是前面一篇<a href="https://www.cnblogs.com/dechinphy/p/18735654/cuda_error" target="_blank">CUDA异常捕获</a>中用到的头文件<code>error.cuh</code></p>
<pre><code class="language-c">#pragma once
#include &lt;stdio.h&gt;

#define CHECK(call) do{const cudaError_t error_code = call; if (error_code != cudaSuccess){printf("CUDA Error:\n"); printf("    File:   %s\n", __FILE__); printf("    Line:   %d\n", __LINE__); printf("    Error code: %d\n", error_code); printf("    Error text: %s\n", cudaGetErrorString(error_code)); exit(1);}} while (0)
</code></pre>
<p>通过这个宏，我们可以在运行CUDA核函数的时候捕获其异常。</p>
<h1 id="cuda-gather函数">CUDA Gather函数</h1>
<p>CUDA实现Gather函数<code>cuda_index.cu</code>还是比较简单的，就是一个简单的Kernel函数再加一个管理DeviceMemory的C函数就可以了：</p>
<pre><code class="language-c">// nvcc -shared ./cuda_index.cu -Xcompiler -fPIC -o ./libcuindex.so
#include &lt;stdio.h&gt;
#include "cuda_index.cuh"
#include "error.cuh"

void __global__ GatherKernel(float *source, int *index, float *res, int N){
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx &lt; N){
        res[idx] = source[index[idx]];
    }
}

extern "C" int Gather(float *source, int *index, float *res, int N, int M){
    float *souce_device, *res_device;
    int *index_device;
    CHECK(cudaMalloc((void **)&amp;souce_device, M * sizeof(float)));
    CHECK(cudaMalloc((void **)&amp;res_device, N * sizeof(float)));
    CHECK(cudaMalloc((void **)&amp;index_device, N * sizeof(int)));
    CHECK(cudaMemcpy(souce_device, source, M * sizeof(float), cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(res_device, res, N * sizeof(float), cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(index_device, index, N * sizeof(int), cudaMemcpyHostToDevice));
    int block_size = 1024;
    int grid_size = (N + block_size - 1) / block_size;
    GatherKernel&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(souce_device, index_device, res_device, N);
    CHECK(cudaGetLastError());
    CHECK(cudaDeviceSynchronize());
    CHECK(cudaMemcpy(res, res_device, N * sizeof(float), cudaMemcpyDeviceToHost));
    CHECK(cudaFree(souce_device));
    CHECK(cudaFree(index_device));
    CHECK(cudaDeviceSynchronize());
    CHECK(cudaFree(res_device));
    CHECK(cudaDeviceReset());
    return 1;
}
</code></pre>
<h1 id="cython调用接口">Cython调用接口</h1>
<p>假定我们有一个<code>numpy.ndarray</code>形式的数组需要进行索引，当然我们也可以用现成的AI框架来直接实现，例如<code>mindspore.Tensor(numpy.ndarray)</code>。只是这里我们用Cython来做一个直接对接CUDA函数的接口<code>wrapper.pyx</code>，理论上可以对数组做一些更加细致的操作。</p>
<pre><code class="language-python"># cythonize -i -f wrapper.pyx

import numpy as np
cimport numpy as np
cimport cython

cdef extern from "&lt;dlfcn.h&gt;" nogil:
    void *dlopen(const char *, int)
    char *dlerror()
    void *dlsym(void *, const char *)
    int dlclose(void *)
    enum:
        RTLD_LAZY

ctypedef int (*GatherFunc)(float *source, int *index, float *res, int N, int M) noexcept nogil

cdef void* handle = dlopen('/path/to/libcuindex.so', RTLD_LAZY)

@cython.boundscheck(False)
@cython.wraparound(False)
cpdef float[:] cuda_gather(float[:] x, int[:] idx):
    cdef:
        GatherFunc Gather
        int success
        int N = idx.shape[0]
        int M = x.shape[0]
        float[:] res = np.zeros((N, ), dtype=np.float32)
    Gather = &lt;GatherFunc&gt;dlsym(handle, "Gather")
    success = Gather(&amp;x[0], &amp;idx[0], &amp;res[0], N, M)
    return res

while not True:
    dlclose(handle)
</code></pre>
<p>这里所使用到的动态链接库<code>libcuindex.so</code>就是编译好的CUDA模块，要使用绝对路径会比较保险。</p>
<h1 id="python调用函数">Python调用函数</h1>
<p>我们最上层的函数还是通过Python脚本<code>test_gather.py</code>来调用，借助其简洁的语法和大量的第三方接口：</p>
<pre><code class="language-python">import numpy as np
np.random.seed(0)
from wrapper import cuda_gather

M = 1024 * 1024 * 128
N = 1024 * 1024
x = np.random.random((M,)).astype(np.float32)
idx = np.random.randint(0, M, (N,)).astype(np.int32)
res = np.asarray(cuda_gather(x, idx))
print (res.shape)
print ((res==x[idx]).sum())
</code></pre>
<p>这里的wrapper就是我们的Cython文件的包名。</p>
<h1 id="运行流程">运行流程</h1>
<p>在编辑好上述的这些相关文件之后，我们需要按照这样的一个流程来进行使用：首先将CUDA相关模块编译成一个动态链接库libxxx.so，然后使用Cython加载这个动态链接库，再将Cython的封装模块编译成一个动态链接库供Python调用，最后直接执行Python任务即可。相关步骤所对应的终端指令如下：</p>
<pre><code class="language-bash">$ nvcc -shared ./cuda_index.cu -Xcompiler -fPIC -o ./libcuindex.so 
$ cythonize -i -f wrapper.pyx 
$ python3 test_gather.py
</code></pre>
<p>运行输出的结果如下：</p>
<pre><code class="language-bash">(1048576,)
1048576
</code></pre>
<p>如果你使用nvitop在监测GPU资源的占用的话，运行过程中就可以看到GPU显存的一些波动。最后输出的结果跟numpy的索引函数直接对比是一致的，也就是说我们的输出结果是正确的。</p>
<h1 id="报错处理">报错处理</h1>
<p>如果在运行的过程中有提示Numpy的相关lib找不到的问题，可以参考<a href="https://www.cnblogs.com/dechinphy/p/18268280/cython-include" target="_blank">这篇文章</a>进行处理。</p>
<h1 id="总结概要">总结概要</h1>
<p>本文使用了Cython作为封装函数，封装一个CUDA C实现的Gather算子，然后通过Python去调用，用这种方法实现一个比较Pythonic的CUDA Gather函数的实现和调用。</p>
<h1 id="版权声明">版权声明</h1>
<p>本文首发链接为：<a href="https://www.cnblogs.com/dechinphy/p/cycuda-gather.html" target="_blank">https://www.cnblogs.com/dechinphy/p/cycuda-gather.html</a></p>
<p>作者ID：DechinPhy</p>
<p>更多原著文章：<a href="https://www.cnblogs.com/dechinphy/" target="_blank">https://www.cnblogs.com/dechinphy/</a></p>
<p>请博主喝咖啡：<a href="https://www.cnblogs.com/dechinphy/gallery/image/379634.html" target="_blank">https://www.cnblogs.com/dechinphy/gallery/image/379634.html</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.4969847410462963" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-27 10:21">2025-02-27 10:20</span>&nbsp;
<a href="https://www.cnblogs.com/dechinphy">DECHIN</a>&nbsp;
阅读(<span id="post_view_count">51</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18740207" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18740207);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18740207', targetLink: 'https://www.cnblogs.com/dechinphy/p/18740207/cycuda-gather', title: 'Cython与CUDA之Gather' })">举报</a>
</div>
        