
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/wang_yb/p/18896593" title="发布于 2025-05-26 11:02">
    <span role="heading" aria-level="2">不同数据场景下的聚类算法</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>在数据分析和机器学习领域，<strong>聚类</strong>是一种非常重要的无监督学习方法，它可以帮助我们发现数据中的内在结构，将相似的数据点分组到一起。</p>
<p>本文将介绍几种常见的<strong>聚类</strong>算法，包括<strong>原型聚类</strong>（如 k-均值、学习向量量化、高斯混合聚类）、<strong>密度聚类</strong>（DBSCAN）和<strong>层次聚类</strong>（AGNES）。</p>
<p>通过浅显易懂的方式介绍它们的原理，探讨它们的适用场景，并通过代码演示如何使用这些算法。</p>
<h1 id="1-原型聚类以中心点代表群体">1. 原型聚类：以"中心点"代表群体</h1>
<h2 id="11-k-均值聚类">1.1. k-均值聚类</h2>
<p><strong>k-均值聚类</strong>（<code>K-Means Clustering</code>）是一种非常直观的聚类方法。</p>
<p>它的目标是将数据划分为$ k $个簇，每个簇由一个<strong>“中心点”</strong>（质心）代表。</p>
<p><strong>算法的步骤</strong>如下：</p>
<ol>
<li>随机选择$ k $个数据点作为<strong>初始质心</strong>。</li>
<li>将每个数据点分配到最近的质心所在的<strong>簇</strong>。</li>
<li>重新计算每个<strong>簇的质心</strong>（即簇内所有点的均值）。</li>
<li>重复上述步骤，直到<strong>质心</strong>不再变化或达到预设的迭代次数。</li>
</ol>
<p><strong>k-均值聚类</strong>适用于数据分布较为均匀且簇形状较为规则的场景。</p>
<p>例如，对用户群体进行市场细分，或者对图像中的像素进行颜色聚类。</p>
<p>基于<code>scikit-learn</code>的代码示例如下：</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs

# 生成模拟数据
X, _ = make_blobs(n_samples=300, centers=4, random_state=42)

# 使用 KMeans 聚类
kmeans = KMeans(n_clusters=4, random_state=42)
kmeans.fit(X)
labels = kmeans.labels_
centroids = kmeans.cluster_centers_

# 可视化结果
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='red', marker='X')
plt.title("K-Means 聚类")
plt.show()
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/83005/202505/83005-20250526110200161-497095147.png" alt="" loading="lazy"></p>
<h2 id="12-学习向量量化">1.2. 学习向量量化</h2>
<p><code>LVQ</code>（<code>Learning Vector Quantization</code>） 是一种受神经网络启发的聚类方法。</p>
<p>它使用一组<strong>“原型向量”</strong>来代表每个簇，算法通过迭代调整这些原型向量的位置，使其更接近属于该簇的数据点，远离其他簇的数据点。</p>
<p><code>LVQ</code> 的<strong>核心思想</strong>是通过学习来优化原型向量的位置。</p>
<p><code>LVQ</code> 适用于数据点分布较为密集且簇边界较为清晰的场景，它在<strong>图像识别</strong>和<strong>模式分类</strong>中表现良好。</p>
<p>虽然<code>scikit-learn</code>没有直接提供 <code>LVQ</code> 的实现，但我们可以使用<code>sklvq</code>库来实现。</p>
<p>安装方式： <code>pip install sklvq</code></p>
<p>代码示例如下：</p>
<pre><code class="language-python">from sklvq import GLVQ  # 使用 GLVQ（Generalized Learning Vector Quantization）
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# 生成模拟数据
X, y = make_blobs(n_samples=300, centers=4, random_state=42)

# 使用 GLVQ 聚类
glvq = GLVQ(random_state=42)
glvq.fit(X, y)

# 获取聚类结果
labels = glvq.predict(X)

# 获取中心点（原型向量）
prototypes = glvq.prototypes_

# 可视化结果
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap="viridis")
plt.scatter(
    prototypes[:, 0], prototypes[:, 1], s=300, c="red", marker="X", label="Prototypes"
)
plt.title("广义学习向量量化 (GLVQ)")
plt.show()
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/83005/202505/83005-20250526110200169-447423170.png" alt="" loading="lazy"></p>
<h2 id="13-高斯混合聚类">1.3. 高斯混合聚类</h2>
<p><strong>高斯混合聚类</strong>（<code>Gaussian Mixture Clustering</code>）假设数据是由多个高斯分布的混合生成的。</p>
<p>每个高斯分布代表一个<strong>簇</strong>，算法通过估计每个高斯分布的<strong>参数</strong>（<strong>均值</strong>、<strong>协方差矩阵</strong>和<strong>权重</strong>）来确定簇的形状和位置。</p>
<p><strong>高斯混合聚类</strong>比** k-均值**更灵活，因为它可以捕捉到簇的形状和大小的变化。</p>
<p><strong>高斯混合聚类</strong>适用于簇形状不规则或数据分布较为复杂的情况。</p>
<p>例如，对金融数据中的异常交易进行聚类分析。</p>
<p>代码示例如下：</p>
<pre><code class="language-python">from sklearn.mixture import GaussianMixture
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# 生成模拟数据
X, _ = make_blobs(n_samples=300, centers=4, random_state=42)

# 使用高斯混合聚类
gmm = GaussianMixture(n_components=4, random_state=42)
gmm.fit(X)
labels = gmm.predict(X)

# 可视化结果
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.title("高斯混合聚类")
plt.show()

</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/83005/202505/83005-20250526110200166-1296609979.png" alt="" loading="lazy"></p>
<h1 id="2-密度聚类发现任意形状的簇">2. 密度聚类：发现任意形状的簇</h1>
<p><code>DBSCAN</code>（<code>Density-Based Spatial Clustering of Applications with Noise</code>）是一种基于密度的聚类算法。</p>
<p>它的<strong>核心思想</strong>是：如果一个点的邻域内有足够的点（即密度足够高），那么这些点可以被划分为同一个簇。</p>
<p>DBSCAN 使用两个参数：</p>
<ul>
<li><code>eps</code>：邻域半径，用于定义<strong>“足够近”</strong>的范围。</li>
<li><code>min_samples</code>：核心点的邻域内必须包含的最小点数。</li>
</ul>
<p><code>DBSCAN</code>的优点是可以发现任意形状的簇，并且能够识别噪声点。</p>
<p><code>DBSCAN</code>适用于数据分布不均匀、簇形状复杂且存在噪声的场景。</p>
<p>例如，对地理数据中的热点区域进行分析。</p>
<p>代码示例如下：</p>
<pre><code class="language-python">from sklearn.cluster import DBSCAN
from sklearn.datasets import make_moons
import matplotlib.pyplot as plt

# 生成模拟数据
X, _ = make_moons(n_samples=300, noise=0.05, random_state=42)

# 使用 DBSCAN 聚类
dbscan = DBSCAN(eps=0.2, min_samples=5)
labels = dbscan.fit_predict(X)

# 可视化结果
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.title("DBSCAN 聚类")
plt.show()
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/83005/202505/83005-20250526110200159-1204097238.png" alt="" loading="lazy"></p>
<h1 id="3-层次聚类构建数据家族树">3. 层次聚类：构建数据家族树</h1>
<p><code>AGNES</code>（<code>Agglomerative Nesting</code>）是一种自底向上的层次聚类算法。</p>
<p>它从每个数据点作为一个单独的簇开始，然后逐步合并距离最近的簇，直到达到预设的簇数量或满足其他停止条件。</p>
<p><code>AGNES</code> 的关键在于如何定义簇之间的距离，常见的方法包括<strong>单链接法</strong>、<strong>全链接法</strong>和<strong>平均链接法</strong>。</p>
<p><code>AGNES</code> 适用于需要逐步分析数据层次结构的场景，例如生物分类学或文档聚类。</p>
<p>代码示例如下：</p>
<pre><code class="language-python">from sklearn.cluster import AgglomerativeClustering
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt

# 生成模拟数据
X, _ = make_blobs(n_samples=300, centers=4, random_state=42)

# 使用 AGNES 聚类
agnes = AgglomerativeClustering(n_clusters=4)
labels = agnes.fit_predict(X)

# 可视化结果
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.title("AGNES 聚类")
plt.show()
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/83005/202505/83005-20250526110200167-831300534.png" alt="" loading="lazy"></p>
<h1 id="4-聚类算法对比">4. 聚类算法对比</h1>
<p>常用的几种聚类算法的对比如下：</p>
<table>
<thead>
<tr>
<th>算法类型</th>
<th>优点</th>
<th>局限性</th>
<th>典型应用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>K-Means</td>
<td>计算效率高</td>
<td>需预设K值</td>
<td>客户分群、图像压缩</td>
</tr>
<tr>
<td>GMM</td>
<td>处理椭圆分布</td>
<td>计算复杂度较高</td>
<td>异常检测、语音识别</td>
</tr>
<tr>
<td>DBSCAN</td>
<td>发现任意形状</td>
<td>参数敏感</td>
<td>地理数据、离群点检测</td>
</tr>
<tr>
<td>AGNES</td>
<td>可视化层次结构</td>
<td>计算复杂度O(n³)</td>
<td>生物分类、文档聚类</td>
</tr>
</tbody>
</table>
<h1 id="5-总结">5. 总结</h1>
<p><strong>聚类算法</strong>的选择取决于数据的特性、问题的需求以及对结果的解释性要求。</p>
<p><strong>k-均值</strong>简单高效，但对簇形状有较强假设；<code>DBSCAN</code> 能够处理复杂形状和噪声；<strong>层次聚类</strong>则提供了数据的层次结构。</p>
<p>在实际应用中，我们通常需要尝试多种算法，并根据具体问题选择最适合的聚类方法。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.6369257923043982" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-05-26 11:03">2025-05-26 11:02</span>&nbsp;
<a href="https://www.cnblogs.com/wang_yb">wang_yb</a>&nbsp;
阅读(<span id="post_view_count">118</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18896593);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18896593', targetLink: 'https://www.cnblogs.com/wang_yb/p/18896593', title: '不同数据场景下的聚类算法' })">举报</a>
</div>
        