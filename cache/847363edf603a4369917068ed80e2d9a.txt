
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/vipstone/p/18853967" title="发布于 2025-04-29 16:42">
    <span role="heading" aria-level="2">国内首个「混合推理模型」Qwen3深夜开源，盘点它的N种对接方式！</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>今日凌晨，通义千问团队正式开源了 Qwen3 大模型，并且一口气发布了 8 个型号，其中包括 0.6B、1.7B、4B、8B、14B、32B 以及 30B-A3B 和 235B-A22B，使用者可以根据自己的业务情况，选择合适的版本进行使用。</p>
<p>更让人惊喜的是，最新的 Qwen3 系列模型具备<strong>双模推理能力（深入思考/快速响应）、支持 119 种语言及方言，并强化了 Agent 功能与代码执行能力</strong>，全面满足复杂问题处理与全球化应用需求。</p>
<blockquote>
<p>PS：Qwen3 也是国内首个「混合推理模型」，「快思考」与「慢思考」集成进同一个模型，对简单需求可低算力「秒回」答案，对复杂问题可多步骤「深度思考」，大大节省算力消耗。</p>
</blockquote>
<p>Qwen3 旗舰模型 Qwen3-235B-A22B 在代码、数学、通用能力等基准测试中，与 DeepSeek-R1、o1、o3-mini、Grok-3 和 Gemini-2.5-Pro 等顶级模型相比，表现出极具竞争力的结果。此外，小型 MoE 模型 Qwen3-30B-A3B 的激活参数数量是 QwQ-32B 的 10%，表现更胜一筹，甚至像 Qwen3-4B 这样的小模型也能匹敌 Qwen2.5-72B-Instruct 的性能，以下是测试报告：</p>
<p><img src="https://img2024.cnblogs.com/blog/172074/202504/172074-20250429164224467-493146404.png" alt="" loading="lazy"></p>
<h2 id="对接-qwen3">对接 Qwen3</h2>
<p>常见对接大模型的方案有以下几种：</p>
<ol>
<li><strong>官方对接方式</strong>：例如，调用阿里百炼平台对接 Qwen3。</li>
<li><strong>本地模型对接方式</strong>：安装 Ollama 部署 Qwen3，对接 Ollama 实现调用。</li>
<li><strong>三方平台对接方式</strong>：使用千帆或火山引擎等三方平台，对接调用 Qwen3。</li>
</ol>
<p>但目前因为 Qwen3 刚刚发布，所以只能使用前两种对接方式，截止发稿时，三方平台还未上线 Qwen3，但也够用了。</p>
<h2 id="具体实现">具体实现</h2>
<p>接下来我们就以官方的调用方式，来实现一下 Qwen3 的具体代码对接吧，这里提供 Spring AI 和 LangChain4j 两种对接实现。</p>
<h2 id="spring-ai-对接-qwen3">Spring AI 对接 Qwen3</h2>
<h3 id="1添加依赖">1.添加依赖</h3>
<p>Spring AI 并没有内置阿里云百炼平台，但百炼平台支持 OpenAI 协议，因此我们可以使用 OpenAI 对接百炼平台，因此我们只需要添加 OpenAI 依赖即可。</p>
<pre><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
  &lt;artifactId&gt;spring-ai-starter-model-openai&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="2设置配置信息">2.设置配置信息</h3>
<pre><code class="language-yaml">spring:
  ai:
    openai:
      base-url: https://dashscope.aliyuncs.com/compatible-mode/
      api-key: ${ALIYUN-AK}
      chat:
        options:
          model: qwen3-235b-a22b
</code></pre>
<p>其中：</p>
<ul>
<li>base-url 填写百炼平台地址。</li>
<li>api-key 为准备阶段在百炼平台申请的 AK 凭证。</li>
<li>model 设置为 qwen3-235b-a22b 模型。</li>
</ul>
<blockquote>
<p>支持的模型列表参考官方文档：<a href="https://help.aliyun.com/zh/model-studio/models?spm=a2c4g.11186623.0.0.78d848237YTeH1#cefdf0875dorc" target="_blank" rel="noopener nofollow">https://help.aliyun.com/zh/model-studio/models?spm=a2c4g.11186623.0.0.78d848237YTeH1#cefdf0875dorc</a></p>
</blockquote>
<h3 id="3编写调用代码">3.编写调用代码</h3>
<pre><code class="language-java">import org.springframework.ai.openai.OpenAiChatModel;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/ds")
public class TestController {

    private final OpenAiChatModel chatModel;

    @Autowired
    public TestController(OpenAiChatModel chatModel) {
        this.chatModel = chatModel;
    }

    @RequestMapping("/chat")
    public String chat(@RequestParam("msg") String msg) {
        String result = chatModel.call(msg);
        System.out.println("返回结果：" + result);
        return result;
    }
}
</code></pre>
<h2 id="langchain4j-对接-qwen3">LangChain4j 对接 Qwen3</h2>
<p>LangChain4j 内置集成了阿里云百炼平台，所以可以直接对接。</p>
<h3 id="1添加依赖-1">1.添加依赖</h3>
<pre><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
  &lt;artifactId&gt;langchain4j-community-dashscope-spring-boot-starter&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>可以为“langchain4j-community-xxx”其添加统一版本管理：</p>
<pre><code class="language-xml">&lt;dependencyManagement&gt;
  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
      &lt;artifactId&gt;langchain4j-community-bom&lt;/artifactId&gt;
      &lt;version&gt;1.0.0-beta3&lt;/version&gt;
      &lt;type&gt;pom&lt;/type&gt;
      &lt;scope&gt;import&lt;/scope&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
</code></pre>
<h3 id="2设置配置信息-1">2.设置配置信息</h3>
<p><strong>注意这里需要配置“chat-model”节点，官方文档有问题</strong>，如果不配置 chat-model 则不能自动注入百炼模型：</p>
<pre><code class="language-yaml">langchain4j:
  community:
    dashscope:
      base-url: https://dashscope.aliyuncs.com/compatible-mode/
      chat-model:
        api-key: ${ALIYUN-AK}
        model-name: qwen-plus
</code></pre>
<p>支持的模型列表：<a href="https://help.aliyun.com/zh/model-studio/models" target="_blank" rel="noopener nofollow">https://help.aliyun.com/zh/model-studio/models</a></p>
<h3 id="3编写调用代码-1">3.编写调用代码</h3>
<pre><code class="language-java">import dev.langchain4j.model.chat.ChatLanguageModel;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping("/qw")
public class QwenController {

    @Autowired
    private ChatLanguageModel qwenChatModel;

    @RequestMapping("/chat")
    public String chat(String question) {
        return qwenChatModel.chat(question);
    }
}
</code></pre>
<h2 id="小结">小结</h2>
<p>当然，以上对接方式是全量输出（得到结果之后一次性返回），生产级别我们通常要使用流式输出，并且需要实现连续（上下文）对话，以及历史对话信息持久化等功能，文章篇幅有限，这里就不一一实现了，大家可以下来自己试试。</p>
<blockquote>
<p>本文已收录到我的技术小站 <a href="https://www.javacn.site" target="_blank" rel="noopener nofollow">www.javacn.site</a>，其中包含的内容有：Spring AI、LangChain4j、MCP、Function Call、RAG、向量数据库、Prompt、多模态、向量数据库、嵌入模型等内容。</p>
</blockquote>

</div>
<div id="MySignature" role="contentinfo">
    <div style="text-align: center; color: red">
关注下面二维码，订阅更多精彩内容。
<br>
<img style="margin-left: 0px" src="https://images.cnblogs.com/cnblogs_com/vipstone/848916/o_211225130402_gognzhonghao.jpg">
</div>

<div style="display: none">
    <img src="http://icdn.apigo.cn/gitchat/rabbitmq.png?imageView2/0/w/500/h/400">
</div>
<div style="margin-bottom: 50px; display: none">

<img title="微信打赏" src="http://icdn.apigo.cn/myinfo/wchat-pay.png" alt="微信打赏">
<br>

<div style="display: none">
<span style="display: block; position: absolute; height: 40px; top: 50%; margin-top: -20px">关注公众号（加好友）：</span>

<img style="margin-left: 144px" src="http://icdn.apigo.cn/gongzhonghao2.png?imageView2/0/w/120/h/120">
</div>
<p></p>

<div id="AllanboltSignature">
    <p style="border-top: #e0e0e0 1px dashed; border-right: #e0e0e0 1px dashed; border-bottom: #e0e0e0 1px dashed; border-left: #e0e0e0 1px dashed; padding-top: 10px; padding-right: 10px; padding-bottom: 10px; padding-left: 60px; background: url(&quot;https://images.cnblogs.com/cnblogs_com/lloydsheng/239039/o_copyright.gif&quot;) #e5f1f4 no-repeat 1% 50%; font-family: 微软雅黑; font-size: 11px" id="PSignature">
        <br> 作者：
        <a href="http://vipstone.cnblogs.com/" target="_blank">王磊的博客</a>
        <br> 出处：
        <a href="http://vipstone.cnblogs.com/" target="_blank">http://vipstone.cnblogs.com/</a>
        <br>
    </p>
</div></div>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.4018691377662037" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-29 16:43">2025-04-29 16:42</span>&nbsp;
<a href="https://www.cnblogs.com/vipstone">磊哥|www.javacn.site</a>&nbsp;
阅读(<span id="post_view_count">120</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18853967);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18853967', targetLink: 'https://www.cnblogs.com/vipstone/p/18853967', title: '国内首个「混合推理模型」Qwen3深夜开源，盘点它的N种对接方式！' })">举报</a>
</div>
        