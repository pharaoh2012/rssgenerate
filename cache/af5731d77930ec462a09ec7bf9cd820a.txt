
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xiao987334176/p/18922128" title="å‘å¸ƒäº 2025-06-10 15:36">
    <span role="heading" aria-level="2">SwanLabå…¥é—¨æ·±åº¦å­¦ä¹ ï¼šQwen3å¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒ</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h1>ä¸€ã€æ¦‚è¿°</h1>
<p>Qwen3æ˜¯é€šä¹‰åƒé—®å›¢é˜Ÿçš„å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œç”±é˜¿é‡Œäº‘é€šä¹‰å®éªŒå®¤ç ”å‘ã€‚ä»¥Qwen3ä½œä¸ºåŸºåº§å¤§æ¨¡å‹ï¼Œé€šè¿‡æŒ‡ä»¤å¾®è°ƒçš„æ–¹å¼å®ç°é«˜å‡†ç¡®ç‡çš„æ–‡æœ¬åˆ†ç±»ï¼Œæ˜¯å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒçš„å…¥é—¨ä»»åŠ¡ã€‚</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610143359181-106648973.png" alt="" width="974" height="384"></p>
<p>æŒ‡ä»¤å¾®è°ƒæ˜¯ä¸€ç§é€šè¿‡åœ¨ç”±ï¼ˆæŒ‡ä»¤ï¼Œè¾“å‡ºï¼‰å¯¹ç»„æˆçš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒLLMsçš„è¿‡ç¨‹ã€‚ å…¶ä¸­ï¼ŒæŒ‡ä»¤ä»£è¡¨æ¨¡å‹çš„äººç±»æŒ‡ä»¤ï¼Œè¾“å‡ºä»£è¡¨éµå¾ªæŒ‡ä»¤çš„æœŸæœ›è¾“å‡ºã€‚ è¿™ä¸ªè¿‡ç¨‹æœ‰åŠ©äºå¼¥åˆLLMsçš„ä¸‹ä¸€ä¸ªè¯é¢„æµ‹ç›®æ ‡ä¸ç”¨æˆ·è®©LLMséµå¾ªäººç±»æŒ‡ä»¤çš„ç›®æ ‡ä¹‹é—´çš„å·®è·ã€‚</p>
<p>åœ¨è¿™ä¸ªä»»åŠ¡ä¸­æˆ‘ä»¬ä¼šä½¿ç”¨Qwen3-1.7Bæ¨¡å‹åœ¨zh_cls_fudan_newsæ•°æ®é›†ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒä»»åŠ¡ï¼ŒåŒæ—¶ä½¿ç”¨SwanLabè¿›è¡Œç›‘æ§å’Œå¯è§†åŒ–ã€‚</p>
<p>&nbsp;</p>
<p>å®éªŒæ—¥å¿—è¿‡ç¨‹ï¼š<a href="https://swanlab.cn/@spark_xiao/Qwen3-fintune/runs/9rzt3rv77885ek176nslh" target="_blank" rel="noopener nofollow">https://swanlab.cn/@spark_xiao/Qwen3-fintune/runs/9rzt3rv77885ek176nslh</a></p>
<p>å‚è€ƒä»£ç ï¼š<a href="https://github.com/Zeyi-Lin/LLM-Finetune" target="_blank" rel="noopener nofollow">https://github.com/Zeyi-Lin/LLM-Finetune</a></p>
<p>æ¨¡å‹ï¼š<a href="https://modelscope.cn/models/Qwen/Qwen3-1.7B" target="_blank" rel="noopener nofollow">https://modelscope.cn/models/Qwen/Qwen3-1.7B</a></p>
<p>æ•°æ®é›†ï¼š<a href="https://www.modelscope.cn/datasets/swift/zh_cls_fudan-news/summary" target="_blank" rel="noopener nofollow">https://www.modelscope.cn/datasets/swift/zh_cls_fudan-news/summary</a></p>
<p>SwanLabï¼š<a href="https://swanlab.cn" target="_blank" rel="noopener nofollow">https://swanlab.cn</a></p>
<h1>äºŒã€SwanLab</h1>
<p>SwanLabï¼ˆhttps://swanlab.cnï¼‰æ˜¯ä¸€ä¸ªç”¨äºAIæ¨¡å‹è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–çš„å·¥å…·ã€‚SwanLabçš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š</p>
<p>è·Ÿè¸ªæ¨¡å‹æŒ‡æ ‡ï¼Œå¦‚æŸå¤±å’Œå‡†ç¡®æ€§ç­‰<br>åŒæ—¶æ”¯æŒäº‘ç«¯å’Œç¦»çº¿ä½¿ç”¨ï¼Œæ”¯æŒè¿œç¨‹æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ï¼Œæ¯”å¦‚å¯ä»¥åœ¨æ‰‹æœºä¸Šçœ‹è¿œç¨‹æœåŠ¡å™¨ä¸Šè·‘çš„è®­ç»ƒ<br>è®°å½•è®­ç»ƒè¶…å‚æ•°ï¼Œå¦‚batch_sizeå’Œlearning_rateç­‰<br>è‡ªåŠ¨è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ—¥å¿—ã€ç¡¬ä»¶ç¯å¢ƒã€Pythonåº“ä»¥åŠGPUï¼ˆæ”¯æŒè‹±ä¼Ÿè¾¾æ˜¾å¡ï¼‰ã€NPUï¼ˆæ”¯æŒåä¸ºæ˜‡è…¾å¡ï¼‰ã€å†…å­˜çš„ç¡¬ä»¶ä¿¡æ¯<br>æ”¯æŒå›¢é˜Ÿå¤šäººåä½œï¼Œå¾ˆé€‚åˆæ‰“Kaggleç­‰æ¯”èµ›çš„é˜Ÿä¼</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610144221570-789373986.png" alt="" width="1286" height="567" loading="lazy"></p>
<p>&nbsp;</p>
<p>SwanLabåº“æ¥è‡ªä¸€ä¸ªä¸­å›½å›¢é˜Ÿï¼ˆæƒ…æ„Ÿæœºå™¨ï¼‰ï¼Œæœ€æ—©çš„å‡ºå‘ç‚¹æ˜¯å…¶å¼€å‘å›¢é˜Ÿçš„å†…éƒ¨è®­ç»ƒéœ€æ±‚ï¼Œåæ¥é€æ¸å¼€æºå¹¶ä¸”å‘å±•æˆé¢å‘å…¬ä¼—çš„äº§å“ã€‚SwanLabåº“åœ¨2024å¹´å‘å…¬ä¼—å‘å¸ƒã€‚SwanLabåˆšå‡ºç°æ—¶åªæœ‰ç¦»çº¿ç‰ˆæœ¬ï¼ˆå¯¹æ ‡Tensorboardï¼‰ï¼Œåæ¥ç»è¿‡è¿­ä»£å’ŒåŠªåŠ›å·²ç»æœ‰äº†äº‘ç«¯ç‰ˆå’Œå„é¡¹åŠŸèƒ½ï¼Œå¹¶ä¸”é›†æˆäº†æ¥è¿‘30+ä¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒåŒ…æ‹¬PyTorchã€HuggingFace Transformersã€Kerasã€XGBoostç­‰ç­‰ï¼Œå…¶ä¸­è¿˜åŒ…æ‹¬åŒæ ·æ˜¯ä¸­å›½å›¢é˜Ÿå¼€å‘çš„LLaMA Factoryã€Modelscope Swiftã€PaddleYOLOç­‰æ¡†æ¶ï¼Œå…·æœ‰äº†å¾ˆå…¨é¢çš„åŠŸèƒ½ã€‚</p>
<h2>è´¦å·æ³¨å†Œ</h2>
<p>SwanLabçš„äº‘ç«¯ç‰ˆä½“éªŒæ˜¯æ¯”è¾ƒå¥½çš„ï¼ˆéå¸¸æ¨èï¼‰ï¼Œèƒ½å¤Ÿæ”¯æŒä½ åœ¨éšæ—¶éšåœ°è®¿é—®è®­ç»ƒè¿‡ç¨‹ã€‚</p>
<p>è¦ä½¿ç”¨äº‘ç«¯ç‰ˆä¹‹å‰éœ€è¦å…ˆæ³¨å†Œä¸€ä¸‹è´¦å·ï¼š</p>
<p>åœ¨ç”µè„‘æˆ–æ‰‹æœºæµè§ˆå™¨è®¿é—®SwanLabå®˜ç½‘ï¼š <a href="https://swanlab.cn" target="_blank" rel="noopener nofollow">https://swanlab.cn</a></p>
<p><strong>ç‚¹å‡»å³ä¸Šè§’æ³¨å†Œ</strong></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610144448932-453479692.png" alt="" loading="lazy"></p>
<p><strong>å¡«å†™æ‰‹æœºå·åï¼Œç‚¹å‡»ã€Œå‘é€çŸ­ä¿¡éªŒè¯ç ã€æŒ‰é’®</strong></p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610144515871-1191038469.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<h4>å¡«å†™ä½ çš„ä¿¡æ¯</h4>
<ul>
<li>ç”¨æˆ·åç§°ï¼šä½ çš„ä¸ªäººæ˜µç§°ï¼Œä¸­è‹±æ–‡å‡å¯</li>
<li>ç”¨æˆ·IDï¼šä½ çš„è‹±æ–‡åï¼Œå¯ç”±æ•°å­—ã€å­—æ¯ã€ä¸‹åˆ’çº¿ã€ä¸­æ¨ªçº¿ç»„æˆ</li>
<li>é‚®ç®±ï¼šä½ çš„é‚®ç®±</li>
<li>æœºæ„/é™¢æ ¡ï¼šä½ æ‰€åœ¨çš„ä¼ä¸šã€æœºæ„æˆ–å­¦æ ¡</li>
<li>æ‚¨ä»å“ªäº†è§£åˆ°SwanLabï¼Ÿï¼šï¼ˆé€‰å¡«é¡¹ï¼‰äº†è§£åˆ°SwanLabçš„æ¸ é“ï¼Œæ¯”å¦‚æœ‹å‹ä»‹ç»</li>






</ul>
<p>&nbsp;</p>
<h4>å¤åˆ¶API Key</h4>
<p>å®Œæˆå¡«å†™åç‚¹å‡»ã€Œå®Œæˆã€æŒ‰é’®ï¼Œä¼šè¿›å…¥åˆ°ä¸‹é¢çš„é¡µé¢ã€‚ç„¶åç‚¹å‡»å·¦è¾¹çš„ã€Œ<strong>è®¾ç½®</strong>ã€ï¼š</p>
<p>åœ¨<strong>API Key</strong>è¿™ä¸ªåœ°æ–¹ï¼Œç‚¹å‡»å¤åˆ¶æŒ‰é’®ï¼Œå¤åˆ¶ä½ çš„API Keyï¼š</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610144824761-177062976.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<h1>ä¸‰ã€ç¯å¢ƒå®‰è£…</h1>
<p>æœ¬æ¡ˆä¾‹åŸºäºPython 3.13.2ï¼Œè¯·åœ¨æ‚¨çš„è®¡ç®—æœºä¸Šå®‰è£…å¥½Pythonï¼Œå¹¶ä¸”æœ‰ä¸€å¼ è‹±ä¼Ÿè¾¾æ˜¾å¡ï¼ˆæ˜¾å­˜è¦æ±‚å¹¶ä¸é«˜ï¼Œå¤§æ¦‚10GBå·¦å³å°±å¯ä»¥è·‘ï¼‰ã€‚</p>
<p>åœ¨è¿™ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ çš„ç¯å¢ƒå†…å·²å®‰è£…äº†pytorchä»¥åŠCUDAï¼š</p>
<p>pytorchä»¥åŠCUDAå®‰è£…ï¼Œè¯·å‚è€ƒæ–‡ç« ï¼š<a href="https://www.cnblogs.com/xiao987334176/p/18876317" target="_blank">https://www.cnblogs.com/xiao987334176/p/18876317</a></p>
<p>&nbsp;</p>
<p>æˆ‘ä»¬éœ€è¦å®‰è£…ä»¥ä¸‹è¿™å‡ ä¸ªPythonåº“ï¼Œä¸€é”®å®‰è£…å‘½ä»¤ï¼š</p>
<div class="cnblogs_code">
<pre>pip <span style="color: rgba(0, 0, 255, 1)">install</span> swanlab modelscope transformers datasets peft pandas accelerate</pre>
</div>
<h2>å‡†å¤‡æ•°æ®é›†</h2>
<p>æœ¬æ¡ˆä¾‹ä½¿ç”¨çš„æ˜¯<a href="https://www.modelscope.cn/datasets/swift/zh_cls_fudan-news/summary" target="_blank" rel="noopener nofollow">zh_cls_fudan-news</a>æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¸»è¦è¢«ç”¨äºè®­ç»ƒæ–‡æœ¬åˆ†ç±»æ¨¡å‹ã€‚</p>
<p>zh_cls_fudan-newsç”±å‡ åƒæ¡æ•°æ®ï¼Œæ¯æ¡æ•°æ®åŒ…å«textã€categoryã€outputä¸‰åˆ—ï¼š</p>
<p>text æ˜¯è®­ç»ƒè¯­æ–™ï¼Œå†…å®¹æ˜¯ä¹¦ç±æˆ–æ–°é—»çš„æ–‡æœ¬å†…å®¹<br>category æ˜¯textçš„å¤šä¸ªå¤‡é€‰ç±»å‹ç»„æˆçš„åˆ—è¡¨<br>output åˆ™æ˜¯textå”¯ä¸€çœŸå®çš„ç±»å‹</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610145316360-420938404.png" alt="" width="1505" height="371" loading="lazy"></p>
<p>&nbsp;æ•°æ®é›†ä¾‹å­å¦‚ä¸‹ï¼š</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(128, 0, 0, 1)">"""
</span><span style="color: rgba(0, 0, 0, 1)">[PROMPT]Text: ç¬¬å››å±Šå…¨å›½å¤§ä¼ä¸šè¶³çƒèµ›å¤èµ›ç»“æŸæ–°åç¤¾éƒ‘å·ï¼•æœˆï¼“æ—¥ç”µï¼ˆå®ä¹ ç”Ÿç”°å…†è¿ï¼‰ä¸Šæµ·å¤§éš†æœºå™¨å‚é˜Ÿæ˜¨å¤©åœ¨æ´›é˜³è¿›è¡Œçš„ç¬¬å››å±Šç‰¡ä¸¹æ¯å…¨å›½å¤§ä¼ä¸šè¶³çƒèµ›å¤èµ›ä¸­ï¼Œä»¥ï¼•ï¼šï¼”åŠ›å…‹æˆéƒ½å†¶é‡‘å®éªŒå‚é˜Ÿï¼Œè¿›å…¥å‰å››åã€‚æ²ªè“‰ä¹‹æˆ˜ï¼ŒåŒæ–¹åŠ¿å‡åŠ›æ•Œï¼Œï¼™ï¼åˆ†é’Ÿä¸åˆ†èƒœè´Ÿã€‚æœ€åï¼ŒåŒæ–¹äº’å°„ç‚¹çƒï¼Œæ²ªé˜Ÿæ‰ä»¥ä¸€çƒä¼˜åŠ¿å–èƒœã€‚å¤èµ›çš„å…¶å®ƒï¼“åœºæ¯”èµ›ï¼Œé’æµ·å±±å·æœºåºŠé“¸é€ å‚é˜Ÿï¼“ï¼šï¼å‡»è´¥ä¸œé“ä¸»æ´›é˜³çŸ¿å±±æœºå™¨å‚é˜Ÿï¼Œé’å²›é“¸é€ æœºæ¢°å‚é˜Ÿï¼“ï¼šï¼‘æˆ˜èƒœçŸ³å®¶åº„ç¬¬ä¸€å°æŸ“å‚é˜Ÿï¼Œæ­¦æ±‰è‚‰è”å‚é˜Ÿï¼‘ï¼šï¼é™©èƒœå¤©æ´¥å¸‚ç¬¬äºŒå†¶é‡‘æœºæ¢°å‚é˜Ÿã€‚åœ¨ä»Šå¤©è¿›è¡Œçš„å†³å®šä¹è‡³åäºŒåçš„ä¸¤åœºæ¯”èµ›ä¸­ï¼ŒåŒ…é’¢æ— ç¼é’¢ç®¡å‚é˜Ÿå’Œæ²³å—å¹³é¡¶å±±çŸ¿åŠ¡å±€ä¸€çŸ¿é˜Ÿåˆ†åˆ«å‡»è´¥æ²³å—å¹³é¡¶å±±é”¦çº¶å¸˜å­å¸ƒå‚é˜Ÿå’Œæ±Ÿè‹ç›åŸæ— çº¿ç”µæ€»å‚é˜Ÿã€‚ï¼”æ—¥å°†è¿›è¡Œä¸¤åœºåŠå†³èµ›ï¼Œç”±é’æµ·å±±å·æœºåºŠé“¸é€ å‚é˜Ÿå’Œé’å²›é“¸é€ æœºæ¢°å‚é˜Ÿåˆ†åˆ«ä¸æ­¦æ±‰è‚‰è”å‚é˜Ÿå’Œä¸Šæµ·å¤§éš†æœºå™¨å‚é˜Ÿäº¤é”‹ã€‚æœ¬å±Šæ¯”èµ›å°†äºï¼–æ—¥ç»“æŸã€‚ï¼ˆå®Œï¼‰
Category: Sports, Politics
Output:[OUTPUT]Sports
</span><span style="color: rgba(128, 0, 0, 1)">"""</span></pre>
</div>
<p>æˆ‘ä»¬çš„è®­ç»ƒä»»åŠ¡ï¼Œä¾¿æ˜¯å¸Œæœ›å¾®è°ƒåçš„å¤§æ¨¡å‹èƒ½å¤Ÿæ ¹æ®Textå’ŒCategoryç»„æˆçš„æç¤ºè¯ï¼Œé¢„æµ‹å‡ºæ­£ç¡®çš„Outputã€‚</p>
<p>&nbsp;</p>
<p>æˆ‘ä»¬å°†æ•°æ®é›†ä¸‹è½½åˆ°æœ¬åœ°ç›®å½•ä¸‹ã€‚ä¸‹è½½æ–¹å¼æ˜¯å‰å¾€<a href="https://www.modelscope.cn/datasets/swift/zh_cls_fudan-news/files" target="_blank" rel="noopener nofollow">zh_cls_fudan-news - é­”æ­ç¤¾åŒº</a>&nbsp;ï¼Œå°†<code>train.jsonl</code>å’Œ<code>test.jsonl</code>ä¸‹è½½åˆ°æœ¬åœ°æ ¹ç›®å½•ä¸‹å³å¯ï¼š</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610145542632-928687883.png" alt="" width="1375" height="322" loading="lazy"></p>
<h2>åŠ è½½æ¨¡å‹</h2>
<p>è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨modelscopeä¸‹è½½Qwen3-1.7Bæ¨¡å‹ï¼ˆmodelscopeåœ¨å›½å†…ï¼Œæ‰€ä»¥ä¸‹è½½ä¸ç”¨æ‹…å¿ƒé€Ÿåº¦å’Œç¨³å®šæ€§é—®é¢˜ï¼‰ï¼Œç„¶åæŠŠå®ƒåŠ è½½åˆ°Transformersä¸­è¿›è¡Œè®­ç»ƒï¼š</p>
<p>train.py</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1)">import torch
from modelscope import snapshot_download, AutoTokenizer
from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq

# TransformersåŠ è½½æ¨¡å‹æƒé‡
tokenizer </span>= AutoTokenizer.from_pretrained(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./Qwen/Qwen3-1.7B/</span><span style="color: rgba(128, 0, 0, 1)">"</span>, use_fast=False, trust_remote_code=<span style="color: rgba(0, 0, 0, 1)">True)
model </span>= AutoModelForCausalLM.from_pretrained(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./Qwen/Qwen3-1.7B/</span><span style="color: rgba(128, 0, 0, 1)">"</span>, device_map=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">auto</span><span style="color: rgba(128, 0, 0, 1)">"</span>, torch_dtype=torch.bfloat16)</pre>
</div>
<p>æ³¨æ„ï¼šç¡®ä¿ä¸‹è½½çš„æ¨¡å‹è·¯å¾„æ­£ç¡®</p>
<p>&nbsp;</p>
<p>è¿è¡Œpythonä»£ç </p>
<div class="cnblogs_code">
<pre>python train.py</pre>
</div>
<p>è¾“å‡ºå¦‚ä¸‹ï¼š</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1)">Loading checkpoint shards: </span><span style="color: rgba(128, 0, 128, 1)">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| <span style="color: rgba(128, 0, 128, 1)">2</span>/<span style="color: rgba(128, 0, 128, 1)">2</span> [<span style="color: rgba(128, 0, 128, 1)">00</span>:<span style="color: rgba(128, 0, 128, 1)">08</span>&lt;<span style="color: rgba(128, 0, 128, 1)">00</span>:<span style="color: rgba(128, 0, 128, 1)">00</span>,  <span style="color: rgba(128, 0, 128, 1)">4</span>.01s/<span style="color: rgba(0, 0, 0, 1)">it]
Map: </span><span style="color: rgba(128, 0, 128, 1)">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| <span style="color: rgba(128, 0, 128, 1)">4000</span>/<span style="color: rgba(128, 0, 128, 1)">4000</span> [<span style="color: rgba(128, 0, 128, 1)">33</span>:<span style="color: rgba(128, 0, 128, 1)">26</span>&lt;<span style="color: rgba(128, 0, 128, 1)">00</span>:<span style="color: rgba(128, 0, 128, 1)">00</span>,  <span style="color: rgba(128, 0, 128, 1)">1.99</span> examples/s]</pre>
</div>
<p>æ²¡æœ‰æç¤ºæŠ¥é”™å°±å¯ä»¥äº†</p>
<p>&nbsp;</p>
<h1>å››ã€é…ç½®è®­ç»ƒå¯è§†åŒ–å·¥å…·</h1>
<p>æˆ‘ä»¬ä½¿ç”¨SwanLabæ¥ç›‘æ§æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶è¯„ä¼°æœ€ç»ˆçš„æ¨¡å‹æ•ˆæœã€‚</p>
<p>è¿™é‡Œç›´æ¥ä½¿ç”¨SwanLabå’ŒTransformersçš„é›†æˆæ¥å®ç°</p>
<p>&nbsp;</p>
<p>å¦‚æœä½ æ˜¯ç¬¬ä¸€æ¬¡ä½¿ç”¨SwanLabï¼Œé‚£ä¹ˆè¿˜éœ€è¦å»<a href="https://swanlab.cn/" rel="noopener nofollow">https://swanlab.cn</a>ä¸Šæ³¨å†Œä¸€ä¸ªè´¦å·ï¼Œåœ¨ç”¨æˆ·è®¾ç½®é¡µé¢å¤åˆ¶ä½ çš„API Key</p>
<p>ç™»å½•SwanLab</p>
<div class="cnblogs_code">
<pre>swanlab <span style="color: rgba(0, 0, 255, 1)">login</span></pre>
</div>
<p>è¾“å…¥API Key</p>
<div class="cnblogs_code">
<pre>swanlab: You can <span style="color: rgba(0, 0, 255, 1)">find</span> your API key at: https:<span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">swanlab.cn/space/~/settings</span>
swanlab: Paste an API key from your profile and hit enter, or press <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">CTRL + C</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)"> to quit
On Windows, use Ctrl </span>+ Shift + V or right-<span style="color: rgba(0, 0, 0, 1)">click to paste the API key:
swanlab: Login successfully. Hi, spark_xiao</span>!</pre>
</div>
<p>æç¤ºç™»å½•æˆåŠŸ</p>
<p>&nbsp;</p>
<h1>äº”ã€å®Œæ•´ä»£ç </h1>
<p>å¼€å§‹è®­ç»ƒæ—¶çš„ç›®å½•ç»“æ„ï¼š</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610151849091-159038488.png" alt="" loading="lazy"></p>
<p>è¯´æ˜ï¼š</p>
<p>Qwenï¼Œå­˜æ”¾é€šä¹‰åƒé—®æ¨¡å‹æ–‡ä»¶</p>
<p>zh_cls_fudan-newsï¼Œä¸‹è½½çš„æ•°æ®é›†ï¼Œæˆ‘è¿™é‡Œæ˜¯ä¸‹è½½çš„æ‰€æœ‰æ–‡ä»¶ã€‚</p>
<p>train.pyï¼Œè®­ç»ƒä»£ç </p>
<p>&nbsp;</p>
<p>train.py</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> json
</span><span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> pandas as pd
</span><span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> torch
</span><span style="color: rgba(0, 0, 255, 1)">from</span> datasets <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> Dataset
</span><span style="color: rgba(0, 0, 255, 1)">from</span> modelscope <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> snapshot_download, AutoTokenizer
</span><span style="color: rgba(0, 0, 255, 1)">from</span> swanlab.integration.huggingface <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> SwanLabCallback
</span><span style="color: rgba(0, 0, 255, 1)">from</span> peft <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> LoraConfig, TaskType, get_peft_model
</span><span style="color: rgba(0, 0, 255, 1)">from</span> transformers <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq
</span><span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> os
</span><span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> swanlab


</span><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> dataset_jsonl_transfer(origin_path, new_path):
    </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">
    å°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸ºå¤§æ¨¡å‹å¾®è°ƒæ‰€éœ€æ•°æ®æ ¼å¼çš„æ–°æ•°æ®é›†
    </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
    messages </span>=<span style="color: rgba(0, 0, 0, 1)"> []

    </span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> è¯»å–æ—§çš„JSONLæ–‡ä»¶</span>
    with open(origin_path, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">r</span><span style="color: rgba(128, 0, 0, 1)">"</span>, encoding=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">utf-8</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">) as file:
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> line <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> file:
            </span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> è§£ææ¯ä¸€è¡Œçš„jsonæ•°æ®</span>
            data =<span style="color: rgba(0, 0, 0, 1)"> json.loads(line)
            context </span>= data[<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">text</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">]
            catagory </span>= data[<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">category</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">]
            label </span>= data[<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">output</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">]
            message </span>=<span style="color: rgba(0, 0, 0, 1)"> {
                </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">instruction</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»é¢†åŸŸçš„ä¸“å®¶ï¼Œä½ ä¼šæ¥æ”¶åˆ°ä¸€æ®µæ–‡æœ¬å’Œå‡ ä¸ªæ½œåœ¨çš„åˆ†ç±»é€‰é¡¹ï¼Œè¯·è¾“å‡ºæ–‡æœ¬å†…å®¹çš„æ­£ç¡®ç±»å‹</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
                </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">input</span><span style="color: rgba(128, 0, 0, 1)">"</span>: f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">æ–‡æœ¬:{context},ç±»å‹é€‰å‹:{catagory}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
                </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">output</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">: label,
            }
            messages.append(message)

    </span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ä¿å­˜é‡æ„åçš„JSONLæ–‡ä»¶</span>
    with open(new_path, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">w</span><span style="color: rgba(128, 0, 0, 1)">"</span>, encoding=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">utf-8</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">) as file:
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> message <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> messages:
            file.write(json.dumps(message, ensure_ascii</span>=False) + <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)


</span><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> process_func(example):
    </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">
    å°†æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†
    </span><span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(0, 0, 0, 1)">
    MAX_LENGTH </span>= 384<span style="color: rgba(0, 0, 0, 1)">
    input_ids, attention_mask, labels </span>=<span style="color: rgba(0, 0, 0, 1)"> [], [], []
    instruction </span>=<span style="color: rgba(0, 0, 0, 1)"> tokenizer(
        f</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">&lt;|im_start|&gt;system\nä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»é¢†åŸŸçš„ä¸“å®¶ï¼Œä½ ä¼šæ¥æ”¶åˆ°ä¸€æ®µæ–‡æœ¬å’Œå‡ ä¸ªæ½œåœ¨çš„åˆ†ç±»é€‰é¡¹ï¼Œè¯·è¾“å‡ºæ–‡æœ¬å†…å®¹çš„æ­£ç¡®ç±»å‹&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\n{example['input']}&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
        add_special_tokens</span>=<span style="color: rgba(0, 0, 0, 1)">False,
    )
    response </span>= tokenizer(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">{example['output']}</span><span style="color: rgba(128, 0, 0, 1)">"</span>, add_special_tokens=<span style="color: rgba(0, 0, 0, 1)">False)
    input_ids </span>= instruction[<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">input_ids</span><span style="color: rgba(128, 0, 0, 1)">"</span>] +<span style="color: rgba(0, 0, 0, 1)"> \
        response[</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">input_ids</span><span style="color: rgba(128, 0, 0, 1)">"</span>] +<span style="color: rgba(0, 0, 0, 1)"> [tokenizer.pad_token_id]
    attention_mask </span>=<span style="color: rgba(0, 0, 0, 1)"> (
        instruction[</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">attention_mask</span><span style="color: rgba(128, 0, 0, 1)">"</span>] + response[<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">attention_mask</span><span style="color: rgba(128, 0, 0, 1)">"</span>] + [1<span style="color: rgba(0, 0, 0, 1)">]
    )
    labels </span>= [-100] * len(instruction[<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">input_ids</span><span style="color: rgba(128, 0, 0, 1)">"</span>]) +<span style="color: rgba(0, 0, 0, 1)"> \
        response[</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">input_ids</span><span style="color: rgba(128, 0, 0, 1)">"</span>] +<span style="color: rgba(0, 0, 0, 1)"> [tokenizer.pad_token_id]
    </span><span style="color: rgba(0, 0, 255, 1)">if</span> len(input_ids) &gt; MAX_LENGTH:  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> åšä¸€ä¸ªæˆªæ–­</span>
        input_ids =<span style="color: rgba(0, 0, 0, 1)"> input_ids[:MAX_LENGTH]
        attention_mask </span>=<span style="color: rgba(0, 0, 0, 1)"> attention_mask[:MAX_LENGTH]
        labels </span>=<span style="color: rgba(0, 0, 0, 1)"> labels[:MAX_LENGTH]
    </span><span style="color: rgba(0, 0, 255, 1)">return</span> {<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">input_ids</span><span style="color: rgba(128, 0, 0, 1)">"</span>: input_ids, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">attention_mask</span><span style="color: rgba(128, 0, 0, 1)">"</span>: attention_mask, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">labels</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">: labels}


</span><span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> predict(messages, model, tokenizer):
    device </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cuda</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">
    text </span>=<span style="color: rgba(0, 0, 0, 1)"> tokenizer.apply_chat_template(
        messages,
        tokenize</span>=<span style="color: rgba(0, 0, 0, 1)">False,
        add_generation_prompt</span>=<span style="color: rgba(0, 0, 0, 1)">True
    )
    model_inputs </span>= tokenizer([text], return_tensors=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">pt</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">).to(device)

    generated_ids </span>=<span style="color: rgba(0, 0, 0, 1)"> model.generate(
        model_inputs.input_ids,
        max_new_tokens</span>=512<span style="color: rgba(0, 0, 0, 1)">
    )
    generated_ids </span>=<span style="color: rgba(0, 0, 0, 1)"> [
        output_ids[len(input_ids):] </span><span style="color: rgba(0, 0, 255, 1)">for</span> input_ids, output_ids <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> zip(model_inputs.input_ids, generated_ids)
    ]

    response </span>=<span style="color: rgba(0, 0, 0, 1)"> tokenizer.batch_decode(
        generated_ids, skip_special_tokens</span>=<span style="color: rgba(0, 0, 0, 1)">True)[0]

    </span><span style="color: rgba(0, 0, 255, 1)">print</span><span style="color: rgba(0, 0, 0, 1)">(response)

    </span><span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> response

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> åœ¨modelscopeä¸Šä¸‹è½½Qwenæ¨¡å‹åˆ°æœ¬åœ°ç›®å½•ä¸‹</span><span style="color: rgba(0, 128, 0, 1)">
#</span><span style="color: rgba(0, 128, 0, 1)"> model_dir = snapshot_download("Qwen/Qwen3-1.7B", cache_dir="./", revision="master")</span>


<span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> TransformersåŠ è½½æ¨¡å‹æƒé‡</span>
tokenizer =<span style="color: rgba(0, 0, 0, 1)"> AutoTokenizer.from_pretrained(
    </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./Qwen/Qwen3-1.7B/</span><span style="color: rgba(128, 0, 0, 1)">"</span>, use_fast=False, trust_remote_code=<span style="color: rgba(0, 0, 0, 1)">True)
model </span>=<span style="color: rgba(0, 0, 0, 1)"> AutoModelForCausalLM.from_pretrained(
    </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./Qwen/Qwen3-1.7B/</span><span style="color: rgba(128, 0, 0, 1)">"</span>, device_map=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">auto</span><span style="color: rgba(128, 0, 0, 1)">"</span>, torch_dtype=<span style="color: rgba(0, 0, 0, 1)">torch.bfloat16)
model.enable_input_require_grads()  </span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> å¼€å¯æ¢¯åº¦æ£€æŸ¥ç‚¹æ—¶ï¼Œè¦æ‰§è¡Œè¯¥æ–¹æ³•</span>

<span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> åŠ è½½ã€å¤„ç†æ•°æ®é›†å’Œæµ‹è¯•é›†</span>
train_dataset_path = <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./zh_cls_fudan-news/train.jsonl</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">
test_dataset_path </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./zh_cls_fudan-news/test.jsonl</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">

train_jsonl_new_path </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">new_train.jsonl</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">
test_jsonl_new_path </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">new_test.jsonl</span><span style="color: rgba(128, 0, 0, 1)">"</span>

<span style="color: rgba(0, 0, 255, 1)">if</span> <span style="color: rgba(0, 0, 255, 1)">not</span><span style="color: rgba(0, 0, 0, 1)"> os.path.exists(train_jsonl_new_path):
    dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)
</span><span style="color: rgba(0, 0, 255, 1)">if</span> <span style="color: rgba(0, 0, 255, 1)">not</span><span style="color: rgba(0, 0, 0, 1)"> os.path.exists(test_jsonl_new_path):
    dataset_jsonl_transfer(test_dataset_path, test_jsonl_new_path)

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> å¾—åˆ°è®­ç»ƒé›†</span>
train_df = pd.read_json(train_jsonl_new_path, lines=<span style="color: rgba(0, 0, 0, 1)">True)
train_ds </span>=<span style="color: rgba(0, 0, 0, 1)"> Dataset.from_pandas(train_df)
train_dataset </span>=<span style="color: rgba(0, 0, 0, 1)"> train_ds.map(
    process_func, remove_columns</span>=<span style="color: rgba(0, 0, 0, 1)">train_ds.column_names)

config </span>=<span style="color: rgba(0, 0, 0, 1)"> LoraConfig(
    task_type</span>=<span style="color: rgba(0, 0, 0, 1)">TaskType.CAUSAL_LM,
    target_modules</span>=[<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">q_proj</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">k_proj</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">v_proj</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
                    </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">o_proj</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">gate_proj</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">up_proj</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">down_proj</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">],
    inference_mode</span>=False,  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> è®­ç»ƒæ¨¡å¼</span>
    r=8,  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Lora ç§©</span>
    lora_alpha=32,  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Lora alaphï¼Œå…·ä½“ä½œç”¨å‚è§ Lora åŸç†</span>
    lora_dropout=0.1,  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Dropout æ¯”ä¾‹</span>
<span style="color: rgba(0, 0, 0, 1)">)

model </span>=<span style="color: rgba(0, 0, 0, 1)"> get_peft_model(model, config)

args </span>=<span style="color: rgba(0, 0, 0, 1)"> TrainingArguments(
    output_dir</span>=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./output/Qwen3-zh_cls_fudan-news</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
    per_device_train_batch_size</span>=4<span style="color: rgba(0, 0, 0, 1)">,
    gradient_accumulation_steps</span>=4<span style="color: rgba(0, 0, 0, 1)">,
    logging_steps</span>=10<span style="color: rgba(0, 0, 0, 1)">,
    num_train_epochs</span>=2<span style="color: rgba(0, 0, 0, 1)">,
    save_steps</span>=100<span style="color: rgba(0, 0, 0, 1)">,
    learning_rate</span>=1e-4<span style="color: rgba(0, 0, 0, 1)">,
    save_on_each_node</span>=<span style="color: rgba(0, 0, 0, 1)">True,
    gradient_checkpointing</span>=<span style="color: rgba(0, 0, 0, 1)">True,
    report_to</span>=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">none</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
)

swanlab_callback </span>=<span style="color: rgba(0, 0, 0, 1)"> SwanLabCallback(
    project</span>=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Qwen3-fintune</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
    experiment_name</span>=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Qwen3-1.7B</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
    description</span>=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ä½¿ç”¨é€šä¹‰åƒé—®Qwen3-1.7Bæ¨¡å‹åœ¨zh_cls_fudan-newsæ•°æ®é›†ä¸Šå¾®è°ƒã€‚</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
    config</span>=<span style="color: rgba(0, 0, 0, 1)">{
        </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">model</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Qwen/Qwen3-1.7B</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
        </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">dataset</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">swift/zh_cls_fudan-news</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
    }
)

trainer </span>=<span style="color: rgba(0, 0, 0, 1)"> Trainer(
    model</span>=<span style="color: rgba(0, 0, 0, 1)">model,
    args</span>=<span style="color: rgba(0, 0, 0, 1)">args,
    train_dataset</span>=<span style="color: rgba(0, 0, 0, 1)">train_dataset,
    data_collator</span>=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=<span style="color: rgba(0, 0, 0, 1)">True),
    callbacks</span>=<span style="color: rgba(0, 0, 0, 1)">[swanlab_callback],
)

trainer.train()

</span><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ç”¨æµ‹è¯•é›†çš„å‰10æ¡ï¼Œæµ‹è¯•æ¨¡å‹</span>
test_df = pd.read_json(test_jsonl_new_path, lines=True)[:10<span style="color: rgba(0, 0, 0, 1)">]

test_text_list </span>=<span style="color: rgba(0, 0, 0, 1)"> []
</span><span style="color: rgba(0, 0, 255, 1)">for</span> index, row <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> test_df.iterrows():
    instruction </span>= row[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">instruction</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]
    input_value </span>= row[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">input</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">]

    messages </span>=<span style="color: rgba(0, 0, 0, 1)"> [
        {</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">role</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">system</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">content</span><span style="color: rgba(128, 0, 0, 1)">"</span>: f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">{instruction}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">},
        {</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">role</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">user</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">content</span><span style="color: rgba(128, 0, 0, 1)">"</span>: f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">{input_value}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">}
    ]

    response </span>=<span style="color: rgba(0, 0, 0, 1)"> predict(messages, model, tokenizer)
    messages.append({</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">role</span><span style="color: rgba(128, 0, 0, 1)">"</span>: <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">assistant</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">content</span><span style="color: rgba(128, 0, 0, 1)">"</span>: f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">{response}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">})
    result_text </span>= f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">{messages[0]}\n\n{messages[1]}\n\n{messages[2]}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">
    test_text_list.append(swanlab.Text(result_text, caption</span>=<span style="color: rgba(0, 0, 0, 1)">response))

swanlab.log({</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Prediction</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">: test_text_list})
swanlab.finish()</span></pre>
</div>
<p>&nbsp;</p>
<p>æ‰§è¡Œä»£ç </p>
<div class="cnblogs_code">
<pre>python train.py</pre>
</div>
<p>&nbsp;</p>
<p>çœ‹åˆ°ä¸‹é¢çš„è¿›åº¦æ¡å³ä»£è¡¨è®­ç»ƒå¼€å§‹ï¼š</p>
<div class="cnblogs_code">
<pre>swanlab: Tracking run with swanlab version <span style="color: rgba(128, 0, 128, 1)">0.6</span>.<span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">
swanlab: Run data will be saved locally </span><span style="color: rgba(0, 0, 255, 1)">in</span> D:\<span style="color: rgba(0, 0, 255, 1)">file</span>\vllm\swanlog\run-20250610_174942-<span style="color: rgba(0, 0, 0, 1)">a3b1799d
swanlab: ğŸ‘‹ Hi spark_xiao, welcome to swanlab</span>!<span style="color: rgba(0, 0, 0, 1)">
swanlab: Syncing run Qwen3</span>-<span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">.7B to the cloud
swanlab: ğŸ  View project at https:</span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">swanlab.cn/@spark_xiao/Qwen3-fintune</span>
swanlab: ğŸš€ View run at https:<span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">swanlab.cn/@spark_xiao/Qwen3-fintune/runs/2k85y57dzb3p3ozpvwkow</span>
  <span style="color: rgba(128, 0, 128, 1)">0</span>%|                                                                                          | <span style="color: rgba(128, 0, 128, 1)">0</span>/<span style="color: rgba(128, 0, 128, 1)">500</span> [<span style="color: rgba(128, 0, 128, 1)">00</span>:<span style="color: rgba(128, 0, 128, 1)">00</span>&lt;?, ?it/s]`<br>use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=<span style="color: rgba(0, 0, 0, 1)">False`.
{</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">loss</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">32.3218</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">grad_norm</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">36.5546875</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">learning_rate</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">9.82e-05</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">epoch</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">0.04</span><span style="color: rgba(0, 0, 0, 1)">}
{</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">loss</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">10.8642</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">grad_norm</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">221.5959014892578</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">learning_rate</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">9.620000000000001e-05</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">epoch</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 128, 1)">0.08</span><span style="color: rgba(0, 0, 0, 1)">}
  </span><span style="color: rgba(128, 0, 128, 1)">5</span>%|â–ˆâ–ˆâ–ˆâ–ˆ                                                                           | <span style="color: rgba(128, 0, 128, 1)">26</span>/<span style="color: rgba(128, 0, 128, 1)">500</span> [<span style="color: rgba(128, 0, 128, 1)">04</span>:<span style="color: rgba(128, 0, 128, 1)">58</span>&lt;<span style="color: rgba(128, 0, 128, 1)">1</span>:<span style="color: rgba(128, 0, 128, 1)">28</span>:<span style="color: rgba(128, 0, 128, 1)">51</span>, <span style="color: rgba(128, 0, 128, 1)">11</span>.25s/it]</pre>
</div>
<p>&nbsp;</p>
<p>ç­‰å¾…1å°æ—¶50åˆ†é’Ÿï¼Œå°±å®Œæˆäº†ï¼Œè¾“å‡º</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(128, 0, 128, 1)">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| <span style="color: rgba(128, 0, 128, 1)">500</span>/<span style="color: rgba(128, 0, 128, 1)">500</span> [<span style="color: rgba(128, 0, 128, 1)">1</span>:<span style="color: rgba(128, 0, 128, 1)">12</span>:<span style="color: rgba(128, 0, 128, 1)">54</span>&lt;<span style="color: rgba(128, 0, 128, 1)">00</span>:<span style="color: rgba(128, 0, 128, 1)">00</span>,  <span style="color: rgba(128, 0, 128, 1)">8</span>.75s/<span style="color: rgba(0, 0, 0, 1)">it]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">s `attention_mask` to obtain reliable results.</span>
D:\<span style="color: rgba(0, 0, 255, 1)">file</span>\conda\envs\my_unsloth_env\Lib\site-packages\torch\utils\checkpoint.py:<span style="color: rgba(128, 0, 128, 1)">86</span>: UserWarning: None of the inputs have requires_grad=<span style="color: rgba(0, 0, 0, 1)">True. Gradients will be None
  warnings.warn(
Computer
Space
Literature
History
History
Space
Transport
Art
Economy
Art
swanlab: ğŸ  View project at https:</span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">swanlab.cn/@spark_xiao/Qwen3-fintune</span>
swanlab: ğŸš€ View run at https:<span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">swanlab.cn/@spark_xiao/Qwen3-fintune/runs/9rzt3rv77885ek176nslh</span></pre>
</div>
<p>æ³¨æ„ï¼šæœ€åä¸€ä¸ªè¾“å‡ºçš„urlï¼Œå°±å¯ä»¥çœ‹åˆ°æ¼”ç¤ºç»“æœã€‚</p>
<p>&nbsp;</p>
<h1>å…­ã€è®­ç»ƒç»“æœæ¼”ç¤º</h1>
<p>åœ¨SwanLabä¸ŠæŸ¥çœ‹æœ€ç»ˆçš„è®­ç»ƒç»“æœï¼š</p>
<p>æ‰“å¼€é“¾æ¥ï¼šhttps://swanlab.cn/@spark_xiao/Qwen3-fintune/runs/9rzt3rv77885ek176nslh</p>
<p>&nbsp;</p>
<p>å¯ä»¥çœ‹åˆ°åœ¨2ä¸ªepochä¹‹åï¼Œå¾®è°ƒåçš„qwen3çš„lossé™ä½åˆ°äº†ä¸é”™çš„æ°´å¹³â€”â€”å½“ç„¶å¯¹äºå¤§æ¨¡å‹æ¥è¯´ï¼ŒçœŸæ­£çš„æ•ˆæœè¯„ä¼°è¿˜å¾—çœ‹ä¸»è§‚æ•ˆæœã€‚</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610153338309-855764500.png" alt="" loading="lazy"></p>
<p>å¯ä»¥çœ‹åˆ°åœ¨ä¸€äº›æµ‹è¯•æ ·ä¾‹ä¸Šï¼Œå¾®è°ƒåçš„qwen3èƒ½å¤Ÿç»™å‡ºå‡†ç¡®çš„æ–‡æœ¬ç±»å‹ï¼š</p>
<p><img src="https://img2024.cnblogs.com/blog/1341090/202506/1341090-20250610153517525-1873628635.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>è‡³æ­¤ï¼Œä½ å·²ç»å®Œæˆäº†qwen3æŒ‡ä»¤å¾®è°ƒçš„è®­ç»ƒï¼</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>æœ¬æ–‡å‚è€ƒé“¾æ¥ï¼š</p>
<p>https://blog.csdn.net/SoulmateY/article/details/139564703</p>
<p>https://blog.csdn.net/qq_45258632/article/details/144971398</p>
<p>&nbsp;</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.09722222222222222" data-date-updated="2025-06-10 17:56">2025-06-10 15:36</span>&nbsp;
<a href="https://www.cnblogs.com/xiao987334176">è‚–ç¥¥</a>&nbsp;
é˜…è¯»(<span id="post_view_count">60</span>)&nbsp;
è¯„è®º(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18922128);return false;">æ”¶è—</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18922128', targetLink: 'https://www.cnblogs.com/xiao987334176/p/18922128', title: 'SwanLabå…¥é—¨æ·±åº¦å­¦ä¹ ï¼šQwen3å¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒ' })">ä¸¾æŠ¥</a>
</div>
        