
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/jimoer/p/19049622" title="发布于 2025-08-20 22:27">
    <span role="heading" aria-level="2">Kafka如何保证「消息不丢失」，「顺序传输」，「不重复消费」，以及为什么会发生重平衡（reblanace）</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="前言">前言</h2>
<p>上一篇文章总结了kafka为什么快，下面来总结一下，kafka高频的常见的问题。内容有点多，全部看完需要有一定的耐心。</p>
<h2 id="kafka如何保证消息不丢失">kafka如何保证消息不丢失</h2>
<h4 id="producer端">Producer端</h4>
<p>要保证消息不丢失，第一点要做的就是要保证消息从producer端发送到了kafka的broker中，并且broker把消息保存了下来。<br>
由于在发送消息的过程中有可能会发生<strong>网络故障，broker故障</strong>等原因导致消息发送失败，因此在producer端有两种方式来避免消息丢失。</p>
<h5 id="接收发送消息回执">接收发送消息回执</h5>
<p>我们在使用kafka发送消息的时候，通常是使用<code>producer.send(msg)</code>方法，但是这个方法其实是一种异步发送，调用此方法发送消息的时候，虽然会立即返回，但是并不代表消息真的发送成功了。<br>
1、<strong>所以可以使用同步发送消息，<code>producer.send(msg).get()</code>此方法会执行同步发生消息，并等待结果返回</strong>。<br>
2、<strong>也可以使用带回调函数的异步方法，<code>producer.send(msg,callback)</code>，用回调函数来监听消息的发送结果，如果发送失败了，可以在回调函数里面进行重试。</strong></p>
<h5 id="producer参数配置">producer参数配置</h5>
<p>producer也提供了一些配置参数来避免消息丢失。</p>
<pre><code class="language-bash">// 此配置表示，Leader和Follower全部成功接收消息后才确认收到消息，
// 可以最大限度保证消息不丢失，但是吞吐量会下降
acks = -1 
// producer 发送消息失败后，自动重试次数
retries = 3
// 发送消息失败后的重试时间间隔
retry.backoff.ms = 300
</code></pre>
<h4 id="broker端">Broker端</h4>
<p>当消息发送到broker后，broker需要保证此消息不会丢失，我们都知道，kafka是会将消息持久化到磁盘中的。<br>
但是kafka为了保持性能采用了，<a href="https://www.cnblogs.com/jimoer/p/18998722" target="_blank">页缓存+异步刷盘</a>的形式将消息持久化到磁盘的。也就是批量定时将消息持久化到磁盘。<br>
但是页缓存如果还没来的及将消息刷到磁盘，broker就挂了，还是会有消息丢失的风险，因此kafka又提供了partition的<strong>ISR（同步副本机制）</strong>，即每一个patrtition都会有一个唯一的Leader和一到多个Follower，Leader专门处理一些事务类型的请求，Follower负责同步Leader的数据。当leader挂了后，会重新从Follower中选举出新的Leader，保证消息能够最终持久化。<br>
另外，在producer中的配置参数<code>acks</code>,配置不同的值，broker也是会做不同的处理的。</p>
<blockquote>
<p>acks=0:表示Producer请求立即返回，不需要等待Leader的任何确认。这种方案有最高的吞吐率，但是不保证消息是否真的发送成功。<br>
acks =-1: 表示分区Leader必须等待消息被成功写入到所有的ISR副本(同步副本)中才认为Producer请求成功。这种方案提供最高的消息持久性保证，但是理论上吞吐率也是最差的。<br>
acks=1: 表示Leader副本必须应答此Producer请求并写入消息到本地日志，之后Producer请求被认为成功。如果此时Leader副本应答请求之后挂掉了，消息会丢失。这个方案，提供了不错的持久性保证和吞吐。</p>
</blockquote>
<p>producer中还有一些参数的配置也是会起到避免消息丢失的作用</p>
<pre><code class="language-powershell">//表示分区副本的个数，replication.factor&gt;1,当Leader挂了，follower会被选举为leader继续提供服务
replication.factor=2

//表示 ISR 最少的副本数量，通常设置 replication.factormin.insync.replicas&gt;1，这样才有可用的follower副本执行替换，保证消息不丢失
replication.factormin.insync.replicas=2

//是否可以把非ISR集合中的副本选举为leader
min.inunclean.leader.election.enable= false
</code></pre>
<h4 id="consumer端">Consumer端</h4>
<p>Consumer端，只要保证消息接收到不胡乱的提交offset就行，kafka本身也是会记录每个pratition的偏移量，但是为了业务的可靠性，也可以自己存储一份offset，防止由于业务代码的问题导致消息没有处理就提交的offset，有自己存储才这一份offset就可以对偏移量进行一个回拨。</p>
<p>为了避免消息丢失，建议使用手动提交偏移量的方式，防止消息的业务逻辑未处理完，提交偏移量后消费者挂了的问题。</p>
<pre><code class="language-powershell">enable.auto.commit=false
</code></pre>
<h2 id="kafka如何保证消息的顺序传输">kafka如何保证消息的顺序传输</h2>
<p>我们知道，kafka的消息实际是存在某个topic的partition中的，一个topic有多个partition分区，同一个partition中的消息是有序的，跨partition的消息是无序的。<br>
这个是怎么实现的呢？<br>
因为我们在【<a href="https://www.cnblogs.com/jimoer/p/18998722" target="_blank">Kafka为什么吞吐量大，速度快？</a>】这篇文章里面总结了，kafka写入磁盘时是顺序写的，并且会被分配一个唯一的offset，所以同一个partition保存的数据都是有序的。而在读取消息时，消费者会从该分区最早的offset开始，依次读取消息，保证了消息顺序消费。</p>
<p>具体实现顺序发送消息有两种方式：<br>
<strong>1、在使用kafka时，对需要保证顺序消费的topic，只创建一个partition，这样消息就都会顺序的存储到这一个partition中，也就能保证顺序消费了。<br>
2、当一个topic有多个partition时，对需要保证顺序的消息，都发到指定的partition即可，这样也能保证顺序消费。</strong></p>
<p>注：需要注意一点，虽然发送时保证了顺序，也都写到了同一个partition中，但在消费端，也要保证顺序消费，即单线程处理消息。</p>
<blockquote>
<p>目前kafka4.0，可以允许一个consumer group下的多个消费者同时消费同一个partition了。</p>
<p>其借助新推出的共享组（Shared Group）特性来达成这一功能，且支持逐条消息确认，从而让消费模式更具灵活性，还能助力提升吞吐量。以往版本默认仅允许一个消费者组内单个消费者消费一个特定分区，当消费者多于分区时，多余消费者会闲置，共享组则可避免出现该类资源浪费情况。</p>
</blockquote>
<p>将消息发到指定partition中也有几种方式。<br>
1、发送消息，组装producerRecord时，指定partition</p>
<pre><code class="language-java">// 创建Kafka生产者
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(getProperties());
// 指定要发送消息的topic
String topic ="jimer_topic";
// 发送的消息内容
String message =“Hello World!";
// 指定发送消息的分区
int partition =0;

// 创建包含分区信息的ProducerRecord
ProducerRecordProducerRecord&lt;String,String&gt; record = new ProducerRecord&lt;&gt;(topic, partition, message);
// 发送消息
producer.send(record);
//关闭Kafka生产者
producer.close();

</code></pre>
<p>2、指定消息的key，保证相同key的消息发送到同一个partition</p>
<pre><code class="language-java">// 创建Kafka生产者
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(getProperties());
// 指定要发送消息的topic
String topic ="jimer_topic";
// 发送的消息内容
String message =“Hello World";
// 指定发送消息的key
String msg_key = "order_msg";

// 创建包含消息key的producerRecord
ProducerRecordProducerRecord&lt;String,String&gt; record = 
new ProducerRecord&lt;&gt;(topic, null,msg_key, message);
// 发送消息
producer.send(record);
//关闭Kafka生产者
producer.close();
</code></pre>
<p>3、自定义Partitioner<br>
除了上面两种方式外，还可以自定义指定分区的方式。通过实现Partitioner这个接口，具体实现partition方法，就可以了。具体使用的时候，在初始化Producer时，指定具体的partition实现类即可。<br>
例如：</p>
<pre><code class="language-java">public class MyPartitioner implatents Partitioner{

@Override
public void configure(Map&lt;String,?&gt; configs){
  // 可以在这里处理和获取分区器的配置参数
}
@0verride
public int partition(String topic, Object key, byte[] keyBytes, 
Object value,byte[] valueBytes,Cluster cluster){
    int partition =  int ss = new Random().nextInt(2);
	// 返回分区编号
	return partition;
}
@0verride
public void close(){
	// 可以在这里进行一些清理操作
}
</code></pre>
<p>使用时</p>
<pre><code class="language-java">Properties propsProducer = new Properties();
        propsProducer.put("acks", "all"); // 全部ISR列表中的副本接收成功后返回
        propsProducer.put("retries", 3);//失败时重试次数
        propsProducer.put("partitioner.class", "com.jimoer.MyPartitioner"); // 指定自定义分区器类
// 创建Kafka生产者
Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(propsProducer);
</code></pre>
<h2 id="kafka如何保证消息不重复消费">kafka如何保证消息不重复消费</h2>
<h4 id="什么情况下会导致消息被重复消费呢">什么情况下会导致消息被重复消费呢？</h4>
<p>1、<strong>生产者</strong>，生产者可能重复推送了一条消息到kafka，例如：某接口未做幂等处理，接口中会发送kafka消息。<br>
2、<strong>kafka</strong>，在消费者消费完消息后，提交offset时，kafka突然挂了，导致kafka认为此消息还未消费，又重新推送了该条消息，导致了重复消费消息。<br>
3、<strong>消费者</strong>，在消费者消费完消息后，提交offset时，Consumer突然宕机挂掉，这个时候，kafka未接收到已处理的offset值，当Consumer恢复后，会重新消费此部分消息。<br>
4、还有一种情况，Kafka 存在 <strong>Partition Balance</strong> 机制，会将多个 Partition 均衡分配给多个消费者。若 Consumer 在默认 5 分钟内未处理完一批消息，会触发 Rebalance 机制，导致 offset 自动提交失败，重新 Rebalance 后，消费者会从之前未提交的 offset 位置开始消费，从而造成消息重复消费。</p>
<h4 id="那么我们该如何防止消息被重复消费呢">那么我们该如何防止消息被重复消费呢</h4>
<p>其实上面的1、2、3、4这些情况都可以用幂等机制来防止消息被重复消费。为消息生成 一个唯一标识，并保存到 mysql 或 redis 中，处理消息前先到 mysql 或 redis 中判断该消息是否已被消费过。</p>
<p>但是第4种情况，前提是要先优化<strong>消费端处理性能，避免触发 Rebalance</strong>，例如：<code>采用异步方式处理消息、缩短单个消息消费时长、调整消息处理超时时间、减少一次性从 Broker 拉取的数据条数等。</code></p>
<h2 id="kafka什么情况下会发生reblanace重平衡">kafka什么情况下会发生reblanace（重平衡）</h2>
<p><strong>Kafka 的重平衡（Rebalance）是指消费者组（Consumer Group）内的消费者与分区（Partition）之间的分配关系发生重新调整的过程</strong>。<br>
主要有以下几种情况会触发：<br>
<strong>1、消费者组成员数量发生变化。((新消费者的加入或者退出)<br>
2、订阅主题(Topic)数量发生变化。<br>
3、订阅主题的分区(Partition)数发生变化。</strong><br>
还有某些异常情况也会触发Rebalance：<br>
1、<strong>消费端处理消息超时</strong>，上面我们说到过，若消费者未在设定时间内处理完消息，消费者组会认为当前消费者有问题了，会触发Rebalance，重新分配消息。又或者当前消费者挂了，也是一样会触发Rebalance。<br>
2、<strong>组协调器(Group Coordinator)是 Kafka 负责管理消费者组的 Broker 节点。如果它崩溃或者发生故障。Kafka 需要重新选举新的 Group Coordinator ，并进行重平衡。</strong></p>
<p>当Kafka 集群要触发重平衡机制时，大致的步骤如下:<br>
1.<strong>暂停消费</strong>:在重平衡开始之前，Kafka 会暂停所有消费者的拉取操作，以确保不会出现重平衡期间的消息丢失或重复消费。<br>
2.<strong>计算分区分配方案</strong>:Kafka 集群会根据当前消费者组的消费者数量和主题分区数量，计算出每个消费者应该分配的分区列表，以实现分区的负载均衡。<br>
3.<strong>通知消费者</strong>:一旦分区分配方案确定，Kafka 集群会将分配方案发送给每个消费者，告诉它们需要消费的分区列表，并请求它们重新加入消费者组。<br>
4.<strong>重新分配分区</strong>:在消费者重新加入消费者组后，Kafka 集群会将分区分配方案应用到实际的分区分配中，重新分配主题分区给各个消费者。<br>
5.<strong>恢复消费</strong>:最后，Kafka 会恢复所有消费者的拉取操作，允许它们消费分配给自己的分区。</p>

</div>
<div id="MySignature" role="contentinfo">
    <div style="float:left;letter-spacing: 1px;font-size: 13px;"><p><strong>作者：</strong><a href="http://www.cnblogs.com/jimoer/">纪莫</a>
<br>欢迎任何形式的转载，但请务必注明出处。<br>
限于本人水平，如果文章和代码有表述不当之处，还请不吝赐教。</p>
<!-- 分享图标开始 -->
<p>欢迎扫描二维码关注公众号：<strong>Jimoer</strong></p>
<p>文章会同步到公众号上面，大家一起成长，共同提升技术能力。</p>
<p><strong>声援博主：</strong>如果您觉得文章对您有帮助，可以点击文章右下角【<a onclick="pepleFavourite();" href="javascript:void(0);" style="font-size: 14pt;">推荐</a>】一下。</p>
<p>您的鼓励是博主的最大动力！</p>
</div>
<div style="float:right;">
<img src="https://img2018.cnblogs.com/blog/772743/201909/772743-20190904004009398-659676330.png" alt="微信公众号"></div>
<!-- 分享图标结束 -->
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.5534722222222223" data-date-updated="2025-08-21 11:44">2025-08-20 22:27</span>&nbsp;
<a href="https://www.cnblogs.com/jimoer">纪莫</a>&nbsp;
阅读(<span id="post_view_count">184</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19049622);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19049622', targetLink: 'https://www.cnblogs.com/jimoer/p/19049622', title: 'Kafka如何保证「消息不丢失」，「顺序传输」，「不重复消费」，以及为什么会发生重平衡（reblanace）' })">举报</a>
</div>
        