
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/qubernet/p/18704234" title="发布于 2025-02-08 15:28">
    <span role="heading" aria-level="2">.Net9中通过HttpClient简单调用Ollama中的DeepSeek R1模型</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<blockquote>
<p>本文主要使用.Net9中的HttpClient组件，调用本地部署的Ollama提供的API接口，获取对应的问答信息。</p>
</blockquote>
<h1 id="1测试环境">1、🥇测试环境</h1>
<ul>
<li>
<p>VS2022；</p>
</li>
<li>
<p>.Net9控制台程序；</p>
</li>
<li>
<p>HttpClient组件；</p>
</li>
<li>
<p>本地部署的Ollama环境</p>
</li>
<li>
<p>DeepSeek R1模型（deepseek-r1:1.5b）</p>
</li>
</ul>
<p>关于本地部署的Ollama环境，可参见文章【<a href="https://www.cnblogs.com/qubernet/p/18702147" target="_blank">通过Ollama本地部署DeepSeek R1以及简单使用的教程（超详细）</a>】。</p>
<hr>
<h1 id="2创建控制台程序">2、🥈创建控制台程序</h1>
<p>我们使用VS2022创建一个基于.Net9的控制台程序，具体如下所示：</p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250208144132808-1982141445.png" alt="控制台程序" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250208144155424-349494272.png" alt="控制台程序" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250208144300052-451934267.png" alt="控制台程序" loading="lazy"></p>
<p>上述我们就创建好了一个控制台程序。</p>
<hr>
<h1 id="3ollama接口">3、🥉Ollama接口</h1>
<p>Ollama为我们提供了多种接口，最常用的接口为：</p>
<ul>
<li>
<p>POST /api/generate</p>
</li>
<li>
<p>POST /api/chat</p>
</li>
</ul>
<p>上述两个接口为最常用的，具体说明可参见【<a href="https://github.com/ollama/ollama/blob/main/docs/api.md" target="_blank" rel="noopener nofollow">https://github.com/ollama/ollama/blob/main/docs/api.md</a>】说明，如下所示为部分使用说明的截图：</p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250208145015710-1933094050.png" alt="Ollama接口" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250208145111027-1097427983.png" alt="Ollama接口" loading="lazy"></p>
<hr>
<h1 id="4调用实现">4、🏅调用实现</h1>
<h2 id="41generate接口">4.1、🎀generate接口</h2>
<p>我们在<code>Program.cs</code>文件中编写具体的代码。</p>
<p>具体代码实现如下所示（复制粘贴即可运行），都有对应的说明：</p>
<pre><code class="language-cs">using System.Data;
using System.Text;
using System.Text.Json;

// HttpClient实例
var httpClient = new HttpClient();

// Ollama API请求地址
var requestUrl = "http://localhost:11434/api/generate";

Console.ForegroundColor = ConsoleColor.Green;
Console.WriteLine("请输入对话内容（输入exit退出）：");

while (true)
{
    // 读取输入的内容
    var input = Console.ReadLine();

    if (input != null &amp;&amp; input.ToLower() == "exit")
    {
        Console.ForegroundColor = ConsoleColor.Red;
        Console.WriteLine("程序即将退出...");

        // 退出循环，程序结束
        break;
    }

    // 请求参数
    var requestData = new
    {
        // 指定模型标识符
        model = "deepseek-r1:1.5b",
        // 输入的提示文本
        prompt = input,
        // 是否启用流式响应
        stream = true,
        // 其他选项
        options = new
        {
            // 控制生成随机性（0-1）
            temperature = 0.7,
            // 最大生成 token 数
            max_tokens = 500
        }
    };

    // 创建HttpRequestMessage实例以及设置请求内容
    using var request = new HttpRequestMessage(HttpMethod.Post, requestUrl);
    request.Content = new StringContent(JsonSerializer.Serialize(requestData), Encoding.UTF8, "application/json");

    // 发送请求并获取响应
    using var response = await httpClient.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);
    await using var stream = await response.Content.ReadAsStreamAsync();
    using var reader = new StreamReader(stream);

    // 循环读取响应流
    while (!reader.EndOfStream)
    {
        var content = await reader.ReadLineAsync();
        if (!string.IsNullOrEmpty(content))
        {
            var partialResponse = JsonSerializer.Deserialize&lt;OllamaResponse&gt;(content);

            // 输出响应内容
            Console.ForegroundColor = ConsoleColor.White;
            Console.Write(partialResponse?.response);
        }
    }

    Console.ForegroundColor = ConsoleColor.Green;
    Console.WriteLine("\r\n\r\n请输入对话内容（输入exit退出）：");
}

/// &lt;summary&gt;
/// Ollama API响应实体类
/// &lt;/summary&gt;
public class OllamaResponse
{
    /// &lt;summary&gt;
    /// 模型标识符
    /// &lt;/summary&gt;
    public string model { get; set; }

    /// &lt;summary&gt;
    /// 创建时间戳
    /// &lt;/summary&gt;
    public string created_at { get; set; }

    /// &lt;summary&gt;
    /// 响应内容
    /// &lt;/summary&gt;
    public string response { get; set; }

    /// &lt;summary&gt;
    /// 是否完成
    /// &lt;/summary&gt;
    public bool done { get; set; }

    /// &lt;summary&gt;
    /// 完成原因
    /// &lt;/summary&gt;
    public string done_reason { get; set; }

    public int[] context { get; set; }
    public long total_duration { get; set; }
    public long load_duration { get; set; }
    public int prompt_eval_count { get; set; }
    public long prompt_eval_duration { get; set; }
    public int eval_count { get; set; }
    public long eval_duration { get; set; }
}
</code></pre>
<p><strong>运行效果：</strong></p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250208151640068-1785980879.gif" alt="运行效果" loading="lazy"></p>
<h2 id="42chat接口">4.2、🎁chat接口</h2>
<p>我们在<code>Program.cs</code>文件中编写具体的代码。</p>
<p>具体代码实现如下所示（复制粘贴即可运行），都有对应的说明：</p>
<pre><code class="language-cs">using System.Data;
using System.Text;
using System.Text.Json;

// HttpClient实例
var httpClient = new HttpClient();

// Ollama API请求地址
var requestUrl = "http://localhost:11434/api/chat";

Console.ForegroundColor = ConsoleColor.Green;
Console.WriteLine("请输入对话内容（输入exit退出）：");

while (true)
{
    // 读取输入的内容
    var input = Console.ReadLine();

    if (input != null &amp;&amp; input.ToLower() == "exit")
    {
        Console.ForegroundColor = ConsoleColor.Red;
        Console.WriteLine("程序即将退出...");

        // 退出循环，程序结束
        break;
    }

    // 请求参数
    var requestData = new
    {
        // 指定模型标识符
        model = "deepseek-r1:1.5b",
        // 输入的提示文本
        messages = new[]
        {
            new { role = "user", content = input }
        },
        // 是否启用流式响应
        stream = true,
        // 其他选项
        options = new
        {
            // 控制生成随机性（0-1）
            temperature = 0.7,
            // 最大生成 token 数
            max_tokens = 500
        }
    };

    // 创建HttpRequestMessage实例以及设置请求内容
    using var request = new HttpRequestMessage(HttpMethod.Post, requestUrl);
    request.Content = new StringContent(JsonSerializer.Serialize(requestData), Encoding.UTF8, "application/json");

    // 发送请求并获取响应
    using var response = await httpClient.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);
    await using var stream = await response.Content.ReadAsStreamAsync();
    using var reader = new StreamReader(stream);

    // 循环读取响应流
    while (!reader.EndOfStream)
    {
        var content = await reader.ReadLineAsync();
        if (!string.IsNullOrEmpty(content))
        {
            var partialResponse = JsonSerializer.Deserialize&lt;OllamaResponse&gt;(content);

            // 输出响应内容
            Console.ForegroundColor = ConsoleColor.White;
            Console.Write(partialResponse?.message.content);
        }
    }

    Console.ForegroundColor = ConsoleColor.Green;
    Console.WriteLine("\r\n\r\n请输入对话内容（输入exit退出）：");
}

/// &lt;summary&gt;
/// Ollama API响应实体类
/// &lt;/summary&gt;
public class OllamaResponse
{
    /// &lt;summary&gt;
    /// 模型标识符
    /// &lt;/summary&gt;
    public string model { get; set; }

    /// &lt;summary&gt;
    /// 创建时间戳
    /// &lt;/summary&gt;
    public string created_at { get; set; }

    /// &lt;summary&gt;
    /// 响应内容
    /// &lt;/summary&gt;
    public OllamaResponseMessage message { get; set; }

    /// &lt;summary&gt;
    /// 是否完成
    /// &lt;/summary&gt;
    public bool done { get; set; }

    /// &lt;summary&gt;
    /// 完成原因
    /// &lt;/summary&gt;
    public string done_reason { get; set; }

    public long total_duration { get; set; }
    public long load_duration { get; set; }
    public int prompt_eval_count { get; set; }
    public long prompt_eval_duration { get; set; }
    public int eval_count { get; set; }
    public long eval_duration { get; set; }
}

/// &lt;summary&gt;
/// Ollama API响应实体类的message子类
/// &lt;/summary&gt;
public class OllamaResponseMessage
{
    /// &lt;summary&gt;
    /// 角色
    /// &lt;/summary&gt;
    public string role { get; set; }

    /// &lt;summary&gt;
    /// 内容
    /// &lt;/summary&gt;
    public string content { get; set; }
}
</code></pre>
<p><strong>运行效果：</strong></p>
<p><img src="https://img2024.cnblogs.com/blog/346453/202502/346453-20250208152246525-2015758116.gif" alt="运行效果" loading="lazy"></p>
<hr>
<p>到此，通过.Net9的HttpClient简单调用Ollama的API就完成了。</p>
<hr>
<h1 id="5其他文章">5、🔖其他文章：</h1>
<ul>
<li><a href="https://www.cnblogs.com/qubernet/p/18702147" target="_blank">通过Ollama本地部署DeepSeek R1以及简单使用的教程（超详细）</a></li>
</ul>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.03114302401736111" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-08 15:32">2025-02-08 15:28</span>&nbsp;
<a href="https://www.cnblogs.com/qubernet">Qubernet</a>&nbsp;
阅读(<span id="post_view_count">4</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18704234" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18704234);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18704234', targetLink: 'https://www.cnblogs.com/qubernet/p/18704234', title: '.Net9中通过HttpClient简单调用Ollama中的DeepSeek R1模型' })">举报</a>
</div>
        