
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/twosedar/p/19036833" title="发布于 2025-08-13 22:23">
    <span role="heading" aria-level="2">为什么RAG技术可以缓解大模型知识固化和幻觉问题</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        
        RAG技术缓解大模型知识固化和幻觉问题的原理
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><strong>1、大模型知识固化和幻觉问题</strong></p>
<p>要理解大模型的时效性问题，需首先明确其技术原理：大模型通过输入文本与已固化在神经网络中的知识进行匹配，预测并输出概率最大的文本内容作为答案。其固化知识的神经网络形成于前期训练阶段，训练输入源自人类现有知识数据（包括互联网及线下知识数据）。模型一旦训练完成，其知识范围便被固定，回答能力完全取决于训练时的数据内容。<br>
幻觉产生的原因是：无论匹配概率多低，模型总会生成输出，这种缺乏依据的输出如同人类空想，即形成幻觉。<br>
如图所示：若大模型A基于2024年12月31日前的数据训练，当询问"2025年发生了哪些地震"时，它无法提供真实信息，强行回答则会虚构内容，因其神经网络中并无2025年数据。<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2960966/202508/2960966-20250813220751854-166380561.png" class="lazyload"></p>
<p>因此，大语言模型面临两大核心问题：<br>
1.知识固化：模型仅能回答训练数据范围内的内容，对训练后发生的事件（如2025年新发生的世界信息）或未参与训练的私有数据（如公司内部信息），统称为"外部知识"的内容，均无法直接回答。<br>
2.幻觉与不可溯源：由于模型输出本质是对固化知识的重组，用户难以验证信息来源，导致不敢轻易相信。</p>
<p><strong>2、RAG技术出现之前的解决方案</strong><br>
在RAG技术出现前，解决知识固化的主流方式是通过补充外部知识对模型进行持续微调，即利用新数据训练生成新模型（如下图所示）。<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2960966/202508/2960966-20250813220846980-27532965.png" class="lazyload"><br>
但该方案效率低，成本高，主要原因包括：<br>
1.需庞大训练数据支撑<br>
2.模型训练需要高昂GPU计算资源<br>
3.模型训练技术门槛要求高<br>
4.训练周期长，且效果不稳定<br>
5.模型更新繁琐：如上图，即使在2025年8月9日好不容易完成了大模型B、C的迭代，仍无法覆盖2025年8月9日后的新知识。</p>
<p><strong>3、RAG技术解决知识固化和幻觉问题的原理</strong><br>
RAG是英文（Retrieval-Augmented Generation，检索增强生成）的缩写，是由 Meta AI（原Facebook AI） 的研究团队于2020年首次提出，核心论文《Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks》（Patrick Lewis等）发表于2021年4月，论文地址：<a href="https://arxiv.org/pdf/2005.11401%E3%80%82" target="_blank" rel="noopener nofollow">https://arxiv.org/pdf/2005.11401。</a><br>
RAG的核心思想是不将新出现的知识内容用于大模型的训练，而是将最新的的问题相关的知识和要问的问题一起送给大模型，利用大模型语言组织能力，形成自然语言形式的答案。<br>
RAG的核心思想是：不将新知识纳入模型训练，而是将实时问题与相关外部知识同步一起输入给模型，利用大模型的语言组织能力生成答案。如下图所示：<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2960966/202508/2960966-20250813222207595-352250177.png" class="lazyload"><br>
第①步：为实时信息/本地数据建立向量索引库。关于向量和向量数据库，请参考：<a href="https://www.cnblogs.com/twosedar/p/18957931" target="_blank">https://www.cnblogs.com/twosedar/p/18957931</a><br>
第②步：用户提问后，将问题向量化；<br>
第③步：通过向量匹配，在第①步中建立的索引库中检索出最相关的条目<br>
第④步：整合问题与检索结果生成提示词，输入给大模型<br>
例如：“2025年发生了哪些地震？请参考如下信息回答：①2025.1.7西藏定日地震，②2025.7.30堪察加地震，回答时需标注参考条目序号"”<br>
第⑤步：将大模型回复结果转述给用户<br>
例如：“2025年发生了两次地震，包括1月7日定日地震，7月30日勘察加地震。参考条目① ②”</p>
<p>RAG巧妙的通过本地信息搜索和大模型集合的流程解决了知识固化问题，同时又避免了模型训练的高成本。而且通过展示参考条目，用户可验证信息来源，有效缓解幻觉问题。</p>
<p><strong>4、那么问题来了，既然能够提前检索到信息，还用大模型做什么？</strong><br>
首先，传统检索只能返回相关段落或者片段，但是大模型却可以生成人性化的自然语言描述的答案。另外，大模型还能基于已有的基础知识进行信息的组织，甚至跨文档推理。如果没有大模型，信息检索就和传统搜索引擎的效果差不多了。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.34097222222222223" data-date-updated="2025-08-14 06:34">2025-08-13 22:23</span>&nbsp;
<a href="https://www.cnblogs.com/twosedar">两棵雪松</a>&nbsp;
阅读(<span id="post_view_count">22</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19036833);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19036833', targetLink: 'https://www.cnblogs.com/twosedar/p/19036833', title: '为什么RAG技术可以缓解大模型知识固化和幻觉问题' })">举报</a>
</div>
        