
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/ForgetAllThings/p/18702207" title="发布于 2025-02-07 10:45">
    <span role="heading" aria-level="2">全网最简单DeepSeek-R1本地部署教程</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h2><strong><span style="font-family: &quot;Microsoft YaHei&quot;; font-size: 14pt">1.安装ollama</span></strong></h2>
<p>打开ollama网址：https://ollama.com/</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102122758-2051223354.png" alt="" loading="lazy"></p>
<p>&nbsp;选择你电脑的系统进行下载</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102208169-1103590039.png" alt="" loading="lazy"></p>
<p>我的电脑是windows的就点击windows然后点击下载即可</p>
<p>&nbsp;</p>
<p>下载完毕后双击打开下载的.exe文件等待软件自动安装完毕</p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102402388-1875869667.png" alt="" loading="lazy"></p>
<p>&nbsp;安装完毕后，点击键盘的win+r键输入cmd进入命令行</p>
<p>然后输入ollama -v会显示版本</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102607391-1555209251.png" alt="" loading="lazy"></p>
<p>&nbsp;说明ollama安装完毕</p>
<h2><span style="font-family: 宋体, &quot;Songti SC&quot;"><strong>2.部署DeepSeek-R1模型</strong></span></h2>
<p>打开ollama官网：https://ollama.com/</p>
<p>然后点击左上角的models</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102831741-1901624322.png" alt="" loading="lazy"></p>
<p>&nbsp;选择DeepSeek-R1模型</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102923824-1235535472.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>模型的大小大致分为1.5b,7b,8b,14b,32b,70b,671b</p>
<p>根据自己的电脑显卡和配置进行选择相应的版本</p>
<h3>显卡要求</h3>
<p>DeepSeek-R1-1.5b&nbsp; &nbsp;NVIDIA RTX 3060 12GB or higher</p>
<p>DeepSeek-R1-7b&nbsp; &nbsp; &nbsp;&nbsp;NVIDIA RTX&nbsp;3060 12GB or higher</p>
<p>DeepSeek-R1-8b&nbsp; &nbsp; &nbsp;&nbsp;NVIDIA RTX&nbsp;3060 12GB or higher</p>
<p>DeepSeek-R1-14b&nbsp; &nbsp;&nbsp;NVIDIA RTX&nbsp;3060 12GB or higher</p>
<p>DeepSeek-R1-32b&nbsp; &nbsp;&nbsp;NVIDIA RTX 4090 24GB</p>
<p>DeepSeek-R1-70b&nbsp; &nbsp;&nbsp;NVIDIA RTX&nbsp;4090 24GB *2</p>
<p>DeepSeek-R1-671b&nbsp;NVIDIA A100 80GB *16</p>
<p>我这边直接选择的是8b模型进行演示</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207103801816-1926975557.png" alt="" loading="lazy"></p>
<p>&nbsp;复制命令，在刚刚的命令行中直接复制+回车</p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104021202-1291918812.jpg" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>显示success则为下载成功，之后可以正常对话</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104158982-467994316.png" alt="" loading="lazy"></p>
<p>&nbsp;如果想要退出可以使用 /bye的方式退出对话</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104249703-1016812204.png" alt="" loading="lazy"></p>
<p>&nbsp;如果后续还想要进入对话，可以使用ollama list</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104335621-2009417251.png" alt="" loading="lazy"></p>
<p>&nbsp;复制name,然后执行ollama run deepseek-r1:8b就可以再次进入对话啦</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104417955-573260652.png" alt="" loading="lazy"></p>
<p>&nbsp;但是我们每次如果想要使用ollama模型的时候都需要运行命令行，这就有点不方便</p>
<p>所以接下来就开始安装可视化的界面来使用本地的模型</p>
<h2>3.安装Chatbox</h2>
<p>打开Chatbox官网：https://chatboxai.app/zh<a href="https://chatboxai.app/zh" rel="noopener nofollow"><br></a></p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110104813-2138666327.png" alt="" loading="lazy"></p>
<p>&nbsp;点击免费下载</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110157847-766670686.png" alt="" loading="lazy"></p>
<p>&nbsp;双击安装</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110227132-1287179704.png" alt="" loading="lazy"></p>
<p>&nbsp;自定义目录然后点击安装</p>
<p>现在我们就成功安装了Chatbox</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110713632-1779206213.jpg" alt="" loading="lazy"></p>
<p>&nbsp;选择使用自己API key或者本地模型</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110751666-383938464.jpg" alt="" loading="lazy"></p>
<p>&nbsp;选择Chatbox AI</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110827162-1778461952.jpg" alt="" loading="lazy"></p>
<p>&nbsp;模型设置页面，模型提供方选择Ollama API</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207111006457-38299076.png" alt="" loading="lazy"></p>
<p>&nbsp;api域名不需要进行更改</p>
<p>模型选择刚在电脑上下载的ollama模型即可</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207111058375-62482974.png" alt="" loading="lazy"></p>
<p>然后点击保存，之后我们就可以在这个可视化模型中进行对话</p>
<p>&nbsp;</p>
<p><img src="https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207111227900-1597162127.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>到这里，本地化安装基本就结束啦，bye!</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.04496096760185185" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-07 11:13">2025-02-07 10:45</span>&nbsp;
<a href="https://www.cnblogs.com/ForgetAllThings">花开花落花谢</a>&nbsp;
阅读(<span id="post_view_count">201</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18702207" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18702207);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18702207', targetLink: 'https://www.cnblogs.com/ForgetAllThings/p/18702207', title: '全网最简单DeepSeek-R1本地部署教程' })">举报</a>
</div>
        