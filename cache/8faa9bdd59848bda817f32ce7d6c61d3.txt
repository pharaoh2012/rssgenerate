
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/somebottle/p/18692240/gpu_container_on_google_colab" title="发布于 2025-01-26 23:01">
    <span role="heading" aria-level="2">【小记】在 Google Colab 等平台上运行 GPU 容器</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        <img src="https://img2024.cnblogs.com/blog/2588810/202501/2588810-20250126230148566-369689354.png" alt="【小记】在 Google Colab 等平台上运行 GPU 容器" class="desc_img">
        这篇笔记主要记录了咱在 Google Colab 以及 AutoDL 平台上测试运行 GPU 容器时的踩坑和爬出坑的过程，涉及到 apptainer 和 udocker 这两个容器管理工具。
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>最近想到了可能的创新点，准备开始做实验了。咱想先在 Colab 这种提供免费 GPU 算力的平台上跑一些小实验，后续再转移到实验室机器上。</p>
<p>如果每次都要重复搭建环境多少有些麻烦了。</p>
<p><img src="https://assets.xbottle.top/img/subaru_nerd-2025-01-18.png" alt="subaru_nerd-2025-01-18" loading="lazy"></p>
<p>那咱用容器化技术不就行啦！直接把环境打包成镜像，到时候环境迁移和实验复现都能便捷很多。</p>
<p>比起 Docker，这回咱决定试试<strong>更为轻量的</strong> Apptainer（前身为 Singularity）：</p>
<ul>
<li>Apptainer 默认以普通用户的身份运行容器，<strong>没有守护进程</strong>，也无需类似于 root 用户的特权，不像 Docker Daemon 那样必须要运行在特权用户下。（因而更安全，也更容易安装部署，不会有什么权限问题）
<ul>
<li>✨ 尽管如此，Apptainer 仍然要求系统支持 User Namespace 等特性，如果<strong>平台在各方面限制得比较死的话</strong>可以看看<a href="#4-%E7%B3%BB%E7%BB%9F%E4%B8%8D%E6%94%AF%E6%8C%81%E7%94%A8%E6%88%B7%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4" rel="noopener nofollow">第 4 节</a>，有惊喜哦 (￣▽￣) 。</li>
</ul>
</li>
<li>Apptainer 针对高性能计算（HPC）这种并行场景进行了优化（虽然我还不太用得上）。</li>
<li>Apptainer 支持 Docker 镜像，体验上近乎无缝（这个是最爽滴）。</li>
</ul>
<p>这篇笔记主要记录一下咱在 Google Colab 以及 AutoDL 平台上运行 GPU 容器时的踩坑和爬出坑的过程。</p>
<h2 id="1-安装-apptainer">1. 安装 Apptainer</h2>
<p>这里不多赘述，图快的话咱主要推荐以下两种安装方式:</p>
<h3 id="11-利用官方脚本安装">1.1. 利用官方脚本安装</h3>
<ul>
<li><a href="https://apptainer.org/docs/admin/1.3/installation.html#install-unprivileged-from-pre-built-binaries" target="_blank" rel="noopener nofollow">官方文档</a></li>
</ul>
<p>注：文档中提到在执行脚本前可能需要安装 <code>curl</code>, <code>cpio</code>, <code>rpm2cpio</code> 等必要的工具：</p>
<pre><code class="language-bash">sudo apt-get update
# rpm2cpio 是 rpm 包的工具
sudo apt-get install -y curl cpio rpm
</code></pre>
<h3 id="12-利用包管理器安装">1.2. 利用包管理器安装</h3>
<ul>
<li><a href="https://apptainer.org/docs/admin/1.3/installation.html#install-ubuntu-packages" target="_blank" rel="noopener nofollow">官方文档</a></li>
</ul>
<p>Colab 默认是 Ubuntu 系统，copy 官方文档中的命令就能顺利安装了~</p>
<h2 id="2-尝试跑一下-hello-world-镜像">2. 尝试跑一下 hello-world 镜像</h2>
<h3 id="21-构建-sif-文件">2.1. 构建 .sif 文件</h3>
<p>Apptainer 可以直接拉取 Docker Hub 上的镜像并构建成 <code>.sif</code> 单文件：</p>
<pre><code class="language-bash">apptainer build hello.sif docker://hello-world
</code></pre>
<p><img src="https://assets.xbottle.top/img/build_hello-2025-01-18.png" alt="build_hello-2025-01-18" loading="lazy"></p>
<h3 id="22-建立普通用户">2.2. 建立普通用户</h3>
<p>Colab 默认在 root 用户下执行命令，这里建立一个普通用户 <code>somebottle</code> ：</p>
<pre><code class="language-bash">adduser --home /home/somebottle --gecos "" --shell /bin/bash --disabled-password somebottle
</code></pre>
<ul>
<li>root 用户当然是可以运行 Apptainer 容器的，但为了安全起见，咱接下来会尝试用普通用户来运行容器。</li>
</ul>
<h3 id="23-启动容器">2.3. 启动容器</h3>
<p>Colab <strong>对 root 用户的权限有所限制</strong>，如果直接尝试启动容器会出现挂载问题：</p>
<pre><code class="language-bash">apptainer run hello.sif
# &gt;&gt; FATAL: container creation failed: mount hook function failure: mount overlay-&gt;/var/lib/apptainer/mnt/session/final error: while mounting overlay: can't mount overlay filesystem to /var/lib/apptainer/mnt/session/final: while setting effective capabilities: CAP_DAC_READ_SEARCH is not in the permitted capability set
</code></pre>
<ul>
<li>相关 issue：<a href="https://github.com/apptainer/apptainer/issues/1041" target="_blank" rel="noopener nofollow">https://github.com/apptainer/apptainer/issues/1041</a></li>
</ul>
<p>✨ 利用 <code>setcap</code> 进行 capabilities 权限设定还是麻烦了，这里我根据 issue 中的指引，直接在一个新的<strong>命名空间</strong>下运行了容器:</p>
<pre><code class="language-bash"># 在 root 用户下执行这条命令，容器内用户为 root
unshare -r apptainer run hello.sif
</code></pre>
<blockquote>
<p><code>unshare -r</code> 建立一个新的<strong>用户命名空间</strong>，并把当前用户映射为命名空间内的 root 用户，这个命名空间内的进程将会默认拥有完整的 capabilities 权限集。</p>
</blockquote>
<ul>
<li>💡 注：如果在 root 用户下执行上面这条命令，其实仍然相当于在特权用户下启动了容器。</li>
</ul>
<hr>
<p>✨ 或者<strong>以普通用户的身份</strong>运行容器:</p>
<pre><code class="language-bash"># 以 somebottle 身份启动容器，容器内用户为 somebottle
sudo -u somebottle apptainer run hello.sif
</code></pre>
<blockquote>
<p>Apptainer 借助用户命名空间特性来运行容器，系统应<strong>支持以非特权方式建立用户命名空间</strong>，经测试 Colab 已经满足了这点。具体要求可查看<a href="https://apptainer.org/docs/admin/1.3/user_namespace.html" target="_blank" rel="noopener nofollow">文档</a>。</p>
</blockquote>
<hr>
<p>✨ 为了能<strong>让普通用户在容器内以 root 用户的身份运行</strong>，可以加上 <code>--fakeroot</code> 选项：</p>
<pre><code class="language-bash"># 以 somebottle 身份启动容器，容器内用户为 root
sudo -u somebottle apptainer run --fakeroot hello.sif
</code></pre>
<p>具体行为可见<a href="https://apptainer.org/docs/user/1.3/fakeroot.html" target="_blank" rel="noopener nofollow">官方文档</a>说明。</p>
<h2 id="3-尝试跑一个-gpu-容器">3. 尝试跑一个 GPU 容器</h2>
<h3 id="31-构建-sif-文件">3.1. 构建 .sif 文件</h3>
<p>这里拉取了 Docker Hub 上 PyTorch 官方的一个 GPU 支持镜像：</p>
<pre><code class="language-bash"># 转换得到 pytorch-gpu.sif 文件
apptainer build pytorch-gpu.sif docker://pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime
</code></pre>
<h3 id="32-使用-apptainer-的标准-gpu-支持">3.2. 使用 Apptainer 的标准 GPU 支持</h3>
<p>Apptainer 默认支持 NVIDIA GPU，前提是宿主机系统中已经安装了 Nvidia 驱动以及 CUDA 相关库。</p>
<ul>
<li>具体要求依旧见<a href="https://apptainer.org/docs/user/1.3/gpu.html#requirements" target="_blank" rel="noopener nofollow">官方文档</a>。</li>
</ul>
<p>在 <code>apptainer</code> 的 <code>run</code>, <code>shell</code>, <code>exec</code> 等命令后加上 <code>--nv</code> 选项即可启用 GPU 支持:</p>
<pre><code class="language-bash"># 以 somebottle 身份启动 GPU 容器，容器内用户为 somebottle
# 启动容器后执行 nvidia-smi 来查看 GPU 状态
sudo -u somebottle apptainer exec --nv pytorch-gpu.sif nvidia-smi
</code></pre>
<h3 id="33-問題襲来">3.3. 問題、襲来</h3>
<p><img src="https://assets.xbottle.top/img/problem_emergence-2025-01-21.png" alt="problem_emergence-2025-01-21" loading="lazy"></p>
<p>诶？动啊，NVIDIA，为什么不动？</p>
<p><img src="https://assets.xbottle.top/img/mio_solemn-2025-01-22.png" alt="mio_solemn-2025-01-22" loading="lazy"></p>
<pre><code class="language-text">NVIDIA-SMI couldn't find libnvidia-ml.so library in your system. Please make sure that the NVIDIA Display Driver is properly installed and present in your system.
Please also try adding directory that contains libnvidia-ml.so to your system PATH.
</code></pre>
<p>定睛一看发现是在容器内找不到动态链接库 <code>libnvidia-ml.so</code>。</p>
<h3 id="34-解决问题">3.4. 解决问题</h3>
<p>提到动态链接库路径，很快能想到一个环境变量 <code>LD_LIBRARY_PATH</code>，动态链接器会在其列出的目录下搜索库。分别在宿主机和容器内输出这个环境变量看看:</p>
<pre><code class="language-bash"># 宿主机上
unshare -r env | grep LD_
# &gt;&gt; LD_LIBRARY_PATH=/usr/lib64-nvidia

# 容器中
unshare -r apptainer exec --nv pytorch-gpu.sif env | grep LD_
# &gt;&gt; LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs
</code></pre>
<p>可见<strong>宿主机上 NVIDIA 动态链接库</strong>位于 <code>/usr/lib64-nvidia</code>。</p>
<p>容器内列出了三个路径，因为其中前两个路径在容器内是不存在的，所以链接器会去 <code>/.singularity.d/libs</code> 这个路径下找共享库。</p>
<pre><code class="language-bash"># 输出看看目录下有什么
unshare -r apptainer exec --nv pytorch-gpu.sif ls -ahl /.singularity.d/libs
</code></pre>
<p><img src="https://assets.xbottle.top/img/list_libraries-2025-01-22.png" alt="list_libraries-2025-01-22" loading="lazy"></p>
<p>推测在使用 <code>--nv</code> 选项时，Apptainer 会自动<strong>将宿主机上的 NVIDIA 动态链接库绑定挂载到容器内</strong>的 <code>/.singularity.d/libs</code> 目录下。</p>
<ul>
<li><a href="https://apptainer.org/docs/user/1.3/gpu.html#requirements" target="_blank" rel="noopener nofollow">用户文档 - GPU Support</a> [1]</li>
<li><a href="https://apptainer.org/docs/admin/1.3/configfiles.html#nvidia-gpus-cuda" target="_blank" rel="noopener nofollow">管理文档 - Apptainer Configuration Files</a> [2]</li>
</ul>
<p>从上面两个文档可以得知，为了处理绑定挂载，Apptainer 有一个配置文件 <code>nvliblist.conf</code>，其中指定了 NVIDIA 相关的可执行文件和动态链接库的<strong>文件名</strong>（没错，仅仅是文件名！）。</p>
<ul>
<li>注: 通过 <code>find / -name "nvliblist.conf"</code> 可找到配置文件路径。</li>
</ul>
<p>在默认的 <code>nvliblist.conf</code> 中可以找到上面 <code>NVIDIA-SMI</code> 运行所缺失的库:</p>
<p><img src="https://assets.xbottle.top/img/find_libnvidia-ml-2025-01-22.png" alt="find_libnvidia-ml-2025-01-22" loading="lazy"></p>
<p>当然也可以找到容器内 <code>/.singularity.d/libs</code> 目录下已有的库。</p>
<hr>
<p><strong>于是现在问题就转换为了</strong>：为什么 <code>/.singularity.d/libs</code> 目录下没有 <code>libnvidia-ml.so</code> 和其他一些必要的库呢？</p>
<p>仍然是看文档， [2] 中提到:</p>
<blockquote>
<p>When adding new entries to <code>nvliblist.conf</code> use the bare filename of executables, and the <code>xxxx.so</code> form of libraries. Libraries are resolved via <code>ldconfig -p</code>, and exectuables are found by searching <code>$PATH</code>.</p>
</blockquote>
<p>即共享库（<code>.so</code>）路径是通过 <code>ldconfig -p</code> 来解析的，而可执行文件则是通过 <code>$PATH</code> 来搜索的。很有可能 Apptainer 在挂载时没有找到 NVIDIA 的库路径。</p>
<pre><code class="language-bash"># ldconfig 可以管理动态链接库的缓存
# 查看 ldconfig -p 的输出（输出已缓存的库），筛出有 nvidia 字段的
ldconfig -p | grep nvidia
# 没有输出，说明 nvidia 相关的库没有被缓存
</code></pre>
<p>哔啵~问题已定位。接下来只需要把宿主机上的 NVIDIA 共享库目录 <code>/usr/lib64-nvidia</code> 加入到缓存中即可。</p>
<p><code>ldconfig</code> 会从 <code>/etc/ld.so.conf.d</code> 目录中的配置文件读取共享库路径，先看看这个目录下有什么:</p>
<pre><code class="language-bash">ls -hl /etc/ld.so.conf.d
# &gt;&gt; total 36K
# &gt;&gt; -rw-r--r-- 1 root root  41 Sep  9  2023 000_cuda.conf
# &gt;&gt; -rw-r--r-- 1 root root  44 Sep  9  2023 988_cuda-12.conf
# &gt;&gt; -rw-r--r-- 1 root root  15 Jan 17 14:36 colab.conf
# &gt;&gt; -rw-r--r-- 1 root root  38 Mar  5  2022 fakeroot-x86_64-linux-gnu.conf
# &gt;&gt; -rw-r--r-- 1 root root  46 Aug 15  2023 gds-12-2.conf
# &gt;&gt; -rw-r--r-- 1 root root  44 Dec 16  2020 libc.conf
# &gt;&gt; -rw-r--r-- 1 root root  46 Nov 10  2023 nvidia.conf
# &gt;&gt; -rw-r--r-- 1 root root 100 Mar  4  2022 x86_64-linux-gnu.conf
# &gt;&gt; -rw-r--r-- 1 root root  56 May  6  2024 zz_i386-biarch-compat.conf

cat /etc/ld.so.conf.d/nvidia.conf /etc/ld.so.conf.d/*cuda*.conf
# &gt;&gt; /usr/local/nvidia/lib
# &gt;&gt; /usr/local/nvidia/lib64
# &gt;&gt; /usr/local/cuda/targets/x86_64-linux/lib
# &gt;&gt; /usr/local/cuda-12/targets/x86_64-linux/lib

ls /usr/local/nvidia/lib
# &gt;&gt; ls: cannot access '/usr/local/nvidia/lib': No such file or directory
</code></pre>
<p>看来大概是 Colab 官方的配置有误。</p>
<p>✨ 为了修复这点，咱们<strong>直接把库路径 <code>/usr/lib64-nvidia</code> 写入到这里的一个配置文件</strong>中:</p>
<pre><code class="language-bash">echo "/usr/lib64-nvidia" &gt;&gt; /etc/ld.so.conf.d/nvidia.conf
</code></pre>
<p>✨ 然后<strong>刷新缓存</strong>，让 <code>ldconfig</code> 重新读取配置文件即可:</p>
<pre><code class="language-bash">ldconfig
</code></pre>
<p>再次查看 <code>ldconfig -p</code> 的输出，就可以看到 <code>libnvidia-ml.so</code> 等共享库已经被缓存了。</p>
<p>再次尝试运行 GPU 容器，<code>nvidia-smi</code> 就能正常打印出 GPU 信息了，冇问题啦!</p>
<p><img src="https://assets.xbottle.top/img/nvidia-smi_success-2025-01-22.png" alt="nvidia-smi_success-2025-01-22" loading="lazy"></p>
<h3 id="35-测试一下-pytorch-是否能正常使用-gpu">3.5. 测试一下 PyTorch 是否能正常使用 GPU</h3>
<p>咱先把如下脚本 <code>test.py</code> 放在了 Colab 会话环境的 <code>/content/test</code> 目录下:</p>
<pre><code class="language-python">import torch
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"GPU 可用，设备: {torch.cuda.get_device_name(0)}")
else:
    device = torch.device("cpu")
    print("GPU 不可用，设备: CPU")
tensor = torch.tensor([1.0, 2.0, 3.0])
tensor = tensor.to(device)
print(f"张量: {tensor}")
print(f"张量所在设备: {tensor.device}")
# compute
result = tensor * 2
print(result)
</code></pre>
<p>把 Python 脚本挂载到容器内并执行:</p>
<pre><code class="language-bash">sudo -u somebottle apptainer exec --bind /content/test:/mnt/data --nv pytorch-gpu.sif python /mnt/data/test.py
# &gt;&gt; GPU 可用，设备: Tesla T4
# &gt;&gt; 张量: tensor([1., 2., 3.], device='cuda:0')
# &gt;&gt; 张量所在设备: cuda:0
# &gt;&gt; tensor([2., 4., 6.], device='cuda:0')
</code></pre>
<p>这样一来我应该就能愉快地在 Google Colab 等平台上使用 Apptainer 跑实验啦~</p>
<h2 id="4-系统不支持用户命名空间">4. 系统不支持用户命名空间</h2>
<p>事情并不总是一帆风顺。当我尝试在 AutoDL 平台上复现上面的流程时，发现 AutoDL 禁止了非特权用户创建用户命名空间，且禁用了 <code>unshare</code>，Apptainer 根本就跑不起来:</p>
<p><img src="https://assets.xbottle.top/img/autodl_unprivileged_user_namespace_not_allowed_2-2025-01-23.png" alt="autodl_unprivileged_user_namespace_not_allowed_2-2025-01-23" loading="lazy"></p>
<blockquote>
<p>而且 AutoDL 也禁用了 <code>setuid</code> 机制。</p>
</blockquote>
<p>难道...就要到此为止了吗！</p>
<p><img src="https://assets.xbottle.top/img/kuyashii-2025-01-24.jpg" alt="kuyashii-2025-01-24" loading="lazy"></p>
<p>不，还没完！我还能战斗！<br>
其实还有个能<strong>完全在用户空间运行</strong>的容器工具实现: <a href="https://indigo-dc.github.io/udocker/" target="_blank" rel="noopener nofollow">udocker</a>。</p>
<p>默认情况下 udocker 利用 <a href="https://github.com/proot-me/proot" target="_blank" rel="noopener nofollow">PRoot</a> 在用户空间拦截并模拟一些系统调用和特权操作，以在非特权用户下运行容器。</p>
<ul>
<li>
<p>udocker 的环境隔离性没有 apptainer 和 docker 好。但我本来也就只想要迁移运行时环境，隔离性也无所谓了（详见官方文档 <a href="https://indigo-dc.github.io/udocker/user_manual.html#13-security" target="_blank" rel="noopener nofollow">1.3. Security</a>）。</p>
</li>
<li>
<p>udocker 容器中<strong>无法执行真正需要特权的操作</strong>，比如文件系统挂载、修改受保护的配置等。当然跑个机器学习实验是没啥问题的（详见官方文档 <a href="https://indigo-dc.github.io/udocker/user_manual.html#12-limitations" target="_blank" rel="noopener nofollow">1.2. Limitations</a>）。</p>
</li>
<li>
<p>以下代码暂且以 <code>udocker 1.3.17</code> 版本为例。</p>
</li>
</ul>
<h3 id="41-以-root-用户运行-udocker">4.1. 以 root 用户运行 udocker</h3>
<p>直接在 root 用户下运行，命令更为简短，注意需要加上 <code>--allow-root</code> 选项:</p>
<details>
<summary>点击展开示例代码（IPython）</summary>
<pre><code class="language-python"># 下载 udocker 包并解压
!wget https://github.com/indigo-dc/udocker/releases/download/1.3.17/udocker-1.3.17.tar.gz
!tar -xzf udocker-1.3.17.tar.gz

# 把 udocker 添加到环境变量中
# 方便起见，给 udocker --allow-root 起个别名 mydocker
%alias mydocker export PATH=udocker-1.3.17/udocker:$PATH; udocker --allow-root

# 初始化 udocker（即使不初始化，首次执行时也会自动初始化）
mydocker install

# 拉取镜像
# dockerpull.cn 是一个 DockerHub 镜像站
mydocker pull dockerpull.cn/pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime

# 创建容器，容器名 gputest
mydocker create --name=gputest dockerpull.cn/pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime

# 启动 NVIDIA 支持
mydocker setup --nvidia gputest

# 查看 GPU 信息（如果有问题请见下面的 4.3 节）
mydocker run gputest nvidia-smi

# 挂载测试脚本并运行
mydocker run --volume=/root/test.py:/script/test.py gputest python /script/test.py
</code></pre>
</details>
<h3 id="42-以普通用户运行-udocker">4.2. 以普通用户运行 udocker</h3>
<p>废话不多说，上代码:</p>
<details>
<summary>点击展开示例代码（IPython）</summary>
<pre><code class="language-python"># 首先还是新建普通用户
!adduser --home /home/somebottle --gecos "" --shell /bin/bash --disabled-password somebottle

# 下载 udocker 包并解压
!wget -P /home/somebottle https://github.com/indigo-dc/udocker/releases/download/1.3.17/udocker-1.3.17.tar.gz
!cd /home/somebottle &amp;&amp; tar zxvf udocker-1.3.17.tar.gz &amp;&amp; chown somebottle udocker-1.3.17

# 把 udocker 添加到用户的环境变量中
!echo "export PATH=/home/somebottle/udocker-1.3.17/udocker:$PATH" &gt;&gt; /home/somebottle/.profile

# 给以 somebottle 身份运行的命令起个别名 urun
# 加上 -l 选项后才会执行 Shell 配置文件(包括上面的 .profile)
%alias urun su somebottle -l -c 

# AutoDL 平台上 python 路径在 /root 目录下，这里为了方便起见直接把目录所有权给 somebottle
# 💡 在 Colab 上可能不需要这一步
!chown -R somebottle /root 2&gt;/dev/null

# 初始化 udocker（即使不初始化，首次执行时也会自动初始化）
urun 'udocker install'

# 接下来就可以拉取镜像试试了
# dockerpull.cn 是一个 DockerHub 镜像站
urun 'udocker pull dockerpull.cn/pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime'

# 创建容器，容器名 gputest
# 从实现上来讲，这一步实际上是把镜像解包到一个用户可访问的目录中，作为 rootfs
urun 'udocker create --name=gputest dockerpull.cn/pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime'

# 启动 NVIDIA 支持
urun 'udocker setup --nvidia gputest'
# 查看 GPU 信息（如果有问题请见下面的 4.3 节）
urun 'udocker run gputest nvidia-smi'
# 挂载测试脚本并运行
urun 'udocker run --volume=/root/test.py:/script/test.py gputest python /script/test.py'
</code></pre>
</details>
<h3 id="43-udocker-容器中没有-nvidia-smi">4.3. udocker 容器中没有 nvidia-smi</h3>
<p>udocker 通过将一些 NVIDIA 相关的可执行文件和库文件复制到容器的对应目录中，从而实现了对 GPU 的支持。</p>
<p>但是目前 udocker 复制 NVIDIA 相关文件的逻辑可能有些问题。已知在 Google Colab 平台上可能无法在容器中访问 <code>nvidia-smi</code> 这种可执行文件，但是相关库文件是可以访问的，因此 PyTorch 能正常使用 GPU。</p>
<p>等待修复:</p>
<ul>
<li><a href="https://github.com/indigo-dc/udocker/pull/438" target="_blank" rel="noopener nofollow">Pull Request #438</a></li>
</ul>
<p>💡 你可以直接用这个 PR 的提交中的 <code>nvidia.py</code> 替换 <code>udocker/engine/nvidia.py</code> 这个文件。</p>
<h2 id="5-附关于-sudo--u">5. 附：关于 sudo -u</h2>
<p>在上面的例子中，我使用了 <code>sudo -u somebottle &lt;command&gt;</code> 来以 somebottle 用户的身份执行命令。</p>
<p>然而 <code>sudo -u</code> 实际上可能会重置环境变量，可以打印出来看看:</p>
<pre><code class="language-bash">echo $PATH
# &gt;&gt; /opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin
sudo -u somebottle env | grep PATH
# &gt;&gt; PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
</code></pre>
<p>很明显至少环境变量 <code>$PATH</code> 被重置了。</p>
<p>3.4 节中文档 [2] 曾提到:</p>
<blockquote>
<p>... , and exectuables are found by searching <code>$PATH</code>.</p>
</blockquote>
<p>即 Apptainer 在挂载时， <code>nvidia-smi</code> 这类可执行文件是依赖于 <code>$PATH</code> 环境变量进行搜索的。</p>
<p>幸运的是，可执行文件 <code>nvidia-smi</code> 在 <code>/usr/bin</code> 目录下有软链，而默认的 <code>$PATH</code> 环境变量中包含有这个目录，因此启动容器时 Apptainer 能成功找到。</p>
<pre><code class="language-bash">whereis nvidia-smi
# &gt;&gt; nvidia-smi: /usr/bin/nvidia-smi /opt/bin/nvidia-smi
ls -hl /usr/bin/nvidia-smi
# &gt;&gt; lrwxrwxrwx 1 root root 27 Jan 22 13:34 /usr/bin/nvidia-smi -&gt; /opt/bin/.nvidia/nvidia-smi
</code></pre>
<hr>
<p>假如需要保留 <code>sudo</code> 执行命令时的环境变量，可以使用 <code>sudo -E</code> 选项，但 <code>$PATH</code> 环境变量可能仍然会被重置，因为在配置文件 <code>/etc/sudoers</code> 中可能有 <code>secure_path</code> 配置项进行了限制:</p>
<pre><code class="language-bash">cat /etc/sudoers | grep secure_path
# &gt;&gt; Defaults   secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"
</code></pre>
<p>这种情况下要不直接修改 <code>/etc/sudoers</code> 文件，要不就手动设定 <code>$PATH</code> 环境变量:</p>
<pre><code class="language-bash"># env PATH=$PATH &lt;command&gt;，在指定环境变量后执行命令
sudo -u somebottle env PATH=$PATH printenv PATH
# &gt;&gt; /opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin
</code></pre>
<h2 id="6-总结">6. 总结</h2>
<p>总结一些要点：</p>
<ol>
<li>
<p>在 Google Colab 上以 <code>root</code> 用户运行 Apptainer 容器时，需要<strong>使用 <code>unshare -r</code> 命令</strong>来在新的命名空间下运行容器，以获得完整的 capabilities 权限集。</p>
</li>
<li>
<p>如果容器中部分 NVIDIA 的库 <code>.so</code> 文件找不到：</p>
<ol>
<li>先在宿主机上查看 <code>$LD_LIBRARY_PATH</code> 环境变量找到 NVIDIA 共享库路径。</li>
<li>把这个路径写入到 <code>/etc/ld.so.conf.d/</code> 目录下的一个配置文件中。</li>
<li>利用 <code>ldconfig</code> 刷新共享库缓存。</li>
</ol>
</li>
<li>
<p>如果平台（比如 AutoDL）不支持用户命名空间，可以尝试使用 udocker 来运行容器。</p>
</li>
</ol>
<p>希望这篇笔记能多多少少帮助到大家吧，咱也要继续苦逼地做实验去啦！</p>
<p>咱们下次再会~ (∠・ω&lt; )⌒★</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.4223372450833333" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-01-26 23:02">2025-01-26 23:01</span>&nbsp;
<a href="https://www.cnblogs.com/somebottle">SomeBottle</a>&nbsp;
阅读(<span id="post_view_count">33</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18692240" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18692240);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18692240', targetLink: 'https://www.cnblogs.com/somebottle/p/18692240/gpu_container_on_google_colab', title: '【小记】在 Google Colab 等平台上运行 GPU 容器' })">举报</a>
</div>
        