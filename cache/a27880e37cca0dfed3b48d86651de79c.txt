
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/cj8988/p/19001179" title="发布于 2025-07-23 17:43">
    <span role="heading" aria-level="2">fantasy-talking：实现图片加音频生成对嘴数字人</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h2 id="引言一张图也能说话">引言：一张图也能“说话”？</h2>
<p><span>你有没有想过，一张静态的照片，配上一段音频，就能变成一段“对嘴”的视频？不是简单的口型同步，而是让图片中的人物“活过来”，仿佛真的在说话、唱歌、甚至表演。</span></p>
<p><span>这听起来像是科幻电影里的场景，但其实，这样的技术已经在我们身边悄然实现了。</span></p>
<p><span>之前已经介绍过一些类似项目的搭建：</span></p>
<p>&nbsp;</p>
<h3><strong><a href="https://www.cnblogs.com/cj8988/p/18984186" target="_blank">FLOAT</a>:&nbsp;<a href="https://www.cnblogs.com/cj8988/p/18984186" target="_blank">https://www.cnblogs.com/cj8988/p/18984186</a>&nbsp;（带表情，比较快，但是会裁剪为正方形尺寸）</strong></h3>
<h3><strong><a href="https://github.com/toto222/DICE-Talk" rel="noopener nofollow" target="_blank">DICE-Talk</a>：<a href="https://www.cnblogs.com/cj8988/p/18957718" target="_blank">https://www.cnblogs.com/cj8988/p/18957718</a>&nbsp; &nbsp;（带表情，比较慢）</strong></h3>
<h3><strong><a href="https://www.cnblogs.com/cj8988/p/18952604" target="_blank">ComfyUI_Sonic</a>：<a href="https://www.cnblogs.com/cj8988/p/18952604" target="_blank">https://www.cnblogs.com/cj8988/p/18952604</a>&nbsp;（基础版，效果好）</strong></h3>
<p>&nbsp;</p>
<p><span>今天要介绍的这个开源项目&nbsp;<span>——&nbsp;<a href="https://github.com/Fantasy-AMAP/fantasy-talking" rel="noopener nofollow">fantasy-talking</a><span>，就是这样一个神奇的存在。它能让你上传一张图片和一段音频，自动生成一段“对嘴”的视频，效果之逼真，令人惊叹。</span></span></span></p>
<p><span>这篇文章，我们就来一起看看这个项目的魅力所在，以及它是如何做到“让图片开口说话”的。</span></p>
<hr>
<h2 id="一项目简介fantasy-talking-是什么">一、项目简介：fantasy-talking 是什么？</h2>
<p><a href="https://github.com/Fantasy-AMAP/fantasy-talking" rel="noopener nofollow">fantasy-talking</a>&nbsp;<span>是一个基于深度学习的开源项目，旨在实现将静态图片与语音音频结合，生成一段看起来像是人物在“说话”的视频。项目代码托管在 GitHub 上，目前已有不少开发者关注和贡献。</span></p>
<p><span>它的核心思想是通过语音驱动模型，生成与语音内容匹配的面部动作（尤其是嘴巴动作），再结合原始图片中的人物面部结构，生成一帧帧动态画面，最终合成一段视频。</span></p>
<p><span>简单来说，只要你有一张正面清晰的人脸照片，和一段你想让他“说”的语音，这个项目就能帮你生成一段“他”在说话的视频。</span></p>
<hr>
<h2 id="二搭建过程动手试试看">二、搭建过程：动手试试看</h2>
<p><span>如果你对这个项目感兴趣，不妨亲自搭建一下试试看。以下是大致的搭建流程：</span></p>
<h3 id="环境准备">环境准备</h3>
<ul>
<li>Python 3.10</li>
<li>Anaconda</li>
<li>PyTorch</li>
<li>CUDA 环境（如果你有 GPU）</li>
<li>磁盘空间大，因为要下载大量的模型文件</li>
</ul>
<h3 id="步骤概览">步骤概览</h3>
<ol>
<li>
<p><strong>克隆仓库</strong></p>
<div class="code-fence-highlighter-copy-button" data-fence-content="Z2l0IGNsb25lIGh0dHBzOi8vZ2l0aHViLmNvbS9GYW50YXN5LUFNQVAvZmFudGFzeS10YWxraW5nLmdpdA=="><img class="code-fence-highlighter-copy-button-icon"></div>
<div class="cnblogs_code">
<pre>git clone https:<span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">github.com/Fantasy-AMAP/fantasy-talking.git</span></pre>
</div>
<p>&nbsp;</p>
</li>
<li>
<p><strong>虚拟环境搭建</strong></p>
<p><span>我的环境是window中的Anaconda</span></p>
<div class="code-fence-highlighter-copy-button" data-fence-content="55Sf5oiQ6Jma5ouf546v5aKD77ya77yI56ys5LiA5qyh77yJCmNvbmRhIGNyZWF0ZSAtbiAgZmFudGFzeS10YWxraW5ncyBweXRob249My4xMAoK5r+A5rS777yaCmNvbmRhIGFjdGl2YXRlIGZhbnRhc3ktdGFsa2luZ3M="><img class="code-fence-highlighter-copy-button-icon"><span>生成虚拟环境：（第一次）</span><span>conda create </span>-n fantasy-talkings python=3.10</div>
<div class="cnblogs_code">
<p>生成虚拟环境：（第一次）<br>conda create -n  fantasy-talkings python=3.10</p>
<p>激活：<br>conda activate fantasy-talkings</p>





</div>
<div class="cnblogs_code">
<pre>#安装依赖：<br>pip install -<span style="color: rgba(0, 0, 0, 1)">r requirements.txt</span></pre>
</div>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)">下面这个是gpu加速的，我在window没有安装成功</span><span style="color: rgba(0, 128, 0, 1)">
#</span><span style="color: rgba(0, 128, 0, 1)">pip install flash_attn</span>
<span style="color: rgba(0, 0, 0, 1)">
如果直接使用pip install flash_attn安装失败，可以试试下面的方法：

</span>1：下载whl文件：https://huggingface.co/lldacing/flash-attention-windows-wheel/tree/<span style="color: rgba(0, 0, 0, 1)">main

</span>2<span style="color: rgba(0, 0, 0, 1)">：找到跟你pip show torch 和 python版本对应的whl下载

</span>3<span style="color: rgba(0, 0, 0, 1)">：安装：
pip  install  flash_attn</span>-.....whl</pre>
</div>
<p>&nbsp;</p>
</li>
</ol>
<p>&nbsp;</p>
<ol start="2">
<li>
<p><strong>模型下载</strong></p>
</li>
</ol>
<p>&nbsp; &nbsp; &nbsp;<img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/692485/202507/692485-20250723173957156-1386322808.png" class="lazyload"></p>
<ol start="2">
<li style="list-style-type: none">
<ul>
<li>这里需要下载的模型非常大：</li>
<li>Wan2.1-I2V-14B-720P：<a href="https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-720P" rel="noopener nofollow">https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-720P</a>&nbsp;或者&nbsp;<a href="https://www.modelscope.cn/models/Wan-AI/Wan2.1-I2V-14B-720P" rel="noopener nofollow">https://www.modelscope.cn/models/Wan-AI/Wan2.1-I2V-14B-720P</a></li>
<li>Wav2Vec：<a href="https://huggingface.co/facebook/wav2vec2-base-960h" rel="noopener nofollow">https://huggingface.co/facebook/wav2vec2-base-960h</a>&nbsp;或者&nbsp;<a href="https://modelscope.cn/models/AI-ModelScope/wav2vec2-base-960h" rel="noopener nofollow">https://modelscope.cn/models/AI-ModelScope/wav2vec2-base-960h</a></li>
<li>FantasyTalking ：<a href="https://huggingface.co/acvlab/FantasyTalking" rel="noopener nofollow">https://huggingface.co/acvlab/FantasyTalking</a>&nbsp;或者&nbsp;<a href="https://www.modelscope.cn/models/amap_cvlab/FantasyTalking/" rel="noopener nofollow">https://www.modelscope.cn/models/amap_cvlab/FantasyTalking/</a></li>
</ul>
</li>
</ol>
<p>特别是第一个模型，非常的大。下载后存放到相应位置：</p>
<div class="cnblogs_code">
<pre> ./models/Wan2.1-I2V-14B-<span style="color: rgba(0, 0, 0, 1)">720P。

 .</span>/models/wav2vec2-base-<span style="color: rgba(0, 0, 0, 1)">960h。

 .</span>/models</pre>
</div>
<p>&nbsp;</p>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/692485/202507/692485-20250723173819474-767883111.png" class="lazyload"></p>
<p><span>可以手动下载，也可以cli下载：</span></p>
<div class="code-fence-highlighter-copy-button" data-fence-content="cGlwIGluc3RhbGwgImh1Z2dpbmdmYWNlX2h1YltjbGldIgogICAgICBodWdnaW5nZmFjZS1jbGkgZG93bmxvYWQgV2FuLUFJL1dhbjIuMS1JMlYtMTRCLTcyMFAgLS1sb2NhbC1kaXIgLi9tb2RlbHMvV2FuMi4xLUkyVi0xNEItNzIwUAogICAgICBodWdnaW5nZmFjZS1jbGkgZG93bmxvYWQgZmFjZWJvb2svd2F2MnZlYzItYmFzZS05NjBoIC0tbG9jYWwtZGlyIC4vbW9kZWxzL3dhdjJ2ZWMyLWJhc2UtOTYwaAogICAgICBodWdnaW5nZmFjZS1jbGkgZG93bmxvYWQgYWN2bGFiL0ZhbnRhc3lUYWxraW5nIGZhbnRhc3l0YWxraW5nX21vZGVsLmNrcHQgLS1sb2NhbC1kaXIgLi9tb2RlbHM="><img class="code-fence-highlighter-copy-button-icon"></div>
<div class="cnblogs_code">
<pre>   pip install <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">huggingface_hub[cli]</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">
   huggingface</span>-cli download Wan-AI/Wan2.1-I2V-14B-720P --local-dir ./models/Wan2.1-I2V-14B-<span style="color: rgba(0, 0, 0, 1)">720P
   huggingface</span>-cli download facebook/wav2vec2-base-960h --local-dir ./models/wav2vec2-base-<span style="color: rgba(0, 0, 0, 1)">960h
   huggingface</span>-cli download acvlab/FantasyTalking fantasytalking_model.ckpt --local-dir ./models</pre>
</div>
<p>&nbsp;</p>
<ol start="4">
<li>
<p><strong>运行项目</strong></p>
<div class="code-fence-highlighter-copy-button" data-fence-content="cGlwIGluc3RhbGwgZ3JhZGlvIHNwYWNlcwpweXRob24gYXBwLnB5"><img class="code-fence-highlighter-copy-button-icon"></div>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 0, 1)">pip install gradio spaces
python app.py</span></pre>
</div>
<p>&nbsp;</p>
</li>
<li>
<p><strong>查看结果</strong><br>上传你的图片和音频，等待一段时间后，查看生成的视频。</p>
<p><img alt="" width="1107" height="651" loading="lazy" data-src="https://img2024.cnblogs.com/blog/692485/202507/692485-20250723173932698-1465958161.png" class="lazyload"></p>
<p>&nbsp;</p>





</li>






</ol><hr>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.005555555555555556" data-date-updated="2025-07-23 17:51">2025-07-23 17:43</span>&nbsp;
<a href="https://www.cnblogs.com/cj8988">Joy_CShow</a>&nbsp;
阅读(<span id="post_view_count">103</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19001179);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19001179', targetLink: 'https://www.cnblogs.com/cj8988/p/19001179', title: 'fantasy-talking：实现图片加音频生成对嘴数字人' })">举报</a>
</div>
        