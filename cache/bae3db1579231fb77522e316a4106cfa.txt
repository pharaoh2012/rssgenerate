
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/myleaf/p/18682945" title="发布于 2025-01-21 10:19">
    <span role="heading" aria-level="2">VAE模型简析和精要（原理和代码）</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="1-前言">1. 前言</h1>
<p>这篇博客主要用于记录<code>VAE</code>的原理部分。<br>
一方面便于日后自己的温故学习，另一方面也便于大家的学习和交流。<br>
如有不对之处，欢迎评论区指出错误，你我共同进步学习！</p>
<p><strong>图均引用自<code>4</code>部分的博客！！！！！！！</strong></p>
<h1 id="2-正文">2. 正文</h1>
<p>这篇博客集各博客之长，比较简洁易懂：因为有的博客交代清楚了原理，但损失函数部分比较迷惑，有的是公式比较清晰，但原理比较迷惑，我从我个人的角度，把我认为比较直观的地方做一个总结。<br>
<code>AE</code>（<code>Auto-Encoder</code>）自编码器<br>
<code>VAE</code>（<code>Variational Auto-Encoder</code>）变分自编码器<br>
变分在哪里？<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121100550947-295101261.png" alt="image" loading="lazy"></p>
<h2 id="21-整体结构">2.1 整体结构</h2>
<blockquote>
<p>编码器就是想把一个物体投到隐空间，相当于编码的过程，提取输入的特征，用向量的形式表征出来，便于运算。</p>
</blockquote>
<p>普通编码器的结构：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121093258691-1597997412.png" alt="image" loading="lazy"><br>
<code>VAE</code>的结构：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121101257165-1413881553.png" alt="image" loading="lazy"></p>
<h2 id="22-主要目的">2.2 主要目的</h2>
<p>假设任何人像图片都可以由表情、肤色、性别、发型等几个特征的取值来唯一确定，那么我们将一张人像图片输入自动编码器后将会得到这张图片在表情、肤色等特征上的取值的向量X’，而后解码器将会根据这些特征的取值重构出原始输入的这张人像图片。<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121093356533-21336678.png" alt="image" loading="lazy"><br>
但如果输入<code>蒙娜丽莎</code>的照片，将微笑特征设定为特定的单值（<code>相当于断定蒙娜丽莎笑了或者没笑</code>）显然不如将微笑特征设定为某个取值范围（例如将微笑特征设定为x到y范围内的某个数，这个范围内既有数值<code>可以表示蒙娜丽莎笑了又有数值可以表示蒙娜丽莎没笑</code>）更合适，于是：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121093421227-1346757047.png" alt="image" loading="lazy"><br>
就可以把确定的事件描述为概率分布：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121093509319-1846286526.png" alt="image" loading="lazy"><br>
然后最后再采样得到所谓的latent变量<code>Z</code><br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121093558870-664137671.png" alt="image" loading="lazy"></p>
<h2 id="23-损失函数">2.3 损失函数</h2>
<p>再来看一下网络结构：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121093640052-1449835529.png" alt="image" loading="lazy"><br>
vae的loss函数为两项，重构损失(<code>reconstruct loss</code>)以及kl散度正则项(<code>kl loss</code>)，分别对应模型训练过程希望达成的两个目的。<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121093631839-771749538.png" alt="image" loading="lazy"></p>
<h3 id="231">2.3.1</h3>
<p>重构损失(<code>reconstruct loss</code>)希望vae生成的结果和输入之间的差异比较小。</p>
<h3 id="232">2.3.2</h3>
<p>kl散度正则项(<code>kl loss</code>)希望编码器生成的隐变量尽可能符合标准正态分布。<br>
为什么呢？<s>详情请查看其他博客的公式推导，因为本文主打一个简洁，公式就不再赘述。</s><br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121101001433-545464527.png" alt="image" loading="lazy"><br>
大概也就是下面这个图：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121101036496-207177995.png" alt="image" loading="lazy"></p>
<h1 id="24-代码实现">2.4 代码实现</h1>
<p>这是<code>pytorch</code>里面的代码实现过程：</p>
<pre><code>class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()

        self.fc1 = nn.Linear(784, 400)
        self.fc21 = nn.Linear(400, 20)
        self.fc22 = nn.Linear(400, 20)
        self.fc3 = nn.Linear(20, 400)
        self.fc4 = nn.Linear(400, 784)

    def encode(self, x):
        h1 = F.relu(self.fc1(x))
        return self.fc21(h1), self.fc22(h1)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5*logvar)
        eps = torch.randn_like(std)
        return mu + eps*std

    def decode(self, z):
        h3 = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h3))

    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar
</code></pre>
<p>给出简单的计算图：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121095443428-385264504.png" alt="image" loading="lazy"><br>
大家对比代码和计算图一起食用，效果更佳！<br>
注意：reparam的代码部分和图的部分对应于我之前的结构图的这个部分：<br>
<img src="https://img2024.cnblogs.com/blog/3481742/202501/3481742-20250121101535372-559731829.png" alt="image" loading="lazy"></p>
<h1 id="3-后记">3. 后记</h1>
<p>这篇博客点到为止，日后我会继续补充，保证你看完后大概明白其原理而不会像其他博客一样一头雾水，因为笔者把很多博客的精华都提炼出来了。<br>
zsy 2025.1.21</p>
<h1 id="4-acknowledge">4. Acknowledge</h1>
<p>本文参考的博客如下：<br>
<a href="https://zhuanlan.zhihu.com/p/64485020" target="_blank" rel="noopener nofollow">https://zhuanlan.zhihu.com/p/64485020</a><br>
<a href="https://zhuanlan.zhihu.com/p/578619659" target="_blank" rel="noopener nofollow">https://zhuanlan.zhihu.com/p/578619659</a><br>
<a href="https://zhuanlan.zhihu.com/p/345360992" target="_blank" rel="noopener nofollow">https://zhuanlan.zhihu.com/p/345360992</a><br>
<a href="https://blog.csdn.net/A2321161581/article/details/140632339" target="_blank" rel="noopener nofollow">https://blog.csdn.net/A2321161581/article/details/140632339</a><br>
下面这篇博客写的非常详细：<br>
<a href="https://spaces.ac.cn/archives/5253" target="_blank" rel="noopener nofollow">https://spaces.ac.cn/archives/5253</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.33694569813194447" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-01-21 10:20">2025-01-21 10:19</span>&nbsp;
<a href="https://www.cnblogs.com/myleaf">泪水下的笑靥</a>&nbsp;
阅读(<span id="post_view_count">10</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18682945" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18682945);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18682945', targetLink: 'https://www.cnblogs.com/myleaf/p/18682945', title: 'VAE模型简析和精要（原理和代码）' })">举报</a>
</div>
        