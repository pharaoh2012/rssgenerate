
		<h2>
			<a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/lmy5215006/p/18818583" title="发布于 2025-04-12 13:59">
    <span role="heading" aria-level="2">重生之我是操作系统(七)----内存管理(上)</span>
    

</a>

		</h2>
		<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="简介">简介</h1>
<p>一个操作系统，要实现对内存的管理，需要实现如下几个核心目标：</p>
<ol>
<li>分配与回收<br>
高效分配，减少内存碎片和内存利用率</li>
<li>空间扩充<br>
内存虚拟化，让进程享受近乎无限的内存地址。</li>
<li>存储隔离<br>
保证各个进程之间不会越界访问。</li>
<li>高效通信<br>
支持进程间内存共享，提高交换效率。</li>
</ol>
<h1 id="分配与回收">分配与回收</h1>
<p>先来分享一个前置知识:<br>
1.内部碎片<br>
分配给进程的内存区域中，有些部分是空闲没有用上。</p>
<blockquote>
<p>比如SQL Server , .NET CLR 。 他们自己内部一套实现了内存管理，因此要先预申请大量内存。</p>
</blockquote>
<p>2.外部碎片<br>
内存中某些空闲分区由于太小难以利用上</p>
<h2 id="连续内存分配">连续内存分配</h2>
<blockquote>
<p>为进程分配的必须是一个连续的内存空间</p>
</blockquote>
<h3 id="单一连续分配">单一连续分配</h3>
<p>long long years ago ，单任务系统时代(MS-DOS)，由于是单任务操作系统。所以内存中<code>只会有一道用户程序</code>。该程序独享整个用户态空间。</p>
<p><img src="https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250411120457593-1874908806.png" alt="image" loading="lazy"></p>
<ol>
<li>优点<br>
实现简单：直接采用覆盖技术扩充内存，且不需要进程隔离<br>
无外部碎片：就一个程序能有啥碎片？</li>
<li>缺点：<br>
有内部碎片</li>
</ol>
<h3 id="固定分配">固定分配</h3>
<p>随着多任务操作系统的兴起，单一连续分配已经不能满足需求。因此发展成，讲整个用户态空间划分为<code>若干个固定大小的分区</code>，每一个分区中只运行一个进程。形成了最早，最原始的多进程内存管理。<br>
<img src="https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250412142052724-1294762885.png" alt="image" loading="lazy"></p>
<ol>
<li>优点<br>
实现简单，不会产生外部碎片。</li>
<li>缺点<br>
-. 当程序太大，分区表中所有分区都无法满足，此时就需要采用<code>覆盖</code>技术来解决。但会降低性能。<br>
-. 会产生内部碎片，一个10M大小的分区，只放了一个9M的程序，还有1M空间被浪费。<br>
-. 分区固定，缺乏灵活性</li>
</ol>
<blockquote>
<p>虽然也有将要分区表划分为不同大小的分区，以此提交灵活性。但依旧是固定分配的范畴。</p>
</blockquote>
<h3 id="动态分配">动态分配</h3>
<p>为了解决固定分配的痛点，操作系统又发展出动态分区分配策略。<br>
这种分配方式<code>不会预先划分内存区域</code>，而是在进程装入内存时，根据进程大小<code>动态建立分区</code>。<br>
<img src="https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250412142043071-15345036.png" alt="image" loading="lazy"></p>
<ol>
<li>优点<br>
不会产生内部碎片，外部碎片可以通过<code>压缩</code>来缓解。</li>
<li>缺点<br>
实现复杂，内存回收时要考虑前后相邻，合并的情况。</li>
</ol>
<h3 id="动态分配算法">动态分配算法</h3>
<h4 id="首次适应first-fit">首次适应(First Fit)</h4>
<ol>
<li>原理<br>
从<code>低地址/起始地址</code>开始搜索，选择满足大小的<code>第一个</code>空闲空间。分割后分配(剩余部分仍为空闲块)。</li>
<li>优点<br>
快速，无需遍历所有空闲块。</li>
<li>缺点<br>
在低地址区域留下大量碎片</li>
</ol>
<blockquote>
<p>【100kb,200kb,50kb】,申请150，选择第二个，变成【100kb,50kb,50kb】</p>
</blockquote>
<h4 id="邻近适应next-fit">邻近适应(Next Fit)</h4>
<p>由首次适应演变而来</p>
<ol>
<li>原理<br>
从<code>上一次分配结束的位置</code>开始搜索，找到第一个足够大的空闲块(类似首次适应)</li>
<li>优点<br>
平衡内存碎片分配位置，较少低地址碎片的堆积，且搜索效率高于首次适应</li>
<li>缺点<br>
只是平衡内存碎片分配的位置，但碎片问题依旧存在，可能导致大分区被分割为小碎片。</li>
</ol>
<h4 id="最佳适应best-fit">最佳适应(Best Fit)</h4>
<ol>
<li>原理<br>
搜索所有空闲块，选择满足大小的<code>最小</code>空闲块。分割后分配(剩余部分仍为空闲块)。</li>
<li>优点<br>
内存利用率最高，会有更多大分区被保留下来，能够满足大进程需求</li>
<li>缺点<br>
产生大量极小内存碎片，且难以利用。</li>
</ol>
<blockquote>
<p>【100kb,200kb,50kb】,申请49，选择第三个，变成【100kb,200kb,1kb】</p>
</blockquote>
<h4 id="最坏适应worst-fit">最坏适应(Worst Fit)</h4>
<p>为了解决最佳适应的缺点，又衍生出最坏适应</p>
<ol>
<li>原理<br>
搜索所有空闲块，选择满足大小的<code>最大</code>空闲块。分割后分配(剩余部分仍为空闲块)。</li>
<li>优点<br>
避免产生微小碎片</li>
<li>缺点<br>
提前消耗大内存块，等大进程来时无法满足。</li>
</ol>
<blockquote>
<p>【100kb,200kb,50kb】,申请15个10，选择第二个，变成【100kb,50kb,50kb】，此时再申请200，无空间可用。</p>
</blockquote>
<h4 id="总结">总结</h4>
<table>
<thead>
<tr>
<th><strong>算法</strong></th>
<th><strong>核心策略</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
<th><strong>典型场景</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>首次适应</td>
<td>第一个足够大的块</td>
<td>分配速度快，实现简单</td>
<td>低地址碎片多</td>
<td>实时性要求高的系统</td>
</tr>
<tr>
<td>最佳适应</td>
<td>最小足够大的块</td>
<td>内存利用率高</td>
<td>微小碎片多，效率低</td>
<td>内存紧张、小内存请求多</td>
</tr>
<tr>
<td>最坏适应</td>
<td>最大空闲块分割</td>
<td>减少微小碎片</td>
<td>大内存块可能提前耗尽</td>
<td>中等大小内存请求为主</td>
</tr>
<tr>
<td>邻近适应</td>
<td>从上一次位置开始搜索</td>
<td>分配均衡，减少碎片堆积</td>
<td>性能中等</td>
<td>通用多任务系统</td>
</tr>
</tbody>
</table>
<blockquote>
<p>tips: 一个反直觉的知识<br>
由于最佳适应/最坏使用需要检索整个空闲块，所以为了提高搜索效率。往往要对空闲块进行排序操作。而邻近适应在实际应用中，并没什么卵用，反而影响大进程的调度。<br>
因此综合下来，反而是首次适应的综合效率更好。</p>
</blockquote>
<h3 id="动态回收算法">动态回收算法</h3>
<h4 id="边界标记法">边界标记法</h4>
<p>每个内存块头部记录块大小和分配状态，尾部存储前一个块的头部地址（或状态），释放时通过前后块地址判断是否相邻空闲：<br>
前向合并：后一个块是空闲块，合并为一个大空闲块。<br>
后向合并：前一个块是空闲块，合并为一个大空闲块。<br>
双向合并：前后块均为空闲块，合并为一个更大的块。</p>
<h2 id="非连续内存分配">非连续内存分配</h2>
<blockquote>
<p>为进程分配的是一些分散的空间</p>
</blockquote>
<p>从上面可以看出，连续内存分配的有如下几个痛点：</p>
<ol>
<li>外部碎片严重，内存利用率低<br>
动态分配在申请和释放过程中，会产生<code>大量不连续</code>的空闲块。需要定期<code>"压缩"</code>内存，而压缩会消耗大量CPU时间。</li>
<li>开销大<br>
动态分配算法中(首次适应，最佳适应，最坏适应)等算法需要<code>遍历整个空闲块</code>,时间复杂度为O(n).<br>
释放算法中，需要合并相邻的空闲块，逻辑复杂且耗时。</li>
<li>不支持虚拟化<br>
动态分配要求是对<code>物理内存的</code>的规划，需要对物理内存进行动态分配。因此无法运行大于物理内存的程序。</li>
<li>管理困难<br>
因为进程地址是单一连续区域，所以难以对程序进行单独的隔离与管理（如代码段、数据段）。</li>
</ol>
<p>为解决上述问题，又进化出了非连续的分配管理方式。</p>
<h3 id="页paging">页(Paging)</h3>
<p><strong>原理</strong>：将物理内存划分为<code>固定大小的页框</code>(Page Frame,4kb)，而程序的逻辑地址空间页划分为<code>相同大小的页</code>(Page，4KB)。通过页表(Page Table)完成页到页框的映射，并允许页在物理内存中的不连续。<br>
<img src="https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250411154321508-1144388670.png" alt="image" loading="lazy"></p>
<ol>
<li>优点<br>
完全消除外部碎片，支持虚拟内存地址</li>
<li>缺点<br>
存在页内碎片(最后一页可能未填满)，页表本身也占用内存</li>
</ol>
<blockquote>
<p>页表转换过程没有图示如此简单，有兴趣可以自行查找资料。</p>
</blockquote>
<h4 id="硬件对页的优化">硬件对页的优化</h4>
<p>为了加速页表的转换，硬件也使出了多种手段。</p>
<ol>
<li>TLB<br>
缓存近期访问的页表项，将地址转换从<code>两次降为一次</code>，(查页表+访问物理内存)=&gt;直接访问物理内存。</li>
<li>多级列表<br>
将页表分页存储，减少内存占用。例如，x86-64采用五级页表，支持64位虚拟地址空间。</li>
</ol>
<blockquote>
<p>页管理方式很好，但依旧难以对程序进行单独的隔离与管理（如代码段、数据段）。</p>
</blockquote>
<h3 id="段segmentation">段(Segmentation)</h3>
<p><strong>原理</strong>：将程序的逻辑模块(如代码段，数据段，栈)分组，每个段在逻辑上连续，但在物理上不连续，通过段表(Segment Table)来实现转换。<br>
<img src="https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250411161114128-1361585537.png" alt="image" loading="lazy"></p>
<ol>
<li>优点<br>
符合程序逻辑的结构，很方便的按照分组来实现共享和保护。<br>
比如：多个进程共享同一段代码段。代码段设置只读，数据段设置可写。</li>
<li>缺点<br>
可能产生外部碎片，因为段与动态分配很像，不确定大小，所以在分配过程中难免产生碎片。</li>
</ol>
<blockquote>
<p>段也可以引用TLB机制与多级段表来优化效率。</p>
</blockquote>
<h3 id="段页segmentd-paging">段页(Segmentd Paging)</h3>
<p><strong>原理</strong>：结合分页与分段的优势，先将程序划分为段，再将每个段划分为页。通过段表和页表的多级映射实现地址转换。<br>
<img src="https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250411163723200-316597756.png" alt="image" loading="lazy"></p>
<ol>
<li>优点<br>
兼顾逻辑分段和物理分页的效率，支持虚拟内存和内存保护</li>
<li>缺点<br>
空间占用大，地址转换效率低，需要三次(查段表+查页表+访问物理内存)。</li>
</ol>
<h2 id="现代操作系统的设计应用">现代操作系统的设计应用</h2>
<ol>
<li>Linux<br>
采用分页方案，使用四级页表（64 位系统），支持大页（Huge Pages，如2MB/1GB）减少页表开销。</li>
<li>Windows<br>
使用段页方案，使用简化版的段与页，同样使用四级页表与大页。</li>
</ol>
<h1 id="空间扩充虚拟化">空间扩充(虚拟化)</h1>
<p><strong>为什么我们需要虚拟化内存？</strong><br>
在上述的连续分配/非连续内存分配方案中，进程<code>一次性全部载入内存</code>后才能开始运行。很多暂时用不到的数据也会长期占用内存，导致内存利用率不高。</p>
<blockquote>
<p>举个例子，有一个经典游戏叫&lt;三男一狗&gt;，他的容量大小将近100g，如果按照目前的方式，内存容量完全不够。</p>
</blockquote>
<h2 id="虚拟化的理论支持局部性原理">虚拟化的理论支持：局部性原理</h2>
<ol>
<li>时间局部性<br>
如果执行了进程中的某条指令，那么不久后这条指令很有可能再次执行，如果某个数据被访问过，也很有可能再次被访问。</li>
<li>空间局部性<br>
一旦程序访问了某个存储单元，那么其附近的存储单元页很有可能被访问。</li>
</ol>
<pre><code>int i;
int a[100];//空间局限性，变量/存储单元基本上都是集中定义在一起，连续存放

for(i=0;i&lt;100;i++){ //时间局部性，程序中充斥着大量的循环
	a[i]=i;
}
</code></pre>
<p>基于局部性原理，在程序载入内存时。</p>
<ol>
<li>可以将程序中<code>先用到的部分先载入内存,暂时用不到的暂不加载</code>。</li>
<li>当所访问的信息<code>不存在</code>时，由操作系统继续从外存(硬盘)加载到内存(缺页故障)。</li>
<li>当内存不够时，由操作系统负责<code>将用不到的内存swap到外存(硬盘)</code>。</li>
</ol>
<blockquote>
<p>在操作系统的管理下，对于程序而言，它看到的是一个近乎无限大的内存空间，这就是虚拟内存技术。</p>
</blockquote>
<h2 id="如何实现虚拟内存">如何实现虚拟内存?</h2>
<p>虚拟内存有以下三个主要特征：</p>
<ol>
<li>多次性<br>
无需在程序运行时一次性全部装入，允许分成多次调用。</li>
<li>对换性<br>
无需一直常驻内存，在合适的情况下，允许swap到外存(硬盘)。</li>
<li>虚拟性<br>
从逻辑上扩充了内存的容量。"欺骗"进程不再关注实际内存大小。</li>
</ol>
<p>因为虚拟内存多次性的存在，如果采用连续分配的方式，就实现不了了。因此，虚拟内存的实现需要建立在<code>'离散分配'</code>的内存管理方式。</p>
<blockquote>
<p>没错，正是在下！非连续内存分配！</p>
</blockquote>
<blockquote>
<p>少林功夫+足球=大有搞头！非连续内存分配+虚拟内存=目前主流操作系统的选择</p>
</blockquote>
<p>因此，在非连续内存分配的基础上，再由操作系统<code>添加缺页故障纠错</code>(多次性)与<code>swap</code>(对换性)功能，即可实现。</p>
<h3 id="如何实现添加缺页故障纠错请求分页">如何实现添加缺页故障纠错(请求分页)</h3>
<ol>
<li>请求页表<br>
与之前提到过的页管理相比，为了实现添加缺页故障纠错，操作系统需要知道每个页<code>是否已经载入内存</code>，如果没有，需要存储外存的位置。<br>
那么，我们对之前页的模型图稍加扩充，就变成了下面的这个样子，该页表也被称为<code>请求页表</code></li>
</ol>
<p><img src="https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250412135906561-1552419430.png" alt="image" loading="lazy"></p>
<ol start="2">
<li>缺页中断机构<br>
在请求分页中，当要访问的页不存在时，操作系统便会产生一个<code>缺页中断</code>，然后系统故障Fault，搜索中断描述表(Interrupt Descriptor Table)，找到对应的中断处理程序。<br>
此时<code>缺页的进程会陷入阻塞</code>，放入阻塞队列，<code>调页</code>完成后再将其唤醒，放回就绪队列。</li>
</ol>
<blockquote>
<p>调页：如果内存中有空闲块，则为进程分配一个空闲块，并更新请求页表。<br>
如果内存空间不足，则由页面置换算法选择一个淘汰的页，若页被修改过，则将其写回外存。如果修改过，直接丢弃。完成后更新请求页表。</p>
</blockquote>
<h3 id="页面置换算法">页面置换算法</h3>
<p>页面置换算法是虚拟内存管理的核心技术，用于在物理内存不足时，选择将哪些页面从内存中置换到外存，以腾出空间加载新页面</p>
<ol>
<li>
<p>OPT, Optimal Algorithm<br>
原理：选择未来最长时间不被访问的页面，理论上缺页率最低<br>
优点：性能最佳<br>
缺点：无法实现，因为操作系统无法预知程序的行为</p>
</li>
<li>
<p>FIFO, First-In-First-Out<br>
原理:置换最早进入的页面<br>
优点：实现简单，用一个链表记录进入队列即可实现<br>
缺点：产生belady异常，且与程序运行规律不相符，因为最早进入的页面，往往最经常被使用。</p>
</li>
</ol>
<blockquote>
<p>比如你代码中的第一个变量，其生命周期大概率跟随整个方法。</p>
</blockquote>
<ol start="2">
<li>
<p>LRU, Least Recently Used<br>
原理：淘汰最近最久未使用的页面，当缺页时，逆向扫描最后出现调页的页号就是被淘汰的页<br>
优点：贴合局部性原理，性能接近OPT<br>
缺点：实现复杂，需要硬件支持</p>
</li>
<li>
<p>Clock Algorithm，CLOCK<br>
在上面介绍的几种算法中，OPT性能最好，但无法实现。FIFO实现简单，但性能查。LRU算法接近OPT，但开销大，需要硬件支持。<br>
而CLOCK算法则比较均衡。<br>
原理：为每个页设置一个访问位(R)，并将整个页表链接起来形成一个环形队列。首次扫描：若页面 R 位为 1，清 0 并跳过；若为 0，置换该页面。若未找到可置换页面，重复扫描<br>
优点：实现复杂度低，比 FIFO 更高效<br>
缺点：仅用访问位，可能置换频繁访问但近期未被访问的页面</p>
</li>
<li>
<p>Modified Clock Algorithm<br>
该算法是对CLOCK的改进，增加修改位(M)，优先置换未被修改且未被访问的页面（减少写回外存的开销），第一轮扫描：找 R=0 且 M=0 的页面（最优候选），若未找到，第二轮扫描：找 R=0 且 M=1 的页面（需写回外存）。<br>
过程中清除 R 位，避免重复扫描<br>
优点：结合访问频率和修改状态，减少 I/O 操作（优先置换干净页面，无需写回）<br>
缺点：精度低于LRU算法</p>
</li>
</ol>
<table>
<thead>
<tr>
<th><strong>算法</strong></th>
<th><strong>核心思想</strong></th>
<th><strong>优点</strong></th>
<th><strong>缺点</strong></th>
<th><strong>典型应用</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>OPT</td>
<td>未来最远访问</td>
<td>理论最优</td>
<td>无法实现</td>
<td>性能基准</td>
</tr>
<tr>
<td>FIFO</td>
<td>最早进入内存</td>
<td>实现简单</td>
<td>可能置换活跃页面，Belady现象</td>
<td>早期系统（如简单嵌入式）</td>
</tr>
<tr>
<td>LRU</td>
<td>最近最少使用</td>
<td>贴近局部性，性能优秀</td>
<td>实现复杂（需硬件支持）</td>
<td>通用操作系统（Linux、Windows）</td>
</tr>
<tr>
<td>Clock/改进版</td>
<td>访问位+修改位近似LRU</td>
<td>平衡性能与实现复杂度</td>
<td>精度低于LRU</td>
<td>实际系统（如Android）</td>
</tr>
</tbody>
</table>
<p>现代操作系统（如 Linux）通常采用 <strong>LRU 改进算法</strong>（如反向映射、大页支持），并结合硬件加速（TLB缓存地址转换），在缺页率和性能之间实现高效平衡。</p>
<blockquote>
<p>熟悉Redis的朋友肯定对此不陌生</p>
</blockquote>

</div>
<div class="clear"></div>

		<p class="postfoot">
			posted on 
<span id="post-date" data-last-update-days="0.16219717836805556" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-12 14:21">2025-04-12 13:59</span>&nbsp;
<a href="https://www.cnblogs.com/lmy5215006">叫我安不理</a>&nbsp;
阅读(<span id="post_view_count">60</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18818583" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18818583);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18818583', targetLink: 'https://www.cnblogs.com/lmy5215006/p/18818583', title: '重生之我是操作系统(七)----内存管理(上)' })">举报</a>

		</p>
	