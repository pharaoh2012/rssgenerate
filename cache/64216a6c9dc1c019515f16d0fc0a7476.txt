
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/ibigboy/p/18790578" title="发布于 2025-03-25 09:15">
    <span role="heading" aria-level="2">从问题排查到源码分析：ActiveMQ消费端频繁日志刷屏的秘密</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="引言">引言</h2>
<p>最近遇到了一个 <code>ActiveMQ</code> 消费端的问题：在没有消息时，日志频繁打印，每秒打印2000多条空消息，导致日志文件迅速膨胀，甚至影响系统性能。经过一番排查，最终定位到问题根源并成功解决。本文将详细记录问题的排查过程、原因分析以及解决方案，希望能为遇到类似问题的同学提供参考。</p>
<hr>
<h2 id="背景">背景</h2>
<p><span style="word-break: break-all">最近优化了一个 ActiveMQ 消费端应用消费速度慢的问题，原先采用 Spring 的<code>@Scheduled</code>定时每秒调用<code>ActiveMQMessageConsumer.receive(2000)</code>拉取消息并同步处理，简化后的代码如下：</span></p>
<pre><code class="language-java">@Scheduled(cron = "1/0 * * * * ?")
public void consumer(){
	new Thread(()-&gt;{
		try{
			logger.info("ActiveMQClient--&gt;receive begin queue_name = {}", QUEUE_NAME);
			ActiveMQMessage msg = (ActiveMQMessage )activeMQMessageConsumer.receive(2000);
			if(null != msg){
				processMsg(msg);//同步处理消息并手动确认
			}
		} catch(Exception e){
			logger.error("ActiveMQClient--&gt;receive error:", e);
		}
	}).start();	
}
</code></pre>
<p>可以看到在调用<code>receive</code>之前打印了一条日志。<strong>当队列无消息时</strong>，上述代码中的<strong>日志每秒打印一次</strong>（定时每秒启动一个线程），日志文件每天最多2-3个。</p>
<p>当业务量激增时，以上每秒消费一条消息的方式远远满足不了业务需求，且会造成 <code>ActiveMQ</code> 服务端消息积压，故做了以下优化，简化后的代码如下：</p>
<pre><code class="language-java">ExecutorService THREAD_POOL = Eecutors.newFiexdThreadPool(1)
@PostConstruct
public void startConsumer(){
	THREAD_POOL.submit(()-&gt;{
		while(true){
			try{
				logger.info("ActiveMQClient--&gt;receive begin queue_name = {}", QUEUE_NAME);
				ActiveMQMessage msg = (ActiveMQMessage )activeMQMessageConsumer.receive(2000);
				if(null != msg){
					processMsg(msg);
				}
			} catch(Exception e){
				logger.error("ActiveMQClient--&gt;receive error:", e);
			}
		}
	});
}
</code></pre>
<p>上述改造采用单线程（为了保持消息消费的有序性）循环执行消息拉取和处理逻辑，相比原先定时任务1秒消费一条消息消费能力有明显提升，另外当队列无消息时<code>receive</code>方法会阻塞两秒，也不会造成线程空转。上述改造部署后，特意观察了无消息时的日志打印频率，确实为2秒一次，日志量和之前相差无几。准备愉快的上线了。</p>
<h3 id="问题描述"><strong>问题描述</strong></h3>
<p>上线前夕，有其他小伙伴在测试环境通过日志排查问题时，发现当天早上日志文件数量就达到了130+，根本不知道该看哪个日志文件。于是我打开其中一个文件统计了一下每秒打印<code>ActiveMQClient--&gt;receive begin queue_name</code>高达2000多条（队列无消息时），貌似队列无消息时<code>receive(2000</code>)阻塞两秒失效了，导致线程在空转，一直拉取消息，导致日志量暴增！</p>
<hr>
<h3 id="排查过程"><strong>排查过程</strong></h3>
<h4 id="1-初步分析"><strong>1. 初步分析</strong></h4>
<ul>
<li>怀疑 <code>receive(2000)</code> 方法的超时设置失效，导致立即返回 <code>null</code>。</li>
<li>检查代码和配置文件，确认 <code>receive(2000)</code> 的超时时间为 2 秒。</li>
</ul>
<h4 id="2-进一步排查"><strong>2. 进一步排查</strong></h4>
<p>对此我感到一头雾水，为啥超时时间会失效呢？我明明记得当时在测试环境特意观察了日志，无消息时确实是每两秒打印一次。</p>
<ul>
<li>
<p><strong>重启大法</strong>：于是我重启消费端程序，观察了一会儿日志，也是每两秒打印一次，这下更懵逼了！</p>
</li>
<li>
<p><strong>观察日志</strong>：没办法，只能继续找问题了。我查看服务器日志，文件太多了，每天都是一百多个压缩文件。我随便找了某天的第一个文件和最后一个文件，打开最后一个文件从文件末尾看，日志频繁打印。打开第一个文件，文件开头从零点开始打印，也是非常频繁，然后我按时间查找中午十点多的，发现日志又正常每两秒打印一次（没消息时），太奇怪了。</p>
</li>
<li>
<p><strong>查找日志变化拐点</strong>：然后我想看看是从什么时候开始变得频繁，果然有了新发现。在那天的第一个文件里，从<code>22:01:07</code>起日志几乎一秒打印2000多条。在此之前紧挨着有几条<code>ActiveMQ</code>的日志，如下图：</p>
</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img15@main/2025/03/21/1742521918801-c1ff8908-6646-4934-bb08-c7f0e1187c7e.png" alt="" loading="lazy"></p>
<p>貌似ActiveMQ关闭某个线程池，从关闭后日志就变得频繁。根据日志发现等待了10秒，最终停止了线程池。</p>
<p>于是我根据日志位置找到对应源码，这段代码定义了一个名为<code>awaitTermination</code>的静态方法，用于等待线程池的终止。这个方法的主要目的是确保在关闭线程池之前，所有提交给线程池的任务都已完成执行。参数<code>executorService</code>是要等待终止的线程池,<code>shutdownAwaitTermination</code>是等待线程池终止的最大时间，以毫秒为单位。</p>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img7@main/2025/03/21/1742523614232-db87fcbf-ed9a-4415-b5ee-85757c6befe1.png" alt="" loading="lazy"></p>
<p>找到调用<code>awaitTermination</code>的地方，即<code>ThreadPoolUtils#doShutdown</code>，它先调用了线程池的<code>shutdown</code>方法，然后调用<code>awaitTermination</code>等待线程终止，根据日志可以看到等待了10秒线程都没终止，最后强行调用<code>shutdownNow</code>方法，然后输出了<code>Shutdown of ExecutorService:.....</code>日志，对应上图中最后一条日志。</p>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img13@main/2025/03/21/1742523957781-84c9d81d-e28f-442b-9778-a4b167eff71a.png" alt="" loading="lazy"></p>
<p><span style="word-break: break-all">然后继续向上找调用<code>ThreadPoolUtils#doShutdown</code>的地方最终找到是在<code>AbstractInactivityMonitor#stopMonitorThreads</code>。</span>由于调用这个方法的地方非常多，无法准确找到是在哪调用的。这条线索中断。</p>
<h4 id="3-灵机一动发现突破口"><strong>3. 灵机一动，发现突破口</strong></h4>
<p>正当我们有头绪时，突然想到去看看ERROR日志文件，看了一下ERROR日志文件比Info文件更多！于是我解压第一个ERROR日志文件，打开后根据Info日志中线程池关闭的时间<code>22:00:07</code>去搜索，果然发现了猫腻。</p>
<p><span style="word-break: break-all">几乎相同时间，<code>AbstractInactivityMonitor</code>的246行抛出了<code>InactivityIOException:Channel was inactive for too (&gt;30000) long</code>异常，即“频道长时间处于非活动状态”</span></p>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img9@main/2025/03/21/1742525607993-8a613e64-6a63-48ca-8981-202ac98567be.png" alt="" loading="lazy"></p>
<p>在后续的ERROR日志中，全部都是<code>IllegalStateException:The Consumer is closed</code>异常，表明客户端和<code>ActiveMQ</code>服务端的连接已经断开！</p>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img1@main/2025/03/21/1742526519172-d62f7ea4-5fb3-4b1b-a7e9-9eef8580d057.png" alt="" loading="lazy"><br>
这也就解释了为什么<code>receive(2000)</code>阻塞两秒失效，while循环调用receive拉消息，由于连接已断开，方法立即报错，又不停地拉可不就一直打日志嘛！</p>
<h3 id="为什么连接被断开了">为什么连接被断开了？</h3>
<p>问了一波AI，给出的回答如下：</p>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img14@main/2025/03/21/1742527480642-0fd23a85-432e-4025-b59d-166461ab1df5.png" alt="" loading="lazy"></p>
<ul>
<li>心跳检测默认是开启的，所以第一个被排除。</li>
<li>日志中没有看到重连，被排除。</li>
<li>第三种也不符合。</li>
</ul>
<p>又陷入了僵局~</p>
<p>马上就要上线了，必须赶快排查出根本原因！</p>
<p>这时候原来负责这块儿的同事突然想到测试环境MQ服务端每天晚上十点停机！</p>
<p>？？？</p>
<p>挖了个渠~好坑</p>
<p>生产环境MQ服务端不会停机</p>
<h3 id="解决方案">解决方案</h3>
<p>解决方法很简单，在原代码逻辑的<code>try-catch</code>的<code>catch</code>模块增加代码使线程休眠1秒。</p>
<pre><code class="language-java">ExecutorService THREAD_POOL = Eecutors.newFiexdThreadPool(1)
@PostConstruct
public void startConsumer(){
	THREAD_POOL.submit(()-&gt;{
		while(true){
			try{
				logger.info("ActiveMQClient--&gt;receive begin queue_name = {}", QUEUE_NAME);
				ActiveMQMessage msg = (ActiveMQMessage )activeMQMessageConsumer.receive(2000);
				if(null != msg){
					processMsg(msg);
				}
			} catch(Exception e){
				logger.error("ActiveMQClient--&gt;receive error:", e);
                try {
            		Thread.sleep(1000);
       		  } catch (InterruptedException ex) {
           		 logger.error("ActiveMQClient--&gt;sleep error after receive error :", ex);
       		 }
			}
		}
	});
}
</code></pre>
<p>回过头看，原来的代码确实存在隐患（抛异常后会立马进入下次while循环），幸亏在测试环境发现了。</p>
<h2 id="复盘">复盘</h2>
<h3 id="现象"><strong>现象</strong></h3>
<ul>
<li>消费端使用 <code>while</code> 循环调用 <code>receive(2000)</code> 方法拉取消息。</li>
<li>当没有消息时，日志应每 2 秒打印一次<code>ActiveMQClient--&gt;receive begin queue_name</code>”。</li>
<li>实际运行时，日志每秒打印高达 2000 次，导致日志刷屏，日志量暴涨。</li>
</ul>
<h3 id="原因"><strong>原因</strong></h3>
<ul>
<li><strong>日志分析</strong>：发现Info日志中出现<code>ActiveMQ InvativityMonitor Worker</code>关闭了某个线程池，且ERROR日志出现<code>InactivityIOException::Channel was inactive for too (&gt;30000) long</code>异常，之后频繁出现 <code>IllegalStateException: The Consumer is closed</code> 异常。异常日志的打印时间与Info日志开始频繁打印的时间吻合。</li>
<li><strong>连接状态</strong>：最终确认连接因服务端关闭，ActiveMQ Client端 <code>InactivityMonitor</code> 检测到不活跃而断开。</li>
<li><strong>消费者状态</strong>：连接断开后，消费者失效，<code>receive()</code> 立即返回 <code>null</code>，线程还在不停while循环调用<code>receive</code>，进而导致日志刷屏，日志量暴涨。</li>
</ul>
<h3 id="根本原因"><strong>根本原因</strong></h3>
<ul>
<li><strong>服务端关闭</strong>：服务端每晚关闭，导致连接中断。</li>
<li><strong>消费者失效</strong>：连接断开后，消费者继续调用 <code>receive()</code> 导致异常。</li>
<li><strong>日志刷屏</strong>：<code>while</code> 循环频繁调用失效的 <code>receive()</code>，日志频繁打印。</li>
</ul>
<h2 id="探索activemq的断连机制">探索ActiveMQ的断连机制</h2>
<h3 id="发现-abstractinactivitymonitor"><strong>发现 <code>AbstractInactivityMonitor</code></strong></h3>
<ul>
<li>在日志中发现了 <code>AbstractInactivityMonitor</code> 关键字，进一步查看源码，了解到其作用。</li>
<li><strong>源码分析</strong>：<code>AbstractInactivityMonitor</code> 是 ActiveMQ 中用于监控连接活跃性的核心组件，其 <code>readCheckerTask</code> 机制用于定期检查连接状态。</li>
</ul>
<h3 id="readcheckertask"><strong>readCheckerTask</strong></h3>
<p><code>readCheckerTask</code>是<code>SchedulerTimerTask</code>实例，通过Java中的Timer定时器周期性的执行任务，默认30秒执行一次。<code>readCheckerTask</code>具体执行的任务如下：</p>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img18@main/2025/03/21/1742534276407-ea171490-4e53-4380-85ea-caf9fb0805be.png" alt="" loading="lazy"></p>
<ul>
<li>
<p><strong>实现原理</strong></p>
<ol>
<li><strong>获取当前时间</strong>：使用System.currentTimeMillis()获取当前时间。</li>
<li><strong>计算时间差</strong>：计算当前时间与上次运行时间之间的差值。</li>
<li><strong>检查上次运行时间</strong>：如果上次运行时间不为0，则记录自上次读取检查以来经过的时间。</li>
<li><strong>允许读取检查</strong>：如果自上次读取检查以来经过的时间小于90%，则放弃当前的读取检查。</li>
<li><strong>执行读取检查</strong>：如果时间足够，则执行<code>readCheck()</code>。</li>
<li><strong>更新上次运行时间</strong>：无论是否执行了读取检查，都会更新lastRunTime为当前时间。</li>
</ol>
</li>
<li>
<p><strong>作用</strong><br>
这段代码确保读取检查不会过于频繁地执行，从而避免资源浪费或潜在的性能问题。当判断通过时执行<code>readCheck()</code>。</p>
</li>
</ul>
<h3 id="readcheck"><strong>readCheck()</strong></h3>
<p>源码如下：</p>
<p><img src="https://fastly.jsdelivr.net/gh/bucketio/img14@main/2025/03/21/1742534885717-2a660d75-9203-40b6-9d43-baf9bd0372ba.png" alt="" loading="lazy"></p>
<ul>
<li><strong>实现原理</strong>
<ol>
<li><strong>获取接收计数器</strong>：获取当前和上一次的接收计数器值，并更新上一次的接收计数器值为当前的接收计数器值。</li>
<li><strong>检查是否正在接收</strong>：如果当前正在接收消息或者接收计数器值发生了变化，则跳过读取检查。</li>
<li><strong>检查是否需要抛出异常</strong>：如果<code>commandReceived</code>为false即没有接收到命令，且<code>monitorStarted</code>为true即监控已经开始，并且异步任务线程池（<code>ASYNC_TASKS</code>）没有关闭，则抛出<code>InactivityIOException</code>异常。异常处理通过异步任务执行，以避免阻塞当前线程。如果异步任务被拒绝执行，并且异步任务没有关闭，则记录错误并重新抛出异常。</li>
<li><strong>重置标志</strong>：最后，重置<code>commandReceived</code>标志，表示没有接收到命令。</li>
</ol>
</li>
</ul>
<ul>
<li>
<p><strong>作用</strong>：定期检查连接状态，确保连接活跃。</p>
</li>
<li>
<p><strong>工作机制</strong>：</p>
<ul>
<li>定时任务：默认每隔 <code>readCheckTime</code>（默认30秒） 时间执行一次。</li>
<li>活跃性检查：每次执行时，检查自上次执行检查以来的时间间隔。如果超过 <code>readCheckTime</code>的90%且当前没有在接收消息和命令，则认为连接不活跃。</li>
<li>处理不活跃连接：关闭连接等相关资源（如定时器、线程池等）并触发 <code>InactivityIOException</code>。</li>
</ul>
</li>
<li>
<p><strong>与服务端关闭的关系</strong></p>
<ul>
<li>如果服务端主动关闭连接，客户端与服务端之间的心跳检测中断，<code>readCheck</code>中的<code>inReceive.get() || currentCounter != previousCounter</code>将为false，从而会触发 <code>InactivityIOException</code>。</li>
<li>如果服务端未关闭，但客户端长时间无数据传输，<code>connectCheckerTask</code> 也会关闭连接。</li>
</ul>
</li>
</ul>
<h2 id="总结">总结</h2>
<ol>
<li><strong>问题根源</strong></li>
</ol>
<ul>
<li>服务端关闭导致连接中断，消费者失效，<code>receive()</code> 立即返回 <code>null</code>，while仍循环调用，导致日志刷屏。</li>
</ul>
<ol start="2">
<li><strong>解决核心</strong></li>
</ol>
<ul>
<li>休眠一秒：快速减少日志频率。</li>
</ul>
<ol start="3">
<li><strong>最终效果</strong></li>
</ol>
<ul>
<li>日志频率显著降低，系统稳定性提升。</li>
<li>生产环境运行平稳，问题彻底解决。</li>
</ul>
<hr>
<h3 id="经验分享"><strong>经验分享</strong></h3>
<ol>
<li><strong>日志分析</strong>：遇到问题时，优先分析日志，定位异常类型和时间点。</li>
<li><strong>连接管理</strong>：ActiveMQ 的连接和消费者状态需要仔细管理，避免资源泄漏。</li>
<li><strong>快速解决</strong>：在紧急情况下，优先采用简单有效的方案（如休眠一秒），再逐步优化。</li>
</ol>
<hr>
<h3 id="互动话题"><strong>互动话题</strong></h3>
<p>你是否也遇到过类似的问题？欢迎在评论区分享你的经验和解决方案！如果本文对你有帮助，请点赞、转发支持！</p>
<hr>
<p><strong>关注公众号，获取更多技术干货！</strong></p>

</div>
<div id="MySignature" role="contentinfo">
    说的再好，不如行动。不怕慢，就怕站。
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.07130464376273148" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-03-25 09:16">2025-03-25 09:15</span>&nbsp;
<a href="https://www.cnblogs.com/ibigboy">问北</a>&nbsp;
阅读(<span id="post_view_count">47</span>)&nbsp;
评论(<span id="post_comment_count">3</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18790578" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18790578);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18790578', targetLink: 'https://www.cnblogs.com/ibigboy/p/18790578', title: '从问题排查到源码分析：ActiveMQ消费端频繁日志刷屏的秘密' })">举报</a>
</div>
        