
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/BNTang/p/18803486" title="发布于 2025-04-01 09:24">
    <span role="heading" aria-level="2">大模型 Token 究竟是啥：图解大模型Token</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>前几天，一个朋友问我：“<strong>大模型</strong>中的 <strong>Token</strong> 究竟是什么？”</p>
<p>这确实是一个很有代表性的问题。许多人听说过 Token 这个概念，但未必真正理解它的作用和意义。思考之后，我决定写篇文章，详细解释这个话题。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329221904262-1613828067.gif" alt="" loading="lazy"></p>
<p>我说：像 <strong>DeepSeek</strong> 和 <strong>ChatGPT</strong> 这样的超大语言模型，都有一个“刀法精湛”的小弟——<strong>分词器（</strong>Tokenizer<strong>）</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329223612477-343640341.png" alt="" loading="lazy"></p>
<p>当<strong>大模型</strong>接<strong>收到一段文字</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329224705879-1626860868.png" alt="" loading="lazy"></p>
<p>会让<strong>分词器</strong>把它<strong>切成很多个小块</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329224911567-619863587.png" alt="" loading="lazy"></p>
<p>这切出来的每一个小块就叫做一个 <strong>Token</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329231936736-1030805454.png" alt="" loading="lazy"></p>
<p>比如这段话（<strong>我喜欢唱、跳、Rap和篮球</strong>），在大模型里可能会被切成这个样子。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329213514131-1707276093.png" alt="" loading="lazy"></p>
<p>像<strong>单个汉字</strong>，可能是一个 <strong>Token</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329213949184-1060535411.png" alt="" loading="lazy"></p>
<p><strong>两个汉字</strong>构成的<strong>词语</strong>，也可能是一个 <strong>Token</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329214101749-234936468.png" alt="" loading="lazy"></p>
<p><strong>三个字</strong>构成的<strong>常见短语</strong>，也可能是一个 <strong>Token</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329214320969-662623668.png" alt="" loading="lazy"></p>
<p><strong>一个标点符号</strong>，也可能是一个 <strong>Token</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329214407497-1732726574.png" alt="" loading="lazy"></p>
<p><strong>一个单词</strong>，或者是<strong>几个字母</strong>组成的一个<strong>词缀</strong>，也可能是一个 <strong>Token</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329214633732-384853561.png" alt="" loading="lazy"></p>
<p>大模型在输出文字的时候，也是一个 Token 一个 Token 的往外蹦，所以看起来可能有点像在打字一样。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250329232612837-845003352.gif" alt="" loading="lazy"></p>
<p>朋友听完以后，好像更疑惑了：</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330013618237-828530496.png" alt="" loading="lazy"></p>
<p>于是，我决定换一个方式，给他通俗解释一下。</p>
<p>大模型的Token究竟是啥，以及为什么会是这样。</p>
<p>首先，请大家快速读一下这几个字：</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330014203560-1662959825.png" alt="" loading="lazy"></p>
<p>是不是有点没有认出来，或者是需要愣两秒才可以认出来？</p>
<p>但是如果这些字出现在<strong>词语</strong>或者<strong>成语</strong>里，你<strong>瞬间</strong>就可以念出来。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330015143896-721304174.png" alt="" loading="lazy"></p>
<p>那之所以会这样，是因为我们的<strong>大脑在日常生活中</strong>，<strong>喜欢</strong>把这些有含义的<strong>词语</strong>或者<strong>短语</strong>，优先作为<strong>一个整体</strong>来对待。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330015710305-238696458.png" alt="" loading="lazy"></p>
<p>不到万不得已，不会去一个字一个字的抠。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330021011370-790893575.png" alt="" loading="lazy"></p>
<p>这就导致我们对这些<strong>词语还挺熟悉</strong>，<strong>单看</strong>这些字（旯妁圳侈邯）的时候，反而会觉得<strong>有点陌生</strong>。</p>
<p>而大脑🧠之所以要这么做，是因为这样可以节省脑力，咱们的大脑还是非常懂得偷懒的。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330030726315-1791083719.png" alt="" loading="lazy"></p>
<p>比如 “<strong>今天天气不错</strong>” 这句话，如果一个字一个字的去处理，一共需要有<strong>6个部分</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330030617520-1888029110.png" alt="" loading="lazy"></p>
<p>但是如果划分成<strong>3个</strong>、<strong>常见</strong>且<strong>有意义的词</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330030928066-100510559.png" alt="" loading="lazy"></p>
<p>就只需要处理<strong>3个</strong>部分<strong>之间的关系</strong>，从而<strong>提高效率</strong>，<strong>节省脑力</strong>。</p>
<p>既然人脑可以这么做，那人工智能也可以这么做。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330034728676-1692578228.png" alt="" loading="lazy"></p>
<p>所以就有了<strong>分词器</strong>，专门<strong>帮大模型</strong>把大段的文字，<strong>拆解成大小合适</strong>的一个个 <strong>Token</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330034901880-907658531.png" alt="" loading="lazy"></p>
<p>不同的分词器，它的分词方法和结果不一样。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330035057914-495700775.png" alt="" loading="lazy"></p>
<p>分得越合理，大模型就越轻松。这就好比餐厅里负责切菜的切配工，它的刀功越好，主厨做起菜来当然就越省事。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330035305316-676264201.png" alt="" loading="lazy"></p>
<p>分词器究竟是怎么分的词呢？</p>
<p>其中一种方法大概是这样，分词器统计了大量文字以后，发现 <strong>“苹果”</strong> 这两个字，<strong>经常一起出现</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330035442025-1702036198.png" alt="" loading="lazy"></p>
<p>就把它们打包成一个 <strong>Token</strong>，给它一个<strong>数字编号</strong>，比如 <strong>19416</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330035535969-1587747105.png" alt="" loading="lazy"></p>
<p>然后丢到一个大的<strong>词汇表</strong>里。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330035623537-190919188.png" alt="" loading="lazy"></p>
<p>这样下次再看到 <strong>“苹果”</strong> 这两个字的时候，就可以直接认出这个组合就可以了。</p>
<p>然后它可能又发现 <strong>“鸡”</strong> 这个字<strong>经常出现</strong>，并且<strong>可以搭配不同的其他字</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330035752625-549436850.png" alt="" loading="lazy"></p>
<p>于是它就把 <strong>“鸡”</strong> 这个字，打包成一个 <strong>Token</strong>，给它<strong>配一个数字编号</strong>，比如 <strong>76074</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330035936186-392337978.png" alt="" loading="lazy"></p>
<p>并且丢到<strong>词汇表</strong>里。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330040346612-1147326693.png" alt="" loading="lazy"></p>
<p>它又发现 <strong>“ing”</strong> 这三个字母<strong>经常一起出现</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330040444164-1266108088.png" alt="" loading="lazy"></p>
<p>于是又把 <strong>“ing”</strong> 这<strong>三个字母</strong>打包成一个 <strong>Token</strong>，给它<strong>配一个数字编号</strong>，比如 <strong>288</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330040552603-1400920552.png" alt="" loading="lazy"></p>
<p>并且收录到<strong>词汇表</strong>里。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330040646815-983421702.png" alt="" loading="lazy"></p>
<p>它又发现 <strong>“逗号”</strong> 经常出现。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330040739749-2145278878.png" alt="" loading="lazy"></p>
<p>于是又把 <strong>“逗号”</strong> 也打包作为一个 <strong>Token</strong>，给它<strong>配一个数字编号</strong>，比如 <strong>14</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330040759029-1687533560.png" alt="" loading="lazy"></p>
<p>收录到<strong>词汇表</strong>里。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330040909080-929892084.png" alt="" loading="lazy"></p>
<p>经过<strong>大量统计</strong>和<strong>收集</strong>，分词器就可以得到<strong>一个庞大的Token表</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330041027313-2070868030.png" alt="" loading="lazy"></p>
<p>可能有<strong>5万个</strong>、<strong>10万个</strong>，甚至<strong>更多Token</strong>，可以<strong>囊括</strong>我们日常见到的各种<strong>字</strong>、<strong>词</strong>、<strong>符号</strong>等等。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330041202714-406489753.png" alt="" loading="lazy"></p>
<p>这样一来，大模型在<strong>输入</strong>和<strong>输出</strong>的时候，都只需要<strong>面对一堆数字编号</strong>就可以了。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330041315336-1323830099.png" alt="" loading="lazy"></p>
<p>再由分词器<strong>按照Token表</strong>，转换成<strong>人类可以看懂</strong>的<strong>文字</strong>和<strong>符号</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330041403085-1030412812.png" alt="" loading="lazy"></p>
<p>这样一分工，工作效率就非常高。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330041513486-954314015.png" alt="" loading="lazy"></p>
<p>有这么一个网站 <strong>Tiktokenizer</strong>：<a href="https://tiktokenizer.vercel.app" target="_blank" rel="noopener nofollow">https://tiktokenizer.vercel.app</a></p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330041733913-1477351521.png" alt="" loading="lazy"></p>
<p>输入一段话，它就可以告诉你，这段话是<strong>由几个Token构成</strong>的，分别是什么，以及这几个<strong>Token的编号分别是多少</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330124658377-412060905.png" alt="" loading="lazy"></p>
<p>我来演示一下，这个网站有很多模型可以选择，像 <strong>GPT-4o</strong>、<strong>DeepSeek</strong>、<strong>LLaMA</strong> 等等。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330124841908-1086689995.png" alt="" loading="lazy"></p>
<p>我选的是 <strong>DeepSeek</strong>，我输入 <strong>“哈哈”</strong>，显示是<strong>一个 Token</strong>，编号是 <strong>11433</strong>：</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330124940576-1066826376.png" alt="" loading="lazy"></p>
<p><strong>“哈哈哈”</strong>，也是<strong>一个 Token</strong>，编号是 <strong>40886</strong>：</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330042254101-1720127855.png" alt="" loading="lazy"></p>
<p><strong>4</strong>个 <strong>“哈”</strong>，还是<strong>一个 Token</strong>，编号是 <strong>59327</strong>：</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330125649628-134511117.png" alt="" loading="lazy"></p>
<p>但是<strong>5</strong>个 <strong>“哈”</strong>，就变成了<strong>两个Token</strong>，编号分别是 <strong>11433</strong>, <strong>40886</strong>：</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130458163-500229089.png" alt="" loading="lazy"></p>
<p>说明大家平常用两个 <strong>“哈”</strong> 或者<strong>三个</strong>的更多。</p>
<p>再来，“一心一意” 是三个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130627407-799656843.png" alt="" loading="lazy"></p>
<p>“鸡蛋” 是一个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130705809-627990355.png" alt="" loading="lazy"></p>
<p>但是 “鸭蛋” 是两个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130734684-1820601027.png" alt="" loading="lazy"></p>
<p>“关羽” 是一个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130814275-959895115.png" alt="" loading="lazy"></p>
<p>“张飞” 是两个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130843670-107093440.png" alt="" loading="lazy"></p>
<p>“孙悟空” 是一个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130915668-780281331.png" alt="" loading="lazy"></p>
<p>“沙悟净” 是三个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330130955222-154375341.png" alt="" loading="lazy"></p>
<p>另外，正如前面提到的，不同模型的分词器可能会有不同的切分结果。比如，“<strong>苹果</strong>” 中的 “<strong>苹</strong>” 字，在 <strong>DeepSeek</strong> 中被拆分成两个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330131239995-368194495.png" alt="" loading="lazy"></p>
<p>但是在 <code>Qwen</code> 模型里却是一个 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330131342692-847984391.png" alt="" loading="lazy"></p>
<p>所以回过头来看，<strong>Token</strong> 到底是什么？</p>
<p>它就是构建大模型世界的一块块积木。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330133139211-359063061.png" alt="" loading="lazy"></p>
<p>大模型之所以能理解和生成文本，就是通过计算这些 Token 之间的关系，来预测下一个最可能出现的 Token。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330133212151-159956032.png" alt="" loading="lazy"></p>
<p>这就是为什么几乎所有大模型公司都按照 <strong>Token</strong> 数量计费，因为 Token 数量直接对应背后的计算成本。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330133338300-964232955.png" alt="" loading="lazy"></p>
<p>“<strong>Token</strong>” 这个词不仅用于<strong>人工智能</strong>领域，在其他领域也经常出现。其实，它们只是<strong>恰好</strong>都叫这个名字而已。<img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330133413332-588777855.png" alt="" loading="lazy"></p>
<p>就像同样都是 <strong>“车模”</strong>，<strong>汽车模型</strong>和<strong>车展模特</strong>，虽然用词相同，但含义却<strong>截然不同</strong>。</p>
<p><img src="https://img2023.cnblogs.com/blog/2105804/202503/2105804-20250330131918921-488085824.png" alt="" loading="lazy"></p>
<h1 id="faq">FAQ</h1>
<h2 id="1-苹为啥会是2个">1. 苹为啥会是2个?</h2>
<p>因为“苹” 字单独出现的概率太低，无法独立成为一个 Token。</p>
<h2 id="2-为什么张飞算两个-token">2. 为什么张飞算两个 Token?</h2>
<p>“张” 和 “飞” 一起出现的频率不够高，或者“ 张” 字和 “飞” 字的搭配不够稳定，经常与其他字组合，因此被拆分为两个 Token。</p>
<hr>
<p>Token 在大模型方面最好的翻译是 '词元' 非常的信雅达。</p>
<p>欢迎关注我的微信公众号【程序员 NEO】！</p>
<p>这里有丰富的技术分享、实用的编程技巧、深度解析微服务架构，还有更多精彩内容等你探索！🚀</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.5363594491712963" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-01 09:24">2025-04-01 09:24</span>&nbsp;
<a href="https://www.cnblogs.com/BNTang">BNTang</a>&nbsp;
阅读(<span id="post_view_count">485</span>)&nbsp;
评论(<span id="post_comment_count">3</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18803486" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18803486);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18803486', targetLink: 'https://www.cnblogs.com/BNTang/p/18803486', title: '大模型 Token 究竟是啥：图解大模型Token' })">举报</a>
</div>
        