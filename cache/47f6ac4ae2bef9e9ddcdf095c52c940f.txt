
	<h1 class="postTitle"><a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/georgewing/p/19063737" title="发布于 2025-08-29 01:02">
    <span role="heading" aria-level="2">10分钟揭秘大模型的原理</span>
    

</a>
</h1>
	<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>2022年11月底OpenAI发布的ChatGPT，一上线就引起了恐慌。我们在有大模型之前，使用百度、Bing搜索问题时，有可能找了几页也找不到自己想要的答案。而有了大模型之后，输出的答案要正确多了。关键是这个回答的正确率太可怕了。我用了几个月，发现它的答案不是说不对，而是提的问题要合理准确。</p>
<p>当然它最厉害的核心是能像人类的语言进行交流，不管是什么语言都可以，就算你写错了也没有问题，它都理解。这是基于生成式AI的高速发展的结果。生成式AI是通过缝合式创作生成一个新的内容。这让AI发展到了里程碑式的节点。</p>
<p>ChatGPT在回答问题的时候，是一个词一个词的往外蹦。这由它的原理而决定。</p>
<p>大模型的原理其实很简单，就是根据上下文来推理下一个文字是什么。然后会不断的文本生成。</p>
<p>从训练到推理的整个过程包括如下3个步骤：</p>
<ol>
<li>预训练</li>
</ol>
<ul>
<li>无监督学习，就是基于知识库进入自主学习</li>
</ul>
<p><img alt="" loading="lazy" data-src="https://img2024.cnblogs.com/blog/11617/202508/11617-20250829010218363-171920910.png" class="lazyload"></p>
<ul>
<li>模型在大数据集中自主学习</li>
</ul>
<ol start="2">
<li>微调</li>
</ol>
<ul>
<li>
<p>不是必需的步骤</p>
</li>
<li>
<p>有监督</p>
</li>
<li>
<p>通过在人工标的数据集上训练优化模型，使其“有用”、“安全”</p>
</li>
</ul>
<ol start="3">
<li>推理</li>
</ol>
<ul>
<li>
<p>与人在线、实时交互</p>
</li>
<li>
<p>使用已经训练好的模型生成响应</p>
</li>
</ul>
<p>Transformer模型的核心是自注意力机制，可有效的捕捉序列内各元素之间的关系。例子是一个动画： <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb#scrollTo=OJKU36QAfqOC" target="_blank" rel="noopener nofollow">https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb#scrollTo=OJKU36QAfqOC</a></p>
<p>这个例子是通过注意力机制判断这一句话中每一个文本之间的关系和语义关系。</p>
<p>当我们把内容放到这个transformer模型后，每一层的自注意力机制，都可以并行的去分析文本里面的不同信息，如GPT-3有96层，可以输出包含所有必要信息的最终词的隐藏状态，这样可以精准地预测下一个词是什么。通过这么多层的模型可以实现对文本有更深层次的理解，并通过大维度词向量来记录每一个词的上下文信息。从而达到如今能够跟人进行自由对话的智能化程度。</p>
<p>这就是整个大模型的工作原理。</p>

</div>
<div class="clear"></div>

	<div class="postDesc">posted on 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-29 01:03">2025-08-29 01:02</span>&nbsp;
<a href="https://www.cnblogs.com/georgewing">豆豆の爸爸</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19063737);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19063737', targetLink: 'https://www.cnblogs.com/georgewing/p/19063737', title: '10分钟揭秘大模型的原理' })">举报</a>
</div>
