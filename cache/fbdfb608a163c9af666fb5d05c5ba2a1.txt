
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/seatunnel/p/18900580" title="发布于 2025-05-28 14:41">
    <span role="heading" aria-level="2">【异常总结】SeaTunnel集群脑裂配置优化方法</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        
        4月份以来，出现了3次集群脑裂现象，均为某节点脑裂/自动关闭。
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="集群配置">集群配置</h2>
<table>
<thead>
<tr>
<th>项目</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>数量</td>
<td>3台</td>
</tr>
<tr>
<td>规格</td>
<td>阿里云ECS 16C64G</td>
</tr>
<tr>
<td>Slot模式</td>
<td>静态50个</td>
</tr>
<tr>
<td>ST内存配置</td>
<td>-Xms32g -Xmx32g -XX:MaxMetaspaceSize=8g</td>
</tr>
</tbody>
</table>
<h2 id="异常问题">异常问题</h2>
<p>4月份以来，出现了3次集群脑裂现象，均为某节点脑裂/自动关闭。</p>
<p>核心日志如下：</p>
<h3 id="master节点">Master节点</h3>
<p>出现Hazelcast监控线程打印的Slow Operation日志</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_005E40BA9C904671A95D8DBE649165D8" alt="file" loading="lazy"></p>
<p>Hazelcast 心跳超时60s后，会看见198已经离开了集群</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_DCDB1B0FF72E40C48D7A2DE4B0AD33D8" alt="file" loading="lazy"></p>
<h3 id="198-worker节点">198 worker节点</h3>
<p>我们可以看到，已经无法获得Hazelcast集群节点的心跳，且超时超过60000ms</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_0C1B468FFE5B4D4CBC780B5DDFF7C9B0" alt="file" loading="lazy"></p>
<p><strong>尝试重连到集群</strong></p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_67EE61B2D4684E5981960EBA60E06789" alt="file" loading="lazy"></p>
<p>然后打到该节点上的状态查询、提交作业等请求，卡死无状态；</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_FFEBB54E32BF4B67AE1DA56EB86C9C7D" alt="file" loading="lazy"></p>
<p>这时整个集群不可用，处于僵死状态，我们写的节点健康检查接口，均不可用， <strong>早高峰时间出现了服务不可用</strong>，于是我们观察日志出现集群脑裂后，快速重启了集群。</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_5CBE82C0954C4A70AC0909595E1535B1" alt="file" loading="lazy"></p>
<p>后期调参后，甚至还出现过调参后节点自动关闭的问题</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_FBE177F9C2CA4FFAAF70C9652EBD59AD" alt="file" loading="lazy"></p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_9C92F0AEA6DB45059DDCD7827951030B" alt="file" loading="lazy"></p>
<h2 id="问题分析">问题分析</h2>
<p>可能出现Hazelcast<strong>集群脑裂组网失败</strong>的问题，有以下几个：</p>
<ul>
<li>
<p>集群所在的ECS系统NTP不一致；</p>
</li>
<li>
<p>集群所在的ECS出现了网络抖动问题，访问不可用；</p>
</li>
<li>
<p>ST出现FULL GC导致JVM卡顿，导致组网失败；</p>
</li>
</ul>
<p>前两个问题，我们通过运维同学，<strong>明确网络无问题</strong>，阿里云NTP服务正常三个服务器<strong>时间无间隔</strong>；</p>
<p>第三个问题，我们再198节点出现异常前最后一次<code>hazelcast</code>健康检查日志发现，<code>cluster time</code>的时间点为-100毫秒，看起来影响不大。</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_E0CC6FA186A24B368164A1EE38AB784E" alt="file" loading="lazy"></p>
<p>于是我们在后续启动时，添加了jvm gc日志参数，用以观察full gc的时间，我们观察过最多有观察到27s， 三个节点相互Ping监控，极易出现hazelcast 60s的心跳超时时间。</p>
<p>同时我们也发现，某个14亿CK表同步时，运行一定时间后，就容易FullGc异常问题。</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_15CE49F192944CAD8DFEDE6105A6F015" alt="file" loading="lazy"></p>
<h2 id="问题解决方案">问题解决方案</h2>
<h3 id="增加st集群心跳时间">增加ST集群心跳时间</h3>
<p><code>hazelcast</code>集群故障检查器负责确定集群中的成员是否无法访问或崩溃。</p>
<p>但根据著名的<strong>FLP结果</strong>，在异步系统中不可能区分崩溃的成员和缓慢的成员。解决此限制的方法是使用不可靠的故障检测器。不可靠的故障检测器允许成员怀疑其他人已经失败，通常基于活性标准，但它可能会在一定程度上犯错误。</p>
<p>Hazelcast 具有以下内置故障检测器：<code>Deadline Failure Detector</code> 和 <code>Phi Accrual Failure Detector</code>。</p>
<p>默认情况下，Hazelcast 使用Deadline Failure Detector进行故障检测。</p>
<p>还有一个 Ping 故障检测器，如果启用，它会与上述检测器并行工作，但会识别 OSI 第 3 层（网络层）上的故障。该检测器默认处于禁用状态。</p>
<p><strong>Deadline Failure Detector</strong></p>
<p>对丢失/丢失的心跳使用绝对超时。超时后，成员将被视为崩溃/不可用并标记为可疑</p>
<p>相关参数及说明</p>
<pre><code>hazelcast:

properties:

hazelcast.heartbeat.failuredetector.type: deadline

hazelcast.heartbeat.interval.seconds: 5

hazelcast.max.no.heartbeat.seconds: 120
</code></pre>
<table>
<thead>
<tr>
<th>配置项</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>hazelcast.heartbeat.failuredetector.type</code></td>
<td>集群故障检查器模式：deadline.</td>
</tr>
<tr>
<td><code>hazelcast.heartbeat.interval.seconds</code></td>
<td>成员之间互相发送心跳消息的时间间隔。</td>
</tr>
<tr>
<td><code>hazelcast.max.no.heartbeat.seconds</code></td>
<td>定义集群成员因未发送任何心跳而受到怀疑的超时时间。</td>
</tr>
</tbody>
</table>
<p><strong>Phi-accrual 计故障检测器</strong></p>
<p>跟踪滑动时间窗口中心跳之间的间隔，测量这些样本的平均值和方差，并计算怀疑级别 (Phi) 值。</p>
<p>当自上次心跳以来的时间间隔变长时，phi 的值会增加。如果网络变得缓慢或不可靠，导<strong>致均值和方差增加</strong>，则怀疑该成员之前需要更长的时间没有收到心跳。</p>
<p>相关参数及说明</p>
<pre><code>hazelcast:

properties:

hazelcast.heartbeat.failuredetector.type: phi-accrual

hazelcast.heartbeat.interval.seconds: 1

hazelcast.max.no.heartbeat.seconds: 60

hazelcast.heartbeat.phiaccrual.failuredetector.threshold: 10

hazelcast.heartbeat.phiaccrual.failuredetector.sample.size: 200

hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis: 100
</code></pre>
<table>
<thead>
<tr>
<th>配置项</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>hazelcast.heartbeat.failuredetector.type</code></td>
<td>集群故障检查器模式：phi-accrual</td>
</tr>
<tr>
<td><code>hazelcast.heartbeat.interval.seconds</code></td>
<td>成员之间互相发送心跳消息的时间间隔</td>
</tr>
<tr>
<td><code>hazelcast.max.no.heartbeat.seconds</code></td>
<td>定义集群成员因未发送任何心跳而受到怀疑的超时时间。由于故障检测器可适应网络条件，您可以定义低于截止时间故障检测器 <code>hazelcast.max.no.heartbeat.seconds</code> 中定义的超时时间</td>
</tr>
<tr>
<td><code>hazelcast.heartbeat.phiaccrual.failuredetector.threshold</code></td>
<td>成员被视为无法访问并标记为可疑的 phi 阈值。计算出的 phi 超过此阈值后，成员将被视为无法访问并标记为可疑。较低的阈值允许您检测成员中的任何崩溃或故障，但可能会生成更多故障并导致错误的成员被标记为可疑。较高的阈值产生的故障较少，但检测实际崩溃/故障的速度较慢。例如，phi = 1 的情况下故障识别的错误率约为 10%，phi = 2 则约为 1%，phi = 3 约为 0.1%。默认情况下，phi 阈值设置为 10</td>
</tr>
<tr>
<td><code>hazelcast.heartbeat.phiaccrual.failuredetector.sample.size</code></td>
<td>为历史保留的样本数量。默认情况下，此项设置为 200</td>
</tr>
<tr>
<td><code>hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis</code></td>
<td>正态分布中 phi 计算的最小标准差</td>
</tr>
</tbody>
</table>
<p>配置参考文档：</p>
<blockquote>
<ul>
<li><a href="https://docs.hazelcast.com/hazelcast/5.1/system-properties" target="_blank" rel="noopener nofollow">https://docs.hazelcast.com/hazelcast/5.1/system-properties</a></li>
<li><a href="https://docs.hazelcast.com/hazelcast/5.1/clusters/failure-detector-configuration" target="_blank" rel="noopener nofollow">https://docs.hazelcast.com/hazelcast/5.1/clusters/failure-detector-configuration</a></li>
<li><a href="https://docs.hazelcast.com/hazelcast/5.4/clusters/phi-accrual-detector" target="_blank" rel="noopener nofollow">https://docs.hazelcast.com/hazelcast/5.4/clusters/phi-accrual-detector</a></li>
</ul>
</blockquote>
<p>为了更准确，我们采用<strong>社区建议</strong>，在<code>hazelcast.yml</code>使用<code>phi-accrual</code> 故障检测器，并配置超时时间为180s:</p>
<pre><code>hazelcast:

properties:

# 以下为追加的新参数

hazelcast.heartbeat.failuredetector.type: phi-accrual

hazelcast.heartbeat.interval.seconds: 1

hazelcast.max.no.heartbeat.seconds: 180

hazelcast.heartbeat.phiaccrual.failuredetector.threshold: 10

hazelcast.heartbeat.phiaccrual.failuredetector.sample.size: 200

hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis: 100
</code></pre>
<h2 id="优化gc配置">优化GC配置</h2>
<p>SeaTunnel默认使用G1垃圾处理器，内存配置的越大，若YoungGC/MixedGC资源回收的不够多(多线程)，从而频繁触发FullGC处理(JAVA8单线程处理，时间很长)，若集群多节点一起FullGC，则会导致集群越有可能出现组网异常问题；</p>
<p>所以我们的目标就是YoungGC/MixedGC尽可能利用线程回收足够多的内存。</p>
<p>未优化的参数</p>
<pre><code>-Xms32g

-Xmx32g

-XX:+HeapDumpOnOutOfMemoryError

-XX:HeapDumpPath=/tmp/seatunnel/dump/zeta-server

-XX:MaxMetaspaceSize=8g

-XX:+UseG1GC

-XX:+PrintGCDetails

-Xloggc:/alidata1/za-seatunnel/logs/gc.log

-XX:+PrintGCDateStamps
</code></pre>
<p>于是我们尝试增加GC暂停的时间</p>
<pre><code>-- 该参数设置所需最大暂停时间的目标值。默认值为 200 毫秒。

-XX:MaxGCPauseMillis=5000
</code></pre>
<p><strong>Mixed Garbage Collections</strong>会根据该参数中该参数和历史回收耗时来计算本次要回收多少Region才能耗时200ms，假如回收了一部分远远没有达到回收的效果，G1还有一个特殊处理方法，STW后进行回收，然后恢复系统线程，然后再次STW，执行混合回收掉一部分Region，‐XX:G1MixedGCCountTarget=8 (默认是8次)，反复执行上述过程8次。</p>
<p>eg：假设要回收400个Region，如果受限200ms，每次只能回收50个Region，反复8次刚好全部回收完毕，避免单次停顿回收STW时间太长。</p>
<p><strong>第一次优化后参数</strong></p>
<pre><code>-Xms32g

-Xmx32g

-XX:+HeapDumpOnOutOfMemoryError

-XX:HeapDumpPath=/tmp/seatunnel/dump/zeta-server

-XX:MaxMetaspaceSize=8g

-XX:+UseG1GC

-XX:+PrintGCDetails

-Xloggc:/alidata1/za-seatunnel/logs/gc.log

-XX:+PrintGCDateStamps

-XX:MaxGCPauseMillis=5000
</code></pre>
<p>MixedGC 日志如下：</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_CA2494192DA94F8DA97E808ECFC9A738" alt="file" loading="lazy"></p>
<p>MixedGC 日志暂停耗时， 该参数仅是预期值，目前看返回结果的均在预期范围内；</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_84B8E5FB55F14663B370093E596E18AD" alt="file" loading="lazy"></p>
<p>full gc日志</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_9F1D518BC4D04645A13B486766E70BFA" alt="file" loading="lazy"></p>
<p>但是仍然无法避免FullGc，切耗时在20s左右，追加的参数只是少量优化GC性能。</p>
<p>我们通过观察日志，发现在MixedGC场景下，老年代没有被正常GC掉，有大量存留数据在老年代中未被清理。<br>
<img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_523CD140CA9A44C5B72B7528CB7259DE" alt="file" loading="lazy"><br>
于是我们，我们尝试从增加老年代内存，以及G1垃圾回收器一些性能参数进行调参；</p>
<p>优化的参数如下：</p>
<pre><code>-Xms42g

-Xmx42g

-XX:GCTimeRatio=4

-XX:G1ReservePercent=15

-XX:G1HeapRegionSize=32M
</code></pre>
<p>堆内存(-Xms / -Xmx) 由32G-&gt;42G，变相增大了老年代区域的上限，理论上可以减少FullGC的次数；</p>
<p>GC占用的CPU和工作线程占用CPU时间比例（-XX:GCTimeRatio） 由10%-&gt;20%，计算公式为100/(1+GCTimeRatio)，增加GC时占用时间；</p>
<p><strong>保留空间</strong>（-XX:G1ReservePercent）由10%-&gt;15%，转移失败（Evacuation Failure）是指当G1无法在堆空间中申请新的分区时，G1便会触发担保机制，执行一次STW式的、单线程的Full GCG。可以保留空间增加，但是调高此值同时也意味着降低了老年代的实际可用空间，于是我们增大了堆内存，提升该参数可以缓解下列场景的出现：</p>
<ul>
<li>从年轻代分区拷贝存活对象时，无法找到可用的空闲分区。</li>
<li>从老年代分区转移存活对象时，无法找到可用的空闲分区。</li>
<li>分配巨型对象时在老年代无法找到足够的连续分区。</li>
</ul>
<p>堆内存Region大小（-XX:G1HeapRegionSize）—大小调整至32MB，优化对大对象的回收；</p>
<p><strong>第二次优化后参数</strong></p>
<pre><code>-Xms42g

-Xmx42g

-XX:+HeapDumpOnOutOfMemoryError

-XX:HeapDumpPath=/tmp/seatunnel/dump/zeta-server

-XX:MaxMetaspaceSize=8g

-XX:+UseG1GC

-XX:+PrintGCDetails

-Xloggc:/alidata1/za-seatunnel/logs/gc.log

-XX:+PrintGCDateStamps

-XX:MaxGCPauseMillis=5000

-XX:GCTimeRatio=4

-XX:G1ReservePercent=15

-XX:G1HeapRegionSize=32M
</code></pre>
<p>优化后我们发现当天整体的FullGC数量有一定下降，但是仍未达到无FullGC的预期</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_2DF3CD658A104533B066E5FD298085C3" alt="file" loading="lazy"></p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_5E62688F25C44A6E8AACABE2366A7258" alt="file" loading="lazy"></p>
<p>继续观察日志，发现并行交集阶消耗了大量的时间，并出现很多次abort记录。</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_34CF4573BC8F4B5FB7F1F18DDF895379" alt="file" loading="lazy"></p>
<p>优化的参数如下：</p>
<pre><code>-XX:ConcGCThreads=12

-XX:InitiatingHeapOccupancyPercent=50
</code></pre>
<p>与应用一起执行的GC线程数量(-XX:ConcGCThreads) 由4-&gt;12，该值越低则系统的吞吐量越大，但过低会导致GC时间过长。当并发周期时间过长时，可以尝试调大GC工作线程数，但是这也意味着此期间应用所占的线程数减少，<strong>会对吞吐量有一定影响</strong>，对于离线数据同步场景，避免FullGC这个参数很重要。</p>
<p>老年代并发标记比率（-XX:InitiatingHeapOccupancyPercent）由 45%-&gt;50%，提早进行并发标记处理，提升MixedGC性能；</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_21F6019469D143319AF2EB0226F03F18" alt="file" loading="lazy"></p>
<p><strong>第三次优化后参数</strong></p>
<pre><code>-Xms42g

-Xmx42g

-XX:+HeapDumpOnOutOfMemoryError

-XX:HeapDumpPath=/tmp/seatunnel/dump/zeta-server

-XX:MaxMetaspaceSize=8g

-XX:+UseG1GC

-XX:+PrintGCDetails

-Xloggc:/alidata1/za-seatunnel/logs/gc.log

-XX:+PrintGCDateStamps

-XX:MaxGCPauseMillis=5000

-XX:InitiatingHeapOccupancyPercent=50

-XX:+UseStringDeduplication

-XX:GCTimeRatio=4

-XX:G1ReservePercent=15

-XX:ConcGCThreads=12

-XX:G1HeapRegionSize=32M
</code></pre>
<p><strong>JVM调优参考：</strong></p>
<blockquote>
<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/g1_gc_tuning.html#sthref56" target="_blank" rel="noopener nofollow">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/g1_gc_tuning.html#sthref56</a>&gt;</li>
<li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/g1_gc.html#pause_time_goal" target="_blank" rel="noopener nofollow">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/g1_gc.html#pause_time_goal</a>&gt;</li>
<li><a href="https://zhuanlan.zhihu.com/p/181305087" target="_blank" rel="noopener nofollow">https://zhuanlan.zhihu.com/p/181305087</a>&gt;</li>
<li><a href="https://blog.csdn.net/qq_32069845/article/details/130594667" target="_blank" rel="noopener nofollow">https://blog.csdn.net/qq_32069845/article/details/130594667</a>&gt;</li>
</ul>
</blockquote>
<p><strong>优化效果</strong></p>
<p>自4月26日配置优化修改后，<strong>未再出现集群脑裂问题</strong>，服务可用性监控显示，集群均可恢复正常。</p>
<p>自4月30日Jvm参数调优后，五一假期内，我们实现了3台节点FullGC数量为0的优化目标，系统健康检查接口未再出现任何卡顿异常。</p>
<p>虽然一定程度上牺牲了应用线程处理的吞吐量，但是我们保证了集群的稳定性，使zeta在内部大规模推广得到了保证。</p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_B677B1E8F94F4796BD95C9A31887905A" alt="file" loading="lazy"></p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_B1C023D9B9AD419AA3C924D7C30A1702" alt="file" loading="lazy"></p>
<p><img src="http://openwrite-whaleops.oss-cn-zhangjiakou.aliyuncs.com/31504_25D50AED4A4D4E4C9313D6BFE9E3B680" alt="file" loading="lazy"></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.06965008084375" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-05-28 14:41">2025-05-28 14:41</span>&nbsp;
<a href="https://www.cnblogs.com/seatunnel">ApacheSeaTunnel</a>&nbsp;
阅读(<span id="post_view_count">34</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18900580);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18900580', targetLink: 'https://www.cnblogs.com/seatunnel/p/18900580', title: '【异常总结】SeaTunnel集群脑裂配置优化方法' })">举报</a>
</div>
        