
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/zhaoweiwei/p/19036381/cuda1" title="发布于 2025-08-15 15:23">
    <span role="heading" aria-level="2">CUDA编程初探</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        
        本文从cuda历史引入，并重点介绍了cuda编程涉及到的关键概念，并给出了一个最简示例程序，基于该程序介绍了相关cuda调试工具的使用方法及侧重点！
    </div>
<div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h1>1 简介</h1>
<h2>1.1 发展历程</h2>
<h3>1. 起步阶段（1990 年代）：从图形加速到 GPU 雏形</h3>
<p>1993年：NVIDIA 成立，初期专注于图形芯片设计。<br>1997年：发布 RIVA 128，首款支持 DirectX 5 和 OpenGL 1.1 的显卡，采用 128-bit 架构，奠定早期 3D 加速基础。<br>1999年：推出 GeForce 256，首次提出“GPU”概念，集成硬件变换与光照（T&amp;L）引擎，不再依赖 CPU 处理图形数据，性能较前代提升 10 倍。</p>
<h3>2. 架构迭代与市场扩张（2000 年代）：从 GeForce 到 CUDA</h3>
<p>2001年：GeForce3 引入可编程着色器（Vertex Shader 和 Pixel Shader），支持 DirectX 8，开启 “可编程图形” 时代。</p>
<p>2004年：GeForce 6800 Ultra（NV40架构）支持 DirectX 9，引入 SM（Streaming Multiprocessor）雏形，为后续并行计算奠定硬件基础。</p>
<p>2006年：GeForce 8800 GTX（G80架构）发布，首次采用统一渲染架构，支持 DirectX 10；同年<span style="color: rgba(255, 0, 0, 1)">推出 CUDA 平台</span>，使GPU具备通用计算能力。</p>
<p>2008年：GeForce GTX 280（GT200架构）强化多GPU协同（SLI 技术），CUDA 核心数量提升至 240 个，通用计算性能显著增强。</p>
<h3>3. 通用计算崛起（2010 年代）：从游戏到 AI</h3>
<p>2010年：GeForce GTX 480（Fermi架构）首次支持 ECC 内存，引入 L2 缓存和双通道 GDDR5 显存，CUDA 核心数量达 480 个，首次被广泛用于 AI 研究。</p>
<p>2012年：GeForce GTX 680（Kepler架构）能效比大幅提升，采用“开普勒”SM 设计，支持动态超频（GPU Boost），推动 GPU 在深度学习领域的应用。</p>
<p>2016年：GeForce GTX 1080 Ti（Pascal架构）采用16nm工艺，显存带宽提升至 484GB/s，CUDA 核心数量达 3584个，成为当时 AI 研究的“主力卡”。</p>
<p>2018年：GeForce RTX 2080 Ti（Turing架构）首次引入RT Core（光线追踪核心）和Tensor Core（张量核心），支持实时光线追踪和 AI 超采样（DLSS），开启“实时光追 + AI 加速”新纪元。</p>
<h3>4. 全能计算时代（2020 年代至今）：Ada Lovelace 与 Blackwell</h3>
<p>2020年：GeForce RTX 3090（Ampere架构）升级 Tensor Core 和 RT Core，支持 FP16 混合精度计算，显存容量达 24GB GDDR6X，兼顾 8K 游戏与 AI 训练。</p>
<p>2022年：GeForce RTX 4090（Ada Lovelace架构）采用 4nm 工艺，引入 Shader Execution Reordering（SER） 和第二代 RT Core，DLSS 3 技术支持 AI 生成帧，光线追踪性能较上一代提升2倍，该架构面向消费级显卡领域。同时发布Hopper 架构，面向数据中心 / AI 领域。</p>
<p>2024年：GeForce RTX 5090（Blackwell架构）发布，集成更多CUDA Core 和Tensor Core，支持 FP4 超算精度，进一步模糊游戏GPU与数据中心GPU的界限，成为AI创作、实时渲染和科学计算的全能平台。</p>
<p>2025年：对应R100 以及 GeForce RTX 60 系列（Rubin架构），R100是基于Rubin 架构的首款产品，预计将于2025年第四季度进入量产。它将采用台积电3nm工艺，配备HBM4内存，使用台积电的CoWoS-L封装技术。此外，基于 Rubin 架构的消费级显卡 GeForce RTX 60 系列也在规划中，包括 RTX 6090、RTX 6080 和 RTX 6070 Ti 等，这些显卡预计会在 2026 年至 2027 年期间推出。</p>
<p>自2006年起，英伟达每次架构发布都是以一位知名科学家的名字命名，用于向他们表示致敬，主要历史如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250813183409980-1607557985.png" alt="" width="1041" height="109" style="display: block; margin-left: auto; margin-right: auto"></p>
<h2>1.2 关键概念</h2>
<h3>1 驱动及toolkit</h3>
<p>首先理解下这两个概念：<span style="color: rgba(255, 0, 0, 1)">驱动关系到程序运行</span>，也就是说程序要在平台（Windows/Linux）上运行，必须要有NVIDIA显卡及对应驱动，两者缺一不可；而<span style="color: rgba(255, 0, 0, 1)">toolkit关系到程序编译</span>，平台上即便不存在显卡及驱动，只要它安装了toolkit即可编译相应的GPU程序，编译出的程序即可拷贝到存在GPU显卡及相关驱动的平台去运行，所以说这两个概念是相对独立的。在Ubuntu 22.04下推荐驱动和CUDA Toolkit分开装，驱动用apt管理，CUDA runfile只安装toolkit，如使用下面命令只安装toolkit，而不安装runfile里面的驱动：</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 255, 1)">sudo</span> <span style="color: rgba(0, 0, 255, 1)">sh</span> cuda_12.<span style="color: rgba(128, 0, 128, 1)">4</span>.1_linux.run --silent --toolkit --toolkitpath=/usr/local/cuda-<span style="color: rgba(128, 0, 128, 1)">12.4</span></pre>
</div>
<p>当然也可以通过sudo sh cuda_12.4.1_linux.run进入交互菜单，在进行安装时把Driver前面的勾去掉，只选Toolkit、Samples等需要的部分。</p>
<p>另外在进行驱动安装前要确定下相关版本及兼容性，下面是chatgpt给出的GTX 1060+Ubuntu 22.04的兼容性参考表：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250813120722904-447826193.png" alt="image" width="794" height="237" loading="lazy" style="display: block; margin-left: auto; margin-right: auto">在Ubuntu 22.04上推荐使用nvidia-driver-550配合12.4/12.6，来做为基于GTX 1060显卡程序运行及开发环境。</p>
<h3>2 硬件角度关键概念</h3>
<p>（1）SP(streaming processor)：最基本的处理单元，也称CUDA core，最后具体的指令和任务都是在SP上处理的，GPU进行并行计算，就是很多SP同时做处理。</p>
<p>（2）SM(streaming multiprocessor)：多个SP加上一些其他资源，如：warp scheduler，register，shared memory等组成一个SM，也叫GPU大核。由于register和shared memory资源的稀缺性，会限制active warps的个数，即限制了GPU的并行能力。</p>
<p>（3）Warp：一个SP可以执行一个thread，但是实际上并不是所有的thread能够在同一时刻执行。Nvidia把32个threads组成一个warp，warp是调度和运行的基本单元。一次调度时，warp的32个线程会被同时分配到32个SP一次执行完成。所以，如果SM有64个SP，就可以同时执行2个warp（64/32=2），如果SM有128个SP，就可在一个周期里同时执行4个warp。</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815141600419-1025612165.png" alt="" width="822" height="506" style="display: block; margin-left: auto; margin-right: auto"></p>
<h3>3 软件角度关键概念</h3>
<p>（1）Kernel：在GPU上调用的函数称为CUDA核函数（Kernel function），核函数会被GPU上的多个线程执行，其调用格式如下：</p>
<div class="cnblogs_code">
<pre>kernel_name&lt;&lt;&lt;grid, block&gt;&gt;&gt;(argument list);</pre>
</div>
<p>（2）Grid：由一个单独的kernel启动的所有线程组成一个grid，grid中所有线程共享global memory。Grid由很多Block组成，可以是一维、二维或三维。</p>
<p>（3）Block：block由许多线程组成，同样可以有一维、二维或者三维，block内部的多个线程可以同步（synchronize），可访问共享内存（share memory）。</p>
<p>（4）dim3：CUDA提供的一个内置类型，本质上是一个三维向量，用于指定网格和块的维度和大小。</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 0, 255, 1)">struct</span><span style="color: rgba(0, 0, 0, 1)"> dim3 {
    unsigned </span><span style="color: rgba(0, 0, 255, 1)">int</span><span style="color: rgba(0, 0, 0, 1)"> x, y, z;
};</span></pre>
</div>
<p>如dim3(16)，则x为16，y和z取默认值为 1，dim3(16, 8)，则x为16，y为8，z取默认值为 1。</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815141559736-1789108971.png" alt="" width="471" height="440" style="display: block; margin-left: auto; margin-right: auto"></p>
<h3>4 关键内置变量</h3>
<p>blockIdx：块儿索引，blockIdx.x表示block在grid中的x坐标。</p>
<p>threadIdx：线程索引，threadIdx.x表示thread在block中的x坐标。</p>
<p>gridDim： 每个grid在三个维度上的块数，gridDim.x表示x维度上block的数量，如上图中gridDim.x为3。</p>
<p>blockDim：每个block在三个维度上的线程数，blockDim.x表示x维度上thread的数量，如上图中blockDim.x为5。</p>
<p>例如，如下调用中grid为一维，有4个block，block也为一维，每个block有8个线程，所以调用会启动4*8=32个线程。</p>
<div class="cnblogs_code">
<pre>kernel_name&lt;&lt;&lt;<span style="color: rgba(128, 0, 128, 1)">4</span>, <span style="color: rgba(128, 0, 128, 1)">8</span>&gt;&gt;&gt;(argumentt list);</pre>
</div>
<p>相应index取值由下图示意：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815142236626-1869638364.png" alt="" width="830" height="130" style="display: block; margin-left: auto; margin-right: auto"></p>
<h3>5 GPU核心</h3>
<p><strong>1 Texture Core（纹理核心）</strong></p>
<p>专门负责纹理采样、过滤和坐标转换等图形渲染任务，广泛用于游戏、影视渲染中对纹理（如皮肤、布料、环境贴图）的处理。</p>
<p><strong>2 CUDA Core（CUDA 核心）</strong></p>
<p>执行传统的浮点运算（如 FP32、FP64）和整数运算，支持 CUDA 编程模型，负责处理通用并行计算任务（如科学计算、图像处理、物理模拟等），是NVIDIA GPU的基础计算核心。</p>
<p><strong>3 Tensor Core（张量核心）</strong></p>
<p>高效执行 FP16/FP32/INT8 等精度的矩阵乘法与累加（GEMM）操作，公式为 D = A × B + C（其中 A、B、C、D 为矩阵）。</p>
<p><strong>4 RT Core（光线追踪核心）</strong></p>
<p>加速光线与物体相交检测（Ray Tracing Intersection）计算，以及辐射度估计等光线追踪核心算法。</p>
<p><strong>5 其他核心</strong></p>
<p>DPU（数据处理单元）、Security Core（安全核心）、Infinity互联核心</p>
<p>现代 NVIDIA GPU（如 Ampere、Hopper、Blackwell 架构）通常同时集成这三种核心，分别负责通用计算、AI 加速和图形渲染，形成“三位一体”的计算能力。</p>
<p>以下是RTX 4070系列显卡相关核心及其他关键参数信息：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815152345414-1399076095.png" alt="" width="939" height="589" style="display: block; margin-left: auto; margin-right: auto"></p>
<h2>1.3 示例程序</h2>
<p>接下来先给出示例程序hello.cu源码：</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> #include&lt;stdio.h&gt;
<span style="color: rgba(0, 128, 128, 1)"> 2</span> #include &lt;cuda.h&gt;
<span style="color: rgba(0, 128, 128, 1)"> 3</span> #include &lt;cuda_profiler_api.h&gt;
<span style="color: rgba(0, 128, 128, 1)"> 4</span> 
<span style="color: rgba(0, 128, 128, 1)"> 5</span> <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">定义gpu 核函数</span>
<span style="color: rgba(0, 128, 128, 1)"> 6</span> __global__ <span style="color: rgba(0, 0, 255, 1)">void</span><span style="color: rgba(0, 0, 0, 1)"> helloFromGPU()
</span><span style="color: rgba(0, 128, 128, 1)"> 7</span> <span style="color: rgba(0, 0, 0, 1)">{
</span><span style="color: rgba(0, 128, 128, 1)"> 8</span>     <span style="color: rgba(0, 0, 255, 1)">int</span> blockIndex = (blockIdx.z * gridDim.y + blockIdx.y) * gridDim.x +<span style="color: rgba(0, 0, 0, 1)"> blockIdx.x;
</span><span style="color: rgba(0, 128, 128, 1)"> 9</span>     <span style="color: rgba(0, 0, 255, 1)">int</span> globalThreadIndex = blockIndex * blockDim.x * blockDim.y * blockDim.z + 
<span style="color: rgba(0, 128, 128, 1)">10</span>                                 (threadIdx.z * blockDim.y + threadIdx.y) * blockDim.x +<span style="color: rgba(0, 0, 0, 1)"> threadIdx.x;
</span><span style="color: rgba(0, 128, 128, 1)">11</span>     printf(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Hello World from block(%d %d %d) thread(%d %d %d) %d!\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, blockIdx.x, blockIdx.y, blockIdx.z, 
</span><span style="color: rgba(0, 128, 128, 1)">12</span> <span style="color: rgba(0, 0, 0, 1)">            threadIdx.x, threadIdx.y, threadIdx.z, globalThreadIndex);
</span><span style="color: rgba(0, 128, 128, 1)">13</span> <span style="color: rgba(0, 0, 0, 1)">}
</span><span style="color: rgba(0, 128, 128, 1)">14</span> <span style="color: rgba(0, 0, 255, 1)">int</span><span style="color: rgba(0, 0, 0, 1)"> main()
</span><span style="color: rgba(0, 128, 128, 1)">15</span> <span style="color: rgba(0, 0, 0, 1)">{
</span><span style="color: rgba(0, 128, 128, 1)">16</span>     <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">hello from cpu</span>
<span style="color: rgba(0, 128, 128, 1)">17</span>     printf(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Hello World CPU!\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">18</span>     dim3 number_of_blocks(<span style="color: rgba(128, 0, 128, 1)">2</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">19</span>     dim3 threads_per_block(<span style="color: rgba(128, 0, 128, 1)">4</span>, <span style="color: rgba(128, 0, 128, 1)">8</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">20</span>     <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">调用核函数</span>
<span style="color: rgba(0, 128, 128, 1)">21</span>     helloFromGPU&lt;&lt;&lt;number_of_blocks, threads_per_block&gt;&gt;&gt;<span style="color: rgba(0, 0, 0, 1)">();
</span><span style="color: rgba(0, 128, 128, 1)">22</span> <span style="color: rgba(0, 0, 0, 1)">    cudaDeviceReset();
</span><span style="color: rgba(0, 128, 128, 1)">23</span>     <span style="color: rgba(0, 0, 255, 1)">return</span> <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">;
</span><span style="color: rgba(0, 128, 128, 1)">24</span> }</pre>
</div>
<p>&nbsp;运行nvcc –o hello hello.cu编译，然后执行该程序。运行结果中，第一个GPU thread输出是blockIdx(1,0,0), threadIdx(0,0,0), 即第1个block（下标从0开始）中第0个线程，所以其全局index为32。</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815142607437-1301364458.png" alt="" width="530" height="473" style="display: block; margin-left: auto; margin-right: auto"></p>
<h1>2 程序调试</h1>
<h2>2.1 调试工具</h2>
<p>CUDA程序主要调试工具如下所示：</p>
<table>
<thead>
<tr><th>工具</th><th>主要用途</th><th>适用平台</th><th>特点</th></tr>
</thead>
<tbody>
<tr>
<td><strong>Nsight Systems</strong></td>
<td>系统级性能分析（时间线、API 调用、CPU/GPU 协作）</td>
<td>Win / Linux</td>
<td>类似 "性能总览 + 火焰图"</td>
</tr>
<tr>
<td><strong>Nsight Compute</strong></td>
<td>内核级性能分析（Warp、SM、Memory、Occupancy）</td>
<td>Win / Linux</td>
<td>适合优化 CUDA kernel</td>
</tr>
<tr>
<td><strong>Nsight Graphics</strong></td>
<td>图形 API 调试（OpenGL, Vulkan, DirectX）</td>
<td>Win / Linux</td>
<td>适合游戏渲染调试</td>
</tr>
<tr>
<td><strong>cuda-gdb</strong></td>
<td>命令行级 GPU 代码调试</td>
<td>Linux</td>
<td>类似 GDB，用于内核断点调试</td>
</tr>
<tr>
<td><strong>cuda-memcheck</strong>（Compute Sanitizer）</td>
<td>内存错误检查</td>
<td>Win / Linux</td>
<td>检查越界、未初始化、数据竞争</td>
</tr>
<tr>
<td><strong>Visual Studio Nsight Integration</strong></td>
<td>集成式调试</td>
<td>Windows</td>
<td>在 VS 里直接调试 CUDA 代码</td>
</tr>
</tbody>
</table>
<p>从表中描述可有如下概括：</p>
<ul>
<li data-start="2710" data-end="2754">
<p data-start="2712" data-end="2754"><strong data-start="2712" data-end="2733">性能总览（CPU/GPU协作分析）</strong> → <strong data-start="2736" data-end="2754">Nsight Systems</strong></p>
</li>
<li data-start="2755" data-end="2790">
<p data-start="2757" data-end="2790"><strong data-start="2757" data-end="2769">单个内核性能优化</strong> → <strong data-start="2772" data-end="2790">Nsight Compute</strong></p>
</li>
<li data-start="2791" data-end="2828">
<p data-start="2793" data-end="2828"><strong data-start="2793" data-end="2808">找 bug（内存错误）</strong> → <strong data-start="2811" data-end="2828">cuda-memcheck</strong></p>
</li>
<li data-start="2829" data-end="2920">
<p data-start="2831" data-end="2848"><strong data-start="2831" data-end="2846">断点调试 GPU 代码</strong></p>
<ul data-start="2851" data-end="2920">
<li data-start="2851" data-end="2895">
<p data-start="2853" data-end="2895">Windows → <strong data-start="2863" data-end="2895">Nsight Visual Studio Edition</strong></p>
</li>
<li data-start="2898" data-end="2920">
<p data-start="2900" data-end="2920">Linux → <strong data-start="2908" data-end="2920">cuda-gdb</strong></p>
</li>
</ul>
</li>
</ul>
<h2>2.2&nbsp;Nsight Systems（系统级分析）</h2>
<p data-start="745" data-end="754"><strong data-start="745" data-end="751">用途</strong>：</p>
<ul data-start="755" data-end="833">
<li data-start="755" data-end="799">
<p data-start="757" data-end="799">查看 CPU 和 GPU 的交互，找出性能瓶颈（比如 GPU 等待 CPU 数据）。</p>
</li>
<li data-start="800" data-end="816">
<p data-start="802" data-end="816">分析多个内核之间的执行顺序。</p>
</li>
<li data-start="817" data-end="833">
<p data-start="819" data-end="833">检测数据传输和计算是否重叠。</p>
</li>
</ul>
<p data-start="835" data-end="842"><strong data-start="835" data-end="841">安装</strong>：</p>
<ul data-start="843" data-end="952">
<li data-start="843" data-end="876">
<p data-start="845" data-end="876">Windows 下随 <strong data-start="856" data-end="872">CUDA Toolkit</strong> 自带。</p>
</li>
<li data-start="877" data-end="952">
<p data-start="879" data-end="952">可在 <code data-start="882" data-end="934">C:\Program Files\NVIDIA Corporation\Nsight Systems</code> 找到 <code data-start="938" data-end="951">nsys-ui.exe</code>。</p>
</li>
</ul>
<p data-start="954" data-end="963"><strong data-start="954" data-end="962">使用步骤</strong>：</p>
<ol data-start="964" data-end="1084">
<li data-start="964" data-end="987">
<p data-start="967" data-end="987">启动 Nsight Systems UI</p>
</li>
<li data-start="988" data-end="1047">
<p data-start="991" data-end="1047">选择 <strong data-start="994" data-end="1005">Profile</strong> → <strong data-start="1008" data-end="1017">Local</strong> → 勾选 <code data-start="1023" data-end="1033">CUDA API</code>、<code data-start="1034" data-end="1047">CUDA Kernel</code></p>
</li>
<li data-start="1048" data-end="1063">
<p data-start="1051" data-end="1063">运行你的 CUDA 程序</p>
</li>
<li data-start="1064" data-end="1084">
<p data-start="1067" data-end="1084">查看时间线，分析 GPU 运行效率</p>
</li>
</ol>
<p data-start="1086" data-end="1096"><strong data-start="1086" data-end="1095">命令行示例</strong>：</p>
<div class="cnblogs_code">
<pre>nsys profile --trace=cuda,nvtx,osrt -o profile_report ./my_cuda_program</pre>
</div>
<p>生成.qdrep文件后，可用Nsight Systems打开。可以看出在Nsight System工具中给出kernel函数helloFromGPU的调用信息：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815145044518-853248184.png" alt="" width="990" height="579" style="display: block; margin-left: auto; margin-right: auto"></p>
<h2>2.3&nbsp;Nsight Compute（内核级分析）</h2>
<p data-start="1257" data-end="1266"><strong data-start="1257" data-end="1263">用途</strong>：</p>
<ul data-start="1267" data-end="1350">
<li data-start="1267" data-end="1290">
<p data-start="1269" data-end="1290">分析单个 CUDA kernel 的性能。</p>
</li>
<li data-start="1291" data-end="1329">
<p data-start="1293" data-end="1329">查看 <strong data-start="1296" data-end="1308">Warp 占用率</strong>、<strong data-start="1309" data-end="1319">SM 利用率</strong>、<strong data-start="1320" data-end="1328">内存带宽</strong>。</p>
</li>
<li data-start="1330" data-end="1350">
<p data-start="1332" data-end="1350">适合优化内核中的内存访问、分支效率。</p>
</li>
</ul>
<p data-start="1352" data-end="1359"><strong data-start="1352" data-end="1358">安装</strong>：</p>
<ul data-start="1360" data-end="1461">
<li data-start="1360" data-end="1389">
<p data-start="1362" data-end="1389">Windows 下随 CUDA Toolkit 安装。</p>
</li>
<li data-start="1390" data-end="1461">
<p data-start="1392" data-end="1461">路径一般在 <code data-start="1398" data-end="1461">C:\Program Files\NVIDIA Corporation\Nsight Compute\ncu-ui.exe</code></p>
</li>
</ul>
<p data-start="1463" data-end="1472"><strong data-start="1463" data-end="1471">使用步骤</strong>：</p>
<ol data-start="1473" data-end="1575">
<li data-start="1473" data-end="1493">
<p data-start="1476" data-end="1493">启动 Nsight Compute</p>
</li>
<li data-start="1494" data-end="1518">
<p data-start="1497" data-end="1518">在 “Launch” 里选择你的可执行程序</p>
</li>
<li data-start="1519" data-end="1535">
<p data-start="1522" data-end="1535">选择要分析的 kernel</p>
</li>
<li data-start="1536" data-end="1575">
<p data-start="1539" data-end="1575">查看报告（包括 Memory Throughput、Occupancy）</p>
</li>
</ol>
<p data-start="1577" data-end="1587"><strong data-start="1577" data-end="1586">命令行示例</strong>：</p>
<div class="cnblogs_code">
<pre>ncu --<span style="color: rgba(0, 0, 255, 1)">set</span> full ./hello</pre>
</div>
<p>Linux下运行解析结果如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815145044414-426918378.png" alt="" width="947" height="518" style="display: block; margin-left: auto; margin-right: auto"></p>
<p>接下来，在windows下使用图形界面Nsight Compute进行分析，运行程序前对程序进行少许改动，再增加一个用于矩阵乘法运算的kernel调用，源码如下：</p>
<div class="cnblogs_code"><img src="https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif" id="code_img_closed_cc2968dd-5692-4f75-8165-4dc8e62fb13e" class="code_img_closed"><img src="https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif" id="code_img_opened_cc2968dd-5692-4f75-8165-4dc8e62fb13e" class="code_img_opened" style="display: none">
<div id="cnblogs_code_open_cc2968dd-5692-4f75-8165-4dc8e62fb13e" class="cnblogs_code_hide">
<pre>#include&lt;stdio.h&gt;<span style="color: rgba(0, 0, 0, 1)">
#include </span>&lt;cuda.h&gt;<span style="color: rgba(0, 0, 0, 1)">
#include </span>&lt;cuda_profiler_api.h&gt;<span style="color: rgba(0, 0, 0, 1)">
#include </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cuda_runtime.h</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">
#include </span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">device_launch_parameters.h</span><span style="color: rgba(128, 0, 0, 1)">"</span>

<span style="color: rgba(0, 0, 255, 1)">using</span> <span style="color: rgba(0, 0, 255, 1)">namespace</span><span style="color: rgba(0, 0, 0, 1)"> std;

</span><span style="color: rgba(0, 0, 255, 1)">const</span> <span style="color: rgba(0, 0, 255, 1)">int</span> Row = <span style="color: rgba(128, 0, 128, 1)">512</span>; <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 行数</span>
<span style="color: rgba(0, 0, 255, 1)">const</span> <span style="color: rgba(0, 0, 255, 1)">int</span> Col = <span style="color: rgba(128, 0, 128, 1)">512</span>; <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 列数</span>
<span style="color: rgba(0, 0, 0, 1)">
__global__
</span><span style="color: rgba(0, 0, 255, 1)">void</span> matrix_mul_gpu(<span style="color: rgba(0, 0, 255, 1)">int</span>* M, <span style="color: rgba(0, 0, 255, 1)">int</span>* N, <span style="color: rgba(0, 0, 255, 1)">int</span>* P, <span style="color: rgba(0, 0, 255, 1)">int</span> width) <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> width代表列数</span>
<span style="color: rgba(0, 0, 0, 1)">{
    </span><span style="color: rgba(0, 0, 255, 1)">int</span> i = threadIdx.x + blockDim.x * blockIdx.x; <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 第i列的线程</span>
    <span style="color: rgba(0, 0, 255, 1)">int</span> j = threadIdx.y + blockDim.y * blockIdx.y; <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 第j行的线程</span>

    <span style="color: rgba(0, 0, 255, 1)">int</span> sum = <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">;
    </span><span style="color: rgba(0, 0, 255, 1)">for</span> (<span style="color: rgba(0, 0, 255, 1)">int</span> k = <span style="color: rgba(128, 0, 128, 1)">0</span>; k &lt; width; k++<span style="color: rgba(0, 0, 0, 1)">)
    {
        </span><span style="color: rgba(0, 0, 255, 1)">int</span> a = M[j * width + k]; <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 第j行的某一个值</span>
        <span style="color: rgba(0, 0, 255, 1)">int</span> b = N[k * width + i]; <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 第i列的某一个值</span>
        sum += a *<span style="color: rgba(0, 0, 0, 1)"> b;
    }
    P[j </span>* width + i] =<span style="color: rgba(0, 0, 0, 1)"> sum;
}

</span><span style="color: rgba(0, 0, 255, 1)">void</span> matrix_mul_cpu(<span style="color: rgba(0, 0, 255, 1)">int</span>* M, <span style="color: rgba(0, 0, 255, 1)">int</span>* N, <span style="color: rgba(0, 0, 255, 1)">int</span>* P, <span style="color: rgba(0, 0, 255, 1)">int</span><span style="color: rgba(0, 0, 0, 1)"> width)
{
    </span><span style="color: rgba(0, 0, 255, 1)">for</span> (<span style="color: rgba(0, 0, 255, 1)">int</span> i = <span style="color: rgba(128, 0, 128, 1)">0</span>; i &lt; width; i++<span style="color: rgba(0, 0, 0, 1)">)
        </span><span style="color: rgba(0, 0, 255, 1)">for</span> (<span style="color: rgba(0, 0, 255, 1)">int</span> j = <span style="color: rgba(128, 0, 128, 1)">0</span>; j &lt; width; j++<span style="color: rgba(0, 0, 0, 1)">)
        {
            </span><span style="color: rgba(0, 0, 255, 1)">int</span> sum = <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">;
            </span><span style="color: rgba(0, 0, 255, 1)">for</span> (<span style="color: rgba(0, 0, 255, 1)">int</span> k = <span style="color: rgba(128, 0, 128, 1)">0</span>; k &lt; width; k++<span style="color: rgba(0, 0, 0, 1)">)
            {
                </span><span style="color: rgba(0, 0, 255, 1)">int</span> a = M[i * width +<span style="color: rgba(0, 0, 0, 1)"> k];
                </span><span style="color: rgba(0, 0, 255, 1)">int</span> b = N[k * width +<span style="color: rgba(0, 0, 0, 1)"> j];
                sum </span>+= a *<span style="color: rgba(0, 0, 0, 1)"> b;
            }
            P[i </span>* width + j] =<span style="color: rgba(0, 0, 0, 1)"> sum;
        }
}

</span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">定义gpu 核函数</span>
__global__ <span style="color: rgba(0, 0, 255, 1)">void</span><span style="color: rgba(0, 0, 0, 1)"> helloFromGPU()
{
    </span><span style="color: rgba(0, 0, 255, 1)">int</span> blockIndex = (blockIdx.z * gridDim.y + blockIdx.y) * gridDim.x +<span style="color: rgba(0, 0, 0, 1)"> blockIdx.x;
    </span><span style="color: rgba(0, 0, 255, 1)">int</span> globalThreadIndex = blockIndex * blockDim.x * blockDim.y * blockDim.z +<span style="color: rgba(0, 0, 0, 1)">
        (threadIdx.z </span>* blockDim.y + threadIdx.y) * blockDim.x +<span style="color: rgba(0, 0, 0, 1)"> threadIdx.x;
    printf(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Hello World from block(%d %d %d) thread(%d %d %d) %d!\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, blockIdx.x, blockIdx.y, blockIdx.z,
        threadIdx.x, threadIdx.y, threadIdx.z, globalThreadIndex);
}
</span><span style="color: rgba(0, 0, 255, 1)">int</span><span style="color: rgba(0, 0, 0, 1)"> main()
{
    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">hello from cpu</span>
    printf(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Hello World CPU!\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">);
    dim3 number_of_blocks(</span><span style="color: rgba(128, 0, 128, 1)">2</span>, <span style="color: rgba(128, 0, 128, 1)">3</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">);
    dim3 threads_per_block(</span><span style="color: rgba(128, 0, 128, 1)">4</span>, <span style="color: rgba(128, 0, 128, 1)">8</span>, <span style="color: rgba(128, 0, 128, 1)">1</span><span style="color: rgba(0, 0, 0, 1)">);
    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">调用核函数</span>
    helloFromGPU &lt;&lt;&lt; number_of_blocks, threads_per_block &gt;&gt;&gt;<span style="color: rgba(0, 0, 0, 1)"> ();
    cudaDeviceReset();


    clock_t GPUstart, GPUend;
    </span><span style="color: rgba(0, 0, 255, 1)">int</span>* A = (<span style="color: rgba(0, 0, 255, 1)">int</span>*)<span style="color: rgba(0, 0, 255, 1)">malloc</span>(<span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    </span><span style="color: rgba(0, 0, 255, 1)">int</span>* B = (<span style="color: rgba(0, 0, 255, 1)">int</span>*)<span style="color: rgba(0, 0, 255, 1)">malloc</span>(<span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    </span><span style="color: rgba(0, 0, 255, 1)">int</span>* C = (<span style="color: rgba(0, 0, 255, 1)">int</span>*)<span style="color: rgba(0, 0, 255, 1)">malloc</span>(<span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">malloc device memory</span>
    <span style="color: rgba(0, 0, 255, 1)">int</span>* d_dataA, * d_dataB, *<span style="color: rgba(0, 0, 0, 1)"> d_dataC;
    cudaMalloc((</span><span style="color: rgba(0, 0, 255, 1)">void</span>**)&amp;d_dataA, <span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    cudaMalloc((</span><span style="color: rgba(0, 0, 255, 1)">void</span>**)&amp;d_dataB, <span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    cudaMalloc((</span><span style="color: rgba(0, 0, 255, 1)">void</span>**)&amp;d_dataC, <span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">set value</span>
    <span style="color: rgba(0, 0, 255, 1)">for</span> (<span style="color: rgba(0, 0, 255, 1)">int</span> i = <span style="color: rgba(128, 0, 128, 1)">0</span>; i &lt; Row * Col; i++<span style="color: rgba(0, 0, 0, 1)">) {
        A[i] </span>= <span style="color: rgba(128, 0, 128, 1)">90</span><span style="color: rgba(0, 0, 0, 1)">;
        B[i] </span>= <span style="color: rgba(128, 0, 128, 1)">10</span><span style="color: rgba(0, 0, 0, 1)">;
    }

    GPUstart </span>=<span style="color: rgba(0, 0, 0, 1)"> clock();
    cudaMemcpy(d_dataA, A, </span><span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col, cudaMemcpyHostToDevice);
    cudaMemcpy(d_dataB, B, </span><span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col, cudaMemcpyHostToDevice);
    dim3 threadPerBlock(</span><span style="color: rgba(128, 0, 128, 1)">16</span>, <span style="color: rgba(128, 0, 128, 1)">16</span><span style="color: rgba(0, 0, 0, 1)">);
    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> (Col + threadPerBlock.x - 1)/threadPerBlock.x=Col/threadPerBlock.x+1，即多拿一个block来装不能整除的部分</span>
    dim3 blockNumber((Col + threadPerBlock.x - <span style="color: rgba(128, 0, 128, 1)">1</span>) / threadPerBlock.x, (Row + threadPerBlock.y - <span style="color: rgba(128, 0, 128, 1)">1</span>) /<span style="color: rgba(0, 0, 0, 1)"> threadPerBlock.y);
    printf(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Block(%d,%d)   Grid(%d,%d).\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, threadPerBlock.x, threadPerBlock.y, blockNumber.x, blockNumber.y);
    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> 每一个线程进行某行乘某列的计算，得到结果中的一个元素。也就是d_dataC中的每一个计算结果都和GPU中线程的布局&lt;blockNumber, threadPerBlock &gt;一致</span>
    matrix_mul_gpu &lt;&lt; &lt;blockNumber, threadPerBlock &gt;&gt; &gt;<span style="color: rgba(0, 0, 0, 1)"> (d_dataA, d_dataB, d_dataC, Col);
    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">拷贝计算数据-一级数据指针</span>
    cudaMemcpy(C, d_dataC, <span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col, cudaMemcpyDeviceToHost);

    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">释放内存</span>
    <span style="color: rgba(0, 0, 255, 1)">free</span><span style="color: rgba(0, 0, 0, 1)">(A);
    </span><span style="color: rgba(0, 0, 255, 1)">free</span><span style="color: rgba(0, 0, 0, 1)">(B);
    </span><span style="color: rgba(0, 0, 255, 1)">free</span><span style="color: rgba(0, 0, 0, 1)">(C);
    cudaFree(d_dataA);
    cudaFree(d_dataB);
    cudaFree(d_dataC);

    GPUend </span>=<span style="color: rgba(0, 0, 0, 1)"> clock();
    </span><span style="color: rgba(0, 0, 255, 1)">int</span> GPUtime = GPUend -<span style="color: rgba(0, 0, 0, 1)"> GPUstart;
    printf(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">GPU运行时间：%d\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, GPUtime);

    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> CPU计算</span>
<span style="color: rgba(0, 0, 0, 1)">    clock_t CPUstart, CPUend;

    </span><span style="color: rgba(0, 0, 255, 1)">int</span>* A2 = (<span style="color: rgba(0, 0, 255, 1)">int</span>*)<span style="color: rgba(0, 0, 255, 1)">malloc</span>(<span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    </span><span style="color: rgba(0, 0, 255, 1)">int</span>* B2 = (<span style="color: rgba(0, 0, 255, 1)">int</span>*)<span style="color: rgba(0, 0, 255, 1)">malloc</span>(<span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);
    </span><span style="color: rgba(0, 0, 255, 1)">int</span>* C2 = (<span style="color: rgba(0, 0, 255, 1)">int</span>*)<span style="color: rgba(0, 0, 255, 1)">malloc</span>(<span style="color: rgba(0, 0, 255, 1)">sizeof</span>(<span style="color: rgba(0, 0, 255, 1)">int</span>) * Row *<span style="color: rgba(0, 0, 0, 1)"> Col);

    </span><span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">set value</span>
    <span style="color: rgba(0, 0, 255, 1)">for</span> (<span style="color: rgba(0, 0, 255, 1)">int</span> i = <span style="color: rgba(128, 0, 128, 1)">0</span>; i &lt; Row * Col; i++<span style="color: rgba(0, 0, 0, 1)">) {
        A2[i] </span>= <span style="color: rgba(128, 0, 128, 1)">90</span><span style="color: rgba(0, 0, 0, 1)">;
        B2[i] </span>= <span style="color: rgba(128, 0, 128, 1)">10</span><span style="color: rgba(0, 0, 0, 1)">;
    }

    CPUstart </span>=<span style="color: rgba(0, 0, 0, 1)"> clock();
    matrix_mul_cpu(A2, B2, C2, Col);
    CPUend </span>=<span style="color: rgba(0, 0, 0, 1)"> clock();
    </span><span style="color: rgba(0, 0, 255, 1)">int</span> CPUtime = CPUend -<span style="color: rgba(0, 0, 0, 1)"> CPUstart;
    printf(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">CPU运行时间：%d\n</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, CPUtime);
    printf(</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">加速比为：%lf\n</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(0, 0, 255, 1)">double</span>(CPUtime) /<span style="color: rgba(0, 0, 0, 1)"> GPUtime);


    </span><span style="color: rgba(0, 0, 255, 1)">return</span> <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">;
}</span></pre>
</div>
<span class="cnblogs_code_collapse">View Code</span></div>
<p>创建Nsight Compute工程，并指定可执行文件，以及分析结果文件：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815145044355-625441241.png" alt="" width="671" height="670" style="display: block; margin-left: auto; margin-right: auto"></p>
<p>之后直接“Launch”程序，由于程序比较简单稍后工具便给出结果，在Summary页中给出了两个核函数的名称、运行时间、Grid Size及Block Size等主要信息：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815145044291-1365148845.png" alt="" width="1109" height="181" style="display: block; margin-left: auto; margin-right: auto"></p>
<p>在Details页给出了更为详细的信息不再显示，在Source页给出了源码与动态运行对应关系：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815145044366-58083183.png" alt="" width="1132" height="425" style="display: block; margin-left: auto; margin-right: auto"></p>
<p>可以通过选择查看两个kernel函数各自的解析。</p>
<h2>2.4&nbsp;cuda-gdb（命令行断点调试）</h2>
<p data-start="1667" data-end="1676"><strong data-start="1667" data-end="1673">用途</strong>：</p>
<ul data-start="1677" data-end="1728">
<li data-start="1677" data-end="1697">
<p data-start="1679" data-end="1697">设置断点到 CUDA kernel。</p>
</li>
<li data-start="1698" data-end="1713">
<p data-start="1700" data-end="1713">查看 GPU 线程变量值。</p>
</li>
<li data-start="1714" data-end="1728">
<p data-start="1716" data-end="1728">单步调试 GPU 代码。</p>
</li>
</ul>
<p data-start="1730" data-end="1739"><strong data-start="1730" data-end="1736">限制</strong>：</p>
<ul data-start="1740" data-end="1798">
<li data-start="1740" data-end="1775">
<p data-start="1742" data-end="1775">仅 Linux 下可用（Windows 用 Nsight 代替）。</p>
</li>
<li data-start="1776" data-end="1798">
<p data-start="1778" data-end="1798">GPU 调试需要 <strong data-start="1787" data-end="1797">调试模式编译</strong>：</p>
</li>
</ul>
<div class="cnblogs_code">
<pre>nvcc -G -g hello.cu -o hellod</pre>
</div>
<p><strong data-start="1843" data-end="1849">示例（该示例调试调用的是未增加矩阵运算的原始代码）</strong>：</p>
<div class="cnblogs_code">
<pre>cuda-gdb ./<span style="color: rgba(0, 0, 0, 1)">hellod
(cuda</span>-gdb) break hello.cu:<span style="color: rgba(128, 0, 128, 1)">9</span><span style="color: rgba(0, 0, 0, 1)">
(cuda</span>-<span style="color: rgba(0, 0, 0, 1)">gdb) run
(cuda</span>-gdb) <span style="color: rgba(0, 0, 255, 1)">info</span><span style="color: rgba(0, 0, 0, 1)"> cuda threads
(cuda</span>-gdb) print blockIndex</pre>
</div>
<p>下图给出了调试过程主要内容：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815145044473-904201300.png" alt="" width="780" height="462" style="display: block; margin-left: auto; margin-right: auto"></p>
<h2>2.5&nbsp;Visual Studio Nsight集成</h2>
<p data-start="2459" data-end="2468"><strong data-start="2459" data-end="2465">用途</strong>：</p>
<ul data-start="2469" data-end="2525">
<li data-start="2469" data-end="2501">
<p data-start="2471" data-end="2501">Windows 下在 VS 里直接打断点调试 GPU 代码。</p>
</li>
<li data-start="2502" data-end="2525">
<p data-start="2504" data-end="2525">支持查看 GPU 线程局部变量、寄存器值。</p>
</li>
</ul>
<p data-start="2527" data-end="2534"><strong data-start="2527" data-end="2533">步骤</strong>：</p>
<ol data-start="2535" data-end="2686">
<li data-start="2535" data-end="2593">
<p data-start="2538" data-end="2593">安装 <strong data-start="2541" data-end="2573">Nsight Visual Studio Edition</strong>（随 CUDA Toolkit 提供）。</p>
</li>
<li data-start="2594" data-end="2641">
<p data-start="2597" data-end="2641">在 VS 菜单“扩展”里选择Nsight&nbsp;→ Start CUDA Debugging<code data-start="2619" data-end="2641"><br></code></p>


</li>
<li data-start="2642" data-end="2677">
<p data-start="2645" data-end="2677">在 CUDA 代码中打断点（__global__内也可以）</p>


</li>
<li data-start="2678" data-end="2686">
<p data-start="2681" data-end="2686">运行并调试</p>


</li>


</ol>
<p>下图直接运行到了第2个核函数中的断点处，此时可方便查看相关局部变量的值：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815145448349-131283067.png" alt="" width="981" height="727" style="display: block; margin-left: auto; margin-right: auto"></p>
<h2>2.6&nbsp;cuda-memcheck（compute-sanitizer）</h2>
<p data-start="2029" data-end="2038"><strong data-start="2029" data-end="2035">用途</strong>：</p>
<ul data-start="2039" data-end="2088">
<li data-start="2039" data-end="2062">
<p data-start="2041" data-end="2062">检查 GPU 内存错误（越界、未初始化）。</p>

</li>
<li data-start="2063" data-end="2088">
<p data-start="2065" data-end="2088">检测数据竞争（race condition）。</p>

</li>

</ul>
<p data-start="2090" data-end="2099"><strong data-start="2090" data-end="2098">命令示例</strong>：</p>
<div class="cnblogs_code">
<pre>cuda-memcheck ./hello</pre>
</div>
<p>从CUDA 11.2版本开始，cuda-memcheck已被compute-sanitizer替代，这是NVIDIA官方推荐的新一代CUDA内存和线程错误检测工具。因此，在较新的 CUDA 工具包中，默认不再包含cuda-memcheck，而是以compute-sanitizer提供更强大的功能。compute-sanitizer完全兼容cuda-memcheck的功能，且支持更多新特性。使用方法与 cuda-memcheck 类似：</p>
<div class="cnblogs_code">
<pre>compute-sanitizer --tool memcheck ./<span style="color: rgba(0, 0, 0, 1)">hello
compute</span>-sanitizer --tool racecheck ./hello</pre>
</div>
<p>由于程序比较简单没有内存及其他问题，运行后结果如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/465567/202508/465567-20250815150756985-1050101699.png" alt="image" width="667" height="100" loading="lazy" style="display: block; margin-left: auto; margin-right: auto"></p>
<p>&nbsp;</p>
<p>参考</p>
<p><a href="https://www.cnblogs.com/upyun/p/17824106.html" target="_blank">https://www.cnblogs.com/upyun/p/17824106.html</a></p>
<p><a href="https://blog.csdn.net/zhuikefeng/article/details/129989441" target="_blank" rel="noopener nofollow">https://blog.csdn.net/zhuikefeng/article/details/129989441</a></p>
<p><a href="https://blog.csdn.net/UCAS_HMM/article/details/126514127" target="_blank" rel="noopener nofollow">https://blog.csdn.net/UCAS_HMM/article/details/126514127</a></p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-15 15:24">2025-08-15 15:23</span>&nbsp;
<a href="https://www.cnblogs.com/zhaoweiwei">weiwei22844</a>&nbsp;
阅读(<span id="post_view_count">34</span>)&nbsp;
评论(<span id="post_comment_count">1</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19036381);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19036381', targetLink: 'https://www.cnblogs.com/zhaoweiwei/p/19036381/cuda1', title: 'CUDA编程初探' })">举报</a>
</div>
        