
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/ranjiang/p/18725581" title="发布于 2025-02-19 23:46">
    <span role="heading" aria-level="2">1 使用ollama完成DeepSeek本地部署</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="1-ollama">1 ollama</h1>
<h2 id="11-什么是ollama">1.1 什么是ollama</h2>
<p>ollama是一个开源的 LLM（大型语言模型）服务工具，用于简化在本地运行大语言模型，降低使用大语言模型的门槛，使得大模型的开发者、研究人员和爱好者能够在本地环境快速实验、管理和部署最新大语言模型。</p>
<h2 id="12-下载ollama">1.2 下载ollama</h2>
<p>（1）直接从ollama官网下载ollama：<a href="https://ollama.com/download" target="_blank" rel="noopener nofollow">https://ollama.com/download</a><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219225328830-1320898949.png" alt="image" loading="lazy"><br>
不推荐此方式，下载速度巨慢，直接从github上下载也有相同的问题。<br>
（2）网上推荐的通过github加速器下载github上的安装包，加速器地址：<a href="https://github.moeyy.xyz/" target="_blank" rel="noopener nofollow">https://github.moeyy.xyz/</a><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219225811263-1509901501.png" alt="image" loading="lazy"><br>
也不推荐，新版ollama安装包较大，无法下载，只能下载较老版本。<br>
（3）通过迅雷下载（推荐），ollama的发布版本地址：<a href="https://github.com/ollama/ollama/releases" target="_blank" rel="noopener nofollow">https://github.com/ollama/ollama/releases</a><br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219230238928-29102220.png" alt="image" loading="lazy"><br>
选择自己需要的安装包，右键，复制链接到迅雷内粘贴即可下载，我这里选择的是ollama-windows-amd64.zip可以免安装，也可以直接选择OllamaSetup.exe运行安装程序完成安装。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219230121804-571007561.png" alt="image" loading="lazy"></p>
<h2 id="13-安装并运行ollama">1.3 安装并运行ollama</h2>
<p>（1）解压ollama-windows-amd64.zip到自己的安装目录，如<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219230915337-2050679200.png" alt="image" loading="lazy"><br>
（2）添加ollama.exe路径到环境变量：<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219231503904-956863145.png" alt="image" loading="lazy"><br>
这样就可以在cmd中运行ollama了。<br>
（3）添加模型的下载路径，用于保存下载的模型文件。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219231723049-540774989.png" alt="image" loading="lazy"><br>
新建环境变量OLLAMA_MODELS，添加自己的存储路径，我的模型文件保存路径为：D:\software\AIModel\ollama-windows-amd64\ollamaModel\Models，要保证路径下无其他文件否则可能无效。不配置此路径或配置路径无效，模型将默认下载到C:\Users\WRJ.ollama\models目录下。<br>
（4）运行ollama<br>
使用快捷键Win+R打开运行，输入cmd运行命令行，输入<code>ollama serve</code>即可运行运行ollama。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219233200916-1986512633.png" alt="image" loading="lazy"></p>
<h1 id="2-部署deepseek模型">2 部署DeepSeek模型</h1>
<p>2.1 进入ollama官网，点击models或直接点击以下链接：<a href="https://ollama.com/search" target="_blank" rel="noopener nofollow">https://ollama.com/search</a><br>
首个就是deepseek模型，点击进入。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219233630636-1578847503.png" alt="image" loading="lazy"><br>
根据自己电脑的配置选择合适的模型，我电脑是AMD 9700X+RTX4070TI SUPER 16G，实测运行14B模型无压力，响应流畅，运行32B需要等待20-30s才可响应。选择好模型后复制命令<code>ollama run deepseek-r1:32b</code>,打开一个新的cmd窗口粘贴运行，等待下载完成即可直接使用了。<br>
<img src="https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219234340763-1475461097.png" alt="image" loading="lazy"></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.5217068266643519" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-19 23:47">2025-02-19 23:46</span>&nbsp;
<a href="https://www.cnblogs.com/ranjiang">wrj的博客</a>&nbsp;
阅读(<span id="post_view_count">338</span>)&nbsp;
评论(<span id="post_comment_count">1</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18725581" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18725581);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18725581', targetLink: 'https://www.cnblogs.com/ranjiang/p/18725581', title: '1 使用ollama完成DeepSeek本地部署' })">举报</a>
</div>
        