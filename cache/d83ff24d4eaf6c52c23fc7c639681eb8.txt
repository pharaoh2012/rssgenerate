
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/johnnyzen/p/18731725" title="发布于 2025-02-23 11:00">
    <span role="heading" aria-level="2">[Jaav SE/程序生命周期] 优雅的Java应用程序的启停钩子框架</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="序">序</h1>
<ul>
<li>
<p>了解 spring 生态及框架的 java er 都知道，spring 应用的生命周期管理及配套接口较为优雅、可扩展。</p>
</li>
<li>
<p>但脱离 spring 的 java 应用程序，如何优雅地启停、管理程序的生命周期呢？（以便应用程序在我们需要的运行阶段中进行相应的动作）</p>
</li>
</ul>
<h1 id="概述java普通应用程序的启停钩子框架">概述：Java普通应用程序的启停钩子框架</h1>
<h2 id="前置知识">前置知识</h2>
<h3 id="javalangfunctionalinterface注解"><code>java.lang.FunctionalInterface</code>注解</h3>
<ul>
<li>推荐文献</li>
</ul>
<blockquote>
<ul>
<li><a href="https://www.cnblogs.com/johnnyzen/p/18364444#_label3_0_2_3" target="_blank">java.lang.FunctionalInterface : 函数式接口(JDK8+) - [Java SE/JDK] Java 注解机制 - 博客园/千千寰宇</a></li>
</ul>
</blockquote>
<h1 id="java普通应用程序的启停钩子框架">Java普通应用程序的启停钩子框架</h1>
<h2 id="applicationstartuphook-抽象的启动钩子接口">ApplicationStartupHook: 抽象的启动钩子接口</h2>
<pre><code class="language-java">package org.example.app.hooks.startup;

@FunctionalInterface
public interface ApplicationStartupHook {
    /**
     * execute the task
     * @throws Exception
     */
    void execute() throws Exception;
}
</code></pre>
<h2 id="applicationstartuphookmanager--统一管理启动钩子">ApplicationStartupHookManager : 统一管理启动钩子</h2>
<pre><code class="language-java">package org.example.app.hooks.startup;

import java.util.ArrayList;
import java.util.List;

public class ApplicationStartupHookManager {
    private static final List&lt;ApplicationStartupHook&gt; hooks = new ArrayList&lt;&gt;();
    private static boolean executed = false;

    // 注册启动任务
    public static void registerHook(ApplicationStartupHook hook) {
        if (executed) {
            throw new IllegalStateException("Application startup hooks already executed");
        }
        hooks.add(hook);
    }

    // 执行所有启动任务
    public static void run() throws Exception {
        if (!executed) {
            for (ApplicationStartupHook hook : hooks) {
                hook.execute();
            }
            executed = true;
        }
    }
}
</code></pre>
<h2 id="applicationshutdownhook--关闭钩子">ApplicationShutdownHook : 关闭钩子</h2>
<pre><code class="language-java">package org.example.app.hooks.shutdown;

@FunctionalInterface
public interface ApplicationShutdownHook {
    /**
     * execute the task
     * @throws Exception
     */
    void execute() throws Exception;
}
</code></pre>
<h2 id="applicationshutdownhookmanager--统一管理关闭钩子">ApplicationShutdownHookManager : 统一管理关闭钩子</h2>
<pre><code class="language-java">package org.example.app.hooks.shutdown;

import lombok.Getter;
import org.example.app.hooks.startup.ApplicationStartupHook;

import java.util.ArrayList;
import java.util.List;

public class ApplicationShutdownHookManager {
    private static final List&lt;ApplicationShutdownHook&gt; hooks = new ArrayList&lt;&gt;();
    @Getter
    private static boolean executed = false;

    // 注册启动任务
    public static void registerHook(ApplicationShutdownHook hook) {
        if (executed) {
            throw new IllegalStateException("Application shutdown hooks already executed");
        }
        hooks.add(hook);
    }

    // 执行所有启动任务
    public static void run() throws Exception {
        if (!executed) {
            for (ApplicationShutdownHook hook : hooks) {
                hook.execute();
            }
            executed = true;
        }
    }
}
</code></pre>
<h2 id="demo应用--slf4j--log4j2--log4j2-kafkaappender--kafka">Demo应用 : Slf4j + Log4j2 + Log4j2 KafkaAppender + Kafka</h2>
<h3 id="maven-依赖">Maven 依赖</h3>
<pre><code class="language-xml">&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;parent&gt;
        &lt;groupId&gt;org.example&lt;/groupId&gt;
        &lt;artifactId&gt;demos-application-parent&lt;/artifactId&gt;
        &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;
        &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt;
    &lt;/parent&gt;

    &lt;artifactId&gt;log4j2-kafka-appender-demo-application&lt;/artifactId&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;bdp-diagnosticbox-model&lt;/name&gt;
    &lt;url&gt;http://maven.apache.org&lt;/url&gt;

    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;lombok.version&gt;1.18.22&lt;/lombok.version&gt;
        &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt;
        &lt;log4j.version&gt;2.20.0&lt;/log4j.version&gt;
        &lt;kafka-clients.version&gt;2.7.2&lt;/kafka-clients.version&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;${lombok.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- log --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
            &lt;version&gt;${slf4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;exclusions&gt;
                &lt;exclusion&gt;
                    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
                    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
                &lt;/exclusion&gt;
            &lt;/exclusions&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
            &lt;artifactId&gt;log4j-jul&lt;/artifactId&gt;
            &lt;!--&lt;version&gt;2.13.3&lt;/version&gt;--&gt;
            &lt;version&gt;${log4j.version}&lt;/version&gt;
            &lt;scope&gt;compile&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;!-- log [end] --&gt;

        &lt;!-- kafka client --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
            &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
            &lt;version&gt;${kafka-clients.version}&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
<h3 id="配置文件">配置文件</h3>
<ul>
<li><code>resource/log4j2.xml</code></li>
</ul>
<pre><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!--&lt;Configuration status="debug" name="demo-application" packages="org.example.app"&gt;--&gt;
&lt;Configuration status="off"&gt;
    &lt;!-- 自定义属性 --&gt;
    &lt;Properties&gt;
        &lt;!-- 应用程序名称 --&gt;
        &lt;Property name="application.name"&gt;bdp-xxx-app&lt;/Property&gt;
        &lt;!-- 应用程序实例的主机地址 --&gt;
        &lt;Property name="application.instance.host"&gt;${env:HOST_IP:-127.0.0.1}&lt;/Property&gt;
        &lt;!-- 应用程序实例的名称，默认值: localInstance --&gt;
        &lt;Property name="application.instance.name"&gt;${env:INSTANCE_NAME:-localInstance}&lt;/Property&gt;

        &lt;!-- 字符集 --&gt;
        &lt;Property name="log.encoding"&gt;UTF-8&lt;/Property&gt;
        &lt;!-- 日志等级，默认 INFO --&gt;
        &lt;Property name="log.level" value="${env:LOG_ACCESS:-INFO}" /&gt;
        &lt;!--&lt;Property name="log.access.level"&gt;${env:LOG_ACCESS:-INFO}&lt;/Property&gt;--&gt;
        &lt;!--&lt;Property name="log.operation.level"&gt;${env:LOG_OPERATE:-INFO}&lt;/Property&gt;--&gt;
        &lt;Property name="log.threshold"&gt;${log.level}&lt;/Property&gt;

        &lt;!-- org.apache.log4j.PatternLayout --&gt;
        &lt;!--&lt;Property name="log.layout" value="CustomPatternLayout"&gt;&lt;/Property&gt;--&gt;
        &lt;Property name="log.layout" value="PatternLayout"&gt;&lt;/Property&gt;

        &lt;!-- property.log.layout.consolePattern=%d{yyyy/MM/dd HH:mm:ss.SSS} %-5p | %T | %t | (%C{1}.java:%L %M) | %m%n --&gt;
        &lt;!-- [%d{yyyy/MM/dd HH:mm:ss.SSS}] [%traceId] [%-5p] [%t] [%C{1}.java:%L %M] %m%n --&gt;
        &lt;!-- [%d{yyyy/MM/dd HH:mm:ss.SSS}] [%X{traceId}] [%-5p] [%t] [%C{1}.java:%L %M] %m%n --&gt;
        &lt;!-- [%traceId] [${application.name}] [system] [%d{yyyy/MM/dd HH:mm:ss.SSS}] [%-5p] [%t] [%C{1}] %M:%L__|%X{traceId}|__%m%n --&gt;
        &lt;!-- [${application.name}] [${instance.name}] [${env:HOST_IP}] [${env:CONTAINER_IP}] [%d{yyyy/MM/dd HH:mm:ss.SSS}] [%p] [%t] [%l] %m%n --&gt;
        &lt;!-- ↓ sample: 2023-02-02 14:35:38,664 WARN  main (MonitorController.java:141 lambda$null$0) name: cn.seres.bd.dataservice.common.query, configLevel(Level):DEBUG, effectiveLevel: DEBUG --&gt;
        &lt;!-- %d %-5p %t (%C{1}.java:%L %M) %m%n --&gt;
        &lt;!-- [%d %r] [%-5p] [%t] [%l] [%m]%n --&gt;
        &lt;!-- %d{yyyy-MM-dd HH\:mm\:ss} %-5p[%t] : %m%n --&gt;
        &lt;!-- ↓ sample: 2025-02-21 15:24:27 INFO  | [2aa06a7b-a81f-469b-a0a0-679005bc35a3] | Log4jKafkaAppenderDemoEntry:36 - 这是一条信息日志 --&gt;
        &lt;!--%d{HH:mm:ss.SSS} %-5p [%-7t] %F:%L - %m%n --&gt;
        &lt;!--[%-4level] | %d{YYYY-MM-dd HH:mm:ss} | [%X{REQ_ID}] | %m| ${sys:java.home}%n--&gt;
        &lt;!-- %d{yyyy-MM-dd HH:mm:ss} %-5p | [%X{REQ_ID}] | %c{1}:%L - %m%n --&gt;
        &lt;!-- ${log.appender.kafka.producer.bootstrap.servers} | ${bundle:application:org.example.confgKey} | ${main:\\-logLevel} |  ${main:\\-\-log\.appender\.kafka\.producer\.bootstrap\.servers} | %c{1}:%L - %m%n --&gt;
        &lt;Property name="log.layout.consolePattern"&gt;
            [%d{yyyy/MM/dd HH:mm:ss.SSS}] [%X{traceId}] [%-5p] [%t] [%C{1}.java:%L %M] %m%n
        &lt;/Property&gt;
        &lt;Property name="log.layout.mainPattern" value="${log.layout.consolePattern}" /&gt;

        &lt;!-- KafkaAppender 的属性值 --&gt;
        &lt;!-- 方式1: 从环境变量获取 --&gt;
        &lt;!--&lt;Property name="log.appender.kafka.producer.bootstrap.servers" value="${env:KAFKA_PRODUCER_BOOTSTRAP_SERVERS:-127.0.0.1:9092}"/&gt;--&gt;
        &lt;!-- 方式2: 从 日志框架 MDC 中获取 --&gt;
        &lt;!--&lt;Property name="log.appender.kafka.producer.bootstrap.servers" value="%X{log.appender.kafka.producer.bootstrap.servers}"/&gt;--&gt;
        &lt;!-- 方式3: 从 应用程序的 main 方法启动入参中获取 --&gt;
        &lt;Property name="log.appender.kafka.producer.bootstrap.servers" value="${main:\\-\-log\.appender\.kafka\.producer\.bootstrap\.servers}"/&gt;

        &lt;!-- 目标 Appenders | 注: 属性值(如: ConsoleAppender)，对应的是 &lt;Appender&gt; 标签的 `name` 属性值 --&gt;
        &lt;!-- 1. 标准输出/控制台的 Appender --&gt;
        &lt;Property name="log.consoleAppender" value="MyConsoleAppender"/&gt;
        &lt;!-- 2. 文件输出 系统类日志的 Appender --&gt;
        &lt;Property name="log.systemFileAppender" value="MySystemFileAppender"/&gt;
        &lt;!-- 3. 文件输出 访问类日志的 Appender --&gt;
        &lt;!--&lt;Property name="log.accessFileAppender"&gt;MyAccessFileAppender&lt;/Property&gt;--&gt;
        &lt;!-- 4. 文件输出 操作类日志的 Appender --&gt;
        &lt;!--&lt;Property name="log.operationFileAppender"&gt;MyOperationFileAppender&lt;/Property&gt;--&gt;
        &lt;!-- 5. 文件输出 协议类日志的 Appender --&gt;
        &lt;!--&lt;Property name="log.protocolFileAppender"&gt;MyProtocolFileAppender&lt;/Property&gt;--&gt;
        &lt;!-- 6. 远程 链路追踪系统的 Appender --&gt;
        &lt;!--&lt;Property name="log.linkTraceClientTargetAppender"&gt;MySkyWalkingClientAppender&lt;/Property&gt;--&gt;
        &lt;!-- 7. 远程 KAFKA/ELK 的 Appender --&gt;
        &lt;Property name="log.loggingSystemMessageQueueAppender" value="MyKafkaAppender"/&gt;
    &lt;/Properties&gt;

    &lt;!-- 输出器 --&gt;
    &lt;Appenders&gt;
        &lt;Console name="MyConsoleAppender" target="SYSTEM_OUT"&gt;
            &lt;PatternLayout pattern="${log.layout.consolePattern}" /&gt;
            &lt;!-- com.platform.sp.framework.log.layout.CustomPatternLayout --&gt;
            &lt;!--&lt;CustomPatternLayout pattern="${log.layout.consolePattern}" /&gt;--&gt;
        &lt;/Console&gt;

        &lt;!--
            @warn
                1. 此 KafkaAppender 不建议在 生产环境 的 log4j2.xml/properties 中启用，因 无法从外部动态注入 kafka broker servers
                2. 针对第1点，需通过 自定义的 {@link org.example.app.hooks.startup.impl.Log4j2KafkaAppenderInitializer } ，实现程序启动时动态注册 KafkaAppender
            @Appender : KafkaAppender | org.apache.logging.log4j.core.appender.mom.kafka.KafkaAppender | log4j-core:2.20.0
            @note
                1. 计划在下一个主要版本中删除此附加程序！如果您正在使用此库，请使用官方支持渠道 与 Log4j 维护人员联系。
                    from https://logging.apache.org/log4j/2.x/manual/appenders/message-queue.html#KafkaAppender
                2. 使用 Kafka Appender 需要额外的运行时依赖项 : org.apache.kafka:kafka-clients:{version}
                    from https://logging.apache.org/log4j/2.x/manual/appenders/message-queue.html#KafkaAppender
                3. Kafka appender ignoreExceptions 必须设置为false，否则无法触发 FailOver Appender
                4. 确保不要让 `org.apache.kafka`Logger 日志记录的日志级别为 DEBUG，因为这将导致`KafkaAppender`递归日志记录
                    from https://logging.apache.org/log4j/2.x/manual/appenders/message-queue.html#KafkaAppender
            @property
                //配置属性
                * name: Log Framework's Appender 's Name
                * topic : Kafka Topic Name

                key:String : Kafka Message(`ProducerRecord`) 的 key。 支持 运行时属性替换，并在全局上下文 中进行评估。
                    参考: https://logging.apache.org/log4j/2.x/manual/appenders/message-queue.html#KafkaAppender
                    参考 : https://logging.apache.org/log4j/2.x/manual/lookups.html#global-context
                    推荐值: key="$${web:contextName}" | contextName 是 log4j2 内置的变量
                ignoreExceptions:boolean[DefaultValue:true] : 如果false，日志记录异常将被转发给日志记录语句的调用者。否则，它们将被忽略。
                syncSend:boolean[DefaultValue:true] : 如果true，附加器将阻塞，直到 Kafka 服务器确认该记录为止。否则，附加器将立即返回，从而实现更低的延迟和更高的吞吐量。

                //嵌套属性
                Filter
                Layout
                Property[0..n] : 这些属性会直接转发给 Kafka 生产者。 有关更多详细信息，请参阅 Kafka 生产者属性。
                    参考: https://kafka.apache.org/documentation.html#producerconfigs
                    bootstrap.servers : 此属性是必需的
                    key.serializer : 不应使用这些属性
                    value.serializer : 不应使用这些属性
        --&gt;
        &lt;Kafka name="MyKafkaAppender" topic="flink_monitor_log" key="$${web:contextName}" syncSend="true" ignoreExceptions="false"&gt;
            &lt;!--&lt;JsonTemplateLayout/&gt;--&gt;
            &lt;PatternLayout pattern="${log.layout.mainPattern}"/&gt;
            &lt;Property name="bootstrap.servers" value="${log.appender.kafka.producer.bootstrap.servers}"/&gt;
            &lt;Property name="max.block.ms"&gt;2000&lt;/Property&gt;
        &lt;/Kafka&gt;

        &lt;RollingFile name="MyFailoverKafkaLogAppender" fileName="../log/failover/request.log"
                     filePattern="../log/failover/request.%d{yyyy-MM-dd}.log"&gt;
            &lt;ThresholdFilter level="INFO" onMatch="ACCEPT" onMismatch="DENY"/&gt;
            &lt;PatternLayout&gt;
                &lt;Pattern&gt;${log.layout.mainPattern}&lt;/Pattern&gt;
            &lt;/PatternLayout&gt;
            &lt;Policies&gt;
                &lt;TimeBasedTriggeringPolicy /&gt;
            &lt;/Policies&gt;
        &lt;/RollingFile&gt;

&lt;!--
        &lt;Failover name="Failover" primary="kafkaLog" retryIntervalSeconds="600"&gt;
            &lt;Failovers&gt;
                &lt;AppenderRef ref="MyFailoverKafkaLogAppender"/&gt;
            &lt;/Failovers&gt;
        &lt;/Failover&gt;
--&gt;

        &lt;!--
            异步输出 | org.apache.logging.log4j.core.async.AsyncLoggerConfig
            1. AsyncAppender接受对其他Appender的引用，并使LogEvents在单独的Thread上写入它们。
            2. 默认情况下，AsyncAppender使用 java.util.concurrent.ArrayBlockingQueue ，它不需要任何外部库。
                请注意，多线程应用程序在使用此appender时应小心：阻塞队列容易受到锁争用的影响，并且我们的 测试 表明，当更多线程同时记录时性能可能会变差。
                考虑使用无锁异步记录器以获得最佳性能。
 --&gt;
&lt;!--        &lt;AsyncLogger name="kafkaAyncLogger" level="INFO" additivity="false"&gt;
            &lt;appender-ref ref="Failover"/&gt;
        &lt;/AsyncLogger&gt;--&gt;
    &lt;/Appenders&gt;

    &lt;!-- 日志器--&gt;
    &lt;Loggers&gt;
        &lt;!-- 定义 RootLogger 等 全局性配置(不可随意修改) --&gt;
        &lt;!-- rootLogger, 根记录器，所有记录器的父辈 | 指定根日志的级别 | All &lt; Trace &lt; Debug &lt; Info &lt; Warn &lt; Error &lt; Fatal &lt; OFF --&gt;
        &lt;Root level="${log.level}"&gt; &lt;!-- ${log.level} --&gt;
            &lt;!-- 2.17.2 版本以下通过这种方式将 root 和 Appender关联起来 / 2.17.2 版本以上有更简便的写法 --&gt;

            &lt;!-- rootLogger.appenderRef.stdout.ref=${log.consoleAppender} --&gt;
            &lt;AppenderRef ref="${log.consoleAppender}" level="INFO" /&gt;

            &lt;!-- rootLogger.appenderRef.kafka.ref=${log.loggingSystemMessageQueueAppender} --&gt;
&lt;!--            &lt;AppenderRef ref="${log.loggingSystemMessageQueueAppender}"/&gt; --&gt;&lt;!-- MyKafkaAppender --&gt;
        &lt;/Root&gt;

        &lt;!-- 指定个别 Class 的 Logger (可随意修改，建议在 nacos 上修改) --&gt;

        &lt;!-- KafkaAppender | org.apache.logging.log4j.core.appender.mom.kafka.KafkaAppender
            1. 确保不要让 org.apache.kafka Logger 的日志级别为 DEBUG，因为这将导致递归日志记录
            2. 请记住将配置 additivity 属性设置为false
         --&gt;
        &lt;Logger name="org.apache.kafka" level="WARN" additivity="false"&gt;
            &lt;AppenderRef ref="${log.consoleAppender}"/&gt;
        &lt;/Logger&gt;

    &lt;/Loggers&gt;
&lt;/Configuration&gt;
</code></pre>
<h3 id="log4j2kafkaappenderinitializer-implements-applicationstartuphook--负责实现具体的启动钩子">Log4j2KafkaAppenderInitializer implements ApplicationStartupHook : 负责实现具体的启动钩子</h3>
<pre><code class="language-java">package org.example.app.hooks.startup.impl;

import lombok.Getter;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.logging.log4j.Level;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.core.Appender;
import org.apache.logging.log4j.core.Filter;
import org.apache.logging.log4j.core.LoggerContext;
import org.apache.logging.log4j.core.appender.mom.kafka.KafkaAppender;
import org.apache.logging.log4j.core.config.Configuration;
import org.apache.logging.log4j.core.config.Property;
import org.apache.logging.log4j.core.layout.PatternLayout;
import org.example.app.constant.Constants;
import org.example.app.hooks.startup.ApplicationStartupHook;
import org.slf4j.MDC;

import java.nio.charset.Charset;
import java.util.Collections;
import java.util.Map;
import java.util.Optional;
import java.util.Properties;

/**
 * @description 基于 log4j2 日志框架，在程序启动时，根据程序的启动参数（kafka brokers地址）动态追加 KafkaAppender
 * @refrence-doc
 *  [1] Log4j2 配置日志记录发送到 kafka 中 - CSDN | https://blog.csdn.net/u010454030/article/details/132589450 【推荐】
 *  [2] 使用代码动态进行 Log4j2 的日志配置 - CSDN | https://blog.csdn.net/scruffybear/article/details/130230414 【推荐】
 *  [3] Apache Log4j2.x - Kafka Appender 【推荐】
 *      https://logging.apache.org/log4j/2.x/manual/appenders.html#KafkaAppender
 *      https://logging.apache.org/log4j/2.x/manual/appenders/message-queue.html#KafkaAppender
 *      {@link org.apache.logging.log4j.core.appender.mom.kafka.KafkaAppender }
 *  -----
 *  [4] Log4j2 - 动态生成Appender - 博客园 | https://www.cnblogs.com/yulinlewis/p/10217385.html
 *  [5] springboot动态添加log4j2的Appender - CSDN | https://blog.csdn.net/qq_25379811/article/details/127620062
 *  [6] log4j2.xml中动态读取配置 - CSDN | https://blog.csdn.net/xiaokanfuchen86/article/details/126695010 【推荐】
 *      https://logging.apache.org/log4j/2.x/manual/lookups.html#global-context 【推荐】
 * @gpt-promt
 */
@Slf4j
public class Log4j2KafkaAppenderInitializer implements ApplicationStartupHook {

    @Getter
    private Properties applicationProperties;

    public Log4j2KafkaAppenderInitializer(Properties applicationProperties) {
        this.applicationProperties = applicationProperties;
    }

    @Override
    public void execute() throws Exception {
        log.debug("Initializing {} ...", this.getClass().getCanonicalName());

        LoggerContext ctx = (LoggerContext) LogManager.getContext(false);
        Configuration config = ctx.getConfiguration();
        Appender kafkaAppender = createKafkaAppender(ctx, config, applicationProperties);
        kafkaAppender.start();//防止错误: Attempted to append to non-started appender testName

        Level level = getLevel(applicationProperties);
        config.getRootLogger().addAppender(kafkaAppender, level, null);// 添加 Appender 到配置中
        ctx.updateLoggers();

        log.debug("Initialized {} ...", this.getClass().getCanonicalName());
    }

    /**
     * @note
     *  1. required properties:
     *      1. {@link Constants.Log4j2KafkaAppender#LEVEL_PARAM}
     * @param applicationProperties
     * @return
     */
    private static Level getLevel(Properties applicationProperties) {
        Level level = null;
        String levelStr = applicationProperties == null ? Constants.Log4j2KafkaAppender.LEVEL_DEFAULT : applicationProperties.getProperty( Constants.Log4j2KafkaAppender.LEVEL_PARAM );
        levelStr = (levelStr == null || levelStr.equals("") ) ? Constants.Log4j2KafkaAppender.LEVEL_DEFAULT : levelStr.toUpperCase();
        level = Level.getLevel(levelStr);
        log.info("user config's `{}`'s log level: {}", KafkaAppender.class.getCanonicalName(), levelStr);
        return level;
    }

    /**
     * create a kafka appender base on log4j2 framework
     * @reference-doc
     *  1. https://logging.apache.org/log4j/2.x/manual/appenders/message-queue.html#KafkaAppender
     * @note
     *  1. required properties:
     *      1. {@link Constants.Log4j2KafkaAppender#KAFKA_PRODUCER_TOPIC_PARAM}
     *      2. {@link ProducerConfig#BOOTSTRAP_SERVERS_CONFIG }
     *  2. optional properties:
     *      {@link ProducerConfig } 's Config Properties
     * @return
     */
    private static Appender createKafkaAppender(LoggerContext loggerContext,Configuration configuration, Properties applicationProperties) {
        KafkaAppender kafkaAppender = null;
        if(loggerContext == null){
            loggerContext = (LoggerContext) LogManager.getContext(false);
        }
        if(configuration == null){
            configuration = loggerContext.getConfiguration();
        }

        final PatternLayout layout = PatternLayout.newBuilder()
                .withCharset(Charset.forName("UTF-8"))
                .withConfiguration(configuration)
                .withPattern("%d %p %c{1.} [%t] %m%n").build();

        Filter filter = null;

        String topic = applicationProperties.getProperty(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_TOPIC_PARAM);
        String appenderName = applicationProperties.getProperty(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_TOPIC_PARAM) + "Log4J2KafkaAppender";

        Property [] propertyArray = propertiesToPropertyArray(applicationProperties);

        String messageKey = applicationProperties.getProperty( Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_KEY_PARAM );
        Boolean isIgnoreExceptions = Boolean.getBoolean(applicationProperties.getProperty(Constants.Log4j2KafkaAppender.KAFKA_APPENDER_IGNORE_EXCEPTIONS_PARAM, Constants.Log4j2KafkaAppender.KAFKA_APPENDER_IGNORE_EXCEPTIONS_DEFAULT));
        Boolean syncSend = Boolean.getBoolean(applicationProperties.getProperty(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_SYNC_SEND_PARAM, Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_SYNC_SEND_DEFAULT));
        Boolean sendEventTimestamp = Boolean.getBoolean(applicationProperties.getProperty(Constants.Log4j2KafkaAppender.KAFKA_APPENDER_SEND_EVENT_TIMESTAMP_PARAM, Constants.Log4j2KafkaAppender.KAFKA_APPENDER_SEND_EVENT_TIMESTAMP_DEFAULT));

        //kafkaAppender = KafkaAppender.createAppender(layout, filter, appenderName, isIgnoreExceptions, topic, propertyArray, configuration, key );//此方式不支持传入 syncSend 参数
        //kafkaAppender = new KafkaAppender(name, layout, filter, isIgnoreExceptions, kafkaManager, getPropertyArray(), getRetryCount());//此方式，因构造器是 private，不支持

        kafkaAppender = KafkaAppender.newBuilder()//此方式 √
                .setName(appenderName)
                .setConfiguration(configuration)
                .setPropertyArray(propertyArray)
                .setFilter(filter)
                .setLayout(layout)
                .setIgnoreExceptions(isIgnoreExceptions)
                .setTopic(topic)
                .setKey(messageKey)
                .setSendEventTimestamp(sendEventTimestamp)
                .setSyncSend(syncSend)
                .setRetryCount(3)
                .build();

        return kafkaAppender; // 需要替换为实际的 Appender 创建代码
    }

    /**
     * Java Properties 转 Log4j2 的 Property []
     * @return
     */
    public static Property [] propertiesToPropertyArray(Properties properties){
        if(properties == null){
            return new Property[] {};
        }
        Property [] propertyArray = new Property[ properties.size() + 1];
        int i = 0;
        for(Map.Entry&lt;Object, Object&gt; entry : properties.entrySet() ) {
            Property property = Property.createProperty((String) entry.getKey(), (String) entry.getValue());
            propertyArray[i] = property;
            i++;
        }

        /**
         * 注入 org.apache.logging.log4j.core.appender.mom.kafka.KafkaAppender 所需的必填参数 {@link ProducerConfig.BOOTSTRAP_SERVERS_CONFIG}
         */
        String kafkaBrokerServers = properties.getProperty(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM);
        if(kafkaBrokerServers != null &amp;&amp; (!kafkaBrokerServers.trim().equals("")) ){
            propertyArray[i] = Property.createProperty( ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBrokerServers);
        } else {
            throw new RuntimeException(
                String.format("The Property `%s` must be not empty for `%s`!"
                    , Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM
                    , KafkaAppender.class.getCanonicalName()
                )
            );
        }
        return propertyArray;
    }
}
</code></pre>
<h3 id="slf4initializer-implements-applicationstartuphook--负责具体实现的启动钩子">Slf4Initializer implements ApplicationStartupHook : 负责具体实现的启动钩子</h3>
<pre><code class="language-java">package org.example.app.hooks.startup.impl;

import lombok.Getter;
import lombok.extern.slf4j.Slf4j;
import org.example.app.constant.Constants;
import org.example.app.hooks.startup.ApplicationStartupHook;
import org.slf4j.MDC;

import java.util.Optional;
import java.util.Properties;

@Slf4j
public class Slf4Initializer implements ApplicationStartupHook {
    @Getter
    private Properties applicationProperties;

    public Slf4Initializer(Properties applicationProperties) {
        this.applicationProperties = applicationProperties;
    }

    @Override
    public void execute() throws Exception {
        log.debug("Initializing {} ...", this.getClass().getCanonicalName());

        //设置 kafka 主机地址
        String kafkaProducerBootstrapServers = applicationProperties.getProperty(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM);
        kafkaProducerBootstrapServers = Optional.ofNullable(kafkaProducerBootstrapServers).&lt;RuntimeException&gt;orElseThrow(() -&gt; {
            throw new RuntimeException(String.format("`{}` must be not empty!", Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM));
        });
        MDC.put(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM, kafkaProducerBootstrapServers);
        log.info("MDC | {} : {}", Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM, MDC.get(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM) );

        log.debug("Initialized {} ...", this.getClass().getCanonicalName());
    }
}
</code></pre>
<h3 id="slf4finalizer-implements-applicationshutdownhook--负责具体实现的钩子">Slf4Finalizer implements ApplicationShutdownHook : 负责具体实现的钩子</h3>
<pre><code class="language-java">package org.example.app.hooks.shutdown.impl;

import lombok.Getter;
import lombok.extern.slf4j.Slf4j;
import org.example.app.constant.Constants;
import org.example.app.hooks.shutdown.ApplicationShutdownHook;
import org.slf4j.MDC;

import java.util.Properties;

@Slf4j
public class Slf4Finalizer implements ApplicationShutdownHook {
    @Getter
    private Properties applicationProperties;

    public Slf4Finalizer(Properties applicationProperties) {
        this.applicationProperties = applicationProperties;
    }

    @Override
    public void execute() throws Exception {
        log.debug("Finalizing {} ...", Slf4Finalizer.class.getCanonicalName());

        // 清理MDC
        log.info("clear MDC before | {} : {}", Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM, MDC.get(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM) );
        //MDC.clear();
        MDC.remove( Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM );//或仅清理需要的属性
        log.info("clear MDC after | {} : {}", Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM, MDC.get(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM) );

        log.debug("Finalized {} ...", Slf4Finalizer.class.getCanonicalName());
    }
}
</code></pre>
<h3 id="log4jkafkaappenderdemoentry">Log4jKafkaAppenderDemoEntry</h3>
<pre><code class="language-java">package org.example.app;

import org.apache.logging.log4j.core.layout.PatternLayout;
import org.example.app.constant.Constants;
import org.example.app.hooks.shutdown.ApplicationShutdownHookManager;
import org.example.app.hooks.shutdown.impl.Slf4Finalizer;
import org.example.app.hooks.startup.ApplicationStartupHookManager;
import org.example.app.hooks.startup.impl.Log4j2KafkaAppenderInitializer;
import org.example.app.hooks.startup.impl.Slf4Initializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;

public class Log4jKafkaAppenderDemoEntry {
    private static final Logger logger = LoggerFactory.getLogger(Log4jKafkaAppenderDemoEntry.class);

    private static final String APPLICATION_NAME = "Log4jKafkaAppenderDemoApplication";

    public static void main(String[] args) throws Exception {
        //从 nacos 等处动态获取配置 (此处可视为在模拟)
        Properties applicationProperties = new Properties();
        applicationProperties.put(Constants.Log4j2KafkaAppender.LEVEL_PARAM, "WARN");
        applicationProperties.put(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_BOOTSTRAP_SERVERS_PARAM, "127.0.0.1:9092");
        applicationProperties.put(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_TOPIC_PARAM, "flink_monitor_log");
        applicationProperties.put(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_KEY_PARAM, APPLICATION_NAME);
        applicationProperties.put(Constants.Log4j2KafkaAppender.KAFKA_PRODUCER_SYNC_SEND_PARAM, "true");
        applicationProperties.put(Constants.Log4j2KafkaAppender.KAFKA_APPENDER_IGNORE_EXCEPTIONS_PARAM, "false");

        enableLog4j2MainLookup(args);//可选步骤（非必须）

        runStartupHooks(applicationProperties);//运行启动钩子
        // 测试不同级别的日志
        logger.info("这是一条信息日志");
        logger.warn("这是一条警告日志");
        try {
            throw new RuntimeException("测试异常");
        } catch (Exception e) {
            logger.error("发生错误", e);
        }

        //关停钩子
        runShutdownHooks(applicationProperties);
    }

    public static void enableLog4j2MainLookup(String [] args){
        /**
         * 若 log4j2.[xml/properties/yaml] 中 Appender 的 pattern 欲以 `${main:\\-logLevel}` ，则需启用如下代码
         */
        try {
            Class.forName("org.apache.logging.log4j.core.lookup.MainMapLookup")
                    .getDeclaredMethod("setMainArguments", String[].class)
                    .invoke(null, (Object) args);
        } catch (final ReflectiveOperationException e) {
            // Log4j Core is not used.
        }
    }

    public static void runStartupHooks(Properties applicationProperties) throws Exception {
        ApplicationStartupHookManager.registerHook( new Slf4Initializer(applicationProperties) );
        ApplicationStartupHookManager.registerHook( new Log4j2KafkaAppenderInitializer(applicationProperties) );
        ApplicationStartupHookManager.run();
    }

    public static void runShutdownHooks(Properties applicationProperties) throws Exception {
        ApplicationShutdownHookManager.registerHook( new Slf4Finalizer(applicationProperties) );
        ApplicationShutdownHookManager.run();
    }
}
</code></pre>
<h1 id="框架的软件设计模式分析">框架的软件设计模式分析</h1>
<h2 id="策略模式strategy-pattern">策略模式（Strategy Pattern）</h2>
<ul>
<li>推荐文献</li>
</ul>
<blockquote>
<ul>
<li><a href="https://www.cnblogs.com/johnnyzen/p/7609425.html" target="_blank">设计模式之策略模式【5】 - 博客园/千千寰宇</a></li>
</ul>
</blockquote>
<p><img src="https://img2023.cnblogs.com/blog/1173617/202303/1173617-20230307200101403-1007645794.png" alt="策略模式" loading="lazy"></p>
<ul>
<li>
<p>策略模式允许在运行时选择算法或行为。<br>
在文档中，ApplicationStartupHook 和 ApplicationShutdownHook 接口定义了启动和关闭钩子的行为，而具体的实现类（如 Log4j2KafkaAppenderInitializer 和 Slf4Initializer）则提供了具体的策略。</p>
</li>
<li>
<p>这种模式允许在【运行时】动态选择和执行不同的钩子逻辑。</p>
</li>
</ul>
<blockquote>
<p>接口定义：</p>
</blockquote>
<pre><code class="language-java">public interface ApplicationStartupHook {
    void execute() throws Exception;
}
</code></pre>
<blockquote>
<p>具体实现：</p>
</blockquote>
<pre><code class="language-java">public class Log4j2KafkaAppenderInitializer implements ApplicationStartupHook {
    @Override
    public void execute() throws Exception {
        // 具体逻辑
    }
}
</code></pre>
<h2 id="单例模式singleton-pattern">单例模式（Singleton Pattern）</h2>
<ul>
<li>单例模式确保一个类只有一个实例，并提供一个全局访问点。</li>
</ul>
<blockquote>
<p>在文档中，ApplicationStartupHookManager 和 ApplicationShutdownHookManager 类使用了单例模式来管理启动和关闭钩子。<br>
这些管理器类维护了一个静态的钩子列表，并提供统一的注册和执行方法。</p>
</blockquote>
<ul>
<li>单例管理器类：</li>
</ul>
<pre><code class="language-java">public class ApplicationStartupHookManager {
    private static final List&lt;ApplicationStartupHook&gt; hooks = new ArrayList&lt;&gt;();
    private static boolean executed = false;

    public static void registerHook(ApplicationStartupHook hook) {
        if (executed) {
            throw new IllegalStateException("Application startup hooks already executed");
        }
        hooks.add(hook);
    }

    public static void run() throws Exception {
        if (!executed) {
            for (ApplicationStartupHook hook : hooks) {
                hook.execute();
            }
            executed = true;
        }
    }
}
</code></pre>
<h2 id="组合模式composite-pattern">组合模式（Composite Pattern）</h2>
<ul>
<li>组合模式允许将对象组合成树形结构，以表示“部分-整体”的层次结构。在文档中，ApplicationStartupHookManager 和 ApplicationShutdownHookManager 类管理了一个钩子列表，这些钩子可以被视为一个组合结构。</li>
</ul>
<blockquote>
<p>每个钩子可以独立执行，而管理器类则负责统一管理和执行这些钩子。</p>
</blockquote>
<ul>
<li>组合结构</li>
</ul>
<pre><code class="language-java">public class ApplicationStartupHookManager {
    private static final List&lt;ApplicationStartupHook&gt; hooks = new ArrayList&lt;&gt;();
    // ...
}
</code></pre>
<blockquote>
<p>这些模式共同实现了灵活、可扩展且优雅的启停钩子框架。</p>
</blockquote>
<h1 id="x-参考文献">X 参考文献</h1>
<ul>
<li>无</li>
</ul>

</div>
<div id="MySignature" role="contentinfo">
    <div class="essaySuffix-box">
    <div class="essaySuffix-box-left" style=" margin: 6px auto; ">
        <img src="https://blog-static.cnblogs.com/files/johnnyzen/cnblogs-qq-group-qrcode.gif?t=1679679148" alt="QQ沟通交流群" onload="changeImg(this,200,100)">
    </div>
<div class="essaySuffix-box-right">
    <span class="essaySuffix-right-title">本文作者</span>：
        <strong><span><a href="https://github.com/Johnny-ZTSD" target="_blank">千千寰宇</a></span></strong>
    <br>
    <span style="font-weight: bold; white-space:nowrap;">本文链接</span>：
        <a href="https://www.cnblogs.com/johnnyzen" target="_blank" id="articleLinkElement"> https://www.cnblogs.com/johnnyzen</a>
    <br>
    <span class="essaySuffix-right-title">关于博文</span>：评论和私信会在第一时间回复，或<a href="https://msg.cnblogs.com/msg/send/johnnyzen" target="_blank">直接私信</a>我。
    <br>
    <span class="essaySuffix-right-title">版权声明</span>：本博客所有文章除特别声明外，均采用 <a title="https://creativecommons.org/licenses/by-nc-nd/4.0/" href="http://blog.sina.com.cn/s/blog_896327b90102y6c6.html" alt="BY-NC-SA" target="_blank">BY-NC-SA</a> 
    许可协议。转载请注明出处！<br>
    <span class="essaySuffix-right-title">日常交流</span>：大数据与软件开发-QQ交流群: 774386015<strong>
        <span style="color: #ff0000; font-size: 12pt;">【<a id="post-up" onclick="votePost(getArticleNumber(),'Digg')" href="javascript:void(0);">入群二维码</a>】</span></strong>参见左下角。您的支持、鼓励<span style="color: #ff0000; font-size: 12pt;"></span>是博主技术写作的重要动力！
    <br>
</div>
<div style="clear: both;">
</div>
</div>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.03495207027083334" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-23 11:27">2025-02-23 11:00</span>&nbsp;
<a href="https://www.cnblogs.com/johnnyzen">千千寰宇</a>&nbsp;
阅读(<span id="post_view_count">3</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18731725" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18731725);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18731725', targetLink: 'https://www.cnblogs.com/johnnyzen/p/18731725', title: '[Jaav SE/程序生命周期] 优雅的Java应用程序的启停钩子框架' })">举报</a>
</div>
        