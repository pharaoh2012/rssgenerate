
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/dinosauria/p/19006174" title="发布于 2025-07-26 15:10">
    <span role="heading" aria-level="2">文生图模型攻击论文原理笔记</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="mma-diffusion">MMA-Diffusion</h1>
<h2 id="mma-diffusion-multimodal-attack-on-diffusion-models">MMA-Diffusion: MultiModal Attack on Diffusion Models</h2>
<p>这篇论文提出的<strong>MMA-Diffusion（多模态攻击框架）</strong> 旨在通过文本和图像双模态攻击，绕过文本到图像（T2I）模型的安全机制（如提示过滤器和后处理安全检查器），生成不当内容（NSFW）。</p>
<h3 id="一文本模态攻击对抗性提示生成的数学原理">一、文本模态攻击：对抗性提示生成的数学原理</h3>
<p>文本模态攻击的目标是生成<strong>对抗性提示（<span class="math inline">\(P_{adv}\)</span>）</strong>，使其不包含敏感词（避开提示过滤器），但语义上与目标不当提示（<span class="math inline">\(P_{tar}\)</span>）一致（引导模型生成预期内容）。其数学机制基于文本嵌入的语义相似性优化。</p>
<h4 id="1-核心目标语义对齐与敏感词规避">1. 核心目标：语义对齐与敏感词规避</h4>
<ul>
<li><strong>语义对齐</strong>：确保<span class="math inline">\(P_{adv}\)</span>与<span class="math inline">\(P_{tar}\)</span>的语义一致，即两者通过文本编码器生成的嵌入向量尽可能相似。</li>
<li><strong>敏感词规避</strong>：<span class="math inline">\(P_{adv}\)</span>中不包含任何敏感词（如“naked”“violence”等），避免被提示过滤器拦截。</li>
</ul>
<h4 id="2-语义相似性损失函数">2. 语义相似性损失函数</h4>
<p>文本编码器<span class="math inline">\(\tau_\theta(\cdot)\)</span>将文本提示映射为高维嵌入向量（如CLIP的文本嵌入）。为保证<span class="math inline">\(P_{adv}\)</span>与<span class="math inline">\(P_{tar}\)</span>的语义一致，定义<strong>余弦相似度最大化目标</strong>：</p>
<p></p><div class="math display">\[\max \cos\left(\tau_\theta(P_{tar}), \tau_\theta(P_{adv})\right) \tag{1}
\]</div><p></p><ul>
<li><span class="math inline">\(\tau_\theta(P)\)</span>：文本提示<span class="math inline">\(P\)</span>的嵌入向量；</li>
<li><span class="math inline">\(\cos(a, b) = \frac{a \cdot b}{||a|| \cdot ||b||}\)</span>：余弦相似度，值越大表示语义越接近。</li>
</ul>
<p>该目标确保<span class="math inline">\(P_{adv}\)</span>的嵌入向量与<span class="math inline">\(P_{tar}\)</span>的嵌入向量在语义空间中高度重合，从而引导T2I模型生成相似内容。</p>
<h4 id="3-梯度驱动的优化过程">3. 梯度驱动的优化过程</h4>
<p>由于文本是离散的（由 tokens 组成），直接优化式（1）需解决离散变量的梯度问题。MMA-Diffusion采用<strong>token 级梯度引导的贪心搜索</strong>：</p>
<ol>
<li>初始化<span class="math inline">\(P_{adv}\)</span>为随机 tokens 序列；</li>
<li>对每个 token 位置<span class="math inline">\(i\)</span>，计算所有候选 token（来自词汇表<span class="math inline">\(V\)</span>）对目标函数（式1）的梯度影响；</li>
<li>按梯度绝对值排序，选择Top-K tokens 替换当前位置，生成候选提示池；</li>
<li>从候选池中选择使式（1）值最大的提示作为新一轮<span class="math inline">\(P_{adv}\)</span>，迭代优化直至收敛。</li>
</ol>
<h4 id="4-敏感词正则化">4. 敏感词正则化</h4>
<p>为确保<span class="math inline">\(P_{adv}\)</span>不包含敏感词，对敏感词集中的 tokens 施加<strong>梯度惩罚</strong>：将敏感词的梯度设为<span class="math inline">\(-\infty\)</span>，使其在贪心搜索中被自动排除。这一机制数学上可表示为：</p>
<p></p><div class="math display">\[\text{if } token \in \text{敏感词集}, \quad \nabla_{token} \cos(\cdot) = -\infty \tag{2}
\]</div><p></p><p>通过压制敏感词的梯度，保证<span class="math inline">\(P_{adv}\)</span>仅由非敏感词组成，从而绕过提示过滤器。</p>
<h3 id="二图像模态攻击对抗性图像编辑">二、图像模态攻击：对抗性图像编辑</h3>
<p>图像模态攻击针对T2I模型的后处理安全检查器（如Stable Diffusion的内置安全检查器），通过对输入图像添加<strong>微小扰动</strong>，使生成的NSFW内容被误判为安全。其数学机制基于约束优化，最小化安全检查器对NSFW特征的敏感度。</p>
<h4 id="1-安全检查器的判定逻辑">1. 安全检查器的判定逻辑</h4>
<p>安全检查器通过对比生成图像的嵌入向量与预定义的NSFW概念嵌入（如“裸身”“暴力”的视觉特征）来判定是否为不当内容：</p>
<ul>
<li>设生成图像的嵌入向量为<span class="math inline">\(I\)</span>（由CLIP视觉编码器生成）；</li>
<li>预定义<span class="math inline">\(M\)</span>个NSFW概念嵌入<span class="math inline">\(C_1, C_2, ..., C_M\)</span>；</li>
<li>若存在<span class="math inline">\(i\)</span>使得<span class="math inline">\(\cos(I, C_i) &gt; T_i\)</span>（<span class="math inline">\(T_i\)</span>为阈值），则图像被标记为NSFW并拦截。</li>
</ul>
<h4 id="2-对抗性图像的优化目标">2. 对抗性图像的优化目标</h4>
<p>图像模态攻击的目标是生成<strong>对抗性输入图像<span class="math inline">\(x_{adv}\)</span></strong>，使得：</p>
<ol>
<li>扰动幅度微小：<span class="math inline">\(\|x_{input} - x_{adv}\|_2 \leq \varepsilon\)</span>（<span class="math inline">\(\varepsilon\)</span>为扰动预算，确保人眼不可察觉）；</li>
<li>生成图像的嵌入<span class="math inline">\(I\)</span>与所有<span class="math inline">\(C_i\)</span>的余弦相似度均不超过阈值<span class="math inline">\(T_i\)</span>，即绕过安全检查器。</li>
</ol>
<p>数学上定义<strong>损失函数</strong>为：</p>
<p></p><div class="math display">\[\min_{\|x_{input} - x_{adv}\|_2 \leq \varepsilon} \sum_{i=1}^M \mathbb{1}_{\{\cos(I, C_i) &gt; T_i\}} \cdot \cos(I, C_i) \tag{3}
\]</div><p></p><ul>
<li><span class="math inline">\(\mathbb{1}_{\{\cdot\}}\)</span>：指示函数，当条件为真时取1，否则取0；</li>
<li>该损失仅针对超过阈值的<span class="math inline">\(\cos(I, C_i)\)</span>进行优化，降低其值至阈值以下，同时忽略未超过阈值的项（减少不必要的扰动）。</li>
</ul>
<h4 id="3-投影梯度下降pgd求解">3. 投影梯度下降（PGD）求解</h4>
<p>式（3）是带约束的优化问题，采用<strong>投影梯度下降</strong>求解：</p>
<ol>
<li>初始化<span class="math inline">\(x_{adv} = x_{input}\)</span>；</li>
<li>迭代计算损失函数关于<span class="math inline">\(x_{adv}\)</span>的梯度：<span class="math inline">\(\nabla_{x_{adv}} L\)</span>；</li>
<li>沿梯度反方向更新<span class="math inline">\(x_{adv}\)</span>：<span class="math inline">\(x_{adv} \leftarrow x_{adv} - \alpha \cdot \text{sign}(\nabla_{x_{adv}} L)\)</span>（<span class="math inline">\(\alpha\)</span>为步长）；</li>
<li>投影到扰动约束内：<span class="math inline">\(x_{adv} \leftarrow \text{clamp}(x_{adv}, x_{input} - \varepsilon, x_{input} + \varepsilon)\)</span>；</li>
<li>重复步骤2-4直至收敛（通常20次迭代）。</li>
</ol>
<h3 id="三多模态攻击的协同机制">三、多模态攻击的协同机制</h3>
<p>当T2I模型同时部署提示过滤器和安全检查器时，MMA-Diffusion将文本模态与图像模态攻击结合：</p>
<ul>
<li>文本模态生成<span class="math inline">\(P_{adv}\)</span>绕过提示过滤器；</li>
<li>图像模态生成<span class="math inline">\(x_{adv}\)</span>绕过安全检查器；</li>
<li>两者协同使模型生成的内容既符合<span class="math inline">\(P_{tar}\)</span>的语义，又不被任何安全机制拦截。</li>
</ul>
<h3 id="总结">总结</h3>
<p>MMA-Diffusion的数学原理核心是：</p>
<ol>
<li><strong>文本模态</strong>：通过余弦相似度最大化和敏感词正则化，生成语义一致且无敏感词的对抗性提示；</li>
<li><strong>图像模态</strong>：通过带约束的梯度优化，生成微小扰动图像，降低安全检查器对】NSFW特征的敏感度。</li>
</ol>
<p>这两种机制分别针对T2I模型的输入和输出安全机制，实现了高效的多模态攻击，揭示了现有防御的脆弱性。</p>
<h1 id="prompting4debuggingp4d">Prompting4Debugging（P4D）</h1>
<h2 id="prompting4debugging-red-teaming-text-to-image-diffusion-models-by-finding-problematic-prompts">Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts</h2>
<p>这篇论文提出的<strong>Prompting4Debugging（P4D）</strong> 是一种自动化红队工具，旨在通过优化提示词（prompt）发现文本到图像（T2I）扩散模型安全机制的漏洞，使带有安全机制的模型生成不当内容（如NSFW图像）。其数学原理核心是通过匹配无约束模型与带安全机制模型的噪声预测，优化出能绕过安全机制的“问题提示词”，具体如下：</p>
<h3 id="一核心目标与数学框架">一、核心目标与数学框架</h3>
<p>P4D的目标是找到<strong>问题提示词<span class="math inline">\(P^*\)</span></strong>，使得：</p>
<ol>
<li>带安全机制的T2I模型<span class="math inline">\(G'\)</span>（如ESD、SLD）在<span class="math inline">\(P^*\)</span>引导下生成含不当概念的图像；</li>
<li><span class="math inline">\(P^*\)</span>需绕过<span class="math inline">\(G'\)</span>的安全机制（如概念移除、负提示过滤）。</li>
</ol>
<p>为实现这一目标，P4D利用无约束T2I模型<span class="math inline">\(G\)</span>（如原始Stable Diffusion）作为“参照”，通过优化使<span class="math inline">\(G'\)</span>在<span class="math inline">\(P^*\)</span>引导下的生成行为逼近<span class="math inline">\(G\)</span>在原始不当提示词<span class="math inline">\(P\)</span>引导下的行为。其数学框架基于扩散模型的噪声预测匹配。</p>
<h3 id="二扩散模型的噪声预测基础">二、扩散模型的噪声预测基础</h3>
<p>T2I扩散模型（如Stable Diffusion）通过逐步去噪生成图像，核心是在每个时间步<span class="math inline">\(t\)</span>预测添加到潜变量中的噪声。对于无约束模型<span class="math inline">\(G\)</span>和带安全机制的模型<span class="math inline">\(G'\)</span>，噪声预测函数分别为：</p>
<ul>
<li><span class="math inline">\(G\)</span>的噪声预测：<span class="math inline">\(\epsilon_\theta(z_t, W(P), t)\)</span>，其中<span class="math inline">\(z_t\)</span>是时间步<span class="math inline">\(t\)</span>的带噪声潜变量，<span class="math inline">\(W(P)\)</span>是提示词<span class="math inline">\(P\)</span>的文本嵌入（如CLIP编码），<span class="math inline">\(\theta\)</span>是<span class="math inline">\(G\)</span>的参数；</li>
<li><span class="math inline">\(G'\)</span>的噪声预测：<span class="math inline">\(\epsilon_{\theta'}(z_t, P_{\text{disc}}^*, t)\)</span>，其中<span class="math inline">\(\theta'\)</span>是<span class="math inline">\(G'\)</span>的参数，<span class="math inline">\(P_{\text{disc}}^*\)</span>是待优化的离散提示词。</li>
</ul>
<h3 id="三优化目标噪声预测匹配损失">三、优化目标：噪声预测匹配损失</h3>
<p>P4D的核心思想是：若<span class="math inline">\(G'\)</span>在<span class="math inline">\(P^*\)</span>引导下的噪声预测与<span class="math inline">\(G\)</span>在<span class="math inline">\(P\)</span>引导下的噪声预测足够接近，则两者生成的图像会包含相似的不当概念。因此，定义<strong>噪声预测匹配损失</strong>：</p>
<p></p><div class="math display">\[\mathcal{L} = \left\| \epsilon_\theta(z_t, W(P), t) - \epsilon_{\theta'}(z_t, P_{\text{disc}}^*, t) \right\|_2^2 \tag{1}
\]</div><p></p><ul>
<li>损失<span class="math inline">\(\mathcal{L}\)</span>衡量两个噪声预测的L2距离，值越小表示两者越接近；</li>
<li>优化目标是最小化<span class="math inline">\(\mathcal{L}\)</span>，使<span class="math inline">\(G'\)</span>在<span class="math inline">\(P_{\text{disc}}^*\)</span>引导下的去噪过程逼近<span class="math inline">\(G\)</span>在<span class="math inline">\(P\)</span>引导下的过程。</li>
</ul>
<h3 id="四连续提示词到离散提示词的优化">四、连续提示词到离散提示词的优化</h3>
<p>由于提示词是离散的（由词汇组成），直接优化离散变量困难。P4D采用“连续-离散”转换策略，平衡优化灵活性与提示词可解释性：</p>
<h4 id="1-连续提示词初始化">1. 连续提示词初始化</h4>
<p>定义连续提示词<span class="math inline">\(P_{\text{cont}}^* = [e_1, e_2, ..., e_N]\)</span>，其中<span class="math inline">\(e_i \in \mathbb{R}^d\)</span>是<span class="math inline">\(d\)</span>维连续嵌入向量（<span class="math inline">\(N\)</span>为提示词长度）。有两种初始化方式：</p>
<ul>
<li><strong>P4D-N</strong>：随机初始化<span class="math inline">\(N\)</span>个连续嵌入（与原始提示词<span class="math inline">\(P\)</span>无关）；</li>
<li><strong>P4D-K</strong>：在原始提示词嵌入<span class="math inline">\(W(P)\)</span>中，每<span class="math inline">\(K\)</span>个token后插入可学习的连续嵌入（保留<span class="math inline">\(P\)</span>的部分语义，提高可解释性）。</li>
</ul>
<h4 id="2-离散化投影">2. 离散化投影</h4>
<p>通过投影函数<span class="math inline">\(F\)</span>将连续提示词<span class="math inline">\(P_{\text{cont}}^*\)</span>转换为离散提示词<span class="math inline">\(P_{\text{disc}}^*\)</span>：</p>
<p></p><div class="math display">\[P_{\text{disc}}^* = F(P_{\text{cont}}^*) \tag{2}
\]</div><p></p><ul>
<li><span class="math inline">\(F\)</span>将每个连续嵌入<span class="math inline">\(e_i\)</span>映射到词汇表中最接近的词汇嵌入（通过余弦相似度匹配），确保<span class="math inline">\(P_{\text{disc}}^*\)</span>是可解析的自然语言提示词。</li>
</ul>
<h4 id="3-梯度下降优化">3. 梯度下降优化</h4>
<p>由于<span class="math inline">\(F\)</span>是非可微的（离散映射），P4D直接利用<span class="math inline">\(P_{\text{disc}}^*\)</span>对损失<span class="math inline">\(\mathcal{L}\)</span>的梯度更新<span class="math inline">\(P_{\text{cont}}^*\)</span>：</p>
<p></p><div class="math display">\[P_{\text{cont}}^* \leftarrow P_{\text{cont}}^* - \gamma \cdot \nabla_{P_{\text{disc}}^*} \mathcal{L} \tag{3}
\]</div><p></p><ul>
<li><span class="math inline">\(\gamma\)</span>是学习率；</li>
<li>迭代优化后，<span class="math inline">\(P_{\text{disc}}^*\)</span>即为最终的问题提示词，可引导<span class="math inline">\(G'\)</span>生成不当内容。</li>
</ul>
<h3 id="五变体设计p4d-n与p4d-k的数学差异">五、变体设计：P4D-N与P4D-K的数学差异</h3>
<table>
<thead>
<tr>
<th>变体</th>
<th>连续提示词结构</th>
<th>数学特点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>P4D-N</strong></td>
<td><span class="math inline">\(P_{\text{cont}}^* = [e_1, ..., e_N]\)</span>（<span class="math inline">\(N\)</span>固定）</td>
<td>与原始提示词<span class="math inline">\(P\)</span>无关，搜索空间更大但可能丢失<span class="math inline">\(P\)</span>的语义</td>
<td>简单场景，需完全重构提示词</td>
</tr>
<tr>
<td><strong>P4D-K</strong></td>
<td>在<span class="math inline">\(W(P)\)</span>中每<span class="math inline">\(K\)</span>个token插入可学习嵌入</td>
<td>保留<span class="math inline">\(P\)</span>的部分结构（<span class="math inline">\(W(P)\)</span>的固定部分），优化仅针对插入的嵌入，语义更连贯</td>
<td>复杂场景，需贴合原始提示词语义</td>
</tr>
</tbody>
</table>
<h3 id="六评估指标失败率fr">六、评估指标：失败率（FR）</h3>
<p>为量化P4D的有效性，定义<strong>失败率</strong>：</p>
<p></p><div class="math display">\[\text{FR} = \frac{\text{生成不当内容的问题提示词数量}}{\text{总提示词数量}} \times 100\% \tag{4}
\]</div><p></p><ul>
<li>若<span class="math inline">\(G'\)</span>在<span class="math inline">\(P^*\)</span>引导下生成的图像被分类器（如NudeNet、Q16）判定为含不当内容，则<span class="math inline">\(P^*\)</span>被视为“问题提示词”；</li>
<li>FR越高，说明P4D发现的漏洞越多，<span class="math inline">\(G'\)</span>的安全机制越脆弱。</li>
</ul>
<h1 id="ring-a-bell">Ring-A-Bell</h1>
<h2 id="ring-a-bell-how-reliable-are-concept-removal-methods-for-diffusion-models">RING-A-BELL! HOW RELIABLE ARE CONCEPT REMOVAL METHODS FOR DIFFUSION MODELS?</h2>
<p>这篇论文提出的<strong>Ring-A-Bell</strong>是一种模型无关的红队工具，旨在通过自动生成“问题提示词”（problematic prompts）评估文本到图像（T2I）扩散模型安全机制的可靠性，揭示其在生成不当内容（如NSFW图像、暴力内容）上的漏洞。其数学原理核心是通过<strong>概念提取</strong>和<strong>提示词优化</strong>，生成能绕过安全机制的提示词，具体如下：</p>
<h3 id="一核心目标与数学框架-1">一、核心目标与数学框架</h3>
<p>Ring-A-Bell的目标是：在不依赖目标模型内部信息的前提下，生成能诱导带安全机制的T2I模型（如ESD、SLD）生成不当内容的提示词。其数学框架基于文本嵌入的语义差异分析，通过提取敏感概念的“本质表示”，再将其注入正常提示词中，生成问题提示词。</p>
<h3 id="二概念提取敏感概念的本质表示">二、概念提取：敏感概念的本质表示</h3>
<p>为了捕捉敏感概念（如“nudity”“violence”）的核心语义，Ring-A-Bell通过对比“含概念”与“不含概念”的提示词对，提取概念的经验表示（empirical representation）。</p>
<h4 id="1-提示词对构建">1. 提示词对构建</h4>
<p>对于目标敏感概念<span class="math inline">\(c\)</span>（如“暴力”），构建<span class="math inline">\(N\)</span>对语义相似但仅在是否包含<span class="math inline">\(c\)</span>上有差异的提示词：</p>
<ul>
<li><span class="math inline">\(P_i^c\)</span>：包含概念<span class="math inline">\(c\)</span>的提示词（如“a clashed battle scene”）；</li>
<li><span class="math inline">\(P_i^{\neg c}\)</span>：不含概念<span class="math inline">\(c\)</span>的提示词（如“a peaceful meeting scene”）。</li>
</ul>
<h4 id="2-概念表示的数学定义">2. 概念表示的数学定义</h4>
<p>利用文本编码器<span class="math inline">\(f(\cdot)\)</span>（如CLIP的文本编码器）将提示词转换为高维嵌入向量，通过计算嵌入差异的平均值，得到概念<span class="math inline">\(c\)</span>的经验表示<span class="math inline">\(\hat{c}\)</span>：</p>
<p></p><div class="math display">\[\hat{c} := \frac{1}{N} \sum_{i=1}^N \left\{ f(P_i^c) - f(P_i^{\neg c}) \right\} \tag{1}
\]</div><p></p><ul>
<li><span class="math inline">\(f(P)\)</span>：提示词<span class="math inline">\(P\)</span>的文本嵌入向量；</li>
<li>直观意义：<span class="math inline">\(\hat{c}\)</span>捕捉了“含概念<span class="math inline">\(c\)</span>”与“不含概念<span class="math inline">\(c\)</span>”的语义差异，即概念<span class="math inline">\(c\)</span>的本质特征（如“暴力”与“和平”的差异）。</li>
</ul>
<h3 id="三提示词优化生成问题提示词">三、提示词优化：生成问题提示词</h3>
<p>基于提取的概念表示<span class="math inline">\(\hat{c}\)</span>，将正常提示词<span class="math inline">\(P\)</span>转换为能绕过安全机制的问题提示词<span class="math inline">\(\hat{P}\)</span>，分为“软提示生成”和“离散化优化”两步。</p>
<h4 id="1-软提示生成">1. 软提示生成</h4>
<p>将正常提示词<span class="math inline">\(P\)</span>的嵌入与概念表示<span class="math inline">\(\hat{c}\)</span>融合，生成“软提示”（连续嵌入）：</p>
<p></p><div class="math display">\[\tilde{P}_{\text{cont}} := f(P) + \eta \cdot \hat{c} \tag{2}
\]</div><p></p><ul>
<li><span class="math inline">\(\eta\)</span>：强度系数（控制概念<span class="math inline">\(c\)</span>的注入强度，<span class="math inline">\(\eta\)</span>越大，提示词越倾向于诱导生成含<span class="math inline">\(c\)</span>的内容）；</li>
<li>作用：将正常提示词的语义与敏感概念<span class="math inline">\(c\)</span>的本质特征结合，形成潜在的问题提示词嵌入。</li>
</ul>
<h4 id="2-离散化优化">2. 离散化优化</h4>
<p>由于T2I模型输入需为离散文本（词汇序列），需将软提示<span class="math inline">\(\tilde{P}_{\text{cont}}\)</span>转换为离散提示词<span class="math inline">\(\hat{P}\)</span>。数学上定义优化目标为：</p>
<p></p><div class="math display">\[\min_{\hat{P}} \left\| f(\hat{P}) - \tilde{P}_{\text{cont}} \right\|^2 \quad \text{subject to } \hat{P} \in S^K \tag{3}
\]</div><p></p><ul>
<li><span class="math inline">\(S\)</span>：词汇表（所有可能的token集合）；</li>
<li><span class="math inline">\(K\)</span>：提示词长度（通常≤77，受限于文本编码器的最大长度）；</li>
<li>目标：找到离散词汇序列<span class="math inline">\(\hat{P}\)</span>，使其嵌入尽可能接近软提示<span class="math inline">\(\tilde{P}_{\text{cont}}\)</span>，从而保留“诱导生成敏感内容”的能力。</li>
</ul>
<h4 id="3-优化方法遗传算法">3. 优化方法：遗传算法</h4>
<p>由于词汇表<span class="math inline">\(S\)</span>是高维离散空间，直接优化式（3）困难。Ring-A-Bell采用<strong>遗传算法（GA）</strong> 进行搜索：</p>
<ol>
<li>初始化：随机生成200个长度为<span class="math inline">\(K\)</span>的候选提示词；</li>
<li>选择与交叉：保留嵌入接近<span class="math inline">\(\tilde{P}_{\text{cont}}\)</span>的候选词，通过交叉组合生成新候选词；</li>
<li>变异：随机替换部分token，增加多样性；</li>
<li>迭代：重复3000代，最终选择嵌入最接近<span class="math inline">\(\tilde{P}_{\text{cont}}\)</span>的提示词作为<span class="math inline">\(\hat{P}\)</span>。</li>
</ol>
<h3 id="四模型特定评估的数学推导辅助分析">四、模型特定评估的数学推导（辅助分析）</h3>
<p>为验证思路，论文还推导了模型特定场景下的攻击损失（假设已知目标模型结构），通过最小化带安全机制的模型与无约束模型的噪声预测差异，揭示安全机制的漏洞。</p>
<h4 id="1-噪声预测匹配损失">1. 噪声预测匹配损失</h4>
<p>对于无约束模型<span class="math inline">\(\epsilon_\theta(\cdot)\)</span>和带安全机制的模型<span class="math inline">\(\epsilon_{\theta'}(\cdot)\)</span>，定义损失<span class="math inline">\(L_{\text{white}}\)</span>：</p>
<p></p><div class="math display">\[L_{\text{white}} = \sum_{\hat{t}=1}^T \mathbb{E}_{z_{\hat{t}} \sim P_{\epsilon_\theta}(z_{\hat{t}} | c)} \left[ \left\| \rho\left( \epsilon_\theta(z_{\hat{t}}, c, \hat{t}) - \epsilon_{\theta'}(z_{\hat{t}}, \tilde{c}, \hat{t}) \right) \right\|^2 \right] \tag{4}
\]</div><p></p><ul>
<li><span class="math inline">\(z_{\hat{t}}\)</span>：时间步<span class="math inline">\(\hat{t}\)</span>的带噪声潜变量；</li>
<li><span class="math inline">\(\rho\)</span>：权重函数（强调关键时间步的差异）；</li>
<li>目标：通过优化对抗概念<span class="math inline">\(\tilde{c}\)</span>，使两个模型的噪声预测尽可能接近，从而诱导带安全机制的模型生成与无约束模型相似的不当内容。</li>
</ul>
<h3 id="五评估指标攻击成功率asr">五、评估指标：攻击成功率（ASR）</h3>
<p>为量化效果，定义<strong>攻击成功率</strong>：</p>
<p></p><div class="math display">\[\text{ASR} = \frac{\text{生成不当内容的问题提示词数量}}{\text{总提示词数量}} \times 100\% \tag{5}
\]</div><p></p><ul>
<li>若<span class="math inline">\(\hat{P}\)</span>诱导带安全机制的模型生成被分类器（如NudeNet、Q16）判定为不当的内容，则视为“成功攻击”；</li>
<li>ASR越高，说明安全机制的漏洞越明显。</li>
</ul>
<h1 id="unlearndiffatk">UnlearnDiffAtk</h1>
<h2 id="to-generate-or-not-safety-driven-unlearned-diffusion-models-are-still-easy-to-generate-unsafe-images--for-now">To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images ... For Now</h2>
<p>这篇论文提出的<strong>UnlearnDiffAtk</strong>是一种针对经过“安全驱动遗忘处理”（unlearning）的扩散模型（DMs）的对抗性提示生成方法，旨在评估这些模型是否仍会生成不安全内容（如NSFW图像）。其数学原理核心是利用扩散模型自身的噪声预测能力和分类特性，将对抗性提示生成转化为可优化的数学问题，无需依赖辅助模型，具体如下：</p>
<h3 id="一扩散模型的基础噪声预测与训练目标">一、扩散模型的基础：噪声预测与训练目标</h3>
<p>扩散模型（如Stable Diffusion）的核心是通过逐步去噪生成图像，其训练目标是最小化预测噪声与真实噪声的差异。对于潜在扩散模型（LDMs），训练损失为：</p>
<p></p><div class="math display">\[\min_{\theta} \mathbb{E}_{(x, c) \sim \mathcal{D}, t, \epsilon \sim \mathcal{N}(0,1)} \left[ \left\| \epsilon - \epsilon_{\theta}(z_t | c) \right\|_2^2 \right] \tag{1}
\]</div><p></p><ul>
<li><span class="math inline">\(x\)</span>：真实图像；<span class="math inline">\(c\)</span>：文本提示；<span class="math inline">\(z_t\)</span>：时间步<span class="math inline">\(t\)</span>的带噪声潜变量；</li>
<li><span class="math inline">\(\epsilon\)</span>：真实高斯噪声；<span class="math inline">\(\epsilon_{\theta}(z_t | c)\)</span>：模型预测的噪声；</li>
<li>目标：使模型学会根据文本提示<span class="math inline">\(c\)</span>和带噪声潜变量<span class="math inline">\(z_t\)</span>，准确预测添加的噪声<span class="math inline">\(\epsilon\)</span>。</li>
</ul>
<h3 id="二核心创新扩散分类器diffusion-classifier">二、核心创新：扩散分类器（Diffusion Classifier）</h3>
<p>UnlearnDiffAtk的关键 insight 是：扩散模型不仅能生成图像，还能通过噪声预测误差实现分类（即“扩散分类器”）。这一特性允许我们无需辅助模型，直接利用目标模型自身的能力生成对抗性提示。</p>
<h4 id="1-从生成到分类的转化">1. 从生成到分类的转化</h4>
<p>根据贝叶斯规则，扩散模型对文本提示<span class="math inline">\(c_i\)</span>的分类概率可表示为：</p>
<p></p><div class="math display">\[p_{\theta}(c_i | x) \propto \frac{p(c_i) \cdot p_{\theta}(x | c_i)}{\sum_j p(c_j) \cdot p_{\theta}(x | c_j)} \tag{2}
\]</div><p></p><ul>
<li><span class="math inline">\(p_{\theta}(x | c_i)\)</span>：模型在提示<span class="math inline">\(c_i\)</span>下生成图像<span class="math inline">\(x\)</span>的概率；</li>
<li>若假设先验概率<span class="math inline">\(p(c_i)\)</span>均匀（即<span class="math inline">\(p(c_i) = p(c_j)\)</span>），则分类概率仅取决于生成概率<span class="math inline">\(p_{\theta}(x | c_i)\)</span>。</li>
</ul>
<h4 id="2-生成概率与噪声预测误差的关系">2. 生成概率与噪声预测误差的关系</h4>
<p><span class="math inline">\(p_{\theta}(x | c_i)\)</span> 与噪声预测误差直接相关：模型对提示 <span class="math inline">\(c_i\)</span> 的噪声预测越准确（误差越小），生成对应图像 <span class="math inline">\(x\)</span> 的概率越高。数学上可表示为：</p>
<p></p><div class="math display">\[p_{\theta}(x | c_i) \propto \exp\left\{-\mathbb{E}_{t, \epsilon} \left[ \left\| \epsilon - \epsilon_{\theta}(x_t | c_i) \right\|_2^2 \right] \right\} \tag{3}
\]</div><p></p><p>其中，<span class="math inline">\(x_t\)</span> 是目标图像 <span class="math inline">\(x\)</span> 在时间步 <span class="math inline">\(t\)</span> 的带噪声版本，<span class="math inline">\(\mathbb{E}_{t, \epsilon}[\cdot]\)</span> 表示对时间步和噪声的期望。</p>
<p>结合式（2）和（3），扩散分类器对提示 <span class="math inline">\(c_i\)</span> 的分类概率可改写为：</p>
<p></p><div class="math display">\[p_{\theta}(c_i | x) \propto \frac{\exp\left\{-\mathbb{E}_{t, \epsilon} \left[ \left\| \epsilon - \epsilon_{\theta}(x_t | c_i) \right\|_2^2 \right] \right\}}{\sum_j \exp\left\{-\mathbb{E}_{t, \epsilon} \left[ \left\| \epsilon - \epsilon_{\theta}(x_t | c_j) \right\|_2^2 \right] \right\}} \tag{4}
\]</div><p></p><p>这表明，扩散模型可通过比较不同提示的噪声预测误差，实现对图像类别的分类。</p>
<h3 id="三对抗性提示生成的数学目标">三、对抗性提示生成的数学目标</h3>
<p>UnlearnDiffAtk 的目标是生成对抗性提示 <span class="math inline">\(c'\)</span>，使经过安全遗忘处理的模型 <span class="math inline">\(\theta^*\)</span>（本应避免生成被遗忘概念）在 <span class="math inline">\(c'\)</span> 引导下，生成包含被遗忘概念的图像。这一目标通过扩散分类器转化为可优化的数学问题。</p>
<h4 id="1-核心优化目标">1. 核心优化目标</h4>
<p>对于包含被遗忘概念的目标图像 <span class="math inline">\(x_{tgt}\)</span>，需最大化扩散分类器对对抗性提示 <span class="math inline">\(c'\)</span> 的概率：</p>
<p></p><div class="math display">\[\max_{c'} p_{\theta^*}(c' | x_{tgt}) \tag{5}
\]</div><p></p><p>即让模型 <span class="math inline">\(\theta^*\)</span> 认为，对抗性提示 <span class="math inline">\(c'\)</span> 与目标图像 <span class="math inline">\(x_{tgt}\)</span> 的匹配度最高。</p>
<h4 id="2-目标简化与推导">2. 目标简化与推导</h4>
<p>直接优化式（5）需计算所有可能提示的噪声误差，计算成本极高。利用扩散分类器中“分类仅依赖噪声误差的相对差异”这一特性，可简化目标：</p>
<ul>
<li>首先，将式（4）中分子分母的指数项转化为相对误差形式；</li>
<li>利用 Jensen 不等式对指数函数的凸性进行上界估计，剔除与 <span class="math inline">\(c'\)</span> 无关的项；</li>
<li>最终，优化目标简化为<strong>最小化对抗性提示 <span class="math inline">\(c'\)</span> 对目标图像带噪声版本 <span class="math inline">\(x_{tgt, t}\)</span> 的噪声预测误差</strong>：<p></p><div class="math display">\[\min_{c'} \mathbb{E}_{t, \epsilon} \left[ \left\| \epsilon - \epsilon_{\theta^*}(x_{tgt, t} | c') \right\|_2^2 \right] \tag{6}
\]</div><p></p>其中，<span class="math inline">\(x_{tgt, t}\)</span> 是目标图像 <span class="math inline">\(x_{tgt}\)</span> 在时间步 <span class="math inline">\(t\)</span> 加入噪声后的版本。</li>
</ul>
<h3 id="四离散提示的优化方法">四、离散提示的优化方法</h3>
<p>由于提示词是离散的（由词汇组成），需采用<strong>投影梯度下降（PGD）</strong> 在离散空间中优化：</p>
<ol>
<li><strong>初始化</strong>：随机生成包含 3~5 个 token 的候选提示（长度根据任务调整）；</li>
<li><strong>梯度计算</strong>：计算当前提示的噪声预测误差（式6）关于 token 嵌入的梯度；</li>
<li><strong>更新与投影</strong>：沿梯度反方向更新 token 嵌入，再将连续嵌入投影到词汇表中最相似的离散 token（确保提示词为自然语言）；</li>
<li><strong>迭代</strong>：重复 40 次迭代，直至误差收敛。</li>
</ol>
<h3 id="总结-1">总结</h3>
<p>UnlearnDiffAtk 的数学原理核心是：<strong>利用扩散模型自身的分类能力（扩散分类器），将对抗性提示生成转化为噪声预测误差的最小化问题</strong>。通过简化优化目标并采用离散 PGD 方法，在不依赖辅助模型的情况下，高效生成能绕过安全遗忘机制的对抗性提示，揭示了当前安全驱动遗忘扩散模型的脆弱性。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.004861111111111111" data-date-updated="2025-07-26 15:17">2025-07-26 15:10</span>&nbsp;
<a href="https://www.cnblogs.com/dinosauria">永是珞珈一恐龙</a>&nbsp;
阅读(<span id="post_view_count">87</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19006174);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19006174', targetLink: 'https://www.cnblogs.com/dinosauria/p/19006174', title: '文生图模型攻击论文原理笔记' })">举报</a>
</div>
        