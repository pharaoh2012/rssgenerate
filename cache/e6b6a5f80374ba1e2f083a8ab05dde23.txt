
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xiaozhi_5638/p/19038858" title="发布于 2025-08-15 07:57">
    <span role="heading" aria-level="2">VideoPipe中集成多模态大模型做视频（图片）分析</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<p><a href="http://www.videopipe.cool/" target="_blank" rel="noopener nofollow">VideoPipe</a>是一个用于视频分析和结构化的框架，采用 C++ 编写、依赖少、易上手。它像管道一样，其中每个节点相互独立并可自行搭配，VideoPipe可用来构建不同类型的视频分析应用，适用于视频结构化、图片搜索、人脸识别、交通/安防领域的行为分析（如交通事件检测）等场景。</p>
<p><img src="https://img2024.cnblogs.com/blog/104032/202508/104032-20250815075335531-431984243.png" alt="p1-1" loading="lazy"></p>
<p>VideoPipe项目仓库中已经提供了50多个集成传统AI算法模型的Sample源码，涉及到车牌识别、人脸识别、违章检测、图搜、OCR、AI变脸、目标检测、图像分类、图像分割等各个领域。在大模型逐渐成为主流的今天（多模态大模型赋能传统AI视觉算法领域中表现优秀），VideoPipe也支持大模型集成啦，这次重点介绍VideoPipe如何集成多模态大模型来完成视频（图片）分析相关任务。</p>
<p><strong>快速开始</strong><br>下面基于VideoPipe和阿里云qwen-vl多模态大模型实现一个简单的图片理解的功能：从本地磁盘读取图片序列（现实场景中可以从网络获取图片或视频数据），大模型根据事先定义的Prompt提示词，对图片进行识别理解，依次对图片进行标签化，然后将标签化结果叠加到图片下方，最后显示结果。</p>
<p>1、创建VideoPipe节点类型（事先准备好aliyun大模型服务api_key）<br>2、将节点串起来，组成Pipeline管道<br>3、启动管道（一共55行代码）</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> #include <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">../nodes/vp_image_src_node.h</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)"> 2</span> #include <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">../nodes/infers/vp_mllm_analyser_node.h</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)"> 3</span> #include <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">../nodes/osd/vp_mllm_osd_node.h</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)"> 4</span> #include <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">../nodes/vp_screen_des_node.h</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)"> 5</span> #include <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">../nodes/vp_rtmp_des_node.h</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)"> 6</span> 
<span style="color: rgba(0, 128, 128, 1)"> 7</span> #include <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">../utils/analysis_board/vp_analysis_board.h</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)"> 8</span> 
<span style="color: rgba(0, 128, 128, 1)"> 9</span> <span style="color: rgba(0, 128, 0, 1)">/*</span>
<span style="color: rgba(0, 128, 128, 1)">10</span> <span style="color: rgba(0, 128, 0, 1)">* ## mllm_analyse_sample_openai ##
</span><span style="color: rgba(0, 128, 128, 1)">11</span> <span style="color: rgba(0, 128, 0, 1)">* image(frame) analyse based on Multimodal Large Language Model(from aliyun or other OpenAI-compatible api services).
</span><span style="color: rgba(0, 128, 128, 1)">12</span> <span style="color: rgba(0, 128, 0, 1)">* read images from disk and analyse the image using MLLM using the prepared prompt.
</span><span style="color: rgba(0, 128, 128, 1)">13</span> <span style="color: rgba(0, 128, 0, 1)">*/</span>
<span style="color: rgba(0, 128, 128, 1)">14</span> <span style="color: rgba(0, 0, 255, 1)">int</span><span style="color: rgba(0, 0, 0, 1)"> main() {
</span><span style="color: rgba(0, 128, 128, 1)">15</span>     VP_SET_LOG_INCLUDE_CODE_LOCATION(<span style="color: rgba(0, 0, 255, 1)">false</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">16</span>     VP_SET_LOG_INCLUDE_THREAD_ID(<span style="color: rgba(0, 0, 255, 1)">false</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">17</span> <span style="color: rgba(0, 0, 0, 1)">    VP_SET_LOG_LEVEL(vp_utils::vp_log_level::INFO);
</span><span style="color: rgba(0, 128, 128, 1)">18</span> <span style="color: rgba(0, 0, 0, 1)">    VP_LOGGER_INIT();
</span><span style="color: rgba(0, 128, 128, 1)">19</span> 
<span style="color: rgba(0, 128, 128, 1)">20</span>     <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> create nodes</span>
<span style="color: rgba(0, 128, 128, 1)">21</span>     auto image_src_0 = std::make_shared&lt;vp_nodes::vp_image_src_node&gt;(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">image_file_src_0</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)">22</span>                                                                     <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)">23</span>                                                                     <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./vp_data/test_images/llm/understanding/%d.jpg</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)">24</span>                                                                     <span style="color: rgba(128, 0, 128, 1)">2</span><span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)">25</span>                                                                     <span style="color: rgba(128, 0, 128, 1)">0.5</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">26</span>     auto writing_prompt = <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">给图片打标签，要求包含：\n</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">27</span>                           <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">1. 先仔细观察图片内容，为图片赋予适合的标签\n</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">28</span>                           <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">2. 给出的标签最多不超过10个\n</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">29</span>                           <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">3. 输出按以下格式：\n</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">30</span>                           <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">通过仔细观察图片，可以为图片赋予这些标签：['标签1', '标签2', '标签3']。</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">;
</span><span style="color: rgba(0, 128, 128, 1)">31</span>     auto mllm_analyser_0 = std::make_shared&lt;vp_nodes::vp_mllm_analyser_node&gt;(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">mllm_analyser_0</span><span style="color: rgba(128, 0, 0, 1)">"</span>,  <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> node name</span>
<span style="color: rgba(0, 128, 128, 1)">32</span>                             <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">qwen-vl-max</span><span style="color: rgba(128, 0, 0, 1)">"</span>,                                       <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> mllm model name (support image as input)</span>
<span style="color: rgba(0, 128, 128, 1)">33</span>                             writing_prompt,                                      <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> prompt</span>
<span style="color: rgba(0, 128, 128, 1)">34</span>                             <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">https://dashscope.aliyuncs.com/compatible-mode/v1</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> api base url</span>
<span style="color: rgba(0, 128, 128, 1)">35</span>                             <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">sk-XXX</span><span style="color: rgba(128, 0, 0, 1)">"</span>,                                            <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> api key (from aliyun)</span>
<span style="color: rgba(0, 128, 128, 1)">36</span>                             llmlib::LLMBackendType::OpenAI);                     <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> backend type</span>
<span style="color: rgba(0, 128, 128, 1)">37</span>     auto mllm_osd_0 = std::make_shared&lt;vp_nodes::vp_mllm_osd_node&gt;(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">osd_0</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)">38</span>                         <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">./vp_data/font/NotoSansCJKsc-Medium.otf</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">39</span>     auto screen_des_0 = std::make_shared&lt;vp_nodes::vp_screen_des_node&gt;(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">screen_des_0</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 128, 1)">0</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">40</span> 
<span style="color: rgba(0, 128, 128, 1)">41</span>     <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> construct pipeline</span>
<span style="color: rgba(0, 128, 128, 1)">42</span>     mllm_analyser_0-&gt;<span style="color: rgba(0, 0, 0, 1)">attach_to({image_src_0});
</span><span style="color: rgba(0, 128, 128, 1)">43</span>     mllm_osd_0-&gt;<span style="color: rgba(0, 0, 0, 1)">attach_to({mllm_analyser_0});
</span><span style="color: rgba(0, 128, 128, 1)">44</span>     screen_des_0-&gt;<span style="color: rgba(0, 0, 0, 1)">attach_to({mllm_osd_0});
</span><span style="color: rgba(0, 128, 128, 1)">45</span> 
<span style="color: rgba(0, 128, 128, 1)">46</span>     image_src_0-&gt;<span style="color: rgba(0, 0, 0, 1)">start();
</span><span style="color: rgba(0, 128, 128, 1)">47</span> 
<span style="color: rgba(0, 128, 128, 1)">48</span>     <span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)"> for debug purpose</span>
<span style="color: rgba(0, 128, 128, 1)">49</span> <span style="color: rgba(0, 0, 0, 1)">    vp_utils::vp_analysis_board board({image_src_0});
</span><span style="color: rgba(0, 128, 128, 1)">50</span>     board.display(<span style="color: rgba(128, 0, 128, 1)">1</span>, <span style="color: rgba(0, 0, 255, 1)">false</span><span style="color: rgba(0, 0, 0, 1)">);
</span><span style="color: rgba(0, 128, 128, 1)">51</span> 
<span style="color: rgba(0, 128, 128, 1)">52</span>     std::<span style="color: rgba(0, 0, 255, 1)">string</span><span style="color: rgba(0, 0, 0, 1)"> wait;
</span><span style="color: rgba(0, 128, 128, 1)">53</span> <span style="color: rgba(0, 0, 0, 1)">    std::getline(std::cin, wait);
</span><span style="color: rgba(0, 128, 128, 1)">54</span>     image_src_0-&gt;<span style="color: rgba(0, 0, 0, 1)">detach_recursively();
</span><span style="color: rgba(0, 128, 128, 1)">55</span> }</pre>
</div>
<p><strong>运行效果</strong></p>
<p>管道运行起来之后，大模型分析节点根据事先定义好的参数（模型名称、提示词、api_key）访问大模型服务，并解析大模型输出，随后显示节点将大模型输出绘制到图片中，并在控制台实时打印。VideoPipe目前支持的大模型后端有：OpenAI协议兼容服务、Ollama/vLLM本地部署服务。（视频效果<a href="http://www.videopipe.cool/index.php/2025/08/13/1-14/" target="_blank" rel="noopener nofollow">参见官网</a>）</p>
<p><img src="https://img2024.cnblogs.com/blog/104032/202508/104032-20250815075500864-2046769637.png" alt="p70" loading="lazy"></p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-15 07:58">2025-08-15 07:57</span>&nbsp;
<a href="https://www.cnblogs.com/xiaozhi_5638">周见智</a>&nbsp;
阅读(<span id="post_view_count">3</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19038858);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19038858', targetLink: 'https://www.cnblogs.com/xiaozhi_5638/p/19038858', title: 'VideoPipe中集成多模态大模型做视频（图片）分析' })">举报</a>
</div>
        