
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/tiome/p/18791530" title="发布于 2025-03-25 15:57">
    <span role="heading" aria-level="2">知识蒸馏实战</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="蒸馏实战小实验">蒸馏实战小实验</h2>
<p>本实验相关代码已开源至<a href="https://github.com/Tiome-tt/MedicalKD" target="_blank" rel="noopener nofollow">github</a></p>
<h3 id="失败经历">失败经历</h3>
<h4 id="爱爱医数据蒸馏qwen25-7b">爱爱医数据蒸馏Qwen2.5-7B</h4>
<p>1.用爬虫在爱爱医网站爬取<strong>1k</strong>条数据。（刚学一点爬虫，不会越过验证码，还是自己一次一次验证😅）</p>
<p>2.数据格式预处理，例如：</p>
<pre><code class="language-json">{
    "instruction": "你需要基于我提供的患者病历，推理并生成完整的诊断推理过程和最终诊断结果。请使用&lt;think&gt;&lt;/think&gt;标签标注推理过程，并在标签外直接输出最终诊断结果。例如：&lt;think&gt;(详细的诊断推理过程)&lt;/think&gt;(诊断结果)。", 
    "input": "【基本信息】男，46岁 【主诉】头痛恶心呕吐1个月。 【现病史】病人在住院一个月之前，没有任何明显的诱发因素，伴有恶心、呕吐，呕吐物为胃内容物，伴有发烧、意识障碍、行走受限，行头 CT检查示：全脑室系统扩张，现为求进一步诊治来我院，门诊以脑积水收入我科。在此期间，病人没有出现痉挛，饮食不佳，第二天睡眠良好。 【既往史】平时健康状况良好。 【查体】T：36.6℃，P：79次/分，R：18次/分，BP：118/72mmHg神清语明，双眼视力正常，双侧瞳孔等大，左：右约25mm：25mm，光反射存在，浅表淋巴结未触及肿大， 颈软，气管居中，无颈静脉怒张，心律齐，肺部未闻及干湿啰音，腹部平坦，无压痛及反跳痛，四肢肌力正常，四肢肌张力正常。 【辅助检查】头CT显示脑室扩张。 【诊治经过】入院后完善头CT显示脑积水，向患者及家属交代病情，患者及家属商量决定保守治疗，入院后完善相关采血：离子测定（急诊）：葡萄糖*：6.50mmol/L↑葡萄糖测定（各种酶法）：葡萄糖*9.08mmo1/L↑高密度脂蛋白-胆固醇：1.74mmoL↑载脂蛋白AI:1.73g/L↑甲功五项：游离三碘甲状腺原氨酸*：7.74pmo1/L↑促甲状腺激素测定*:0.0619uIU/mL血流变学检查：红细胞比积测定：0.37红细胞流变特性检测（刚性指数）：10.03；目前诊断脑积水，给予甘露醇注射液125ml，一天一次静脉点滴；给予甘油果糖注射液250ml，一天一次静脉点滴、给予醒脑静注射液20ml，一天一次静脉点滴；给予舒血宁注射液20ml，一天一次静脉点滴；给予复方氨基酸注射液500ml，一天一次静脉点滴，通过7天保守治疗，患者头痛恶心呕吐症状明显缓解，达到出院标准，嘱咐患者出院后注意休息，继续口服药物治疗，定期复查。", 
    "output": "&lt;think&gt;患者为中年男性，主诉头痛、恶心、呕吐1个月，伴意识障碍及行走受限，提示中枢神经系统受累。查体虽未见明显神经系统定位体征，但头CT显示全脑室系统扩张，符合脑积水影像学特征。发热史需与感染性脑膜炎鉴别，但病程长达一个月且缺乏脑膜刺激征（颈软、无克氏征/布氏征），不支持急性感染。血糖升高可能与应激反应相关，甲功异常需排除代谢因素但非主要矛盾。甘露醇和甘油果糖的脱水降颅压治疗有效，症状缓解验证了颅内压增高的病理机制。需注意脑积水病因未明，梗阻性脑积水可能性大，需排除肿瘤或中脑导水管狭窄等结构异常，但当前资料未提供进一步影像学证据。&lt;/think&gt;脑积水。", 
    "system": "你是一名专业的临床医生。"
}
</code></pre>
<p>3.调用DeepSeek官方API进行蒸馏推理依据（Ratonales）</p>
<p>蒸馏结果如上面示例"output"里用<strong><think></think></strong>标签包括的内容</p>
<p><s>吐槽:DeepSeek官方API响应很慢，而且一次请求可能得重复请求两三次才能得到回复（重复消费）</s></p>
<p>历经几小时最后得到<strong>820</strong>条包含推理的蒸馏数据集iiyiTrainData</p>
<p>4.安装LLama-Factory框架，使用iiyiTrainData蒸馏数据集进行LoRA微调</p>
<p><u>具体的<strong>安装命令</strong>在下面会细讲这里不再阐述</u></p>
<p>5.输入与回复</p>
<p><strong>输入：</strong></p>
<p>任务：你需要基于我提供的患者病历，推理并生成完整的诊断推理过程和最终诊断结果。请使用<think></think>标签标注推理过程，并在标签外直接输出最终诊断结果。例如：<think>(详细的诊断推理过程)</think>(诊断结果)。<br>
【基本信息】男，46岁 【主诉】头痛恶心呕吐1个月。 【现病史】病人在住院一个月之前，没有任何明显的诱发因素，伴有恶心、呕吐，呕吐物为胃内容物，伴有发烧、意识障碍、行走受限，行头 CT检查示：全脑室系统扩张，现为求进一步诊治来我院，门诊以脑积水收入我科。在此期间，病人没有出现痉挛，饮食不佳，第二天睡眠良好。 【既往史】平时健康状况良好。 【查体】T：36.6℃，P：79次/分，R：18次/分，BP：118/72mmHg神清语明，双眼视力正常，双侧瞳孔等大，左：右约25mm：25mm，光反射存在，浅表淋巴结未触及肿大， 颈软，气管居中，无颈静脉怒张，心律齐，肺部未闻及干湿啰音，腹部平坦，无压痛及反跳痛，四肢肌力正常，四肢肌张力正常。 【辅助检查】头CT显示脑室扩张。 【诊治经过】入院后完善头CT显示脑积水，向患者及家属交代病情，患者及家属商量决定保守治疗，入院后完善相关采血：离子测定（急诊）：葡萄糖<em>：6.50mmol/L↑葡萄糖测定（各种酶法）：葡萄糖</em>9.08mmo1/L↑高密度脂蛋白-胆固醇：1.74mmoL↑载脂蛋白AI:1.73g/L↑甲功五项：游离三碘甲状腺原氨酸<em>：7.74pmo1/L↑促甲状腺激素测定</em>:0.0619uIU/mL血流变学检查：红细胞比积测定：0.37红细胞流变特性检测（刚性指数）：10.03；目前诊断脑积水，给予甘露醇注射液125ml，一天一次静脉点滴；给予甘油果糖注射液250ml，一天一次静脉点滴、给予醒脑静注射液20ml，一天一次静脉点滴；给予舒血宁注射液20ml，一天一次静脉点滴；给予复方氨基酸注射液500ml，一天一次静脉点滴，通过7天保守治疗，患者头痛恶心呕吐症状明显缓解，达到出院标准，嘱咐患者出院后注意休息，继续口服药物治疗，定期复查。</p>
<p><strong>回复：</strong></p>
<p><strong>Qwen2.5-7B-Base模型：</strong></p>
<p>微调后：</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154056069-1684991850.png" alt="image" loading="lazy"></p>
<pre><code class="language-json">// 评估结果
{
    "predict_bleu-4": 15.410856707317073,
    "predict_model_preparation_time": 0.0065,
    "predict_rouge-1": 33.76439756097561,
    "predict_rouge-2": 13.446685487804878,
    "predict_rouge-l": 20.279881707317074,
    "predict_runtime": 5382.5632,
    "predict_samples_per_second": 0.152,
    "predict_steps_per_second": 0.076
}
</code></pre>
<p>微调前：</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154136359-1573838267.png" alt="image" loading="lazy"></p>
<pre><code class="language-json">// 评估结果
{
    "predict_bleu-4": 11.915909756097559,
    "predict_model_preparation_time": 0.0055,
    "predict_rouge-1": 29.76750548780488,
    "predict_rouge-2": 9.160844268292683,
    "predict_rouge-l": 17.595996707317074,
    "predict_runtime": 5725.6516,
    "predict_samples_per_second": 0.143,
    "predict_steps_per_second": 0.072
}
</code></pre>
<p><strong>Qwen2.5-7B-Instruct模型：</strong></p>
<p>微调后：</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154152333-217599043.png" alt="image" loading="lazy"></p>
<p>微调前：</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154159288-1486699480.png" alt="image" loading="lazy"></p>
<p>6.总结</p>
<p>①Base模型输入中增加“任务”这一内容，模型会有“思考”过程，但是最终会乱输出，如果不增加“任务”，模型并不会出现“思考”过程，但回复合理</p>
<p>②Instruct模型本身就有“思考”能力，只要增加“任务”进行指导，就会出现“思考”过程。但是不会自主进行“思考”。而且“思考”过程比未经过微调好一点。此外，Instruct模型经过大量数据对齐，并不会乱回复，但是即便是使用微调的数据进行询问，最终诊断的结果也不会和该数据的真实诊断结果相同。</p>
<p><strong>思考：</strong>如果使用Base模型需要使用大量微调数据进行对齐,使用Instruct模型又不一定能微调出自主涌现的“思考”能力，可能需要进行强化学习。<strong>数据集格式</strong>可能需要重新构建。</p>
<h3 id="llms推理能力蒸馏">LLMs推理能力蒸馏</h3>
<p><strong>概览：</strong>本次实验使用的是网上开源且与医学相关的数据集，这些数据集都是从DeepSeek或者ChatGPT-O1模型中蒸馏的，具体来说是给定问题和参考回复，让LLM生成相关的推理过程。然后使用这些数据对Qwen2.5-7B-Base模型进行LoRA微调，以增强小模型的推理能力。结果上来说比起<strong>失败经历</strong>效果更好了一些，但是还是有一定的问题，作为蒸馏和模型微调实战还是<strong>有一定的意义</strong>。</p>
<blockquote>
<p>故不积跬步，无以至千里；不积小流，无以成江海。 —— 荀子《劝学》</p>
</blockquote>
<h4 id="环境搭建">环境搭建</h4>
<p>本次用到的机器为Linux系统， 3块 RTX 3090 24G显卡（两块也能跑，时间更长一些）</p>
<p>默认你已经对机器学习有了一定的基础，对于<strong>Anaconda</strong>的安装就不再细说，网上有大把资料。</p>
<pre><code class="language-shell"># 虚拟环境创建
conda create -n MedicalKD python=3.10
# 进入虚拟环境
conda activate MedicalKD

# 安装pytorch
# CUDA 12.0 
# 版本对应参考https://blog.csdn.net/ttrr27/article/details/144162171
pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124 -i https://pypi.tuna.tsinghua.edu.cn/simple/

# 安装LLaMa Factory
# 安装前可以自行创建一个文件夹(文件管理方便) 命令:mkdir xxx
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics]" -i https://pypi.tuna.tsinghua.edu.cn/simple

# 环境校验
python
import torch
torch.cuda.current_device()
torch.cuda.get_device_name(0)
torch.__version__
# 框架校验
llamafactory-cli train -h

# 可以安装一下deepspeed，加速训练，减少显存消耗(WebUi最下方有选项可以使用deepspeed)
pip install deepspeed
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154217195-1842492147.png" alt="image" loading="lazy"></p>
<p>出现错误，缺少socksio，下面命令安装</p>
<pre><code>pip install socksio
</code></pre>
<h4 id="模型下载">模型下载</h4>
<p>国内可以使用<strong>魔塔</strong>下载，速度快些，外网可使用huggingface</p>
<p>这里用魔塔示例</p>
<pre><code class="language-shell"># 下载Qwen 7B //通过魔塔
# git clone https://www.modelscope.cn/Qwen/Qwen2.5-7B-Instruct.git
git clone https://www.modelscope.cn/Qwen/Qwen2.5-7B.git

# 模型直接推理
CUDA_VISIBLE_DEVICES=0 llamafactory-cli webchat \
    --model_name_or_path /mnt/mxy/models/Qwen2.5-7B-Instruct/ \
    --template qwen
</code></pre>
<h4 id="数据集介绍">数据集介绍</h4>
<p>本实验涉及四个<strong>中文开源</strong>数据集，并最终将它们打乱顺序合并成一个</p>
<p><strong>medical_o1_sft_Chinese.json</strong> 医疗 24772条 <a href="https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT/blob/main/medical_o1_sft_Chinese.json" target="_blank" rel="noopener nofollow">下载链接</a></p>
<p><strong>medical_r1_distill_sft_Chinese.json</strong> 医疗 17000条 <a href="https://huggingface.co/datasets/FreedomIntelligence/Medical-R1-Distill-Data-Chinese/tree/main" target="_blank" rel="noopener nofollow">下载链接</a></p>
<p><strong>distill_psychology-10k-r1.json</strong> 心理健康 8775条 <a href="https://huggingface.co/datasets/Kedreamix/psychology-10k-Deepseek-R1-zh/blob/main/distill_psychology-10k-r1.json" target="_blank" rel="noopener nofollow">下载链接</a></p>
<p><strong>hwtcm_deepseek_r1_distill_data.json</strong> 中医 12219条 <a href="https://huggingface.co/datasets/Monor/hwtcm-deepseek-r1-distill-data" target="_blank" rel="noopener nofollow">下载链接</a></p>
<p>共计：62766 条</p>
<p><strong>注：</strong>如果你想自己构建蒸馏数据集可参考代码中蒸馏爱爱医数据部分，调用的DeepSeek官方接口生成推理依据。</p>
<p><u>但是这样开销很大，只蒸馏小部分数据不足以达到训练预期目标。</u></p>
<p>github仓库中缺少<strong>medical_r1_distill_sft_Chinese.json</strong>请自行下载后放入下方文件夹中</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154247557-1910938084.png" alt="image" loading="lazy"></p>
<h5 id="数据格式"><strong>数据格式</strong></h5>
<blockquote>
<p>代码已经完成格式转换</p>
</blockquote>
<p>包含三部分：问题，推理依据（rationales）和总结回复</p>
<p>推理依据包含在<think></think>标签内</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154320938-1077741624.png" alt="image" loading="lazy"></p>
<h4 id="使用llama-factory进行微调">使用LLaMA-Factory进行微调</h4>
<h5 id="数据集注册">数据集注册</h5>
<p>首先确保所适用数据集放在<strong>data</strong>目录下：</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154339430-1627893191.png" alt="image" loading="lazy"></p>
<p>打开<strong>data</strong>目录下的<u>dataset_info.json</u>文件，在其中增加内容：</p>
<pre><code class="language-json">  "mergedData": {
    "file_name": "merged_dataset_random.json"
  },
</code></pre>
<h5 id="使用webui进行微调">使用webui进行微调</h5>
<p>LLaMA-Factory提供了可视化页面，可以实现<strong>无代码</strong>进行模型训练、评估和对话，非常方便。</p>
<pre><code class="language-shell"># 下面命令用于启动webui
# 请确认系统已经在llama-factory文件目录下
CUDA_VISIBLE_DEVICES=0 llamafactory-cli webui

# 训练时间过长，可以在服务器上建一个screen，这样本地电脑即使断开ssh连接，服务器上也会继续训练
# 类似服务器电脑上打开一个窗口，一直不关闭
#  新建screen
screen -S your_screen_name
#  显示screen list
screen -ls
# 进入screen
screen -r your_screen_name
# 删除screen
Ctrl+D  # 在当前screen下，输入Ctrl+D，删除该screen
Ctrl+A，Ctrl+D  # 在当前screen下，输入先后Ctrl+A，Ctrl+D，退出该screen
</code></pre>
<p>如果你是windows系统调用远程云服务器，可能需要端口映射</p>
<pre><code class="language-shell"># 端口映射
# xxx为远程服务器地址
ssh -L 7860:localhost:7860 root@xxx.xxx.xxx.xxx
</code></pre>
<p>然后在本地浏览器打开<strong>localhost:7860</strong>，然后会看到如下界面</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154400399-1762240153.png" alt="image" loading="lazy"></p>
<h5 id="微调参数设置">微调参数设置</h5>
<p>模型选择：Qwen2.5-7B		模型路径：下载到的本地路径</p>
<p>对话模版：qwen</p>
<p>微调方法：lora		训练阶段：SFT		训练轮数(epoch)：2.0		批处理大小(batch_size):2</p>
<p>预热步数：5		验证集比例：0.1		保存间隔：200</p>
<p>LoRA秩：16		LoRA缩放系数:32</p>
<p>启用DeepSpeed stage</p>
<p><strong>其余参数全默认</strong>,训练时间大概40小时</p>
<h4 id="结果对比">结果对比</h4>
<p>选择webui中的Chat，然后检查点路径选择训练时保存的checkpoint路径，加载模型就可以与训练后的模型对话，反之不填检查点路径，就是和原始模型对话。</p>
<p><strong>下面问题是微调数据集外的问题</strong></p>
<p>Prompt：</p>
<p><strong>任务：</strong>请先输出推理过程并将其包含在<think></think>标签内，然后在标签后直接输出最终总结回复。例如：<think>(详细的诊断推理过程)</think>(总结回复)。<strong>问题：</strong>我近期反复出现高热、剧烈咳嗽并伴有胸痛和气短，影像检查提示肺部异常，这可能是什么疾病？</p>
<h5 id="微调前qwen25-7b-base">微调前Qwen2.5-7B-Base</h5>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154508767-1818329932.png" alt="image" loading="lazy"></p>
<p>微调前会依据指令<strong>强行</strong>将回复内容包含在<think></think>标签内，而<strong>不是所期望的推理过程</strong>。</p>
<p>不加prompt中<strong>任务</strong>部分内容，模型正常回复：</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154519434-914093467.png" alt="image" loading="lazy"></p>
<h5 id="微调后qwen25-7b-base">微调后Qwen2.5-7B-Base</h5>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154532175-787393614.png" alt="image" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154538615-1703057656.png" alt="image" loading="lazy"></p>
<p>模型有概率不会将推理过程包含在<think></think>标签中，但也会有推理过程和总结回复两部分：</p>
<p>（优化提示词？增加数据量进一步训练？）</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154549361-388612351.png" alt="image" loading="lazy"></p>
<p>不加prompt中<strong>任务</strong>部分内容，模型正常回复：</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154557301-1620879248.png" alt="image" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154603915-1851241139.png" alt="image" loading="lazy"></p>
<h4 id="微调后模型合并">微调后模型合并</h4>
<p>进入Export，填写导出目录即可合并</p>
<p><img src="https://img2024.cnblogs.com/blog/2838661/202503/2838661-20250325154618417-564232068.png" alt="image" loading="lazy"></p>
<h4 id="问题">问题</h4>
<p>1.模型可能会出现重复输出无法停止、乱回复问题</p>
<p>2.不加下面任务部分提示词，模型不会自主输出思考过程</p>
<blockquote>
<p>任务：请先输出推理过程并将其包含在<think></think>标签内，然后在标签后直接输出最终总结回复。例如：<think>(详细的诊断推理过程)</think>(总结回复)。</p>
</blockquote>
<h5 id="展望">展望</h5>
<p>后续可能会增加强化学习阶段，观察模型是否会涌现出自主出现思考过程的能力，做一些小调整解决模型重复输出问题。<br>
<strong>如果成功了就会再写一个随笔来记录</strong></p>
<h3 id="参考文档">参考文档</h3>
<p>1.<a href="https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md" target="_blank" rel="noopener nofollow">LLaMA-Factory github地址</a></p>
<p>2.<a href="https://zhuanlan.zhihu.com/p/695287607" target="_blank" rel="noopener nofollow">LLaMa-Factory入门文档</a></p>
<p>3.<a href="https://ezool.net/blog/LLAMA_FACTORYKuangJiaGeCanShuZhengLi/24.html" target="_blank" rel="noopener nofollow">LLaMa Factory参数详解</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.1885478052511574" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-03-25 16:00">2025-03-25 15:57</span>&nbsp;
<a href="https://www.cnblogs.com/tiome">猫猫不会吃芋头</a>&nbsp;
阅读(<span id="post_view_count">45</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18791530" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18791530);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18791530', targetLink: 'https://www.cnblogs.com/tiome/p/18791530', title: '知识蒸馏实战' })">举报</a>
</div>
        