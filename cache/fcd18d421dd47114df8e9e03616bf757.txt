
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/lmy5215006/p/18993854" title="发布于 2025-08-27 12:28">
    <span role="heading" aria-level="2">优雅求模，一致性哈希算法</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="传统哈希局限性">传统哈希局限性</h1>
<p>求模，<code>也就是 key % 节点数 N</code>, 当节点数量变化时（如服务器扩容 / 下线），几乎所有数据的映射关系都会失效，导致大量数据需要重新迁移，引发 “哈希雪崩”。</p>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827094349949-2026419285.png" class="lazyload"></p>
<table>
<thead>
<tr>
<th>key的hash值</th>
<th>节点数</th>
<th>求模</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>3</td>
<td>10 % 3 = 1</td>
</tr>
<tr>
<td>11</td>
<td>3</td>
<td>11 % 3 = 2</td>
</tr>
<tr>
<td>12</td>
<td>3</td>
<td>12 % 3 = 0</td>
</tr>
<tr>
<td>10</td>
<td>4</td>
<td>10 % 4 = 2</td>
</tr>
<tr>
<td>11</td>
<td>4</td>
<td>11 % 4 = 3</td>
</tr>
<tr>
<td>12</td>
<td>4</td>
<td>12 % 4 = 0</td>
</tr>
</tbody>
</table>
<p>此时可以看到之前分配到1，2，0节点的key，需要被重新移动到2，3，0。也就是<code>75%的数据</code>需要移动。<br>
<code>如果这个总数是20亿呢？这会是一场灾难</code></p>
<blockquote>
<p>关于哈希可以参考此文 <a href="https://www.cnblogs.com/lmy5215006/p/18748028" target="_blank">https://www.cnblogs.com/lmy5215006/p/18748028</a></p>
</blockquote>
<h1 id="理论支撑一致性哈希">理论支撑：一致性哈希</h1>
<p>那如何解决这个问题呢？<br>
正所谓头痛医头，脚痛医脚。既然是因为分母发生变化导致，那我想个办法让<code>分母不变</code>不就解决这个问题了？<br>
聪明的小伙伴已经想到了，把分母设为int最大值2³²-1即可。<br>
这时候新的问题又来了，2³²-1=4294967295 这么大的一个分母(节点数)，任何数求模余数都是他自己，这就失去了求模的意义，<code>求模的本质是为了对hash瘦身，你倒好又绕回来了</code>，因此这条路走不通，但也提供了灵感。</p>
<h2 id="哈希环hash-ring">哈希环(hash ring)</h2>
<p>因此，在1997年，consistent hash算法被提出，它结合了环形数组与上述的灵感。将hash算法的输出范围抽象成一个圆环，并hash值限定为0-2³²-1。</p>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827105255111-1276827104.png" class="lazyload"></p>
<h2 id="节点映射到哈希环">节点映射到哈希环</h2>
<p>把每一个节点(Node)算出一个hash值，放在hash ring对应的位置上</p>
<blockquote>
<p>假设有3个节点<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827111700769-1581102719.png" class="lazyload"></p>
</blockquote>
<h2 id="数据映射到哈希环">数据映射到哈希环</h2>
<p>将要存储的数据(key)也通过<code>相同的算法</code>计算出hash值，放在hash ring对应的位置上</p>
<blockquote>
<p>假设有1000个key，数据映射到环后，<code>顺时针</code>方向寻找第一个遇到的节点，该节点就是存储key的节点<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827111713678-1951872722.png" class="lazyload"></p>
</blockquote>
<h2 id="节点动态增删">节点动态增删</h2>
<p>当要动态增删节点时，一致性hash只会影响hash ring上相邻节点的<code>部份数据</code>，而不是迁移所有数据，这极大减少了数据迁移量<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827111847626-11199521.png" class="lazyload"><br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827111946297-735389839.png" class="lazyload"></p>
<blockquote>
<p>删除结节也同理，就是一个在hash ring上此消彼长的过程。</p>
</blockquote>
<h2 id="进一步优化虚拟节点">进一步优化：虚拟节点</h2>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827111713678-1951872722.png" class="lazyload"><br>
让我们再回到此图，在最初的3个节点中，我们会发现一丝丝不和谐的因素，蓝色节点中keys的数量为<code>103</code>，绿色节点keys的数量为<code>572</code>，红色节点的keys数量为<code>325</code>，他们之间的分配并不均衡。</p>
<p>当节点较少时，keys可能集中分布在某一个特定节点，导致旱的旱死，涝的涝死，这便是<code>数据倾斜</code>。<br>
那如何优化呢？在计算机中，没有什么是不能通过增加一层中间层能解决的。</p>
<blockquote>
<p>为每个物理节点创建多个"虚拟节点"，由虚拟节点代替物理节点，映射到hash ring上</p>
</blockquote>
<p><img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1084317/202508/1084317-20250827113606287-3808030.png" class="lazyload"></p>
<h1 id="具体落地hash-slot">具体落地：Hash Slot</h1>
<p>有了理论支撑，在具体落地的过程中，发生了细微变化。但核心目标依旧不变：<code>当节点变化时，数据最小化迁移</code>。</p>
<table>
<thead>
<tr>
<th></th>
<th>Consistend Hash</th>
<th>Hash Slot</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>空间初始化</strong></td>
<td>构建 0~2³²-1 的hash ring。</td>
<td>划分固定数量的Hash Slot，比如Redis的16384个槽。</td>
</tr>
<tr>
<td><strong>数据映射</strong></td>
<td>通过hash(key)映射到ring上的某个点，顺时针找到最近节点</td>
<td>通过hash(key)得到hash，再通过<code>hash%槽总数</code>得到槽编号，最后通过<code>槽编号与节点的映射关系</code>得到所属节点。</td>
</tr>
<tr>
<td><strong>节点映射</strong></td>
<td>计算节点的hash值，比如(IP+端口)，直接映射到环上</td>
<td>节点不直接映射，而是通过维护与槽位的映射关系，如节点 A 负责槽 0~5460，节点 B 负责槽 5461~10922</td>
</tr>
</tbody>
</table>
<h2 id="hash-slot解决了什么痛点">Hash Slot解决了什么痛点？</h2>
<table>
<thead>
<tr>
<th>Consisten hash痛点</th>
<th>Hash Slot方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据倾斜</td>
<td>槽的数量足够大，且槽数量在节点之间均匀分配，比如Redis有16384个槽，假设3个节点，每个节点分配5461个槽，因为槽的数量很大，所以天然避免数据倾斜</td>
</tr>
<tr>
<td>数据迁移颗粒度大</td>
<td>迁移粒度从 “节点级” 缩小到 “槽级”—— 节点扩容 / 缩容时，仅需迁移 “待分配 / 释放的槽”（而非整个节点的数据）</td>
</tr>
</tbody>
</table>
<blockquote>
<p>事实上，Hash Slot与Consistend Hash在思想上没有本质上的差别。你也可以创建16384个虚拟节点来对标Hash Slot，只是工程化难度不同的选择而已</p>
</blockquote>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-27 12:28">2025-08-27 12:28</span>&nbsp;
<a href="https://www.cnblogs.com/lmy5215006">叫我安不理</a>&nbsp;
阅读(<span id="post_view_count">7</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18993854);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18993854', targetLink: 'https://www.cnblogs.com/lmy5215006/p/18993854', title: '优雅求模，一致性哈希算法' })">举报</a>
</div>
        