
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/dechinphy/p/18741585/cuda-time-record" title="发布于 2025-02-28 09:45">
    <span role="heading" aria-level="2">CUDA时长统计</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        <img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250228094118980-832643743.png" alt="CUDA时长统计" class="desc_img">
        这篇文章主要介绍了一个CUDA入门的技术：使用CUDA头文件写一个专门用于CUDA函数运行时长统计的宏，这样就可以统计目标Kernel函数的运行时长。可以直接在CUDA中打印相应的数值，也可以回传到Cython或者Python中进行打印。
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="技术背景">技术背景</h1>
<p>前面的一篇文章中介绍了在<a href="https://www.cnblogs.com/dechinphy/p/18735654/cuda_error" target="_blank">CUDA中使用宏来监测CUDA C函数或者Kernel函数的运行报错</a>问题。同样的思路，我们可用写一个用于统计函数运行时长的宏，这样不需要使用额外的工具来对函数体的性能进行测试。</p>
<h1 id="文件准备">文件准备</h1>
<p>因为这里的宏改动，主要涉及CUDA头文件和CUDA文件的修改，所以Cython文件和Python文件还有异常捕获宏我们还是复用<a href="https://www.cnblogs.com/dechinphy/p/18740207/cycuda-gather" target="_blank">这篇文章</a>里面用到的。测试内容是，定义一个原始数组和一个索引数组，输出索引的结果数组。</p>
<h2 id="wrapperpyx">wrapper.pyx</h2>
<pre><code class="language-python"># cythonize -i -f wrapper.pyx

import numpy as np
cimport numpy as np
cimport cython

cdef extern from "&lt;dlfcn.h&gt;" nogil:
    void *dlopen(const char *, int)
    char *dlerror()
    void *dlsym(void *, const char *)
    int dlclose(void *)
    enum:
        RTLD_LAZY

ctypedef int (*GatherFunc)(float *source, int *index, float *res, int N, int M) noexcept nogil

cdef void* handle = dlopen('/path/to/libcuindex.so', RTLD_LAZY)

@cython.boundscheck(False)
@cython.wraparound(False)
cpdef float[:] cuda_gather(float[:] x, int[:] idx):
    cdef:
        GatherFunc Gather
        int success
        int N = idx.shape[0]
        int M = x.shape[0]
        float[:] res = np.zeros((N, ), dtype=np.float32)
    Gather = &lt;GatherFunc&gt;dlsym(handle, "Gather")
    success = Gather(&amp;x[0], &amp;idx[0], &amp;res[0], N, M)
    return res

while not True:
    dlclose(handle)
</code></pre>
<h2 id="test_gatherpy">test_gather.py</h2>
<pre><code class="language-python">import numpy as np
np.random.seed(0)
from wrapper import cuda_gather

M = 1024 * 1024 * 128
N = 1024 * 1024
x = np.random.random((M,)).astype(np.float32)
idx = np.random.randint(0, M, (N,)).astype(np.int32)
res = np.asarray(cuda_gather(x, idx))
print (res.shape)
print ((res==x[idx]).sum())
</code></pre>
<h2 id="errorcuh">error.cuh</h2>
<pre><code class="language-c">#pragma once
#include &lt;stdio.h&gt;

#define CHECK(call) do{const cudaError_t error_code = call; if (error_code != cudaSuccess){printf("CUDA Error:\n"); printf("    File:   %s\n", __FILE__); printf("    Line:   %d\n", __LINE__); printf("    Error code: %d\n", error_code); printf("    Error text: %s\n", cudaGetErrorString(error_code)); exit(1);}} while (0)
</code></pre>
<h1 id="计时宏">计时宏</h1>
<p>这里增加一个用于计时的<code>record.cuh</code>头文件，里面写一个<code>TIME_CUDA_FUNCTION</code>宏，然后在CUDA中需要统计的函数前调用，就可以输出CUDA函数的运行时长了。</p>
<pre><code class="language-c">#pragma once
#include &lt;stdio.h&gt;
#include &lt;cuda_runtime.h&gt;

// 宏定义，用于测量CUDA函数的执行时间
#define TIME_CUDA_FUNCTION(func) \
    do { \
        cudaEvent_t start, stop; \
        float elapsedTime; \
        cudaEventCreate(&amp;start); \
        cudaEventCreate(&amp;stop); \
        cudaEventRecord(start, NULL); \
        \
        func; \
        \
        cudaEventRecord(stop, NULL); \
        cudaEventSynchronize(stop); \
        cudaEventElapsedTime(&amp;elapsedTime, start, stop); \
        printf("Time taken by function %s is: %f ms\n", #func, elapsedTime); \
        \
        cudaEventDestroy(start); \
        cudaEventDestroy(stop); \
    } while (0)
</code></pre>
<h1 id="计时宏的使用">计时宏的使用</h1>
<p>我们在CUDA文件<code>cuda_index.cu</code>中调用<code>record.cuh</code>里面的计时宏，这里用来统计一个CUDA核函数的执行时间：</p>
<pre><code class="language-c">// nvcc -shared ./cuda_index.cu -Xcompiler -fPIC -o ./libcuindex.so
#include &lt;stdio.h&gt;
#include "cuda_index.cuh"
#include "error.cuh"
#include "record.cuh"

void __global__ GatherKernel(float *source, int *index, float *res, int N){
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx &lt; N){
        res[idx] = source[index[idx]];
    }
}

extern "C" int Gather(float *source, int *index, float *res, int N, int M){
    float *souce_device, *res_device;
    int *index_device;
    CHECK(cudaMalloc((void **)&amp;souce_device, M * sizeof(float)));
    CHECK(cudaMalloc((void **)&amp;res_device, N * sizeof(float)));
    CHECK(cudaMalloc((void **)&amp;index_device, N * sizeof(int)));
    CHECK(cudaMemcpy(souce_device, source, M * sizeof(float), cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(res_device, res, N * sizeof(float), cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(index_device, index, N * sizeof(int), cudaMemcpyHostToDevice));
    int block_size = 1024;
    int grid_size = (N + block_size - 1) / block_size;
    TIME_CUDA_FUNCTION((GatherKernel&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(souce_device, index_device, res_device, N)));
    CHECK(cudaGetLastError());
    CHECK(cudaDeviceSynchronize());
    CHECK(cudaMemcpy(res, res_device, N * sizeof(float), cudaMemcpyDeviceToHost));
    CHECK(cudaFree(souce_device));
    CHECK(cudaFree(index_device));
    CHECK(cudaDeviceSynchronize());
    CHECK(cudaFree(res_device));
    CHECK(cudaDeviceReset());
    return 1;
}
</code></pre>
<p>需要注意的是，<code>TIME_CUDA_FUNCTION</code>宏只能有一个输入，但是使用CUDA核函数的时候实际上会被当作是两个输入，因此我们需要将CUDA核函数用括号再封装起来。</p>
<h1 id="输出结果">输出结果</h1>
<p>最终按照<a href="https://www.cnblogs.com/dechinphy/p/18740207/cycuda-gather#%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B" target="_blank">这篇文章</a>中的运行流程，可以得到这样的输出结果：</p>
<pre><code class="language-bash">Time taken by function (GatherKernel&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(souce_device, index_device, res_device, N)) is: 0.584224 ms
(1048576,)
1048576
</code></pre>
<p>这里CUDA核函数的运行时长被正确的格式化输出了。</p>
<h1 id="返回耗时数值">返回耗时数值</h1>
<p>除了在CUDA中直接打印耗时的数值，我们还可以修改<code>record.cuh</code>中的宏，让其返回耗时数值：</p>
<pre><code class="language-c">#pragma once
#include &lt;stdio.h&gt;
#include &lt;cuda_runtime.h&gt;

// 宏定义，用于测量CUDA函数的执行时间
#define TIME_CUDA_FUNCTION(func) \
    do { \
        cudaEvent_t start, stop; \
        float elapsedTime; \
        cudaEventCreate(&amp;start); \
        cudaEventCreate(&amp;stop); \
        cudaEventRecord(start, NULL); \
        \
        func; \
        \
        cudaEventRecord(stop, NULL); \
        cudaEventSynchronize(stop); \
        cudaEventElapsedTime(&amp;elapsedTime, start, stop); \
        printf("Time taken by function %s is: %f ms\n", #func, elapsedTime); \
        \
        cudaEventDestroy(start); \
        cudaEventDestroy(stop); \
    } while (0)

// 宏定义，用于测量CUDA函数的执行时间并返回该时间
#define GET_CUDA_TIME(func) \
    ({ \
        cudaEvent_t start, stop; \
        float elapsedTime = 0.0f; \
        cudaEventCreate(&amp;start); \
        cudaEventCreate(&amp;stop); \
        cudaEventRecord(start, NULL); \
        \
        func; \
        \
        cudaEventRecord(stop, NULL); \
        cudaEventSynchronize(stop); \
        cudaEventElapsedTime(&amp;elapsedTime, start, stop); \
        \
        cudaEventDestroy(start); \
        cudaEventDestroy(stop); \
        \
        elapsedTime; \
    })
</code></pre>
<p>修改头文件<code>cuda_index.cuh</code>，因为这里我们需要返回一个运行时长的float数值，不再是int类型了：</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

extern "C" float Gather(float *source, int *index, float *res, int N, int M);
</code></pre>
<p>最后再对应修改下<code>cuda_index.cu</code>中的内容：</p>
<pre><code class="language-c">// nvcc -shared ./cuda_index.cu -Xcompiler -fPIC -o ./libcuindex.so
#include &lt;stdio.h&gt;
#include "cuda_index.cuh"
#include "error.cuh"
#include "record.cuh"

void __global__ GatherKernel(float *source, int *index, float *res, int N){
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx &lt; N){
        res[idx] = source[index[idx]];
    }
}

extern "C" float Gather(float *source, int *index, float *res, int N, int M){
    float *souce_device, *res_device;
    int *index_device;
    CHECK(cudaMalloc((void **)&amp;souce_device, M * sizeof(float)));
    CHECK(cudaMalloc((void **)&amp;res_device, N * sizeof(float)));
    CHECK(cudaMalloc((void **)&amp;index_device, N * sizeof(int)));
    CHECK(cudaMemcpy(souce_device, source, M * sizeof(float), cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(res_device, res, N * sizeof(float), cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(index_device, index, N * sizeof(int), cudaMemcpyHostToDevice));
    int block_size = 1024;
    int grid_size = (N + block_size - 1) / block_size;
    float timeTaken = GET_CUDA_TIME((GatherKernel&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(souce_device, index_device, res_device, N)));
    CHECK(cudaGetLastError());
    CHECK(cudaDeviceSynchronize());
    CHECK(cudaMemcpy(res, res_device, N * sizeof(float), cudaMemcpyDeviceToHost));
    CHECK(cudaFree(souce_device));
    CHECK(cudaFree(index_device));
    CHECK(cudaDeviceSynchronize());
    CHECK(cudaFree(res_device));
    CHECK(cudaDeviceReset());
    return timeTaken;
}
</code></pre>
<p>这样就可以把函数运行耗时的数值返回给Cython文件，然后在Cython文件<code>wrapper.pyx</code>中打印耗时：</p>
<pre><code class="language-python"># cythonize -i -f wrapper.pyx

import numpy as np
cimport numpy as np
cimport cython

cdef extern from "&lt;dlfcn.h&gt;" nogil:
    void *dlopen(const char *, int)
    char *dlerror()
    void *dlsym(void *, const char *)
    int dlclose(void *)
    enum:
        RTLD_LAZY

ctypedef float (*GatherFunc)(float *source, int *index, float *res, int N, int M) noexcept nogil

cdef void* handle = dlopen('/home/dechin/projects/gitee/dechin/tests/cuda/libcuindex.so', RTLD_LAZY)

@cython.boundscheck(False)
@cython.wraparound(False)
cpdef float[:] cuda_gather(float[:] x, int[:] idx):
    cdef:
        GatherFunc Gather
        float timeTaken
        int N = idx.shape[0]
        int M = x.shape[0]
        float[:] res = np.zeros((N, ), dtype=np.float32)
    Gather = &lt;GatherFunc&gt;dlsym(handle, "Gather")
    timeTaken = Gather(&amp;x[0], &amp;idx[0], &amp;res[0], N, M)
    print (timeTaken)
    return res

while not True:
    dlclose(handle)
</code></pre>
<p>最后再通过Python模块调用（无需改动），输出结果为：</p>
<pre><code class="language-bash">0.6107839941978455
(1048576,)
1048576
</code></pre>
<p>这里的单位是ms。</p>
<h1 id="总结概要">总结概要</h1>
<p>这篇文章主要介绍了一个CUDA入门的技术：使用CUDA头文件写一个专门用于CUDA函数运行时长统计的宏，这样就可以统计目标Kernel函数的运行时长。可以直接在CUDA中打印相应的数值，也可以回传到Cython或者Python中进行打印。</p>
<h1 id="版权声明">版权声明</h1>
<p>本文首发链接为：<a href="https://www.cnblogs.com/dechinphy/p/cuda-time-record.html" target="_blank">https://www.cnblogs.com/dechinphy/p/cuda-time-record.html</a></p>
<p>作者ID：DechinPhy</p>
<p>更多原著文章：<a href="https://www.cnblogs.com/dechinphy/" target="_blank">https://www.cnblogs.com/dechinphy/</a></p>
<p>请博主喝咖啡：<a href="https://www.cnblogs.com/dechinphy/gallery/image/379634.html" target="_blank">https://www.cnblogs.com/dechinphy/gallery/image/379634.html</a></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.20388311372685186" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-28 09:45">2025-02-28 09:45</span>&nbsp;
<a href="https://www.cnblogs.com/dechinphy">DECHIN</a>&nbsp;
阅读(<span id="post_view_count">21</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18741585" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18741585);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18741585', targetLink: 'https://www.cnblogs.com/dechinphy/p/18741585/cuda-time-record', title: 'CUDA时长统计' })">举报</a>
</div>
        