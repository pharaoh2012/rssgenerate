
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/12lisu/p/18795510" title="发布于 2025-03-27 10:49">
    <span role="heading" aria-level="2">MQ 如何保证数据一致性？</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="前言">前言</h2>
<p>上个月，我们有个电商系统出了个灵异事件：用户支付成功了，但订单状态死活不改成“已发货”。</p>
<p>折腾了半天才定位到问题：订单服务的MQ消息，像人间蒸发一样消失了。</p>
<p>这个Bug让我明白：（MQ）消息队列的数据一致性设计，绝对能排进分布式系统三大噩梦之一！</p>
<p>今天这篇文章跟大家一起聊聊，MQ如何保证数据一致性？希望对你会有所帮助。</p>
<h2 id="1-数据一致性问题的原因">1 数据一致性问题的原因</h2>
<p>这些年在Kafka、RabbitMQ、RocketMQ踩过的坑，总结成四类致命原因：</p>
<ol>
<li><strong>生产者悲剧</strong>：消息成功进Broker，却没写入磁盘就断电。</li>
<li><strong>消费者悲剧</strong>：消息消费成功，但业务执行失败。</li>
<li><strong>轮盘赌局</strong>：网络抖动导致消息重复投递。</li>
<li><strong>数据孤岛</strong>：数据库和消息状态割裂（下完单没发券）</li>
</ol>
<p>这些情况，都会导致MQ产生数据不一致的问题。</p>
<p>那么，如何解决这些问题呢？</p>
<h2 id="2-消息不丢的方案">2 消息不丢的方案</h2>
<p>我们首先需要解决消息丢失的问题。</p>
<h3 id="21-事务消息的两阶段提交">2.1 事务消息的两阶段提交</h3>
<p>以RocketMQ的事务消息为例，工作原理就像双11的预售定金伪代码如下：</p>
<pre><code class="language-java">// 发送事务消息核心代码
TransactionMQProducer producer = new TransactionMQProducer("group");
producer.setTransactionListener(new TransactionListener() {
    // 执行本地事务（比如扣库存）
    public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
        return doBiz() ? LocalTransactionState.COMMIT : LocalTransactionState.ROLLBACK;
    }

    // Broker回调检查本地事务状态
    public LocalTransactionState checkLocalTransaction(MessageExt msg) {
        return checkDB(msg.getTransactionId()) ? COMMIT : ROLLBACK;
    }
});
</code></pre>
<p>真实场景中，别忘了在<code>checkLocalTransaction</code>里做好妥协查询（查流水表或分布式事务日志）。</p>
<p>去年在物流系统救火，就遇到过事务超时的坑——本地事务成功了，但因网络问题没收到Commit，导致Broker不断回查。</p>
<h3 id="22-持久化配置">2.2 持久化配置</h3>
<p>RabbitMQ的坑都在配置表里：</p>
<table>
<thead>
<tr>
<th>配置项</th>
<th>例子</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>队列持久化</td>
<td>durable=true</td>
<td>队列元数据不丢</td>
</tr>
<tr>
<td>消息持久化</td>
<td>deliveryMode=2</td>
<td>消息存入磁盘</td>
</tr>
<tr>
<td>Lazy Queue</td>
<td>x-queue-mode=lazy</td>
<td>消息直接写盘不读取进内存</td>
</tr>
<tr>
<td>Confirm机制</td>
<td>publisher-confirm-type</td>
<td>生产者确认消息投递成功</td>
</tr>
</tbody>
</table>
<p>RabbitMQ本地存储+备份交换机双重保护代码如下：</p>
<pre><code class="language-java">channel.queueDeclare("order_queue", true, false, false, 
    new HashMap&lt;String, Object&gt;(){{
        put("x-dead-letter-exchange", "dlx_exchange"); // 死信交换机
    }});
</code></pre>
<p>去年双十一订单系统就靠这个组合拳硬刚流量峰值：主队列消息积压触发阈值时，自动转移消息到备份队列给应急服务处理。</p>
<h3 id="23-副本配置">2.3 副本配置</h3>
<table>
<thead>
<tr>
<th>消息队列</th>
<th>保命绝招</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kafka</td>
<td>acks=all + 副本数≥3</td>
</tr>
<tr>
<td>RocketMQ</td>
<td>同步刷盘 + 主从同步策略</td>
</tr>
<tr>
<td>Pulsar</td>
<td>BookKeeper多副本存储</td>
</tr>
</tbody>
</table>
<p>上周帮一个金融系统迁移到Kafka，为了数据安全启用了最高配置。</p>
<p>server.properties配置如下：</p>
<pre><code class="language-yml">acks=all
min.insync.replicas=2
unclean.leader.election.enable=false
</code></pre>
<p>结果发现吞吐量只剩原来的三分之一，但客户说“钱比速度重要”——这一行哪有银弹，全是取舍。</p>
<p>不同的业务场景，情况不一样。</p>
<h2 id="3-应对重复消费的方案">3 应对重复消费的方案</h2>
<p>接下来，需要解决消息的重复消费问题。</p>
<h3 id="31-唯一id">3.1 唯一ID</h3>
<p>订单系统的架构课代表代码：</p>
<pre><code class="language-java">// 雪花算法生成全局唯一ID
Snowflake snowflake = new Snowflake(datacenterId, machineId);
String bizId = "ORDER_" + snowflake.nextId();

// 查重逻辑（Redis原子操作）
String key = "msg:" + bizId;
if(redis.setnx(key, "1")) {
    redis.expire(key, 72 * 3600);
    processMsg();
}
</code></pre>
<p>先使用雪花算法生成全局唯一ID，然后使用Redis的setnx命令加分布式锁，来保证请求的唯一性。</p>
<p>某次促销活动因Redis集群抖动，导致重复扣款。</p>
<p>后来改用：本地布隆过滤器+分布式Redis 双校验，总算解决这个世纪难题。</p>
<h3 id="32-幂等设计">3.2 幂等设计</h3>
<p>针对不同业务场景的三种对策：</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>代码示例</th>
<th>关键点</th>
</tr>
</thead>
<tbody>
<tr>
<td>强一致性</td>
<td>SELECT FOR UPDATE先查后更新</td>
<td>数据库行锁</td>
</tr>
<tr>
<td>最终一致性</td>
<td>版本号控制（类似CAS）</td>
<td>乐观锁重试3次</td>
</tr>
<tr>
<td>补偿型事务</td>
<td>设计反向操作（如退款、库存回滚）</td>
<td>操作日志必须落库</td>
</tr>
</tbody>
</table>
<p>去年重构用户积分系统时，就靠着这个三板斧把错误率从0.1%降到了0.001%：</p>
<p>积分变更幂等示例如下：</p>
<pre><code class="language-java">public void addPoints(String userId, String orderId, Long points) {
    if (pointLogDao.exists(orderId)) return;
    
    User user = userDao.selectForUpdate(userId); // 悲观锁
    user.setPoints(user.getPoints() + points);
    userDao.update(user);
    pointLogDao.insert(new PointLog(orderId)); // 幂等日志
}
</code></pre>
<p>这里使用了数据库行锁实现的幂等性。</p>
<h3 id="33-死信队列">3.3 死信队列</h3>
<p>RabbitMQ的终极保命配置如下：</p>
<pre><code class="language-java">// 消费者设置手动ACK
channel.basicConsume(queue, false, deliverCallback, cancelCallback);

// 达到重试上限后进入死信队列
public void process(Message msg) {
    try {
        doBiz();
        channel.basicAck(deliveryTag);
    } catch(Exception e) {
        if(retryCount &lt; 3) {
            channel.basicNack(deliveryTag, false, true);
        } else {
            channel.basicNack(deliveryTag, false, false); // 进入DLX
        }
    }
}
</code></pre>
<p>消费者端手动ACK消息。</p>
<p>在消费者端消费消息时，如果消费失败次数，达到重试上限后进入死信队列。</p>
<p>这个方案救了社交系统的推送服务——通过DLX收集全部异常消息，凌晨用补偿Job重跑。</p>
<h2 id="4-系统架构设计">4 系统架构设计</h2>
<p>接下来，从系统架构设计的角度，聊聊MQ要如何保证数据一致性？</p>
<h3 id="41-生产者端">4.1 生产者端</h3>
<p>对于实效性要求不太高的业务场景，可以使用：本地事务表+定时任务扫描的补偿方案。</p>
<p>流程图如下：<br>
<img src="https://files.mdnice.com/user/5303/0ccf1076-996c-43be-9e94-84498cceff28.png" alt="" loading="lazy"></p>
<h3 id="42-消费者端">4.2 消费者端</h3>
<p>消费者端为了防止消息风暴，要设置合理的并发消费线程数。</p>
<p>流程图如下：<br>
<img src="https://files.mdnice.com/user/5303/2bb0c977-9d9f-474e-b930-21d287453981.png" alt="" loading="lazy"></p>
<h3 id="43-终极方案">4.3 终极方案</h3>
<p>对于实时性要求比较高的业务场景，可以使用 事务消息+本地事件表 的黄金组合.</p>
<p>流程图如下：<br>
<img src="https://files.mdnice.com/user/5303/b575f681-601e-47f7-9d00-7d239b3d6ee9.png" alt="" loading="lazy"></p>
<h2 id="5-血泪经验十条">5 血泪经验十条</h2>
<ol>
<li><strong>消息必加唯一业务ID</strong>（别用MQ自带的ID）</li>
<li><strong>消费逻辑一定要幂等</strong>（重复消费是必然事件）</li>
<li><strong>数据库事务和消息发送必须二选一</strong>（或者用事务消息）</li>
<li><strong>消费者线程数不要超过分区数*2</strong>（Kafka的教训）</li>
<li><strong>死信队列必须加监控报警</strong>（别等客服找你）</li>
<li><strong>测试环境一定要模拟网络抖动</strong>（chaos engineering）</li>
<li><strong>消息体要兼容版本号</strong>（血的教训警告）</li>
<li><strong>不要用消息队列做业务主流程</strong>（它只配当辅助）</li>
<li><strong>消费者offset定时存库</strong>（防止重平衡丢消息）</li>
<li><strong>业务指标和MQ监控要联动</strong>（比如订单量和消息量的波动要同步）</li>
</ol>
<h2 id="总结">总结</h2>
<p>（MQ）消息队列像金融系统的SWIFT结算网络，看似简单实则处处杀机。</p>
<p>真正的高手不仅要会调参，更要设计出能兼容<strong>可靠性</strong>与<strong>性能</strong>的架构。</p>
<p>记住，分布式系统的数据一致性不是银弹，而是通过层层防御达成的动态平衡。</p>
<p>就像当年我在做资金结算系统时，老板说的那句震耳发聩的话：<strong>“宁可慢十秒，不可错一分”</strong>。</p>
<h2 id="最后说一句求关注别白嫖我">最后说一句(求关注，别白嫖我)</h2>
<p>如果这篇文章对您有所帮助，或者有所启发的话，帮忙关注一下我的同名公众号：苏三说技术，您的支持是我坚持写作最大的动力。</p>
<p>求一键三连：点赞、转发、在看。</p>
<p>关注公众号：【苏三说技术】，在公众号中回复：进大厂，可以免费获取我最近整理的10万字的面试宝典，好多小伙伴靠这个宝典拿到了多家大厂的offer。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.5625927728912037" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-03-27 10:50">2025-03-27 10:49</span>&nbsp;
<a href="https://www.cnblogs.com/12lisu">苏三说技术</a>&nbsp;
阅读(<span id="post_view_count">297</span>)&nbsp;
评论(<span id="post_comment_count">1</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18795510" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18795510);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18795510', targetLink: 'https://www.cnblogs.com/12lisu/p/18795510', title: 'MQ 如何保证数据一致性？' })">举报</a>
</div>
        