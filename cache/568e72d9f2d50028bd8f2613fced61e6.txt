
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/dechinphy/p/18703831/deepseek3" title="发布于 2025-02-08 15:16">
    <span role="heading" aria-level="2">DeepSeek部署本地知识库</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        <img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208151543985-1121092440.png" alt="DeepSeek部署本地知识库" class="desc_img">
        大模型之大，可以训练我们所有人日常生活学习工作可能使用到的所有知识。但是完整的大模型，要实现一个本地化的部署，可能是有点困难，因此才有了大模型的蒸馏技术。蒸馏之后大模型可能会损失大多数的行业知识，而我们可以通过本地知识库构建的方法，在本地构建一个私有的专业大模型。
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="技术背景">技术背景</h1>
<p>在前面的两篇文章中，分别介绍过<a href="https://www.cnblogs.com/dechinphy/p/18699554/deepseek" target="_blank">Ubuntu上关于DeepSeek的部署</a>以及<a href="https://www.cnblogs.com/dechinphy/p/18702523/deepseek2" target="_blank">Windows平台关于DeepSeek的部署</a>。其中内容包含了Ollama的下载安装和基本使用、DeepSeek模型文件的下载，以及使用ChatBox导入Ollama本地模型进行本地对话的方法。这里再介绍一个使用AnythingLLM构建本地知识库的方法，本地知识库跟ChatBox两种对话模式的主要不同点在于，ChatBox对话中输入给大模型的其实是上下N条对话的内容，而本地知识库是先给大模型输入本地一系列的文件内容，然后再进行对话，这就是大模型领域专业化的一个重要应用。</p>
<h1 id="下载安装anythingllm">下载安装AnythingLLM</h1>
<p>这里我们仅介绍Windows平台的方案，首先访问<a href="https://anythingllm.com/desktop" target="_blank" rel="noopener nofollow">AnythingLLM官网</a>，找到一个适合自己本地环境的版本下载，Windows系统就直接安装就可以了：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208111040848-219354428.png">
</div>
<p>由于安装过程中有可能要联网下载一些库，所以不能离线安装，而且要耗费一些时间。</p>
<h1 id="anythingllm本地工作区配置">AnythingLLM本地工作区配置</h1>
<p>安装完成后打开界面是这样的：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121638853-1352550404.png">
</div>
<p>选择第一个，点击<code>-&gt;</code>进入下一步：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121646571-1406565187.png">
</div>
<p>中间可能还要填一些邮箱用途之类的，没什么影响，按情况填写然后继续点击<code>-&gt;</code>进入下一步：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121652822-396699820.png">
</div>
<p>输入工作区名称，就创建完成了：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121721725-1982836044.png">
</div>
<p>我感觉这个对话框还是比ChatBox简洁很多，看个人吧，喜欢哪个就用哪个。</p>
<h1 id="anythingllm模型配置">AnythingLLM模型配置</h1>
<p>点击左下角的扳手图标，先配置一些基本参数：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121732672-1989581721.png">
</div>
<p>模型配置在<code>LLM首选项</code>里边：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121738372-1339279207.png">
</div>
<p>选择Ollama，然后剩下的按照自己的本地情况进行配置：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121745421-172576660.png">
</div>
<p>这里稍有点不同的是，ChatBox里面配置远程IP的时候，可以直接用<code>xxx.xxx.xxx.xxx:11434</code>这样的形式。但是在AnythingLLM里面配置远程ip的话，需要加上http，也就是<code>http://xxx.xxx.xxx.xxx:11434</code>这样的形式。然后就可以进入到聊天窗口，这里再修改一下工作区的模型配置：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121806171-1635148468.png">
</div>
<p>这里就可以看到对应IP下的所有本地模型，配置完成后就可以开始对话了：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121811348-1554255832.png">
</div>
<h1 id="工作区上传知识库文档">工作区上传知识库文档</h1>
<p>在工作区那里有两个按钮，一个是上面一个章节用到的模型配置按钮，还有一个就是上传知识库文档的按钮了，点击可以进入这样的一个界面：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121816643-1032203090.png">
</div>
<p>可以本地打开一个文件夹，把相应的文件拖到左下角那朵云上面，就上传到临时交换区了。这里还可以把网页链接输进去，也是直接同步到交换区。在传完文件之后，在交换区选择需要传输到工作区里面的文件，点击<code>Move To Workspace</code>就可以把所有选中的文件传到工作区里面了。这里还没结束，需要再点击一个<code>Save and Embed</code>同步到工作区中，这需要一点点解析的时间。传输完成后，可以在右侧工作区的文件面板上看到传输过来的文件，包含网页内容：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121820539-1923037228.png">
</div>
<p>这样就可以构建属于自己专业领域的本地知识库了，相当于让DeepSeek的模型学习一遍这些传进去的文档。</p>
<h1 id="应用场景">应用场景</h1>
<p>这里只是做一个简单的演示。我先在一个空白的工作区里面提问：“什么是mindsponge”。这个问题对于模型来说可能会有点陌生，因为它学习到的数据里面可能没有这个工具，所以它的回答也是不知所云：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208144907225-578319532.png">
</div>
<p>但是当我把之前写过的一些<a href="https://www.cnblogs.com/dechinphy/collections/5620" target="_blank">关于mindsponge的博客</a>传上去之后，再问一遍“什么是mindsponge”，它的回答是这样的：</p>
<div align="center">
	<img src="https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208141747295-2104397942.png">
</div>
<p>相对来说信息就准确了很多，可以认为大模型从本地的知识库里面学习到了行业相关内容，这就完成了一个大模型+专业领域知识库的构建。</p>
<h1 id="提示">提示</h1>
<p>这里提供1条可能有用的提示：载入新的知识库文件之后，最好reset一下对话，发送一个<code>/reset</code>即可。</p>
<h1 id="总结概要">总结概要</h1>
<p>大模型之大，可以训练我们所有人日常生活学习工作可能使用到的所有知识。但是完整的大模型，要实现一个本地化的部署，可能是有点困难，因此才有了大模型的蒸馏技术。蒸馏之后大模型可能会损失大多数的行业知识，而我们可以通过本地知识库构建的方法，在本地构建一个私有的专业大模型。</p>
<h1 id="版权声明">版权声明</h1>
<p>本文首发链接为：<a href="https://www.cnblogs.com/dechinphy/p/deepseek3.html" target="_blank">https://www.cnblogs.com/dechinphy/p/deepseek3.html</a></p>
<p>作者ID：DechinPhy</p>
<p>更多原著文章：<a href="https://www.cnblogs.com/dechinphy/" target="_blank">https://www.cnblogs.com/dechinphy/</a></p>
<p>请博主喝咖啡：<a href="https://www.cnblogs.com/dechinphy/gallery/image/379634.html" target="_blank">https://www.cnblogs.com/dechinphy/gallery/image/379634.html</a></p>
<h1 id="参考链接">参考链接</h1>
<ol>
<li><a href="https://readdevdocs.com/blog/ai/%E5%A6%82%E4%BD%95%E7%94%A8DeepSeek%20R1%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E5%BA%93%EF%BC%9F.html#%E5%89%8D%E8%A8%80" target="_blank" rel="noopener nofollow">https://readdevdocs.com/blog/ai/如何用DeepSeek R1搭建个人知识库？.html#前言</a></li>
</ol>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.040755250733796294" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-08 15:18">2025-02-08 15:16</span>&nbsp;
<a href="https://www.cnblogs.com/dechinphy">DECHIN</a>&nbsp;
阅读(<span id="post_view_count">177</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18703831" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18703831);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18703831', targetLink: 'https://www.cnblogs.com/dechinphy/p/18703831/deepseek3', title: 'DeepSeek部署本地知识库' })">举报</a>
</div>
        