
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/flyup/p/18975971" title="发布于 2025-07-10 00:03">
    <span role="heading" aria-level="2">深度学习模型在C++平台的部署</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="一概述">一、概述</h2>
<p>  深度学习模型能够在各种生产场景中发挥重要的作用，而深度学习模型往往在Python环境下完成训练，因而训练好的模型如何在生产环境下实现稳定可靠的部署，便是一个重要内容。C++开发平台广泛存在于各种复杂的生产环境，随着业务效能需求的不断提高，充分运用深度学习技术的优势显得尤为重要。本文介绍如何实现将深度学习模型部署在C++平台上。</p>
<h2 id="二步骤">二、步骤</h2>
<p>  s1. Python环境中安装深度学习框架（如PyTorch、TensorFlow等）；</p>
<p>  s2. P	ython环境中设计并训练深度学习模型；</p>
<p>  s3. 将训练好的模型保存为.onnx格式的模型文件；</p>
<p>  s4. C++环境中安装Microsoft.ML.OnnxRuntime程序包；<br>
  （Visual Studio 2022中可通过项目-&gt;管理NuGet程序包完成快捷安装）</p>
<p>  s5. C++环境中加载模型文件，完成功能开发。</p>
<h2 id="三示例">三、示例</h2>
<p>  在Python环境下设计并训练一个关于手写数字识别的卷积神经网络（CNN）模型，将模型导出为ONNX格式的文件，然后在C++环境下完成对模型的部署和推理。</p>
<h3 id="1-python训练和导出">1. Python训练和导出</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.functional import F

# 定义简单的CNN模型
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(32 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 32 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# 数据预处理
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# 加载训练数据
train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)

# 初始化模型、损失函数和优化器
model = SimpleCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练模型
def train(model, train_loader, criterion, optimizer, epochs=5):
    model.train()
    for epoch in range(epochs):
        running_loss = 0.0
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')

# 训练模型
train(model, train_loader, criterion, optimizer)

# 导出为ONNX格式
dummy_input = torch.randn(1, 1, 28, 28)
torch.onnx.export(
    model,
    dummy_input,
    "mnist_model.onnx",
    export_params=True,
    opset_version=11,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
)

print("模型已成功导出为mnist_model.onnx")


</code></pre>
<p><img alt="图片1" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2197714/202507/2197714-20250710000115543-1785478278.png" class="lazyload"></p>
<h3 id="2-c-部署和推理">2. C++ 部署和推理</h3>
<pre><code class="language-cpp">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;onnxruntime_cxx_api.h&gt;

int main() {
    // 初始化环境
    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, "MNIST");
    Ort::SessionOptions session_options;
    session_options.SetIntraOpNumThreads(1);
    session_options.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);


    // 加载模型
    std::wstring model_path = L"mnist_model.onnx";
    Ort::Session session(env, model_path.c_str(), session_options);


    // 准备输入
    std::vector&lt;int64_t&gt; input_shape = { 1, 1, 28, 28 };
    size_t input_tensor_size = 28 * 28;
    std::vector&lt;float&gt; input_tensor_values(input_tensor_size);
    

    // 读取测试图片
    cv::Mat test_image = cv::imread("test.jpg", cv::IMREAD_GRAYSCALE);         

    // 将Mat数据复制到vector中
    for (int i = 0; i &lt; test_image.rows; ++i) {
        for (int j = 0; j &lt; test_image.cols; ++j) {
            input_tensor_values[i * test_image.cols + j] = static_cast&lt;float&gt;(test_image.at&lt;uchar&gt;(i, j)); // 注意：uchar是unsigned char的缩写，表示无符号字符，通常用于存储灰度值
        }
    }
 

    // 创建输入张量
    auto memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
    Ort::Value input_tensor = Ort::Value::CreateTensor&lt;float&gt;(
        memory_info, input_tensor_values.data(), input_tensor_size, input_shape.data(), 4);

    // 设置输入输出名称
    std::vector&lt;const char*&gt; input_names;
    std::vector&lt;const char*&gt; output_names;
    input_names.push_back(session.GetInputNameAllocated(0, Ort::AllocatorWithDefaultOptions()).get());
    output_names.push_back(session.GetOutputNameAllocated(0, Ort::AllocatorWithDefaultOptions()).get());

    // 运行推理
    auto output_tensors = session.Run(
        Ort::RunOptions{ nullptr },
        input_names.data(),
        &amp;input_tensor,
        1,
        output_names.data(),
        1);

    // 获取输出结果
    float* output = output_tensors[0].GetTensorMutableData&lt;float&gt;();
    std::vector&lt;float&gt; results(output, output + 10);

    // 找到预测的数字
    int predicted_digit = 0;
    float max_probability = results[0];
    for (int i = 1; i &lt; 10; i++) {
        if (results[i] &gt; max_probability) {
            max_probability = results[i];
            predicted_digit = i;
        }
    }

    std::cout &lt;&lt; "预测结果: " &lt;&lt; predicted_digit &lt;&lt; std::endl;
    std::cout &lt;&lt; "置信度分布:" &lt;&lt; std::endl;
    for (int i = 0; i &lt; 10; i++) {
        std::cout &lt;&lt; "数字 " &lt;&lt; i &lt;&lt; ": " &lt;&lt; results[i] &lt;&lt; std::endl;
    }

    return 0;
}


</code></pre>
<p><strong>测试图片：</strong><br>
<img alt="test" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2197714/202507/2197714-20250710000155737-1321831207.jpg" class="lazyload"></p>
<p><strong>程序运行：</strong><br>
<img alt="图片2" loading="lazy" data-src="https://img2024.cnblogs.com/blog/2197714/202507/2197714-20250710000226452-95675573.png" class="lazyload"></p>
<br>
<br>
<p><em><strong>End.</strong></em></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-07-10 00:04">2025-07-10 00:03</span>&nbsp;
<a href="https://www.cnblogs.com/flyup">归去_来兮</a>&nbsp;
阅读(<span id="post_view_count">22</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18975971);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18975971', targetLink: 'https://www.cnblogs.com/flyup/p/18975971', title: '深度学习模型在C++平台的部署' })">举报</a>
</div>
        