
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/wjw2003512/p/19035691" title="发布于 2025-08-13 14:20">
    <span role="heading" aria-level="2">Kafka2.13-3.3.2 安装部署+最后报错处理全过程（CentOS 7 虚拟机）</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="查看环境寻找安装包">查看环境，寻找安装包</h2>
<h3 id="官网寻找安装包">官网寻找安装包</h3>
<ol>
<li>
<p>打开官方“存档”页面<br>
3.3 系列已从首页的 <strong>Supported</strong> 区域下架，进入了 <strong>Archived releases</strong>。<br>
直接访问：<a href="https://kafka.apache.org/downloads" target="_blank" rel="noopener nofollow">https://kafka.apache.org/downloads</a><br>
在页面最下方 “Archived releases” 区域即可看到</p>
<pre><code>3.3.2
3.3.1
3.3.0
</code></pre>
<p>任选其一即可下载，例如：</p>
<pre><code>kafka_2.13-3.3.2.tgz  (asc, sha512)
</code></pre>
</li>
<li>
<p>校验文件（官方唯一验证方法）<br>
① 下载同名的 <code>.sha512</code> 文件</p>
<pre><code class="language-bash">wget https://archive.apache.org/dist/kafka/3.3.2/kafka_2.13-3.3.2.tgz.sha512
</code></pre>
<p>② Linux/Mac 终端执行</p>
<pre><code class="language-bash">sha512sum -c kafka_2.13-3.3.2.tgz.sha512
</code></pre>
<p>输出 <code>OK</code> 即通过验证。</p>
</li>
</ol>
<p>附：官方 3.3 文档固定入口<br>
<a href="https://kafka.apache.org/33/documentation.html" target="_blank" rel="noopener nofollow">https://kafka.apache.org/33/documentation.html</a></p>
<h3 id="版本选择要求高可用">版本选择，要求高可用</h3>
<p>一句话结论<br>
<strong>只用 3.3.2（Scala 2.13 版）</strong>，不要再纠结 3.3.0/3.3.1；单机 CentOS 7 也能跑“伪分布式三副本”，只是<strong>三副本≠高可用</strong>——一台虚拟机挂了所有副本一起挂。下面给你完整可落地的“单机 3.3.2 三副本”步骤，先跑通，再考虑以后多机扩展。</p>
<hr>
<p>一、3.3.2 为什么更合适</p>
<ol>
<li>3.3.2 是 3.3 线的最后一个补丁版，修掉 20 个 bug（含潜在数据丢失/稳定性问题）。</li>
<li>Scala 2.13 比 2.12 体积小一点点，官方也写 <strong>“建议使用 2.13”</strong>。</li>
<li>以后真要扩容到多机，同一版本直接复制配置即可，避免混版本。</li>
</ol>
<hr>
<p>二、CentOS 7 单机跑“伪分布式 3 副本”思路</p>
<ul>
<li>用同一台机器开 <strong>3 个 Kafka 进程</strong>，每个进程一个 <code>broker.id</code> 和独立端口/目录，Zookeeper 仍用同一实例。</li>
<li>只能<strong>验证功能/调试用</strong>，真正高可用必须 ≥3 台物理机。</li>
</ul>
<hr>
<p>三、10 分钟落地步骤</p>
<ol>
<li>
<p>前置依赖</p>
<pre><code class="language-bash">sudo yum install -y java-11-openjdk-devel wget
java -version   # 确认 11+
</code></pre>
</li>
<li>
<p>目录规划</p>
<pre><code class="language-bash">sudo mkdir -p /opt/kafka-cluster
cd /opt/kafka-cluster
</code></pre>
</li>
<li>
<p>下载并解压 3.3.2</p>
<pre><code class="language-bash">wget https://archive.apache.org/dist/kafka/3.3.2/kafka_2.13-3.3.2.tgz
tar -xzf kafka_2.13-3.3.2.tgz
mv kafka_2.13-3.3.2 kafka
# 建 3 份配置
cp -r kafka kafka-1 kafka-2 kafka-3
</code></pre>
</li>
<li>
<p>起 Zookeeper（单节点）</p>
<pre><code class="language-bash"># 用自带脚本即可
nohup kafka/bin/zookeeper-server-start.sh kafka/config/zookeeper.properties &gt; zk.log 2&gt;&amp;1 &amp;
</code></pre>
</li>
<li>
<p>为 3 个 broker 准备配置文件<br>
把下面三段分别写进 <code>kafka-1/config/server.properties</code>、<code>kafka-2/config/server.properties</code>、<code>kafka-3/config/server.properties</code>，只改差异项：</p>
<table>
<thead>
<tr>
<th>配置项</th>
<th>broker 1</th>
<th>broker 2</th>
<th>broker 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>broker.id</td>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>listeners</td>
<td>PLAINTEXT://:9092</td>
<td>PLAINTEXT://:9093</td>
<td>PLAINTEXT://:9094</td>
</tr>
<tr>
<td>log.dirs</td>
<td>/tmp/kafka-logs-1</td>
<td>/tmp/kafka-logs-2</td>
<td>/tmp/kafka-logs-3</td>
</tr>
<tr>
<td>zookeeper.connect</td>
<td>localhost:2181</td>
<td>localhost:2181</td>
<td>localhost:2181</td>
</tr>
</tbody>
</table>
<p>其余保持默认即可。</p>
</li>
<li>
<p>启动 3 个 broker</p>
<pre><code class="language-bash">nohup kafka-1/bin/kafka-server-start.sh kafka-1/config/server.properties &gt; k1.log 2&gt;&amp;1 &amp;
nohup kafka-2/bin/kafka-server-start.sh kafka-2/config/server.properties &gt; k2.log 2&gt;&amp;1 &amp;
nohup kafka-3/bin/kafka-server-start.sh kafka-3/config/server.properties &gt; k3.log 2&gt;&amp;1 &amp;
</code></pre>
</li>
<li>
<p>验证 3 副本 topic</p>
<pre><code class="language-bash"># 建 topic，3 副本 3 分区
kafka/bin/kafka-topics.sh --create --topic test-ha \
  --bootstrap-server localhost:9092 \
  --partitions 3 --replication-factor 3

# 查看分区分布
kafka/bin/kafka-topics.sh --describe --topic test-ha --bootstrap-server localhost:9092
</code></pre>
<p>应当看到每个分区都有 <code>Leader</code>, <code>Replicas: 1,2,3</code>, <code>Isr: 1,2,3</code>。</p>
</li>
<li>
<p>简单生产/消费测试</p>
<pre><code class="language-bash"># 生产
kafka/bin/kafka-console-producer.sh --topic test-ha --bootstrap-server localhost:9092
# 消费
kafka/bin/kafka-console-consumer.sh --topic test-ha --bootstrap-server localhost:9092 --from-beginning
</code></pre>
</li>
</ol>
<hr>
<p>四、单机“三副本”的局限</p>
<ul>
<li>高可用：❌ 一台机器挂了，三个进程一起死。</li>
<li>功能验证：✅ 可以跑通多副本、Leader 切换、ISR 列表变化。</li>
<li>后续扩容：把配置里的 <code>listeners</code> 改成各自主机名/IP，<code>log.dirs</code> 换成独立磁盘即可。</li>
</ul>
<hr>
<p>一句话总结<br>
<strong>下载 kafka_2.13-3.3.2.tgz，单机起 3 个 broker 就能跑 3 副本测试</strong>；真正高可用还需再加两台机器。</p>
<p>注：<code>/usr/local</code> 是给“<strong>本地手工编译</strong>”或“<strong>包管理器之外的系统级软件</strong>”留的；Kafka 官方只提供二进制压缩包，解压即用，既不属于系统自带，也不走 <code>make install</code>，所以社区习惯放到 <code>/opt</code>（<strong>专门放大型第三方独立软件</strong>），避免日后系统升级或包管理器误碰。</p>
<h2 id="安装和部署">安装和部署</h2>
<p>下面给你一份<strong>面向 CentOS 7、虚拟机单机</strong>的“一行不落”复制粘贴教程。<br>
目标目录：<code>/opt/kafka3.3.2</code><br>
源包路径：<code>/root/kafka_2.13-3.3.2.tgz</code></p>
<hr>
<h3 id="一提前确认">一、提前确认</h3>
<pre><code class="language-bash">java -version   # 需 11 以上

#输出
[root@localhost redis6.2.14]# java -version
java version "17.0.15" 2025-04-15 LTS
Java(TM) SE Runtime Environment (build 17.0.15+9-LTS-241)
Java HotSpot(TM) 64-Bit Server VM (build 17.0.15+9-LTS-241, mixed mode, sharing)
[root@localhost redis6.2.14]#
</code></pre>
<hr>
<h3 id="二解压并更名">二、解压并更名</h3>
<pre><code class="language-bash">sudo mkdir -p /opt/kafka3.3.2
sudo tar -xzf /root/kafka_2.13-3.3.2.tgz -C /opt/kafka3.3.2 --strip-components=1
</code></pre>
<p>解压后目录结构应为：<br>
<code>/opt/kafka3.3.2/bin</code><br>
<code>/opt/kafka3.3.2/config</code><br>
…</p>
<hr>
<h3 id="三建数据--日志目录">三、建数据 / 日志目录</h3>
<pre><code class="language-bash">sudo mkdir -p /opt/kafka3.3.2/data/zookeeper
sudo mkdir -p /opt/kafka3.3.2/data/kafka-logs-1 \
               /opt/kafka3.3.2/data/kafka-logs-2 \
               /opt/kafka3.3.2/data/kafka-logs-3
sudo chown -R $USER:$USER /opt/kafka3.3.2
</code></pre>
<hr>
<h3 id="四zookeeper-单节点配置">四、Zookeeper 单节点配置</h3>
<pre><code class="language-bash">cp /opt/kafka3.3.2/config/zookeeper.properties /opt/kafka3.3.2/config/zookeeper.properties.bak
</code></pre>
<p>编辑 <code>/opt/kafka3.3.2/config/zookeeper.properties</code> 只改两项（其余默认）：</p>
<pre><code>dataDir=/opt/kafka3.3.2/data/zookeeper
clientPort=2181
</code></pre>
<hr>
<h3 id="五准备-3-份-broker-配置">五、准备 3 份 broker 配置</h3>
<pre><code class="language-bash">for i in 1 2 3; do
  cp /opt/kafka3.3.2/config/server.properties /opt/kafka3.3.2/config/server-$i.properties
done
</code></pre>
<p>分别编辑 3 个文件，只改以下 4 行（操作在之后代码块）：</p>
<table>
<thead>
<tr>
<th>文件</th>
<th>broker.id</th>
<th>listeners</th>
<th>log.dirs</th>
<th>advertised.listeners</th>
</tr>
</thead>
<tbody>
<tr>
<td>server-1.properties</td>
<td>1</td>
<td>PLAINTEXT://:9092</td>
<td>/opt/kafka3.3.2/data/kafka-logs-1</td>
<td>PLAINTEXT://localhost:9092</td>
</tr>
<tr>
<td>server-2.properties</td>
<td>2</td>
<td>PLAINTEXT://:9093</td>
<td>/opt/kafka3.3.2/data/kafka-logs-2</td>
<td>PLAINTEXT://localhost:9093</td>
</tr>
<tr>
<td>server-3.properties</td>
<td>3</td>
<td>PLAINTEXT://:9094</td>
<td>/opt/kafka3.3.2/data/kafka-logs-3</td>
<td>PLAINTEXT://localhost:9094</td>
</tr>
</tbody>
</table>
<p>其余保持默认（尤其 <code>zookeeper.connect=localhost:2181</code>）。</p>
<p>不需要手动打开图形编辑器。<br>
用一条 sed 或 echo 命令就能一次改好，下面给出复制即用的三行脚本，把 4 个关键配置一次性写入对应文件：</p>
<p>下面给出一次可直接复制/粘贴的 <strong>修正版脚本</strong>，并逐条指出与旧脚本的区别。</p>
<hr>
<p>可直接执行的脚本（已修复换行/引号问题）</p>
<pre><code class="language-bash"># 1 号 broker
sed -ri \
  -e 's/^broker.id=.*/broker.id=1/' \
  -e 's|^listeners[[:space:]]*=.*|listeners=PLAINTEXT://:9092|' \
  -e 's|^log.dirs[[:space:]]*=.*|log.dirs=/opt/kafka3.3.2/data/kafka-logs-1|' \
  -e 's|^#?advertised.listeners[[:space:]]*=.*|advertised.listeners=PLAINTEXT://localhost:9092|' \
  /opt/kafka3.3.2/config/server-1.properties

# 2 号 broker
sed -ri \
  -e 's/^broker.id=.*/broker.id=2/' \
  -e 's|^listeners[[:space:]]*=.*|listeners=PLAINTEXT://:9093|' \
  -e 's|^log.dirs[[:space:]]*=.*|log.dirs=/opt/kafka3.3.2/data/kafka-logs-2|' \
  -e 's|^#?advertised.listeners[[:space:]]*=.*|advertised.listeners=PLAINTEXT://localhost:9093|' \
  /opt/kafka3.3.2/config/server-2.properties

# 3 号 broker
sed -ri \
  -e 's/^broker.id=.*/broker.id=3/' \
  -e 's|^listeners[[:space:]]*=.*|listeners=PLAINTEXT://:9094|' \
  -e 's|^log.dirs[[:space:]]*=.*|log.dirs=/opt/kafka3.3.2/data/kafka-logs-3|' \
  -e 's|^#?advertised.listeners[[:space:]]*=.*|advertised.listeners=PLAINTEXT://localhost:9094|' \
  /opt/kafka3.3.2/config/server-3.properties
</code></pre>
<hr>
<p>与旧脚本的区别逐条说明（注意之前的报错，因为出现转义字符的问题，上面代码已经修改过。）</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>旧问题</th>
<th>修正做法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>单引号里跨行反斜杠续行</td>
<td>直接拆成 <strong>多段 <code>-e</code> 表达式</strong></td>
<td>避免 <code>sed</code> 报 “未终止的正则”</td>
</tr>
<tr>
<td>2</td>
<td>分隔符 <code>/</code> 与路径 <code>/opt/...</code> 冲突</td>
<td>统一用 `</td>
<td>` 作分隔符</td>
</tr>
<tr>
<td>3</td>
<td>正则 <code>^listeners=.*</code> 可能匹配不到空格</td>
<td>写成 <code>^listeners[[:space:]]*=</code></td>
<td>兼容 <code>key=value</code> 或 <code>key = value</code></td>
</tr>
<tr>
<td>4</td>
<td>只处理 <code>#advertised.listeners</code> 的注释行</td>
<td>改成 <code>#?</code></td>
<td>同时匹配已取消注释或仍注释的行</td>
</tr>
<tr>
<td>5</td>
<td>无 <code>-r</code> 扩展正则</td>
<td>加 <code>-r</code>（GNU sed）</td>
<td>让 <code>?</code>、`</td>
</tr>
</tbody>
</table>
<p>把上面脚本一次性粘进终端即可，无需再手工编辑。</p>
<p>执行完后，三份配置就全部改好，无需再打开任何编辑器。</p>
<hr>
<h3 id="六创建并启动脚本一次性复制即可用">六、创建并启动脚本（一次性复制即可用）</h3>
<p>​	下面给你一条命令一条命令的「复制-粘贴」版完整步骤，连脚本内容都帮你一次性生成，<strong>不用手写</strong>，跟着敲即可。</p>
<hr>
<h3 id="-一键生成启动脚本包含全部内容">① 一键生成启动脚本（包含全部内容）</h3>
<pre><code class="language-bash">cat &gt; ~/start-kafka.sh &lt;&lt;'EOF'  #这一步直接是创建脚本，就是把下面的代码保存成脚本'~/start-kafka.sh'
#!/bin/bash
# 启动 Zookeeper
nohup /opt/kafka3.3.2/bin/zookeeper-server-start.sh \
  -daemon /opt/kafka3.3.2/config/zookeeper.properties \
  &gt; /opt/kafka3.3.2/zk.log 2&gt;&amp;1 &amp;

sleep 5   # 等 Zookeeper 完全起来

# 启动 3 个 broker
for i in 1 2 3; do
  nohup /opt/kafka3.3.2/bin/kafka-server-start.sh \
    -daemon /opt/kafka3.3.2/config/server-$i.properties \
    &gt; /opt/kafka3.3.2/broker-$i.log 2&gt;&amp;1 &amp;
done

echo "Zookeeper + 3 brokers started. Logs under /opt/kafka3.3.2/"
EOF
</code></pre>
<hr>
<h3 id="-赋可执行权限">② 赋可执行权限</h3>
<pre><code class="language-bash">chmod +x ~/start-kafka.sh
</code></pre>
<hr>
<h3 id="-运行脚本">③ 运行脚本</h3>
<pre><code class="language-bash">~/start-kafka.sh

#运行结果
Zookeeper + 3 brokers started. Logs under /opt/kafka3.3.2/#
</code></pre>
<hr>
<h3 id="-验证是否都起来了">④ 验证是否都起来了</h3>
<pre><code class="language-bash">jps | egrep 'QuorumPeerMain|Kafka'
</code></pre>
<p>应看到 1 个 <code>QuorumPeerMain</code>（Zookeeper）+ 3 个 <code>Kafka</code> 进程。</p>
<pre><code class="language-bash">#运行结果（有偏差）
27940 Kafka
26891 QuorumPeerMain
</code></pre>
<h4 id="有偏差你只看到-1-个-kafka-进程说明-3-个-broker-并没有全部成功启动后面有我的解决和修改过程可以直接跳过你也可以在这里逐步排查可能问题不一样">有偏差：你只看到 1 个 <code>Kafka</code> 进程，说明 3 个 broker 并没有全部成功启动（后面有我的解决和修改过程可以直接跳过，你也可以在这里逐步排查，可能问题不一样）</h4>
<p>你只看到 1 个 <code>Kafka</code> 进程，说明 3 个 broker 并没有全部成功启动。</p>
<p>按下面 3 步排查并一次性修复：</p>
<hr>
<ol>
<li>立即查日志定位原因  ，然后这里我的是空目录</li>
</ol>
<pre><code class="language-bash"># 看看每个 broker 日志末尾 20 行
tail -n 20 /opt/kafka3.3.2/broker-*.log
</code></pre>
<p>常见报错：端口被占用、目录权限不足、<code>log.dirs</code> 不存在、JMX 端口冲突等。</p>
<hr>
<ol start="2">
<li>一键补齐缺失目录 &amp; 权限</li>
</ol>
<pre><code class="language-bash">mkdir -p /opt/kafka3.3.2/data/{kafka-logs-1,kafka-logs-2,kafka-logs-3}
chown -R $(whoami):$(whoami) /opt/kafka3.3.2
</code></pre>
<hr>
<ol start="3">
<li>先停后启（干净重启）</li>
</ol>
<pre><code class="language-bash"># 如果还有残存进程
pkill -f 'kafka\.Kafka'    # 杀 Kafka
pkill -f QuorumPeerMain    # 杀 Zookeeper

# 重新启动
~/start-kafka.sh

# 再验证
sleep 5
jps | egrep 'QuorumPeerMain|Kafka'
</code></pre>
<p>正常应看到 1 个 <code>QuorumPeerMain</code> + 3 个 <code>Kafka</code>。</p>
<hr>
<p>如果日志里出现 <strong>“Address already in use”</strong><br>
说明 9092/9093/9094 端口被系统占用，改脚本里的端口即可；<br>
如果日志里出现 <strong>“No space left on device”</strong> 或 <strong>权限 denied</strong>，就回到第 2 步继续修正目录/权限。</p>
<hr>
<h4 id="下面是我的解决过程梳理和总结">下面是我的解决过程梳理和总结</h4>
<p>【一句话总结错误原因】<br>
<strong>“9092 被旧 broker 死死占着，导致 2、3 号 broker 起不来；把旧进程杀掉、把 3 台 broker 端口一次性改成 9191/9192/9193，再清掉 .lock 文件，就彻底 OK。”</strong></p>
<hr>
<h3 id="1完整报错链路按时间线">1、完整报错链路（按时间线）</h3>
<table>
<thead>
<tr>
<th>时间</th>
<th>现象</th>
<th>根因</th>
<th>日志关键行</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>T0</strong></td>
<td><code>jps</code> 只有 1 个 Kafka</td>
<td>2、3 号没起来</td>
<td>—</td>
</tr>
<tr>
<td><strong>T1</strong></td>
<td><code>broker-2.log</code> 报错</td>
<td><strong>端口 9092 被占用</strong></td>
<td><code>Socket server failed to bind to 0.0.0.0:9092: 地址已在使用</code></td>
</tr>
<tr>
<td><strong>T2</strong></td>
<td><code>ls -l /opt/kafka3.3.2/data</code> 目录缺</td>
<td><strong>log.dirs 没提前建</strong></td>
<td>—</td>
</tr>
<tr>
<td><strong>T3</strong></td>
<td><code>.lock</code> 已存在</td>
<td><strong>旧进程没停干净</strong></td>
<td><code>Failed to acquire lock on file .lock</code></td>
</tr>
</tbody>
</table>
<hr>
<h3 id="2修复步骤复制即用">2、修复步骤（复制即用）</h3>
<ol>
<li><strong>杀干净所有残留进程</strong></li>
</ol>
<pre><code class="language-bash">pkill -9 -f 'kafka\.Kafka'
pkill -f QuorumPeerMain
</code></pre>
<ol start="2">
<li><strong>一次性建目录 + 删 .lock</strong></li>
</ol>
<pre><code class="language-bash">mkdir -p /opt/kafka3.3.2/data/{kafka-logs-1,kafka-logs-2,kafka-logs-3}
chown -R $(whoami):$(whoami) /opt/kafka3.3.2/data
for i in 1 2 3; do rm -f /opt/kafka3.3.2/data/kafka-logs-$i/.lock; done
</code></pre>
<ol start="3">
<li><strong>把 3 份配置端口全部改成 9191/9192/9193</strong></li>
</ol>
<pre><code class="language-bash">for i in 1 2 3; do
  port=$((9190+i))
  cfg="/opt/kafka3.3.2/config/server-$i.properties"
  sed -ri \
    -e "s#^listeners[[:space:]]*=.*#listeners=PLAINTEXT://:${port}#" \
    -e "s#^advertised.listeners[[:space:]]*=.*#advertised.listeners=PLAINTEXT://localhost:${port}#" \
    -e "s#^broker.id[[:space:]]*=.*#broker.id=$i#" \
    "$cfg"
done
</code></pre>
<ol start="4">
<li><strong>启动并验证</strong></li>
</ol>
<pre><code class="language-bash">~/start-kafka.sh
sleep 5 &amp;&amp; jps | egrep 'QuorumPeerMain|Kafka'
</code></pre>
<p>实际输出结果，终于成功：</p>
<pre><code class="language-bash">[root@localhost ~]# ~/start-kafka.sh

Zookeeper + 3 brokers started. Logs under /opt/kafka3.3.2/
[root@localhost ~]# sleep 5 &amp;&amp; jps | egrep 'QuorumPeerMain|Kafka'

36151 Kafka
36152 Kafka
36186 Kafka
26891 QuorumPeerMain
30317 Kafka
[root@localhost ~]# 
[root@localhost ~]# ss -lntup | grep :9092
tcp    LISTEN     0      50     [::]:9092               [::]:*                   users:(("java",pid=30317,fd=125))
[root@localhost ~]# # 会看到 PID 30317
[root@localhost ~]# kill -9 30317
[root@localhost ~]# sleep 2 &amp;&amp; jps | egrep 'QuorumPeerMain|Kafka'
26891 QuorumPeerMain
[root@localhost ~]# for p in 9191 9192 9193; do echo "== $p =="; ss -lntup | grep ":$p"; done
== 9191 ==
== 9192 ==
== 9193 ==
</code></pre>
<ol start="5">
<li><strong>确认 9092 已释放</strong></li>
</ol>
<pre><code class="language-bash">ss -lntup | grep :9092   # 应无结果
</code></pre>
<hr>
<h3 id="3后续不再踩坑的-3-条建议">3、后续不再踩坑的 3 条建议</h3>
<ol>
<li><strong>永远先杀干净旧进程</strong>再启动新配置。</li>
<li><strong>端口批量错开</strong>（如 9191/9192/9193），避免手动改漏。</li>
<li><strong>日志为空或报错时立即 <code>tail -n 30</code></strong>，定位关键字只用 10 秒。</li>
</ol>
<hr>
<h3 id="七-一键关闭可选备用脚本">七、 一键关闭（可选备用脚本）</h3>
<p>如果想一次性关闭，再做一个 <code>~/stop-kafka.sh</code>：</p>
<pre><code class="language-bash">cat &gt; ~/stop-kafka.sh &lt;&lt;'EOF'
#!/bin/bash
# 依次关闭 3 个 broker
for i in 1 2 3; do
  /opt/kafka3.3.2/bin/kafka-server-stop.sh /opt/kafka3.3.2/config/server-$i.properties
done
# 关闭 Zookeeper
/opt/kafka3.3.2/bin/zookeeper-server-stop.sh /opt/kafka3.3.2/config/zookeeper.properties
echo "All stopped."
EOF
#赋权
chmod +x ~/stop-kafka.sh
</code></pre>
<p>全部完成，直接复制即可。</p>
<hr>
<p>​	验证</p>
<pre><code class="language-bash"># 建 topic（3 分区 3 副本）
/opt/kafka3.3.2/bin/kafka-topics.sh --create --topic test-ha \
  --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3

# 查看
/opt/kafka3.3.2/bin/kafka-topics.sh --describe --topic test-ha --bootstrap-server localhost:9092
</code></pre>
<p>看到每个分区 <code>Replicas: 1,2,3</code> 且 <code>Isr: 1,2,3</code> 即成功。</p>
<hr>
<h3 id="八开机自启可选">八、开机自启（可选）</h3>
<p>下面给出 <strong>CentOS 7 systemd 一键方案</strong>，复制即可用。<br>
完成后执行 <code>systemctl enable --now kafka</code> 就能开机自启 + 立即启动。</p>
<hr>
<h3 id="-创建-systemd-服务文件">① 创建 systemd 服务文件</h3>
<pre><code class="language-bash">sudo tee /etc/systemd/system/kafka.service &gt;/dev/null &lt;&lt;'EOF'
[Unit]
Description=Kafka 3.3.2 Cluster (3 brokers)
After=network.target

[Service]
Type=forking
User=root
ExecStart=/root/start-kafka.sh
ExecStop=/root/stop-kafka.sh
RemainAfterExit=yes
TimeoutStartSec=60
TimeoutStopSec=30

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<hr>
<h3 id="-创建对应的-stop-脚本如果还没有">② 创建对应的 stop 脚本（如果还没有）</h3>
<pre><code class="language-bash">sudo tee /root/stop-kafka.sh &gt;/dev/null &lt;&lt;'EOF'
#!/bin/bash
# 依次停 3 个 broker
for i in 1 2 3; do
  /opt/kafka3.3.2/bin/kafka-server-stop.sh
done
# 停 Zookeeper
/opt/kafka3.3.2/bin/zookeeper-server-stop.sh
EOF
sudo chmod +x /root/stop-kafka.sh
</code></pre>
<hr>
<h3 id="-重载并设为开机自启">③ 重载并设为开机自启</h3>
<pre><code class="language-bash">sudo systemctl daemon-reload
sudo systemctl enable --now kafka
</code></pre>
<hr>
<h3 id="-验证">④ 验证</h3>
<pre><code class="language-bash">#一般检查到这一步就可以，出现active就成功，不用之后的重启
systemctl status kafka
</code></pre>
<h3 id="慎重验证">⑤慎重验证</h3>
<pre><code class="language-bash"># 重启后自动拉起，该命令用于重启整个Linux服务器就是整个机器！！慎用！！！
sudo reboot
# 登录后检查，jps用来列出所有java进程和主类名，后面用来确定Zookeeper和Kafka boker是否正常执行
jps | egrep 'QuorumPeerMain|Kafka'
</code></pre>
<p>看到 1 个 <code>QuorumPeerMain</code> + 3 个 <code>Kafka</code> 即成功。</p>
<hr>
<h4 id="这里我报错">这里我报错：</h4>
<ul>
<li>
<p><code>systemctl status kafka</code> 显示 <strong>active (exited)</strong>，说明 systemd 认为 <code>start-kafka.sh</code> 已经<strong>执行完成并退出</strong>，但 <strong>它不负责守护进程</strong>。</p>
</li>
<li>
<p>而 <code>jps</code> 里 <strong>看不到任何 Zookeeper/Kafka 进程</strong> → <strong>3 个 broker 并没有真正跑起来</strong>。</p>
</li>
<li>
<p>根本原因<br>
<code>start-kafka.sh</code> 里用了 <code>nohup … &amp;</code> 把进程放到后台，<strong>systemd 默认 <code>Type=forking</code></strong> 需要主进程长期存活，而你的脚本<strong>瞬间结束</strong>，systemd 就认为服务已经“成功退出”。</p>
</li>
<li>
<p>问题概述：<code>start-kafka.sh</code> 依旧是 <strong>“瞬间结束”</strong> 的脚本——它把 Zookeeper 和 3 个 Kafka <strong>丢到后台</strong>就退出了，systemd（<code>Type=simple</code>）发现主进程退出，于是立即执行 <code>ExecStop</code>，然后整服务标记为 <strong>failed</strong>。</p>
<p>解决思路：让 systemd <strong>直接托管</strong> Zookeeper + 3 个 Kafka，而不是托管一个“启动脚本”。最简做法是把它们拆成 <strong>4 个独立 service</strong>（1 Zookeeper + 3 Kafka），相互依赖即可。下面给出 <strong>“一条龙” 方案</strong>，复制即用。</p>
</li>
<li>
<p>之后又所有服务都报 <strong>status=127</strong> —— 典型“找不到可执行文件或脚本”错误。<br>
90% 是 <strong>路径写错</strong> 或 <strong>没给执行权限</strong>。原因是：1.J<strong>DK 不在 PATH</strong>（systemd 环境变量 ≠ 登录 shell）2.<strong>配置里缺 JAVA_HOME</strong>。</p>
<p>解决办法为下面的⑦，然后成功</p>
</li>
<li></li>
</ul>
<h4 id="快速修复">快速修复：</h4>
<p>下面是一份<strong>“问题-定位-修复”</strong>的完整复盘，<strong>完全保留你运行过的每一个代码块</strong>，方便你后续直接复制使用或给团队做文档。<br>
⏩ 从 <strong>第一次只看到 1 个 Kafka</strong> 开始，直到 <strong>真正 4 个进程常驻并成功开机自启</strong>。</p>
<hr>
<h3 id="-第一次现象只有-1-个-kafka">① 第一次现象：只有 1 个 Kafka</h3>
<pre><code class="language-bash">[root@localhost ~]# jps | egrep 'QuorumPeerMain|Kafka'
27940 Kafka
26891 QuorumPeerMain
</code></pre>
<hr>
<h3 id="-立即查看-3-份日志尾">② 立即查看 3 份日志尾</h3>
<pre><code class="language-bash">[root@localhost ~]# tail -n 20 /opt/kafka3.3.2/broker-*.log
==&gt; /opt/kafka3.3.2/broker-1.log &lt;==

==&gt; /opt/kafka3.3.2/broker-2.log &lt;==

==&gt; /opt/kafka3.3.2/broker-3.log &lt;==
</code></pre>
<p>日志为空 → 说明根本没成功启动。</p>
<hr>
<h3 id="-前台启动-2-号-broker现场报错">③ 前台启动 2 号 broker，现场报错</h3>
<pre><code class="language-bash"># 先停干净
pkill -f 'kafka\.Kafka'
pkill -f QuorumPeerMain

# 前台跑 2 号
/opt/kafka3.3.2/bin/kafka-server-start.sh /opt/kafka3.3.2/config/server-2.properties
</code></pre>
<p>输出核心报错：</p>
<pre><code>Socket server failed to bind to 0.0.0.0:9092: 地址已在使用.
</code></pre>
<hr>
<h3 id="-确认-9092-被谁占用">④ 确认 9092 被谁占用</h3>
<pre><code class="language-bash">[root@localhost ~]# ss -lntup|grep 9092
tcp    LISTEN     0      50     [::]:9092               [::]:*                   users:(("java",pid=27940,fd=125))
</code></pre>
<hr>
<h3 id="-杀掉旧进程--清理锁文件">⑤ 杀掉旧进程 &amp; 清理锁文件</h3>
<pre><code class="language-bash"># 杀掉所有残留
pkill -9 -f 'kafka\.Kafka'

# 清理 .lock
for i in 1 2 3; do
  rm -f /opt/kafka3.3.2/data/kafka-logs-$i/.lock
done
</code></pre>
<hr>
<h3 id="-把-3-份配置端口改成不冲突的-919191929193">⑥ 把 3 份配置端口改成不冲突的 9191/9192/9193</h3>
<pre><code class="language-bash">for i in 1 2 3; do
  port=$((9190+i))
  cfg="/opt/kafka3.3.2/config/server-$i.properties"
  sed -ri \
    -e "s#^listeners[[:space:]]*=.*#listeners=PLAINTEXT://:${port}#" \
    -e "s#^advertised.listeners[[:space:]]*=.*#advertised.listeners=PLAINTEXT://localhost:${port}#" \
    -e "s#^broker.id[[:space:]]*=.*#broker.id=$i#" \
    "$cfg"
done
</code></pre>
<hr>
<h3 id="-写死-java_home-到所有-systemd-单元">⑦ 写死 JAVA_HOME 到所有 systemd 单元</h3>
<pre><code class="language-bash"># 查出 JDK 路径
[root@localhost ~]# readlink -f $(which java)
/usr/local/jdk17/bin/java

# 写入环境变量
for f in /etc/systemd/system/{zookeeper,kafka-{1..3}}.service; do
  sudo sed -i '/\[Service\]/a Environment=JAVA_HOME=/usr/local/jdk17' "$f"
done
</code></pre>
<hr>
<h3 id="-一键创建-4-个独立-systemd-单元复制即用">⑧ 一键创建 4 个独立 systemd 单元（复制即用）</h3>
<h4 id="81-zookeeper">8.1 Zookeeper</h4>
<pre><code class="language-bash">sudo tee /etc/systemd/system/zookeeper.service &gt;/dev/null &lt;&lt;'EOF'
[Unit]
Description=Zookeeper for Kafka
After=network.target

[Service]
Type=simple
User=root
ExecStart=/opt/kafka3.3.2/bin/zookeeper-server-start.sh /opt/kafka3.3.2/config/zookeeper.properties
ExecStop=/opt/kafka3.3.2/bin/zookeeper-server-stop.sh
Environment=JAVA_HOME=/usr/local/jdk17
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF
</code></pre>
<h4 id="82-3-个-kafka-broker">8.2 3 个 Kafka broker</h4>
<pre><code class="language-bash">for i in 1 2 3; do
port=$((9190+i))
sudo tee /etc/systemd/system/kafka-${i}.service &gt;/dev/null &lt;&lt;EOF
[Unit]
Description=Kafka Broker ${i}
After=zookeeper.service
Requires=zookeeper.service

[Service]
Type=simple
User=root
ExecStart=/opt/kafka3.3.2/bin/kafka-server-start.sh /opt/kafka3.3.2/config/server-${i}.properties
ExecStop=/opt/kafka3.3.2/bin/kafka-server-stop.sh
Environment=JAVA_HOME=/usr/local/jdk17
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF
done
</code></pre>
<hr>
<h3 id="-重载--自启">⑨ 重载 &amp; 自启</h3>
<pre><code class="language-bash">sudo systemctl daemon-reload
sudo systemctl enable --now zookeeper
for i in 1 2 3; do
  sudo systemctl enable --now kafka-${i}
done
</code></pre>
<hr>
<h3 id="-最终验证">⑩ 最终验证</h3>
<pre><code class="language-bash">[root@localhost ~]# systemctl status zookeeper kafka-{1..3}
# 四条均显示 active (running)

[root@localhost ~]# jps | egrep 'QuorumPeerMain|Kafka'
12288 Kafka
12289 Kafka
12286 QuorumPeerMain
12287 Kafka
</code></pre>
<hr>
<h3 id="最后这里成功">最后这里成功！！！</h3>
<pre><code class="language-bash">[root@localhost ~]# ls -l /opt/kafka3.3.2/bin/zookeeper-server-start.sh
-rwxr-xr-x. 1 root root 1393 12月 22 2022 /opt/kafka3.3.2/bin/zookeeper-server-start.sh
[root@localhost ~]# ls -l /opt/kafka3.3.2/bin/kafka-server-start.sh
-rwxr-xr-x. 1 root root 1376 12月 22 2022 /opt/kafka3.3.2/bin/kafka-server-start.sh
[root@localhost ~]# readlink -f $(which java)
/usr/local/jdk17/bin/java
[root@localhost ~]# for f in /etc/systemd/system/{zookeeper,kafka-{1..3}}.service; do
&gt;   sudo sed -i '/\[Service\]/a Environment=JAVA_HOME=/usr/local/jdk17' "$f"
&gt; done
[root@localhost ~]# sudo systemctl daemon-reload
[root@localhost ~]# sudo systemctl restart zookeeper kafka-{1..3}
[root@localhost ~]# systemctl status zookeeper kafka-{1..3}
● zookeeper.service - Zookeeper for Kafka
   Loaded: loaded (/etc/systemd/system/zookeeper.service; enabled; vendor preset: disabled)
   Active: active (running) since 三 2025-08-13 11:49:54 CST; 5s ago
 Main PID: 12286 (java)
   CGroup: /system.slice/zookeeper.service
           └─12286 /usr/local/jdk17/bin/java -Xmx512M -Xms512M -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djav...

8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,318] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,435] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,448] INFO 325 txns loaded in 64 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,448] INFO Snapshot loaded in 214 ms, highest zxid is 0x145, digest is 44971706807 (org.apache.zookeep...ZKDatabase)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,448] INFO Snapshotting: 0x145 to /tmp/zookeeper/version-2/snapshot.145 (org.apache.zookeeper.server.p...TxnSnapLog)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,449] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,507] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,510] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.Pr...tProcessor)
8月 13 11:49:58 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:58,636] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeep...nerManager)
8月 13 11:49:59 localhost.localdomain zookeeper-server-start.sh[12286]: [2025-08-13 11:49:59,471] INFO Creating new log file: log.146 (org.apache.zookeeper.server.persistence.FileTxnLog)

● kafka-1.service - Kafka Broker 1
   Loaded: loaded (/etc/systemd/system/kafka-1.service; enabled; vendor preset: disabled)
   Active: active (running) since 三 2025-08-13 11:49:54 CST; 5s ago
 Main PID: 12287 (java)
   CGroup: /system.slice/kafka-1.service
           └─12287 /usr/local/jdk17/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.aw...

8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,407] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,407] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,410] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.z....ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,419] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,426] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,456] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,462] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:41508, server: lo...ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,467] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,560] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000...ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12287]: [2025-08-13 11:49:59,566] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)

● kafka-2.service - Kafka Broker 2
   Loaded: loaded (/etc/systemd/system/kafka-2.service; enabled; vendor preset: disabled)
   Active: active (running) since 三 2025-08-13 11:49:54 CST; 5s ago
 Main PID: 12288 (java)
   CGroup: /system.slice/kafka-2.service
           └─12288 /usr/local/jdk17/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.aw...

8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,370] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,370] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,374] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.z....ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,401] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,414] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,430] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,436] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:41506, server: lo...ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,441] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,525] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000...ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12288]: [2025-08-13 11:49:59,530] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)

● kafka-3.service - Kafka Broker 3
   Loaded: loaded (/etc/systemd/system/kafka-3.service; enabled; vendor preset: disabled)
   Active: active (running) since 三 2025-08-13 11:49:54 CST; 5s ago
 Main PID: 12289 (java)
   CGroup: /system.slice/kafka-3.service
           └─12289 /usr/local/jdk17/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.aw...

8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,456] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,456] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,459] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.z....ZooKeeper)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,487] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,494] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,500] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,513] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,538] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:41510, server: lo...ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,558] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000...ClientCnxn)
8月 13 11:49:59 localhost.localdomain kafka-server-start.sh[12289]: [2025-08-13 11:49:59,564] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
Hint: Some lines were ellipsized, use -l to show in full.
[root@localhost ~]# jps | egrep 'QuorumPeerMain|Kafka'
12288 Kafka
12289 Kafka
12286 QuorumPeerMain
12287 Kafka

</code></pre>
<hr>
<h3 id="-重启整机测试可选">⑪ 重启整机测试（可选）</h3>
<pre><code class="language-bash">sudo reboot
# 重新登录
jps | egrep 'QuorumPeerMain|Kafka'
</code></pre>
<p>再次看到 1 个 <code>QuorumPeerMain</code> + 3 个 <code>Kafka</code>，<strong>开机自启完成</strong>。</p>
<hr>
<p>一句话总结<br>
复制上面 1~6 步即可在 <code>/opt/kafka3.3.2</code> 跑起单机 3 broker 3 副本环境，验证完功能后再考虑真正多机高可用。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-08-13 14:21">2025-08-13 14:20</span>&nbsp;
<a href="https://www.cnblogs.com/wjw2003512">柒寒（平安）</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19035691);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19035691', targetLink: 'https://www.cnblogs.com/wjw2003512/p/19035691', title: 'Kafka2.13-3.3.2 安装部署+最后报错处理全过程（CentOS 7 虚拟机）' })">举报</a>
</div>
        