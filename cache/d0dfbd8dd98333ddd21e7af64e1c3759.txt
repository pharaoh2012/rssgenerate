
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/xueweihan/p/18723279" title="发布于 2025-02-19 08:50">
    <span role="heading" aria-level="2">重磅发布！DeepSeek 微调秘籍揭秘，一键解锁升级版全家桶，AI 玩家必备神器！</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><img src="https://img2024.cnblogs.com/blog/759200/202502/759200-20250219084543448-1220645429.png" alt="" loading="lazy"></p>
<p>DeepSeek V3/R1 火爆全网，基于原始模型的解决方案和 API 服务已随处可见，陷入低价和免费内卷。</p>
<p>如何站在巨人肩膀上，通过后训练（post-training）结合专业领域数据，<strong>低成本打造高质量私有模型</strong>，提升业务竞争力与价值？</p>
<p>已收获近 <strong>4 万 GitHub Star</strong> 的 Colossal-AI，发布<strong>开源大模型后训练工具箱</strong>，包含：</p>
<ul>
<li>DeepSeek V3/R1 满血 671B LoRA 低成本 SFT 微调</li>
<li>完整的强化学习工具链 PPO、GRPO、DPO、SimPO 等</li>
<li>无缝适配 DeepSeek 系列蒸馏模型在内的 HuggingFace 开源模型</li>
<li>兼容支持英伟达 GPU、华为昇腾 NPU 等多种硬件</li>
<li>支持混合精度训练、gradient checkpoint 等训练加速降低成本</li>
<li>灵活的训练配置接口，支持自定义奖励函数、损失函数等</li>
<li>提供灵活的并行策略配置接口，包括数据并行、模型并行、专家并行、ZeRO 和 Offload 等，以适应不同硬件规模</li>
</ul>
<blockquote>
<p>开源地址：<a href="https://github.com/hpcaitech/ColossalAI" target="_blank" rel="noopener nofollow">github.com/hpcaitech/ColossalAI</a></p>
</blockquote>
<h2 id="低成本监督微调满血版-deepseek-v3r1-671b">低成本监督微调满血版 DeepSeek V3/R1 671B</h2>
<p>DeepSeek V3/R1 满血版参数高达 6710 亿，如何低成本进行低成本微调呢? 仅需以下几个步骤，即可快速完成。</p>
<h3 id="数据集准备">数据集准备</h3>
<p>该脚本接收 JSONL（JSON Lines）格式的文件作为输入数据集，例如 <a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/examples/training_scripts/lora_sft_data.jsonl" target="_blank" rel="noopener nofollow">lora_sft_data.jsonl</a> 数据集的每一行应为一个聊天对话列表。例如：</p>
<pre><code>[{"role": "user", "content": "你好，最近怎么样？"}, {"role": "assistant", "content": "我很好。今天有什么可以帮你的吗？"}]
[{"role": "user", "content": "火烧赤壁 曹操为何不拨打119求救？"}, {"role": "assistant", "content": "因为在三国时期，还没有电话和现代的消防系统，所以曹操无法拨打119求救。"}]
</code></pre>
<p>该数据格式，兼容 Huggingface chat template，支持自定义 system prompt，因此可灵活按需配置。</p>
<h3 id="模型权重准备">模型权重准备</h3>
<p>为保证更好的微调效果，使用 BF16 权重进行微调。</p>
<p>如果已下载了 FP8 的 DeepSeek V3/R1 权重，可以使用 DeepSeek 官方脚本 <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/inference/fp8_cast_bf16.py" target="_blank" rel="noopener nofollow">fp8_cast_bf16.py</a> 通过 GPU 将权重转换为 BF16。</p>
<p>对于使用国产华为昇腾算力，可以下载 <a href="https://gitee.com/ascend/ModelZoo-PyTorch/blob/master/MindIE/LLM/DeepSeek/DeepSeek-V2/NPU_inference/fp8_cast_bf16.py" target="_blank" rel="noopener nofollow">fp8_cast_bf16.py</a> 脚本转换权重。</p>
<h3 id="使用方法">使用方法</h3>
<p>在准备好数据集和模型权重后，可使用 Colossal-AI 提供的一键启动脚本 <a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/examples/training_scripts/lora_finetune.py" target="_blank" rel="noopener nofollow">lora_finetune.py</a></p>
<p>该脚本与常见 SFT 脚本类似，且完全兼容 HuggingFace PEFT，启动命令：</p>
<pre><code>colossalai run --hostfile path-to-host-file --nproc_per_node 8 lora_finetune.py --pretrained path-to-DeepSeek-R1-bf16 --dataset path-to-dataset.jsonl --plugin moe --lr 2e-5 --max_length 256 -g --ep 8 --pp 3 --batch_size 24 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 8 --tensorboard_dir logs --save_dir DeepSeek-R1-bf16-lora
</code></pre>
<p>有关每个参数的更多详细信息，可以运行 <code>python lora_finetune.py --help</code> 查看。该脚本可通过 tensorboard 记录学习率、loss、grad norm 信息，方便对训练进行监控。</p>
<h3 id="使用-lora-优化硬件资源消耗">使用 LoRA 优化硬件资源消耗</h3>
<p>通过使用 LoRA 等优化，示例命令已将 SFT DeepSeek V3/R1 671B <strong>最低硬件要求降低近 10 倍</strong>，可使用 32 个 Ascend 910B NPU 64GB（使用 <code>ep=8,pp=4</code>）或 24 个 H100/H800 GPU（使用 <code>ep=8,pp=3</code>）。如果你通过 <code>--zero_cpu_offload</code> 启用 CPU offload，硬件要求可以进一步降低，但会损失一定的训练速度。</p>
<p>如下图验证，在 SFT DeepSeek V3/R1 671B 时，Loss 可以顺利降低。</p>
<p><img src="https://img2024.cnblogs.com/blog/759200/202502/759200-20250218225958116-765603214.png" alt="" loading="lazy"></p>
<p>对于资金充裕的开发团队，也可以使用上述脚本，<strong>将并行度高效扩展至数百及数千卡</strong>，快速完成 DeepSeek V3/R1 671B 全参微调或并行加速。</p>
<p>对于预算有限，又想借助强化学习构建自己的类 DeepSeek R1 模型，Colossal-AI 也提供了解决方案，并利用小模型对算法进行了验证。</p>
<h2 id="通过强化学习微调蒸馏版-deepseek">通过强化学习微调蒸馏版 DeepSeek</h2>
<p>Colossal-AI 团队验证并实现了 DeepSeek 论文中的 <strong>GRPO 算法及 verifiable reward</strong>，使用 Qwen2.5-3B-Base 模型进行了实验。其中，奖励的设计如下：</p>
<ol>
<li>奖励 = 0，如果格式是正确的；</li>
<li>奖励 = 1， 如果格式是正确的但是结果是错误的；</li>
<li>奖励 = 10，如果格式与结果都是正确的；</li>
</ol>
<p>Colossal-AI 团队以 Qwen2.5-3B-Base 模型为例，提供了用于验证 GRPO 的对话模板及设定 Qwen_Qwen2.5-3B.json[<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/conversation_template/Qwen_Qwen2.5-3B.json" target="_blank" rel="noopener nofollow">https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/conversation_template/Qwen_Qwen2.5-3B.json</a>]，通过配置以下 bash 文件，即可一键启动：<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/examples/training_scripts/train_grpo.sh" target="_blank" rel="noopener nofollow">train_grpo.sh</a></p>
<p>同时，在 GRPO 章节，Colossal-AI 团队还提供了验证过程中的部分发现及各种参数的详细描述，可供参考。</p>
<p>代码中设计了可灵活配置奖励函数的模板，因此，用户可根据自己的具体情况设计自己的奖励函数体系。</p>
<p>由下图可以看到，即使是 3B 的模型，<strong>平均奖励与模型回复长度随着时间逐步增长</strong>。</p>
<p><img src="https://img2024.cnblogs.com/blog/759200/202502/759200-20250218231353061-487247791.jpg" alt="" loading="lazy"></p>
<p>随着训练的进行，我们可以看到一些有意思的例子。例如随着训练迭代，模型开始了<strong>自我纠正</strong>：</p>
<p><img src="https://img2024.cnblogs.com/blog/759200/202502/759200-20250218230249169-134966527.png" alt="" loading="lazy"></p>
<h2 id="colossal-ai最佳后训练工具箱">Colossal-AI：最佳后训练工具箱</h2>
<p>Colossal-AI 在深耕大模型预训练降本增效的基础上，致力于进一步成为开发者开箱即用的最佳后训练工具，帮助用户基于开源模型，低成本快速构建私有模型。</p>
<blockquote>
<p>开源地址：<a href="https://github.com/hpcaitech/ColossalAI" target="_blank" rel="noopener nofollow">github.com/hpcaitech/ColossalAI</a></p>
</blockquote>

</div>
<div id="MySignature" role="contentinfo">
    <div>    
    <p style="border-top: #e0e0e0 1px dashed; border-right: #e0e0e0 1px dashed; border-bottom: #e0e0e0 1px dashed; border-left: #e0e0e0 1px dashed; padding-top: 5px; padding-right: 10px; padding-bottom: 10px; padding-left: 150px; background: url(https://images.cnblogs.com/cnblogs_com/xueweihan/859919/o_200924043112qrcode_for_gh_4fb030b35bb4_258.jpg) #e5f1f4 no-repeat 1% 50%; background-size:130px 130px;font-family: 微软雅黑; font-size: 13px" id="PSignature">
    <br>
    作者：<a href="https://github.com/521xueweihan" target="_blank">削微寒</a>

    <br>
    <strong>扫描左侧的二维码可以联系到我</strong>
    <br>

    <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh"><img alt="知识共享许可协议" style="border-width: 0" src="https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png"></a><br>本作品采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh">署名-非商业性使用-禁止演绎 4.0 国际 </a>进行许可。
    </p>
</div>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.0004772355034722222" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-19 09:01">2025-02-19 08:50</span>&nbsp;
<a href="https://www.cnblogs.com/xueweihan">削微寒</a>&nbsp;
阅读(<span id="post_view_count">26</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18723279" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18723279);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18723279', targetLink: 'https://www.cnblogs.com/xueweihan/p/18723279', title: '重磅发布！DeepSeek 微调秘籍揭秘，一键解锁升级版全家桶，AI 玩家必备神器！' })">举报</a>
</div>
        