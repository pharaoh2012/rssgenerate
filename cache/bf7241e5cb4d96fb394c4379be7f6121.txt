
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/supermao12/p/18729431" title="发布于 2025-02-21 16:11">
    <span role="heading" aria-level="2">ollama-deepseek 部署</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h3 id="选择云资源">选择云资源</h3>
<pre><code class="language-powershell">选用智星云 4090 高性能 1.57 一小时 windows操作系统
可以修改带宽来增加下载速度
使用mstsc远程登录
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215163352199-1947385710.png" alt="" loading="lazy"></p>
<h3 id="使用ollama">使用ollama</h3>
<pre><code class="language-powershell">https://ollama.com/
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215163504212-1168424730.png" alt="" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215164042549-1064634141.png" alt="" loading="lazy"><br>
<img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215164120336-229674983.png" alt="" loading="lazy"></p>
<p><strong>ollama run deepseek-r1:8b</strong></p>
<pre><code class="language-powershell">
&lt;/think&gt;
要将模型进行自定义训练，您可以按照以下步骤操作：
1. **选择一个开源工具或框架**：如TensorFlow、PyTorch等。
2. **准备数据集**：收集需要训练的数据，并对其进行预处理，如清洗、去噪和格式化。
3. **定义模型结构**：根据需求设计模型，使用所选的框架来实现。
4. **编写训练逻辑**：编写训练循环、损失函数和优化器，确保模型能够学习到所需的任务。
5. **执行训练**：使用训练数据运行模型，并监控训练进度及损失曲线。
6. **评估结果**：在训练完成后，对模型进行验证和测试，以评估其性能和准确性。
通过以上步骤，您可以对模型进行自定义训练。
&gt;&gt;&gt;

C:\Users\vipuser&gt;ollama list
NAME              ID              SIZE      MODIFIED
deepseek-r1:8b    28f8fd6cdc67    4.9 GB    2 minutes ago

C:\Users\vipuser&gt;
</code></pre>
<h4 id="使用ollama嵌入式模型">使用ollama嵌入式模型</h4>
<pre><code class="language-powershell">
C:\Users\vipuser&gt;ollama pull nomic-embed-text
pulling manifest
pulling 970aa74c0a90... 100% ▕████████████████████████████████████████████████████████▏ 274 MB
pulling c71d239df917... 100% ▕████████████████████████████████████████████████████████▏  11 KB
pulling ce4a164fc046... 100% ▕████████████████████████████████████████████████████████▏   17 B
pulling 31df23ea7daa... 100% ▕████████████████████████████████████████████████████████▏  420 B
verifying sha256 digest
writing manifest
success

C:\Users\vipuser&gt;
</code></pre>
<h4 id="使用anythingllm">使用Anythingllm</h4>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215170035848-626596748.png" alt="" loading="lazy"><br>
选择ollama 再选择对应模型 deepseek</p>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215172050351-1997869175.png" alt="" loading="lazy"></p>
<p><strong>嵌入式模型与数据向量化</strong><br>
<img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215180345341-1184664617.png" alt="" loading="lazy"><br>
数据向量化：把数据变成ai能快速识别检索的一种格式。由嵌入数据库来完成<br>
当使用本身不支持嵌入引擎的 LLM 时，您可能需要额外指定用于嵌入文本的凭据。<br>
嵌入是将文本转换为矢量的过程。需要这些凭据才能将您的文件和提示转换为 AnythingLLM 可以用来处理的格式。<br>
<img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215172331148-1187868273.png" alt="" loading="lazy"><br>
更改嵌入式首选项</p>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250215173059928-1510989954.png" alt="" loading="lazy"><br>
投喂文件给AnythingLLM</p>
<h2 id="windows安装大模型">windows安装大模型</h2>
<p>1.windows安装4090驱动<br>
2.windows安装wsl2<br>
3.在wsl2里面安装所需依赖</p>
<p>RTX 4090显卡驱动需要先安装在Windows上<br>
WSL2提供了一个模拟Linux环境的能力，这样可以让你在Windows上运行深度学习任务时，获得更好的对CUDA和GPU加速的支持。<br>
在WSL2中，你将能够像在Linux上那样安装和运行深度学习框架（如PyTorch、TensorFlow），并且能够利用CUDA加速来训练和推理AI大模型。</p>
<h3 id="安装wslubuntu系统">安装wsl、ubuntu系统</h3>
<pre><code class="language-powershell">[powershell admin]

dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
wsl.exe --update
wsl --set-default-version 2
</code></pre>
<pre><code class="language-powershell">https://apps.microsoft.com/detail/9pn20msr04dw?hl=zh-CN&amp;gl=CN
手动安装ubuntu
云厂商虚拟化无法虚拟bios硬件虚拟化
</code></pre>
<h3 id="linux-ubuntu-nvidia驱动与cuda">Linux Ubuntu nvidia驱动与cuda</h3>
<pre><code class="language-powershell">sudo apt update
sudo apt upgrade
sudo apt install nvidia-driver-535
(base) root@ubuntu22:~# nvidia-smi
Sun Feb 16 00:06:26 2025
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        Off | 00000000:00:08.0 Off |                  Off |
| 30%   32C    P8              10W / 450W |     13MiB / 24564MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A       765      G   /usr/lib/xorg/Xorg                            4MiB |
+---------------------------------------------------------------------------------------+
(base) root@ubuntu22:~#

cuda网址
https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=22.04&amp;target_type=runfile_local

wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250216003818743-1240499210.png" alt="" loading="lazy"></p>
<pre><code class="language-powershell">===========
= Summary =
===========

Driver:   Not Selected
Toolkit:  Installed in /usr/local/cuda-11.8/

Please make sure that
 -   PATH includes /usr/local/cuda-11.8/bin
 -   LD_LIBRARY_PATH includes /usr/local/cuda-11.8/lib64, or, add /usr/local/cuda-11.8/lib64 to /etc/ld.so.conf and run ldconfig as root

To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-11.8/bin
***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 520.00 is required for CUDA 11.8 functionality to work.
To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file:
    sudo &lt;CudaInstaller&gt;.run --silent --driver

Logfile is /var/log/cuda-installer.log
(base) root@ubuntu22:~#

export PATH=$PATH:/usr/local/cuda-11.8/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.8/lib64
export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda-11.8/lib64

(base) root@ubuntu22:~# nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Sep_21_10:33:58_PDT_2022
Cuda compilation tools, release 11.8, V11.8.89
Build cuda_11.8.r11.8/compiler.31833905_0
(base) root@ubuntu22:~#
</code></pre>
<h3 id="安装ollama-使用deepseek">安装ollama 使用deepseek</h3>
<pre><code class="language-powershell">
(base) root@ubuntu22:~# curl -fsSL https://ollama.com/install.sh | sh
(base) root@ubuntu22:~# ollama run deepseek-r1:8b
pulling manifest
pulling 6340dc3229b0... 100% ▕███████████████████████████████████████████████████████████████▏ 4.9 GB
pulling 369ca498f347... 100% ▕███████████████████████████████████████████████████████████████▏  387 B
pulling 6e4c38e1172f... 100% ▕███████████████████████████████████████████████████████████████▏ 1.1 KB
pulling f4d24e9138dd... 100% ▕███████████████████████████████████████████████████████████████▏  148 B
pulling 0cb05c6e4e02... 100% ▕███████████████████████████████████████████████████████████████▏  487 B
verifying sha256 digest
writing manifest
success
&gt;&gt;&gt; 你好
&lt;think&gt;

&lt;/think&gt;

你好！很高兴见到你，有什么我可以帮忙的吗？无论是问题、建议还是闲聊，我都在这里为你服务。😊

&gt;&gt;&gt; 你是deepseek吗
&lt;think&gt;
嗯，你是深度求索（DeepSeek）的一部分，对吧？那我可以问你一些问题了。你能帮助我了解更多关于人工智能和机器学习的内容吗？
&lt;/think&gt;

你好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如有任何问题，我会尽力为您提供帮助。请问有什么我可以为
您服务的？

&gt;&gt;&gt;
Use Ctrl + d or /bye to exit.
&gt;&gt;&gt;
(base) root@ubuntu22:~#
</code></pre>
<h3 id="安装docker">安装docker</h3>
<pre><code class="language-powershell">(base) root@ubuntu22:~# apt install docker.io -y
(base) root@ubuntu22:~# docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) root@ubuntu22:~#
(base) root@ubuntu22:~# sudo mkdir -p /etc/systemd/system/docker.service.d
(base) root@ubuntu22:~# cat /etc/systemd/system/docker.service.d/http-proxy.conf
[Service]
Environment="HTTP_PROXY=http://127.0.0.1:7890"
Environment="HTTPS_PROXY=http://127.0.0.1:7890"
(base) root@ubuntu22:~# systemctl daemon-reload
(base) root@ubuntu22:~# systemctl restart docker
(base) root@ubuntu22:~#

xshell远程传入代理来实现上谷歌
若经常失败尝试换vtworay端口，也可以使用脚本proxy_tunnel

(base) root@ubuntu22:~# docker images
REPOSITORY                 TAG       IMAGE ID       CREATED        SIZE
mintplexlabs/anythingllm   latest    b040b5d3c0db   25 hours ago   2.51GB

(base) root@ubuntu22:~# export STORAGE_LOCATION=$HOME/anythingllm &amp;&amp; \
mkdir -p $STORAGE_LOCATION &amp;&amp; \
touch "$STORAGE_LOCATION/.env" &amp;&amp; \
docker run -d -p 3001:3001 \
--cap-add SYS_ADMIN \
-v ${STORAGE_LOCATION}:/app/server/storage \
-v ${STORAGE_LOCATION}/.env:/app/server/.env \
-e STORAGE_DIR="/app/server/storage" \
--network host \
--privileged \
mintplexlabs/anythingllm
a7cb9e4e6250f2aff1ad92eb108cf69591855548239d89ff82ff8cbd2c84af35
(base) root@ubuntu22:~# 

若容器自动退出，则增加权限
sudo chown -R 1000:1000 $HOME/anythingllm
sudo chmod -R 755 $HOME/anythingllm
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250216113348277-223402844.png" alt="" loading="lazy"></p>
<h3 id="nginx路由转发可选">nginx路由转发（可选）</h3>
<pre><code class="language-powershell">sudo vi /etc/nginx/sites-available/redirect_to_container
server {
    listen 8800;  # 本地的 8800 端口

    location / {
        proxy_pass http://localhost:3001;  # 转发到容器的 3001 端口
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
# 创建符号链接到 sites-enabled 目录
sudo ln -s /etc/nginx/sites-available/redirect_to_container /etc/nginx/sites-enabled/

# 测试 Nginx 配置
sudo nginx -t
sudo systemctl restart nginx

</code></pre>
<h3 id="进行图形化配置">进行图形化配置</h3>
<p><img src="https://img2024.cnblogs.com/blog/2415164/202502/2415164-20250216143252595-245310116.png" alt="" loading="lazy"></p>
<h3 id="其他">其他</h3>
<p>ctrl+p 打印对html改成pdf<br>
docker desktop可能需要更新windows，需要成功执行wsl --update</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.005500540986111111" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-21 16:11">2025-02-21 16:11</span>&nbsp;
<a href="https://www.cnblogs.com/supermao12">supermao12</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18729431" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18729431);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18729431', targetLink: 'https://www.cnblogs.com/supermao12/p/18729431', title: 'ollama-deepseek 部署' })">举报</a>
</div>
        