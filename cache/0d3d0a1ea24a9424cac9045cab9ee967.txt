
		<h1 class="postTitle">
			<a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/guoxiaoyu/p/18699495" title="发布于 2025-02-05 17:17">
    <span role="heading" aria-level="2">腾讯云HAI服务器上部署与调用DeepSeek-R1大模型的实战指南</span>
    

</a>

		</h1>
		<div class="clear"></div>
		<div class="postBody">
			<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>上次我们大概了解了一下 DeepSeek-R1 大模型，并简单提及了 Ollama 的一些基本信息。今天，我们将深入实际操作，利用腾讯云的 HAI 服务器进行 5 分钟部署，并实现本地 DeepSeek-R1 大模型的实时调用。接下来，我们直接进入部署过程。</p>
<h1 id="服务器准备">服务器准备</h1>
<p>首先，我们需要登录腾讯云平台并购买 HAI 应用服务。腾讯云提供了两种计费方式：包月计费和按时计费。由于我目前并没有特别紧迫或庞大的需求，因此为了节省成本，我选择了按时计费方式。具体的购买流程和配置选项可以参考下面的图示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150639046-1327050268.png" alt="image" loading="lazy"></p>
<p>在我完成购买后，腾讯云 HAI 服务器会自动为我们部署 DeepSeek-R1 模型并启动运行，整个过程非常简便。同时，HAI 还提供了算力连接的选择，具体有三种不同的方式：</p>
<ol>
<li><strong>ChatBotUI</strong>：这是一种广泛应用的可视化聊天界面，它不仅支持实时的聊天互动，还具备管理聊天记录和提示词模板等功能，非常适合需要快速构建对话系统的场景。</li>
<li><strong>CloudStudio</strong>：CloudStudio 是一款功能强大的在线集成开发环境（IDE）。它允许我们编写 Python 脚本、调试代码、进行多种应用开发和测试，非常适合开发者进行项目调试和优化。</li>
<li><strong>JupyterLab</strong>：作为一种极为流行的数据科学工具，JupyterLab 提供了多个终端选择，包括 Linux 终端和 Python 脚本执行环境。它为数据分析、模型训练及执行等任务提供了非常便捷的支持。</li>
</ol>
<h2 id="chatbotui">ChatBotUI</h2>
<p>在这里，我们首先来了解一下可视化界面，并演示如何快速上手使用。通过这一界面，用户可以直观地进行各种操作，轻松实现需求的配置和调整。具体的操作步骤和界面效果可以参考下面的图示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150647201-549518582.png" alt="image" loading="lazy"></p>
<p>可以选择其他选项，虽然有时候需要进行角色授权，授权过程非常简单，点击“授权”按钮即可完成，无需进行复杂操作。一旦授权完成，你便可以进入聊天界面。在该界面中，HAI服务器提供了多种参数选项，例如7B和1.5B。选择合适的参数后，你就可以立即开始实时聊天，无需等待。</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150652866-2122753249.png" alt="image" loading="lazy"></p>
<h2 id="ollama终端">ollama终端</h2>
<p>我们继续选择JupyterLab方式连接算力，这里选择终端，如图所示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150658297-1924415126.png" alt="image" loading="lazy"></p>
<p>我们去看下终端命令查看下，如图所示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150704888-819001029.png" alt="image" loading="lazy"></p>
<p>在这里，我们可以看到其实它使用的也是基于Ollama运行的DeepSeek-R1大模型。通过这种方式，用户可以非常方便地直接使用Ollama提供的命令，来查看和操作相应的API接口。如图所示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150709766-1103776718.png" alt="image" loading="lazy"></p>
<p>这里我们演示的是直接使用 Ollama 运行 DeepSeek-R1 大模型，模型参数为 1.5B。要结束当前会话，您可以使用快捷键 Ctrl + D 退出。不过，需要注意的是，采用这种方式仅支持在本地运行和启动，无法进行外网调用或配置远程访问。</p>
<p>因此，如果希望实现外网访问或其他更复杂的配置，接下来的步骤将会介绍相关方法。</p>
<h2 id="ollama-api服务">ollama-API服务</h2>
<p>这里我们查看ollama如果想要启动大模型服务接口，可以使用<code>ollama serve</code>命令启动，如图所示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150715944-2109174082.png" alt="image" loading="lazy"></p>
<p>可以看到，系统已经成功开机并启动，且绑定的端口号为6399。在这种情况下，我们只需直接开放该端口即可。值得注意的是，HAI服务器还提供了外网IP地址，因此我们可以通过访问该IP来进行端口的开放设置。</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150721622-1727866660.png" alt="image" loading="lazy"></p>
<p>接下来，我们将按照Ollama的API文档中的指引，完成端口设置的操作。具体操作流程如下所示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150726231-422225048.png" alt="image" loading="lazy"></p>
<h2 id="cloudstudio连接">CloudStudio连接</h2>
<p>启动完API服务后，我们直接使用CloudStudio进行本地调用。新建一个py文件，代码内容如下：</p>
<pre><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="ollama", base_url="http://localhost:6399/v1/")

response = client.chat.completions.create(
    model="deepseek-r1:1.5b",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ],
    stream=False
)

print(response.choices[0].message.content)
</code></pre>
<p>这里虽然写了api-key信息，但是ollama是不会校验的，你可以写任何字符串，以为这个参数是方法必传参数。结果运行如下：</p>
<p><img src="https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250205150735272-1077151232.png" alt="image" loading="lazy"></p>
<p>如果你安装完openai依赖包，但仍是无法找到，那么你就在CloudStudio中添加虚拟环境即可，命令如下：</p>
<blockquote>
<p>python -m venv venv</p>
</blockquote>
<p>然后再执行<code>pip3 install openai</code>命令即可成功运行。当然这里是本地测试，你也可以使用公网IP进行配置并调试。</p>
<h1 id="总结">总结</h1>
<p>通过本次实践，我们成功地使用腾讯云的HAI服务器进行了DeepSeek-R1大模型的部署与实时调用。从购买HAI应用服务，到通过ChatBotUI、JupyterLab、CloudStudio等工具进行配置和调试，我们详细介绍了每个步骤。</p>
<p>通过本地和外网API的操作，我们不仅了解了模型部署的基本流程，还掌握了如何利用Ollama提供的API服务进行大模型调用。</p>
<hr>
<p>我是努力的小雨，一个正经的 Java 东北服务端开发，整天琢磨着 AI 技术这块儿的奥秘。特爱跟人交流技术，喜欢把自己的心得和大家分享。还当上了腾讯云创作之星，阿里云专家博主，华为云云享专家，掘金优秀作者。各种征文、开源比赛的牌子也拿了。</p>
<p>💡 想把我在技术路上走过的弯路和经验全都分享出来，给你们的学习和成长带来点启发，帮一把。</p>
<p>🌟 欢迎关注努力的小雨，咱一块儿进步！🌟</p>

</div>
<div class="clear"></div>

		</div>
		<div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.20628954460300927" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-05 17:18">2025-02-05 17:17</span>&nbsp;
<a href="https://www.cnblogs.com/guoxiaoyu">努力的小雨</a>&nbsp;
阅读(<span id="post_view_count">58</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18699495" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18699495);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18699495', targetLink: 'https://www.cnblogs.com/guoxiaoyu/p/18699495', title: '腾讯云HAI服务器上部署与调用DeepSeek-R1大模型的实战指南' })">举报</a>
</div>
	