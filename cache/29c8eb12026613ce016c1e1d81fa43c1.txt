
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/zylAK/p/18884621" title="发布于 2025-05-19 17:47">
    <span role="heading" aria-level="2">✨生物大语言模型Evo2——解码基因密码的AI革命🚀</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        
        本文深入解析生物大语言模型Evo2的Embedding魔法——通过提取基因序列的语义特征，结合深度神经网络（DNN），成功将BRCA1单核苷酸突变效应预测的AUROC从0.7左右提升至0.9左右。从NVIDIA NIM云端部署到Auto-dl本地环境搭建，从Embedding批量提取到DNN模型优化，提供开箱即用的代码与避坑指南，为生物计算研究者打开"AI+基因"的创新应用范式。
    </div>
<div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h3>🌟 2025：生物AI的"DeepSeek时刻"</h3>
<p>当整个中文互联网为国产大语言模型DeepSeek欢呼时，生命科学界正悄然掀起一场静默革命——由Arc Institute领衔，斯坦福、UC Berkeley、哥大、UCSF携手英伟达等顶尖AI企业，共同推出百亿参数级生物语义理解引擎Evo2！这个能直接"读懂"核苷酸语言的神奇模型，正在重新定义我们对基因密码的认知方式🧬</p>
<p>&nbsp;</p>
<p class="ds-markdown-paragraph">🌟模型亮点速览：</p>
<ul>
<li>
<p class="ds-markdown-paragraph">🧬 直接解析核苷酸序列的"生物语言"</p>
</li>
<li>
<p class="ds-markdown-paragraph">🚀 支持8192长度（base模型）1 百万（完整模型）超长基因片段处理</p>
</li>
<li>
<p class="ds-markdown-paragraph">🌍 跨物种基因理解能力升级</p>
</li>
<li>
<p class="ds-markdown-paragraph">🔓 完全开源！支持NVIDIA NIM云端部署和本地运行</p>
</li>
</ul>
<p class="ds-markdown-paragraph">（👉小贴士：想了解Evo1到Evo2的架构革命？快在评论区催更技术解析专题！）</p>
<p class="ds-markdown-paragraph">&nbsp;</p>
<p class="ds-markdown-paragraph">🔍本期实战目标：</p>
<p>　　🛠️ 从零开始的保姆级教程</p>
<p>　　🚀用Embedding+DNN实现BRCA1突变效应预测</p>
<p class="ds-markdown-paragraph">　　📊性能飞跃：相较于仅用score函数差值预测的0.7 AUROC（Fair级），Embedding+DNN方案直冲0.9 AUROC（Good级）📈</p>
<p>&nbsp;</p>
<p>&nbsp;✨ 小贴士：</p>
<p>我从零开始，租用新的Auto-dl服务器，搭建环境，重跑code，以保证每个新手小白都能有成功感地一次性运行成功，不产生任何报错。已准备好开箱即用的Auto-dl镜像，评论区@zylAK（我的博客园昵称）即刻获取🚀 如果觉得帖子不错欢迎转发zylAK的帖子给小伙伴们，你们的支持是我更新的动力。如果还想了解Evo2更多的应用，例如如何设计新的核酸序列、如何获得可解释的大语言模型理解等，都可以在评论区催更。</p>
<p>&nbsp;</p>
<p>废话不多说，以Auto-dl云服务器为例，直接上代码：</p>
<p>一、前期准备：<br>1.1 云服务器配置：</p>
<p><img src="https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519153719421-699431769.png" alt="" width="304" height="102" loading="lazy"></p>
<p>&nbsp;</p>
<p>1.2 开启Auto-dl的学术加速并从github上下载Evo2项目文件，激活：<br>命令行是：</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)">1</span> source /etc/<span style="color: rgba(0, 0, 0, 1)">network_turbo #开启学术加速<br>
</span><span style="color: rgba(0, 128, 128, 1)">2</span> git clone https:<span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">github.com/ArcInstitute/evo2.git #下载Evo2项目文件<br></span>
<span style="color: rgba(0, 128, 128, 1)">3</span> <span style="color: rgba(0, 0, 0, 1)">cd evo2 #进入项目路径<br></span></pre>
<pre><span style="color: rgba(0, 128, 128, 1)">4 git clone https://github.com/Zymrael/vortex.git</span><span class="pl-c1"> #手动安装vortex依赖</span></pre>
<pre><span style="color: rgba(0, 128, 128, 1)">5</span> python setup.py <span style="color: rgba(0, 0, 255, 1)">install</span> #项目激活</pre>
</div>
<p>&nbsp;</p>
<p>1.3 从hugging face镜像站hf-mirror上下载对应Evo2模型，并存储在本地，以供后续调用。目前4090机器的配置可以运行1b和7b的模型（完整和base版均可），40b模型可能需要内存更高的机器且需要多卡GPU部署，这一期暂不讨论。三种参数量的模型效果相差不那么明显。<br>命令行是：</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)">1</span> cd /root/autodl-tmp/evo2/<span style="color: rgba(0, 0, 0, 1)">evo2_models #在项目文件夹中单独创建一个evo2_model文件夹用于保存下载的模型，这样就不用每次调用时重新下载了
</span><span style="color: rgba(0, 128, 128, 1)">2</span> 
<span style="color: rgba(0, 128, 128, 1)">3</span> #设置huggingface-<span style="color: rgba(0, 0, 0, 1)">cli下载的镜像网址
</span><span style="color: rgba(0, 128, 128, 1)">4</span> export HF_ENDPOINT=https:<span style="color: rgba(0, 128, 0, 1)">//</span><span style="color: rgba(0, 128, 0, 1)">hf-mirror.com</span>
<span style="color: rgba(0, 128, 128, 1)">5</span> 
<span style="color: rgba(0, 128, 128, 1)">6</span> <span style="color: rgba(0, 0, 0, 1)">#下载evo2_1b_base模型为例
</span><span style="color: rgba(0, 128, 128, 1)">7</span> huggingface-cli download --resume-download arcinstitute/evo2_1b_base --local-dir /root/autodl-tmp/evo2/evo2_models</pre>
</div>
<p>正确的下载运行时会有如下的输出（进度条逐渐增加）</p>
<p><img src="https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519161115806-813906910.png" alt="" loading="lazy"></p>
<p>&nbsp;</p>
<p>二、模型加载与Embeddings提取</p>
<p>2.1 导入项目需要用到的所有packages</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> <span style="color: rgba(0, 0, 255, 1)">from</span> Bio <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> SeqIO
</span><span style="color: rgba(0, 128, 128, 1)"> 2</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> gzip
</span><span style="color: rgba(0, 128, 128, 1)"> 3</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> matplotlib.pyplot as plt
</span><span style="color: rgba(0, 128, 128, 1)"> 4</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> numpy as np
</span><span style="color: rgba(0, 128, 128, 1)"> 5</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> pandas as pd
</span><span style="color: rgba(0, 128, 128, 1)"> 6</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> os
</span><span style="color: rgba(0, 128, 128, 1)"> 7</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> seaborn as sns
</span><span style="color: rgba(0, 128, 128, 1)"> 8</span> <span style="color: rgba(0, 0, 255, 1)">from</span> sklearn.metrics <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> roc_auc_score
</span><span style="color: rgba(0, 128, 128, 1)"> 9</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> numpy as np
</span><span style="color: rgba(0, 128, 128, 1)">10</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> torch
</span><span style="color: rgba(0, 128, 128, 1)">11</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> torch.nn as nn
</span><span style="color: rgba(0, 128, 128, 1)">12</span> <span style="color: rgba(0, 0, 255, 1)">from</span> torch.utils.data <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> DataLoader, TensorDataset
</span><span style="color: rgba(0, 128, 128, 1)">13</span> <span style="color: rgba(0, 0, 255, 1)">from</span> sklearn.model_selection <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> train_test_split
</span><span style="color: rgba(0, 128, 128, 1)">14</span> <span style="color: rgba(0, 0, 255, 1)">from</span> sklearn.metrics <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> roc_auc_score
</span><span style="color: rgba(0, 128, 128, 1)">15</span> <span style="color: rgba(0, 0, 255, 1)">from</span> torch.optim.lr_scheduler <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> ReduceLROnPlateau
</span><span style="color: rgba(0, 128, 128, 1)">16</span> <span style="color: rgba(0, 0, 255, 1)">from</span> pathlib <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> Path
</span><span style="color: rgba(0, 128, 128, 1)">17</span> <span style="color: rgba(0, 0, 255, 1)">from</span> tqdm.notebook <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> tqdm
</span><span style="color: rgba(0, 128, 128, 1)">18</span> <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> transformer_engine.pytorch as te
</span><span style="color: rgba(0, 128, 128, 1)">19</span> <span style="color: rgba(0, 0, 255, 1)">from</span> transformer_engine.common <span style="color: rgba(0, 0, 255, 1)">import</span> recipe</pre>
</div>
<p>&nbsp;可能会出现报错：</p>
<p><img src="https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519162030634-373452541.png" alt="" loading="lazy"></p>
<p>&nbsp;但完全不影响后续代码运行。如果后期flash-attn包升级造成冲突，可以指定安装2.7.4版本。</p>
<p>&nbsp;</p>
<p>2.2 加载模型</p>
<div class="cnblogs_code">
<pre>os.chdir(<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">/root/autodl-tmp/evo2/evo2</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
model_path </span>= <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">/root/autodl-tmp/evo2/evo2_models/evo2_1b_base/evo2_1b_base.pt</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 0, 255, 1)">from</span> evo2.models <span style="color: rgba(0, 0, 255, 1)">import</span><span style="color: rgba(0, 0, 0, 1)"> Evo2
model </span>= Evo2(model_name=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">evo2_1b_base</span><span style="color: rgba(128, 0, 0, 1)">'</span>,local_path=model_path)</pre>
</div>
<p>&nbsp;</p>
<p>2.3 加载并解析输入数据——BRCA1数据，包括序列数据，突变位点，突变效应分类。详细说明请见Evo2项目案例介绍：https://github.com/ArcInstitute/evo2/tree/main/notebooks/brca1</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1 </span>os.chdir('/root/autodl-tmp/evo2')<br>   brca1_df =<span> pd.read_excel(</span></pre>
<pre><span style="color: rgba(0, 128, 128, 1)"> 2</span>     os.path.join(<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">notebooks</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">brca1</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">41586_2018_461_MOESM3_ESM.xlsx</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)"> 3</span>     header=2<span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)"> 4</span> <span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 5</span> brca1_df =<span style="color: rgba(0, 0, 0, 1)"> brca1_df[[
</span><span style="color: rgba(0, 128, 128, 1)"> 6</span>     <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">chromosome</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">position (hg19)</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">reference</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">alt</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">function.score.mean</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">func.class</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)"> 7</span> <span style="color: rgba(0, 0, 0, 1)">]]
</span><span style="color: rgba(0, 128, 128, 1)"> 8</span> 
<span style="color: rgba(0, 128, 128, 1)"> 9</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 对列名重命名</span>
<span style="color: rgba(0, 128, 128, 1)">10</span> brca1_df.rename(columns=<span style="color: rgba(0, 0, 0, 1)">{
</span><span style="color: rgba(0, 128, 128, 1)">11</span>     <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">chromosome</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">chrom</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">12</span>     <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">position (hg19)</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">pos</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">13</span>     <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">reference</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">ref</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">14</span>     <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">alt</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">alt</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">15</span>     <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">function.score.mean</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">score</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">16</span>     <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">func.class</span><span style="color: rgba(128, 0, 0, 1)">'</span>: <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">class</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">17</span> }, inplace=<span style="color: rgba(0, 0, 0, 1)">True)
</span><span style="color: rgba(0, 128, 128, 1)">18</span> 
<span style="color: rgba(0, 128, 128, 1)">19</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 将突变效应命名为二分类标签</span>
<span style="color: rgba(0, 128, 128, 1)">20</span> brca1_df[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">class</span><span style="color: rgba(128, 0, 0, 1)">'</span>] = brca1_df[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">class</span><span style="color: rgba(128, 0, 0, 1)">'</span>].replace([<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">FUNC</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">INT</span><span style="color: rgba(128, 0, 0, 1)">'</span>], <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">FUNC/INT</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">21</span> 
<span style="color: rgba(0, 128, 128, 1)">22</span> WINDOW_SIZE = 8192
<span style="color: rgba(0, 128, 128, 1)">23</span> 
<span style="color: rgba(0, 128, 128, 1)">24</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 读取17号染色体参考基因组序列</span>
<span style="color: rgba(0, 128, 128, 1)">25</span> with gzip.open(os.path.join(<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">notebooks</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">brca1</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">GRCh37.p13_chr17.fna.gz</span><span style="color: rgba(128, 0, 0, 1)">'</span>), <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">rt</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">) as handle:
</span><span style="color: rgba(0, 128, 128, 1)">26</span>     <span style="color: rgba(0, 0, 255, 1)">for</span> record <span style="color: rgba(0, 0, 255, 1)">in</span> SeqIO.parse(handle, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">fasta</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">):
</span><span style="color: rgba(0, 128, 128, 1)">27</span>         seq_chr17 =<span style="color: rgba(0, 0, 0, 1)"> str(record.seq)
</span><span style="color: rgba(0, 128, 128, 1)">28</span>         <span style="color: rgba(0, 0, 255, 1)">break</span>
<span style="color: rgba(0, 128, 128, 1)">29</span> 
<span style="color: rgba(0, 128, 128, 1)">30</span> <span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> parse_sequences(pos, ref, alt):
</span><span style="color: rgba(0, 128, 128, 1)">31</span>     <span style="color: rgba(128, 0, 0, 1)">"""</span>
<span style="color: rgba(0, 128, 128, 1)">32</span> <span style="color: rgba(128, 0, 0, 1)">    解析参考序列（未突变序列）和突变序列
</span><span style="color: rgba(0, 128, 128, 1)">33</span>     <span style="color: rgba(128, 0, 0, 1)">"""</span>
<span style="color: rgba(0, 128, 128, 1)">34</span>     p = pos - 1 <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Convert to 0-indexed position</span>
<span style="color: rgba(0, 128, 128, 1)">35</span>     full_seq =<span style="color: rgba(0, 0, 0, 1)"> seq_chr17
</span><span style="color: rgba(0, 128, 128, 1)">36</span> 
<span style="color: rgba(0, 128, 128, 1)">37</span>     ref_seq_start = max(0, p - WINDOW_SIZE//2<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">38</span>     ref_seq_end = min(len(full_seq), p + WINDOW_SIZE//2<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">39</span>     ref_seq =<span style="color: rgba(0, 0, 0, 1)"> seq_chr17[ref_seq_start:ref_seq_end]
</span><span style="color: rgba(0, 128, 128, 1)">40</span>     snv_pos_in_ref = min(WINDOW_SIZE//2<span style="color: rgba(0, 0, 0, 1)">, p)
</span><span style="color: rgba(0, 128, 128, 1)">41</span>     var_seq = ref_seq[:snv_pos_in_ref] + alt + ref_seq[snv_pos_in_ref+1<span style="color: rgba(0, 0, 0, 1)">:]
</span><span style="color: rgba(0, 128, 128, 1)">42</span> 
<span style="color: rgba(0, 128, 128, 1)">43</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 数据合理性检查</span>
<span style="color: rgba(0, 128, 128, 1)">44</span>     <span style="color: rgba(0, 0, 255, 1)">assert</span> len(var_seq) ==<span style="color: rgba(0, 0, 0, 1)"> len(ref_seq)
</span><span style="color: rgba(0, 128, 128, 1)">45</span>     <span style="color: rgba(0, 0, 255, 1)">assert</span> ref_seq[snv_pos_in_ref] ==<span style="color: rgba(0, 0, 0, 1)"> ref
</span><span style="color: rgba(0, 128, 128, 1)">46</span>     <span style="color: rgba(0, 0, 255, 1)">assert</span> var_seq[snv_pos_in_ref] ==<span style="color: rgba(0, 0, 0, 1)"> alt
</span><span style="color: rgba(0, 128, 128, 1)">47</span> 
<span style="color: rgba(0, 128, 128, 1)">48</span>     <span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> ref_seq, var_seq
</span><span style="color: rgba(0, 128, 128, 1)">49</span> 
<span style="color: rgba(0, 128, 128, 1)">50</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 给参考序列一个索引值</span>
<span style="color: rgba(0, 128, 128, 1)">51</span> ref_seqs =<span style="color: rgba(0, 0, 0, 1)"> []
</span><span style="color: rgba(0, 128, 128, 1)">52</span> ref_seq_to_index =<span style="color: rgba(0, 0, 0, 1)"> {}
</span><span style="color: rgba(0, 128, 128, 1)">53</span> 
<span style="color: rgba(0, 128, 128, 1)">54</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 解析序列并存储索引值</span>
<span style="color: rgba(0, 128, 128, 1)">55</span> ref_seq_indexes =<span style="color: rgba(0, 0, 0, 1)"> []
</span><span style="color: rgba(0, 128, 128, 1)">56</span> var_seqs =<span style="color: rgba(0, 0, 0, 1)"> []
</span><span style="color: rgba(0, 128, 128, 1)">57</span> 
<span style="color: rgba(0, 128, 128, 1)">58</span> <span style="color: rgba(0, 0, 255, 1)">for</span> _, row <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> brca1_df.iterrows():
</span><span style="color: rgba(0, 128, 128, 1)">59</span>     ref_seq, var_seq = parse_sequences(row[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">pos</span><span style="color: rgba(128, 0, 0, 1)">'</span>], row[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">ref</span><span style="color: rgba(128, 0, 0, 1)">'</span>], row[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">alt</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">])
</span><span style="color: rgba(0, 128, 128, 1)">60</span> 
<span style="color: rgba(0, 128, 128, 1)">61</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 给当前循环到的参考序列获取/创建索引</span>
<span style="color: rgba(0, 128, 128, 1)">62</span>     <span style="color: rgba(0, 0, 255, 1)">if</span> ref_seq <span style="color: rgba(0, 0, 255, 1)">not</span> <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> ref_seq_to_index:
</span><span style="color: rgba(0, 128, 128, 1)">63</span>         ref_seq_to_index[ref_seq] =<span style="color: rgba(0, 0, 0, 1)"> len(ref_seqs)
</span><span style="color: rgba(0, 128, 128, 1)">64</span> <span style="color: rgba(0, 0, 0, 1)">        ref_seqs.append(ref_seq)
</span><span style="color: rgba(0, 128, 128, 1)">65</span>     
<span style="color: rgba(0, 128, 128, 1)">66</span> <span style="color: rgba(0, 0, 0, 1)">    ref_seq_indexes.append(ref_seq_to_index[ref_seq])
</span><span style="color: rgba(0, 128, 128, 1)">67</span> <span style="color: rgba(0, 0, 0, 1)">    var_seqs.append(var_seq)
</span><span style="color: rgba(0, 128, 128, 1)">68</span> 
<span style="color: rgba(0, 128, 128, 1)">69</span> ref_seq_indexes = np.array(ref_seq_indexes)</pre>
</div>
<p>&nbsp;</p>
<p>2.4 以BCRA1序列为输入，提取全部全部层的Embedding并保存下来</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 配置参数 ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 2</span> device =<span style="color: rgba(0, 0, 0, 1)"> next(model.model.parameters()).device
</span><span style="color: rgba(0, 128, 128, 1)"> 3</span> candidate_layers = [f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">blocks.{i}.pre_norm</span><span style="color: rgba(128, 0, 0, 1)">"</span> <span style="color: rgba(0, 0, 255, 1)">for</span> i <span style="color: rgba(0, 0, 255, 1)">in</span> range(25<span style="color: rgba(0, 0, 0, 1)">)]
</span><span style="color: rgba(0, 128, 128, 1)"> 4</span> batch_size = 8  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 根据GPU显存调整</span>
<span style="color: rgba(0, 128, 128, 1)"> 5</span> save_dir = <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">extract_embeddings</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)"> 6</span> os.makedirs(save_dir, exist_ok=<span style="color: rgba(0, 0, 0, 1)">True)
</span><span style="color: rgba(0, 128, 128, 1)"> 7</span> 
<span style="color: rgba(0, 128, 128, 1)"> 8</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 批量嵌入提取  ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 9</span> <span style="color: rgba(0, 0, 255, 1)">def</span> process_sequences(seq_list, layer_name, desc, prefix=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ref</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">):
</span><span style="color: rgba(0, 128, 128, 1)">10</span>     <span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">批量处理序列嵌入并确保文件保存</span><span style="color: rgba(128, 0, 0, 1)">"""</span>
<span style="color: rgba(0, 128, 128, 1)">11</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 生成标准化文件名</span>
<span style="color: rgba(0, 128, 128, 1)">12</span>     sanitized_layer = layer_name.replace(<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">.</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">_</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">13</span>     memmap_path = os.path.join(save_dir, f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">{prefix}_{sanitized_layer}.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">14</span>     
<span style="color: rgba(0, 128, 128, 1)">15</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 创建内存映射文件并立即保存头信息</span>
<span style="color: rgba(0, 128, 128, 1)">16</span>     emb_mmap =<span style="color: rgba(0, 0, 0, 1)"> np.lib.format.open_memmap(
</span><span style="color: rgba(0, 128, 128, 1)">17</span> <span style="color: rgba(0, 0, 0, 1)">        memmap_path, 
</span><span style="color: rgba(0, 128, 128, 1)">18</span>         dtype=<span style="color: rgba(0, 0, 0, 1)">np.float32,
</span><span style="color: rgba(0, 128, 128, 1)">19</span>         mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">w+</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">20</span>         shape=(len(seq_list), 1920<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">21</span> <span style="color: rgba(0, 0, 0, 1)">    )
</span><span style="color: rgba(0, 128, 128, 1)">22</span>     
<span style="color: rgba(0, 128, 128, 1)">23</span>     <span style="color: rgba(0, 0, 255, 1)">try</span><span style="color: rgba(0, 0, 0, 1)">:
</span><span style="color: rgba(0, 128, 128, 1)">24</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 分批处理</span>
<span style="color: rgba(0, 128, 128, 1)">25</span>         <span style="color: rgba(0, 0, 255, 1)">for</span> i <span style="color: rgba(0, 0, 255, 1)">in</span> tqdm(range(0, len(seq_list), batch_size), desc=desc, leave=<span style="color: rgba(0, 0, 0, 1)">False):
</span><span style="color: rgba(0, 128, 128, 1)">26</span>             batch_seqs = seq_list[i:i+<span style="color: rgba(0, 0, 0, 1)">batch_size]
</span><span style="color: rgba(0, 128, 128, 1)">27</span>             
<span style="color: rgba(0, 128, 128, 1)">28</span>             <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> Tokenize并填充</span>
<span style="color: rgba(0, 128, 128, 1)">29</span>             batch_tokens =<span style="color: rgba(0, 0, 0, 1)"> []
</span><span style="color: rgba(0, 128, 128, 1)">30</span>             <span style="color: rgba(0, 0, 255, 1)">for</span> seq <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> batch_seqs:
</span><span style="color: rgba(0, 128, 128, 1)">31</span>                 tokens =<span style="color: rgba(0, 0, 0, 1)"> model.tokenizer.tokenize(seq)
</span><span style="color: rgba(0, 128, 128, 1)">32</span>                 batch_tokens.append(torch.tensor(tokens, dtype=<span style="color: rgba(0, 0, 0, 1)">torch.long))
</span><span style="color: rgba(0, 128, 128, 1)">33</span>             
<span style="color: rgba(0, 128, 128, 1)">34</span>             max_len = max(len(t) <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> batch_tokens)
</span><span style="color: rgba(0, 128, 128, 1)">35</span>             padded_tokens =<span style="color: rgba(0, 0, 0, 1)"> torch.stack([
</span><span style="color: rgba(0, 128, 128, 1)">36</span>                 torch.nn.functional.pad(t, (0, max_len - len(t))) <span style="color: rgba(0, 0, 255, 1)">for</span> t <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> batch_tokens
</span><span style="color: rgba(0, 128, 128, 1)">37</span> <span style="color: rgba(0, 0, 0, 1)">            ]).to(device)
</span><span style="color: rgba(0, 128, 128, 1)">38</span>             
<span style="color: rgba(0, 128, 128, 1)">39</span>             <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 前向传播</span>
<span style="color: rgba(0, 128, 128, 1)">40</span> <span style="color: rgba(0, 0, 0, 1)">            with torch.no_grad():
</span><span style="color: rgba(0, 128, 128, 1)">41</span>                 _, emb_dict =<span style="color: rgba(0, 0, 0, 1)"> model.forward(
</span><span style="color: rgba(0, 128, 128, 1)">42</span> <span style="color: rgba(0, 0, 0, 1)">                    padded_tokens,
</span><span style="color: rgba(0, 128, 128, 1)">43</span>                     return_embeddings=<span style="color: rgba(0, 0, 0, 1)">True,
</span><span style="color: rgba(0, 128, 128, 1)">44</span>                     layer_names=<span style="color: rgba(0, 0, 0, 1)">[layer_name]
</span><span style="color: rgba(0, 128, 128, 1)">45</span> <span style="color: rgba(0, 0, 0, 1)">                )
</span><span style="color: rgba(0, 128, 128, 1)">46</span>             
<span style="color: rgba(0, 128, 128, 1)">47</span>             <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 写入内存映射文件</span>
<span style="color: rgba(0, 128, 128, 1)">48</span>             batch_emb = emb_dict[layer_name].float().mean(dim=1<span style="color: rgba(0, 0, 0, 1)">).cpu().numpy()
</span><span style="color: rgba(0, 128, 128, 1)">49</span>             emb_mmap[i:i+len(batch_emb)] =<span style="color: rgba(0, 0, 0, 1)"> batch_emb
</span><span style="color: rgba(0, 128, 128, 1)">50</span>             
<span style="color: rgba(0, 128, 128, 1)">51</span>             <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 立即刷新写入磁盘</span>
<span style="color: rgba(0, 128, 128, 1)">52</span> <span style="color: rgba(0, 0, 0, 1)">            emb_mmap.flush()
</span><span style="color: rgba(0, 128, 128, 1)">53</span>             
<span style="color: rgba(0, 128, 128, 1)">54</span>     <span style="color: rgba(0, 0, 255, 1)">finally</span><span style="color: rgba(0, 0, 0, 1)">:
</span><span style="color: rgba(0, 128, 128, 1)">55</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 确保文件关闭</span>
<span style="color: rgba(0, 128, 128, 1)">56</span>         <span style="color: rgba(0, 0, 255, 1)">del</span><span style="color: rgba(0, 0, 0, 1)"> emb_mmap
</span><span style="color: rgba(0, 128, 128, 1)">57</span>     
<span style="color: rgba(0, 128, 128, 1)">58</span>     <span style="color: rgba(0, 0, 255, 1)">return</span><span style="color: rgba(0, 0, 0, 1)"> memmap_path
</span><span style="color: rgba(0, 128, 128, 1)">59</span> 
<span style="color: rgba(0, 128, 128, 1)">60</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 主流程 ==========</span>
<span style="color: rgba(0, 128, 128, 1)">61</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 预先生成全局索引文件 (只需保存一次)</span>
<span style="color: rgba(0, 128, 128, 1)">62</span> np.save(os.path.join(save_dir, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ref_idx.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">), ref_seq_indexes)
</span><span style="color: rgba(0, 128, 128, 1)">63</span> 
<span style="color: rgba(0, 128, 128, 1)">64</span> <span style="color: rgba(0, 0, 255, 1)">for</span> layer_name <span style="color: rgba(0, 0, 255, 1)">in</span> tqdm(candidate_layers, desc=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">🔍 Processing Layers</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">):
</span><span style="color: rgba(0, 128, 128, 1)">65</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 处理参考序列 (生成 ref_blocks_0_pre_norm.npy)</span>
<span style="color: rgba(0, 128, 128, 1)">66</span>     _ =<span style="color: rgba(0, 0, 0, 1)"> process_sequences(
</span><span style="color: rgba(0, 128, 128, 1)">67</span> <span style="color: rgba(0, 0, 0, 1)">        ref_seqs, 
</span><span style="color: rgba(0, 128, 128, 1)">68</span> <span style="color: rgba(0, 0, 0, 1)">        layer_name,
</span><span style="color: rgba(0, 128, 128, 1)">69</span>         f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">🧬 Ref {layer_name}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">70</span>         prefix=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ref</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">71</span> <span style="color: rgba(0, 0, 0, 1)">    )
</span><span style="color: rgba(0, 128, 128, 1)">72</span>     
<span style="color: rgba(0, 128, 128, 1)">73</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 处理变异序列 (生成 var_blocks_0_pre_norm.npy)</span>
<span style="color: rgba(0, 128, 128, 1)">74</span>     _ =<span style="color: rgba(0, 0, 0, 1)"> process_sequences(
</span><span style="color: rgba(0, 128, 128, 1)">75</span> <span style="color: rgba(0, 0, 0, 1)">        var_seqs,
</span><span style="color: rgba(0, 128, 128, 1)">76</span> <span style="color: rgba(0, 0, 0, 1)">        layer_name,
</span><span style="color: rgba(0, 128, 128, 1)">77</span>         f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">🧬 Var {layer_name}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">,
</span><span style="color: rgba(0, 128, 128, 1)">78</span>         prefix=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">var</span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">79</span>     )</pre>
</div>
<p>正确运行后有如下输出显示：</p>
<p><img src="https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519170247866-509314315.png" alt="" width="657" height="115" loading="lazy"></p>
<p>&nbsp;</p>
<p>三、基于保存的Embeddings开发下游的突变效应预测器：</p>
<p>3.1 Embedding数据加载函数的定义</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 新增配置参数 ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 2</span> embed_dir = Path(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">extract_embeddings</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 3</span> layers_to_train = [f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">blocks.{i}.pre_norm</span><span style="color: rgba(128, 0, 0, 1)">"</span> <span style="color: rgba(0, 0, 255, 1)">for</span> i <span style="color: rgba(0, 0, 255, 1)">in</span> range(25)]  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 需要训练的层列表，全部的25层</span>
<span style="color: rgba(0, 128, 128, 1)"> 4</span> results_dir = Path(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">training_results</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 5</span> results_dir.mkdir(exist_ok=<span style="color: rgba(0, 0, 0, 1)">True)
</span><span style="color: rgba(0, 128, 128, 1)"> 6</span> 
<span style="color: rgba(0, 128, 128, 1)"> 7</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 数据加载函数 ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 8</span> <span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> load_layer_data(layer_name):
</span><span style="color: rgba(0, 128, 128, 1)"> 9</span>     <span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">加载指定层的嵌入数据和标签</span><span style="color: rgba(128, 0, 0, 1)">"""</span>
<span style="color: rgba(0, 128, 128, 1)">10</span>     sanitized = layer_name.replace(<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">.</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">_</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">11</span>     
<span style="color: rgba(0, 128, 128, 1)">12</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 加载嵌入数据（内存映射模式）</span>
<span style="color: rgba(0, 128, 128, 1)">13</span>     ref_emb = np.load(embed_dir/f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ref_{sanitized}.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span>, mmap_mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">r</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">14</span>     var_emb = np.load(embed_dir/f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">var_{sanitized}.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span>, mmap_mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">r</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">15</span>     ref_idx = np.load(embed_dir/<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">ref_idx.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">16</span>     
<span style="color: rgba(0, 128, 128, 1)">17</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 拼接特征</span>
<span style="color: rgba(0, 128, 128, 1)">18</span>     X = np.concatenate([ref_emb[ref_idx], var_emb], axis=1<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">19</span>     
<span style="color: rgba(0, 128, 128, 1)">20</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 获取标签（从原始数据框）</span>
<span style="color: rgba(0, 128, 128, 1)">21</span>     y = brca1_df[<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">class</span><span style="color: rgba(128, 0, 0, 1)">'</span>].map({<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">FUNC/INT</span><span style="color: rgba(128, 0, 0, 1)">'</span>:0, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">LOF</span><span style="color: rgba(128, 0, 0, 1)">'</span>:1<span style="color: rgba(0, 0, 0, 1)">}).values
</span><span style="color: rgba(0, 128, 128, 1)">22</span>     
<span style="color: rgba(0, 128, 128, 1)">23</span>     <span style="color: rgba(0, 0, 255, 1)">return</span> X, y</pre>
</div>
<p>&nbsp;</p>
<p>3.2 Embeddings数据正确性检验。主要是验证数据是否存在，以及是否符合Evo2_1b_base模型中间层的维度（1920维）</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 示例，检查第24层文件是否存在</span>
<span style="color: rgba(0, 128, 128, 1)"> 2</span> <span style="color: rgba(0, 0, 255, 1)">assert</span> os.path.exists(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">extract_embeddings/ref_blocks_24_pre_norm.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 3</span> <span style="color: rgba(0, 0, 255, 1)">assert</span> os.path.exists(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">extract_embeddings/var_blocks_24_pre_norm.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 4</span> 
<span style="color: rgba(0, 128, 128, 1)"> 5</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 验证嵌入维度</span>
<span style="color: rgba(0, 128, 128, 1)"> 6</span> ref_emb = np.load(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">extract_embeddings/ref_blocks_24_pre_norm.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span>, mmap_mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">r</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 7</span> var_emb = np.load(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">extract_embeddings/var_blocks_24_pre_norm.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span>, mmap_mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">r</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 8</span> <span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">参考序列嵌入维度: {ref_emb.shape}</span><span style="color: rgba(128, 0, 0, 1)">"</span>)  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 应为 (N_ref, 1920)</span>
<span style="color: rgba(0, 128, 128, 1)"> 9</span> <span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">变异序列嵌入维度: {var_emb.shape}</span><span style="color: rgba(128, 0, 0, 1)">"</span>)  <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 应为 (N_ref, 1920)</span>
<span style="color: rgba(0, 128, 128, 1)">10</span> 
<span style="color: rgba(0, 128, 128, 1)">11</span> <span style="color: rgba(0, 0, 255, 1)">for</span> layer_name <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> layers_to_train:
</span><span style="color: rgba(0, 128, 128, 1)">12</span>     <span style="color: rgba(0, 0, 255, 1)">print</span><span style="color: rgba(0, 0, 0, 1)">(layer_name)
</span><span style="color: rgba(0, 128, 128, 1)">13</span>     X, y =<span style="color: rgba(0, 0, 0, 1)"> load_layer_data(layer_name)
</span><span style="color: rgba(0, 128, 128, 1)">14</span>     <span style="color: rgba(0, 0, 255, 1)">print</span>(X.shape)</pre>
</div>
<p>&nbsp;</p>
<p><strong>3.3 （重要）定义分离器DNN的结构（仿照原文中的DNN结构）</strong></p>
<p></p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 模型架构 ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 2</span> <span style="color: rgba(0, 0, 255, 1)">class</span><span style="color: rgba(0, 0, 0, 1)"> BRCA1Classifier(nn.Module):
</span><span style="color: rgba(0, 128, 128, 1)"> 3</span>     <span style="color: rgba(0, 0, 255, 1)">def</span> <span style="color: rgba(128, 0, 128, 1)">__init__</span><span style="color: rgba(0, 0, 0, 1)">(self, input_dim):
</span><span style="color: rgba(0, 128, 128, 1)"> 4</span>         super().<span style="color: rgba(128, 0, 128, 1)">__init__</span><span style="color: rgba(0, 0, 0, 1)">()
</span><span style="color: rgba(0, 128, 128, 1)"> 5</span>         self.net =<span style="color: rgba(0, 0, 0, 1)"> nn.Sequential(
</span><span style="color: rgba(0, 128, 128, 1)"> 6</span>             nn.Linear(input_dim, 512<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)"> 7</span> <span style="color: rgba(0, 0, 0, 1)">            nn.ReLU(),
</span><span style="color: rgba(0, 128, 128, 1)"> 8</span>             nn.BatchNorm1d(512<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)"> 9</span>             nn.Dropout(0.3<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)">10</span>             
<span style="color: rgba(0, 128, 128, 1)">11</span>             nn.Linear(512, 128<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)">12</span> <span style="color: rgba(0, 0, 0, 1)">            nn.ReLU(),
</span><span style="color: rgba(0, 128, 128, 1)">13</span>             nn.BatchNorm1d(128<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)">14</span>             nn.Dropout(0.3<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)">15</span>             
<span style="color: rgba(0, 128, 128, 1)">16</span>             nn.Linear(128, 32<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)">17</span> <span style="color: rgba(0, 0, 0, 1)">            nn.ReLU(),
</span><span style="color: rgba(0, 128, 128, 1)">18</span>             nn.BatchNorm1d(32<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)">19</span>             
<span style="color: rgba(0, 128, 128, 1)">20</span>             nn.Linear(32, 1<span style="color: rgba(0, 0, 0, 1)">),
</span><span style="color: rgba(0, 128, 128, 1)">21</span> <span style="color: rgba(0, 0, 0, 1)">            nn.Sigmoid()
</span><span style="color: rgba(0, 128, 128, 1)">22</span> <span style="color: rgba(0, 0, 0, 1)">        )
</span><span style="color: rgba(0, 128, 128, 1)">23</span>         
<span style="color: rgba(0, 128, 128, 1)">24</span>     <span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> forward(self, x):
</span><span style="color: rgba(0, 128, 128, 1)">25</span>         <span style="color: rgba(0, 0, 255, 1)">return</span> self.net(x)</pre>
</div>
<p>&nbsp;</p>
<p><strong>3.4 （重要）训练流程定义</strong></p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)">  1</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 训练流程 ==========</span>
<span style="color: rgba(0, 128, 128, 1)">  2</span> <span style="color: rgba(0, 0, 255, 1)">def</span><span style="color: rgba(0, 0, 0, 1)"> train_for_layer(layer_name):
</span><span style="color: rgba(0, 128, 128, 1)">  3</span>     <span style="color: rgba(128, 0, 0, 1)">"""</span><span style="color: rgba(128, 0, 0, 1)">单层训练流程</span><span style="color: rgba(128, 0, 0, 1)">"""</span>
<span style="color: rgba(0, 128, 128, 1)">  4</span>     <span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">\n=== 开始训练层 {layer_name} ===</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">  5</span>     
<span style="color: rgba(0, 128, 128, 1)">  6</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 加载数据</span>
<span style="color: rgba(0, 128, 128, 1)">  7</span>     X, y =<span style="color: rgba(0, 0, 0, 1)"> load_layer_data(layer_name)
</span><span style="color: rgba(0, 128, 128, 1)">  8</span>     
<span style="color: rgba(0, 128, 128, 1)">  9</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 数据划分</span>
<span style="color: rgba(0, 128, 128, 1)"> 10</span>     X_temp, X_test, y_temp, y_test =<span style="color: rgba(0, 0, 0, 1)"> train_test_split(
</span><span style="color: rgba(0, 128, 128, 1)"> 11</span>         X, y, test_size=0.2, random_state=42, stratify=<span style="color: rgba(0, 0, 0, 1)">y
</span><span style="color: rgba(0, 128, 128, 1)"> 12</span> <span style="color: rgba(0, 0, 0, 1)">    )
</span><span style="color: rgba(0, 128, 128, 1)"> 13</span>     X_train, X_val, y_train, y_val =<span style="color: rgba(0, 0, 0, 1)"> train_test_split(
</span><span style="color: rgba(0, 128, 128, 1)"> 14</span>         X_temp, y_temp, test_size=0.25, random_state=42, stratify=<span style="color: rgba(0, 0, 0, 1)">y_temp
</span><span style="color: rgba(0, 128, 128, 1)"> 15</span> <span style="color: rgba(0, 0, 0, 1)">    )
</span><span style="color: rgba(0, 128, 128, 1)"> 16</span>     
<span style="color: rgba(0, 128, 128, 1)"> 17</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 转换为PyTorch Dataset</span>
<span style="color: rgba(0, 128, 128, 1)"> 18</span>     train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train).unsqueeze(1<span style="color: rgba(0, 0, 0, 1)">))
</span><span style="color: rgba(0, 128, 128, 1)"> 19</span>     val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val).unsqueeze(1<span style="color: rgba(0, 0, 0, 1)">))
</span><span style="color: rgba(0, 128, 128, 1)"> 20</span>     test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test).unsqueeze(1<span style="color: rgba(0, 0, 0, 1)">))
</span><span style="color: rgba(0, 128, 128, 1)"> 21</span>     
<span style="color: rgba(0, 128, 128, 1)"> 22</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 训练配置 ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 23</span>     device = torch.device(<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cuda</span><span style="color: rgba(128, 0, 0, 1)">"</span> <span style="color: rgba(0, 0, 255, 1)">if</span> torch.cuda.is_available() <span style="color: rgba(0, 0, 255, 1)">else</span> <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">cpu</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 24</span>     model = BRCA1Classifier(X.shape[1<span style="color: rgba(0, 0, 0, 1)">]).to(device)
</span><span style="color: rgba(0, 128, 128, 1)"> 25</span> 
<span style="color: rgba(0, 128, 128, 1)"> 26</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 优化器和损失函数</span>
<span style="color: rgba(0, 128, 128, 1)"> 27</span>     optimizer = torch.optim.Adam(model.parameters(), lr=3e-4<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 28</span>     criterion =<span style="color: rgba(0, 0, 0, 1)"> nn.BCELoss()
</span><span style="color: rgba(0, 128, 128, 1)"> 29</span> 
<span style="color: rgba(0, 128, 128, 1)"> 30</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 学习率调度器</span>
<span style="color: rgba(0, 128, 128, 1)"> 31</span>     scheduler =<span style="color: rgba(0, 0, 0, 1)"> ReduceLROnPlateau(
</span><span style="color: rgba(0, 128, 128, 1)"> 32</span> <span style="color: rgba(0, 0, 0, 1)">        optimizer, 
</span><span style="color: rgba(0, 128, 128, 1)"> 33</span>         mode=<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">max</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)"> 34</span>         factor=0.5<span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)"> 35</span>         patience=20<span style="color: rgba(0, 0, 0, 1)">, 
</span><span style="color: rgba(0, 128, 128, 1)"> 36</span>         min_lr=1e-6
<span style="color: rgba(0, 128, 128, 1)"> 37</span> <span style="color: rgba(0, 0, 0, 1)">    )
</span><span style="color: rgba(0, 128, 128, 1)"> 38</span>     
<span style="color: rgba(0, 128, 128, 1)"> 39</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 数据加载器</span>
<span style="color: rgba(0, 128, 128, 1)"> 40</span>     train_loader = DataLoader(train_dataset, batch_size=128, shuffle=<span style="color: rgba(0, 0, 0, 1)">True)
</span><span style="color: rgba(0, 128, 128, 1)"> 41</span>     val_loader = DataLoader(val_dataset, batch_size=128<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 42</span>     test_loader = DataLoader(test_dataset, batch_size=128<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 43</span> 
<span style="color: rgba(0, 128, 128, 1)"> 44</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 训练循环 ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 45</span>     best_auc =<span style="color: rgba(0, 0, 0, 1)"> 0
</span><span style="color: rgba(0, 128, 128, 1)"> 46</span>     patience_counter =<span style="color: rgba(0, 0, 0, 1)"> 0
</span><span style="color: rgba(0, 128, 128, 1)"> 47</span>     max_patience = 100
<span style="color: rgba(0, 128, 128, 1)"> 48</span> 
<span style="color: rgba(0, 128, 128, 1)"> 49</span>     <span style="color: rgba(0, 0, 255, 1)">for</span> epoch <span style="color: rgba(0, 0, 255, 1)">in</span> range(500<span style="color: rgba(0, 0, 0, 1)">):
</span><span style="color: rgba(0, 128, 128, 1)"> 50</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 训练阶段</span>
<span style="color: rgba(0, 128, 128, 1)"> 51</span> <span style="color: rgba(0, 0, 0, 1)">        model.train()
</span><span style="color: rgba(0, 128, 128, 1)"> 52</span>         train_loss =<span style="color: rgba(0, 0, 0, 1)"> 0
</span><span style="color: rgba(0, 128, 128, 1)"> 53</span>         <span style="color: rgba(0, 0, 255, 1)">for</span> inputs, labels <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> train_loader:
</span><span style="color: rgba(0, 128, 128, 1)"> 54</span>             inputs, labels =<span style="color: rgba(0, 0, 0, 1)"> inputs.to(device), labels.to(device)
</span><span style="color: rgba(0, 128, 128, 1)"> 55</span>             
<span style="color: rgba(0, 128, 128, 1)"> 56</span> <span style="color: rgba(0, 0, 0, 1)">            optimizer.zero_grad()
</span><span style="color: rgba(0, 128, 128, 1)"> 57</span>             outputs =<span style="color: rgba(0, 0, 0, 1)"> model(inputs)
</span><span style="color: rgba(0, 128, 128, 1)"> 58</span>             loss =<span style="color: rgba(0, 0, 0, 1)"> criterion(outputs, labels)
</span><span style="color: rgba(0, 128, 128, 1)"> 59</span>         
<span style="color: rgba(0, 128, 128, 1)"> 60</span>             <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 梯度裁剪</span>
<span style="color: rgba(0, 128, 128, 1)"> 61</span>             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0<span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 62</span>         
<span style="color: rgba(0, 128, 128, 1)"> 63</span> <span style="color: rgba(0, 0, 0, 1)">            loss.backward()
</span><span style="color: rgba(0, 128, 128, 1)"> 64</span> <span style="color: rgba(0, 0, 0, 1)">            optimizer.step()
</span><span style="color: rgba(0, 128, 128, 1)"> 65</span>             train_loss += loss.item() *<span style="color: rgba(0, 0, 0, 1)"> inputs.size(0)
</span><span style="color: rgba(0, 128, 128, 1)"> 66</span>     
<span style="color: rgba(0, 128, 128, 1)"> 67</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 验证阶段</span>
<span style="color: rgba(0, 128, 128, 1)"> 68</span> <span style="color: rgba(0, 0, 0, 1)">        model.eval()
</span><span style="color: rgba(0, 128, 128, 1)"> 69</span>         val_loss =<span style="color: rgba(0, 0, 0, 1)"> 0
</span><span style="color: rgba(0, 128, 128, 1)"> 70</span>         y_true, y_pred =<span style="color: rgba(0, 0, 0, 1)"> [], []
</span><span style="color: rgba(0, 128, 128, 1)"> 71</span> <span style="color: rgba(0, 0, 0, 1)">        with torch.no_grad():
</span><span style="color: rgba(0, 128, 128, 1)"> 72</span>             <span style="color: rgba(0, 0, 255, 1)">for</span> inputs, labels <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> val_loader:
</span><span style="color: rgba(0, 128, 128, 1)"> 73</span>                 inputs, labels =<span style="color: rgba(0, 0, 0, 1)"> inputs.to(device), labels.to(device)
</span><span style="color: rgba(0, 128, 128, 1)"> 74</span>                 outputs =<span style="color: rgba(0, 0, 0, 1)"> model(inputs)
</span><span style="color: rgba(0, 128, 128, 1)"> 75</span>                 val_loss += criterion(outputs, labels).item() *<span style="color: rgba(0, 0, 0, 1)"> inputs.size(0)
</span><span style="color: rgba(0, 128, 128, 1)"> 76</span> <span style="color: rgba(0, 0, 0, 1)">                y_true.extend(labels.cpu().numpy())
</span><span style="color: rgba(0, 128, 128, 1)"> 77</span> <span style="color: rgba(0, 0, 0, 1)">                y_pred.extend(outputs.cpu().numpy())
</span><span style="color: rgba(0, 128, 128, 1)"> 78</span>     
<span style="color: rgba(0, 128, 128, 1)"> 79</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 计算指标</span>
<span style="color: rgba(0, 128, 128, 1)"> 80</span>         train_loss /=<span style="color: rgba(0, 0, 0, 1)"> len(train_loader.dataset)
</span><span style="color: rgba(0, 128, 128, 1)"> 81</span>         val_loss /=<span style="color: rgba(0, 0, 0, 1)"> len(val_loader.dataset)
</span><span style="color: rgba(0, 128, 128, 1)"> 82</span>         val_auc =<span style="color: rgba(0, 0, 0, 1)"> roc_auc_score(y_true, y_pred)
</span><span style="color: rgba(0, 128, 128, 1)"> 83</span>     
<span style="color: rgba(0, 128, 128, 1)"> 84</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 学习率调整</span>
<span style="color: rgba(0, 128, 128, 1)"> 85</span> <span style="color: rgba(0, 0, 0, 1)">        scheduler.step(val_auc)
</span><span style="color: rgba(0, 128, 128, 1)"> 86</span>     
<span style="color: rgba(0, 128, 128, 1)"> 87</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 早停机制</span>
<span style="color: rgba(0, 128, 128, 1)"> 88</span>         <span style="color: rgba(0, 0, 255, 1)">if</span> val_auc &gt;<span style="color: rgba(0, 0, 0, 1)"> best_auc:
</span><span style="color: rgba(0, 128, 128, 1)"> 89</span>             best_auc =<span style="color: rgba(0, 0, 0, 1)"> val_auc
</span><span style="color: rgba(0, 128, 128, 1)"> 90</span>             patience_counter =<span style="color: rgba(0, 0, 0, 1)"> 0
</span><span style="color: rgba(0, 128, 128, 1)"> 91</span>             torch.save(model.state_dict(), <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">best_model.pth</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 92</span>         <span style="color: rgba(0, 0, 255, 1)">else</span><span style="color: rgba(0, 0, 0, 1)">:
</span><span style="color: rgba(0, 128, 128, 1)"> 93</span>             patience_counter += 1
<span style="color: rgba(0, 128, 128, 1)"> 94</span>             <span style="color: rgba(0, 0, 255, 1)">if</span> patience_counter &gt;=<span style="color: rgba(0, 0, 0, 1)"> max_patience:
</span><span style="color: rgba(0, 128, 128, 1)"> 95</span>                 <span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">早停触发于第{epoch}轮</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)"> 96</span>                 <span style="color: rgba(0, 0, 255, 1)">break</span>
<span style="color: rgba(0, 128, 128, 1)"> 97</span>     
<span style="color: rgba(0, 128, 128, 1)"> 98</span>         <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 打印进度</span>
<span style="color: rgba(0, 128, 128, 1)"> 99</span>         <span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Epoch {epoch+1}: </span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">100</span>               f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Train Loss: {train_loss:.4f} | </span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">101</span>               f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Val Loss: {val_loss:.4f} | </span><span style="color: rgba(128, 0, 0, 1)">"</span>
<span style="color: rgba(0, 128, 128, 1)">102</span>               f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Val AUROC: {val_auc:.4f}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">103</span>         
<span style="color: rgba(0, 128, 128, 1)">104</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 最终评估 ==========</span>
<span style="color: rgba(0, 128, 128, 1)">105</span>     model.load_state_dict(torch.load(<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">best_model.pth</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">))
</span><span style="color: rgba(0, 128, 128, 1)">106</span> <span style="color: rgba(0, 0, 0, 1)">    model.eval()
</span><span style="color: rgba(0, 128, 128, 1)">107</span>     y_test_true, y_test_pred =<span style="color: rgba(0, 0, 0, 1)"> [], []
</span><span style="color: rgba(0, 128, 128, 1)">108</span> <span style="color: rgba(0, 0, 0, 1)">    with torch.no_grad():
</span><span style="color: rgba(0, 128, 128, 1)">109</span>         <span style="color: rgba(0, 0, 255, 1)">for</span> inputs, labels <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> test_loader:
</span><span style="color: rgba(0, 128, 128, 1)">110</span>             inputs, labels =<span style="color: rgba(0, 0, 0, 1)"> inputs.to(device), labels.to(device)
</span><span style="color: rgba(0, 128, 128, 1)">111</span>             outputs =<span style="color: rgba(0, 0, 0, 1)"> model(inputs)
</span><span style="color: rgba(0, 128, 128, 1)">112</span> <span style="color: rgba(0, 0, 0, 1)">            y_test_true.extend(labels.cpu().numpy())
</span><span style="color: rgba(0, 128, 128, 1)">113</span> <span style="color: rgba(0, 0, 0, 1)">            y_test_pred.extend(outputs.cpu().numpy())
</span><span style="color: rgba(0, 128, 128, 1)">114</span> 
<span style="color: rgba(0, 128, 128, 1)">115</span>     test_auc =<span style="color: rgba(0, 0, 0, 1)"> roc_auc_score(y_test_true, y_test_pred)
</span><span style="color: rgba(0, 128, 128, 1)">116</span>     <span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">\n最终测试集AUROC: {test_auc:.4f}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">117</span>     
<span style="color: rgba(0, 128, 128, 1)">118</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 保存结果</span>
<span style="color: rgba(0, 128, 128, 1)">119</span>     sanitized = layer_name.replace(<span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">.</span><span style="color: rgba(128, 0, 0, 1)">'</span>, <span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(128, 0, 0, 1)">_</span><span style="color: rgba(128, 0, 0, 1)">'</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">120</span>     torch.save(model.state_dict(), results_dir/f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">best_model_{sanitized}.pth</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">121</span>     np.save(results_dir/f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">test_pred_{sanitized}.npy</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">, y_test_pred)
</span><span style="color: rgba(0, 128, 128, 1)">122</span>     
<span style="color: rgba(0, 128, 128, 1)">123</span>     <span style="color: rgba(0, 0, 255, 1)">return</span> test_auc</pre>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>3.5 执行训练流程</p>
<div class="cnblogs_code">
<pre><span style="color: rgba(0, 128, 128, 1)"> 1</span> <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> ========== 主执行流程 ==========</span>
<span style="color: rgba(0, 128, 128, 1)"> 2</span> <span style="color: rgba(0, 0, 255, 1)">if</span> <span style="color: rgba(128, 0, 128, 1)">__name__</span> == <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">__main__</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">:
</span><span style="color: rgba(0, 128, 128, 1)"> 3</span>     results =<span style="color: rgba(0, 0, 0, 1)"> {}
</span><span style="color: rgba(0, 128, 128, 1)"> 4</span>     <span style="color: rgba(0, 0, 255, 1)">for</span> layer <span style="color: rgba(0, 0, 255, 1)">in</span> tqdm(layers_to_train, desc=<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">Training Layers</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">):
</span><span style="color: rgba(0, 128, 128, 1)"> 5</span>         <span style="color: rgba(0, 0, 255, 1)">try</span><span style="color: rgba(0, 0, 0, 1)">:
</span><span style="color: rgba(0, 128, 128, 1)"> 6</span>             auc =<span style="color: rgba(0, 0, 0, 1)"> train_for_layer(layer)
</span><span style="color: rgba(0, 128, 128, 1)"> 7</span>             results[layer] =<span style="color: rgba(0, 0, 0, 1)"> auc
</span><span style="color: rgba(0, 128, 128, 1)"> 8</span>         <span style="color: rgba(0, 0, 255, 1)">except</span><span style="color: rgba(0, 0, 0, 1)"> Exception as e:
</span><span style="color: rgba(0, 128, 128, 1)"> 9</span>             <span style="color: rgba(0, 0, 255, 1)">print</span>(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">训练层 {layer} 时出错: {str(e)}</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">)
</span><span style="color: rgba(0, 128, 128, 1)">10</span>             results[layer] =<span style="color: rgba(0, 0, 0, 1)"> None
</span><span style="color: rgba(0, 128, 128, 1)">11</span>     
<span style="color: rgba(0, 128, 128, 1)">12</span>     <span style="color: rgba(0, 128, 0, 1)">#</span><span style="color: rgba(0, 128, 0, 1)"> 保存最终结果</span>
<span style="color: rgba(0, 128, 128, 1)">13</span>     with open(results_dir/<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">summary.txt</span><span style="color: rgba(128, 0, 0, 1)">"</span>, <span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">w</span><span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(0, 0, 0, 1)">) as f:
</span><span style="color: rgba(0, 128, 128, 1)">14</span>         <span style="color: rgba(0, 0, 255, 1)">for</span> layer, auc <span style="color: rgba(0, 0, 255, 1)">in</span><span style="color: rgba(0, 0, 0, 1)"> results.items():
</span><span style="color: rgba(0, 128, 128, 1)">15</span>             f.write(f<span style="color: rgba(128, 0, 0, 1)">"</span><span style="color: rgba(128, 0, 0, 1)">{layer}: {auc:.4f}\n</span><span style="color: rgba(128, 0, 0, 1)">"</span>)</pre>
</div>
<p>运行成功后会有类似如下输出：</p>
<p><img src="https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519171121782-2028203774.png" alt="" width="570" height="460" loading="lazy"></p>
<p>&nbsp;最后，我们可以通过检查summary.txt获取训练最优的训练结果是利用哪一层Embedding。我训练的结果显示第12层embedding训练得到的DNN预测器效果最好，小伙伴伴们也可以自己尝试不同的模型下，不同的DNN结构，哪一层能获得最好的预测效果。</p>
<p><img src="https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519172442978-1111004721.png" alt="" width="191" height="421" loading="lazy"></p>
<p>&nbsp;</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.18625611739699074" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-05-19 17:48">2025-05-19 17:47</span>&nbsp;
<a href="https://www.cnblogs.com/zylAK">zylAK</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18884621);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18884621', targetLink: 'https://www.cnblogs.com/zylAK/p/18884621', title: '✨生物大语言模型Evo2——解码基因密码的AI革命&amp;#128640;' })">举报</a>
</div>
        