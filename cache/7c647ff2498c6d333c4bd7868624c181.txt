
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/whuanle/p/18719302" title="发布于 2025-02-17 08:27">
    <span role="heading" aria-level="2">C# TorchSharp 图像分类实战：VGG大规模图像识别的超深度卷积网络</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p></p><div class="toc"><div class="toc-container-header">目录</div><ul><li><a href="#vgg大规模图像识别的超深度卷积网络" rel="noopener nofollow">VGG大规模图像识别的超深度卷积网络</a></li><li><a href="#数据集" rel="noopener nofollow">数据集</a><ul><li><a href="#直接下载" rel="noopener nofollow">直接下载</a></li><li><a href="#opendatalab-数据集社区" rel="noopener nofollow">opendatalab 数据集社区</a></li><li><a href="#自定义数据集" rel="noopener nofollow">自定义数据集</a></li></ul></li><li><a href="#模型训练" rel="noopener nofollow">模型训练</a></li></ul></div><br>
教程名称：使用 C# 入门深度学习<p></p>
<p>作者：痴者工良</p>
<p>教程地址：</p>
<p><a href="https://torch.whuanle.cn" target="_blank" rel="noopener nofollow">https://torch.whuanle.cn</a></p>
<p>电子书仓库：<a href="https://github.com/whuanle/cs_pytorch" target="_blank" rel="noopener nofollow">https://github.com/whuanle/cs_pytorch</a></p>
<p>Maomi.Torch 项目仓库：<a href="https://github.com/whuanle/Maomi.Torch" target="_blank" rel="noopener nofollow">https://github.com/whuanle/Maomi.Torch</a></p>
<h3 id="vgg大规模图像识别的超深度卷积网络">VGG大规模图像识别的超深度卷积网络</h3>
<p>本文主要讲解用于大规模图像识别的超深度卷积网络 VGG，通过 VGG 实现自有数据集进行图像分类训练模型和识别，VGG 有 vgg11、vgg11_bn、vgg13、vgg13_bn、vgg16、vgg16_bn、vgg19、vgg19_bn 等变种，VGG 架构的实现可参考论文：<a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="noopener nofollow">https://arxiv.org/abs/1409.1556</a></p>
<blockquote>
<p>论文中文版地址：</p>
<p><a href="https://noahsnail.com/2017/08/17/2017-08-17-VGG%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E6%96%87%E7%89%88/" target="_blank" rel="noopener nofollow">https://noahsnail.com/2017/08/17/2017-08-17-VGG论文翻译——中文版/</a></p>
</blockquote>
<h3 id="数据集">数据集</h3>
<p>本文主要使用经典图像分类数据集 CIFAR-10 进行训练，CIFAR-10 数据集中有 10 个分类，每个类别均有 60000 张图像，50000 张训练图像和 10000 张测试图像，每个图像都经过了预处理，生成 32x32 彩色图像。</p>
<p>CIFAR-10 的 10 个分类分别是：</p>
<pre><code>airplane
automobile
bird
cat
deer
dog
frog
horse
ship
truck
</code></pre>
<p>下面给出几种数据集的本地化导入方式。</p>
<h4 id="直接下载">直接下载</h4>
<p>由于 CIFAR-10 是经典数据集，因此 TorchSharp 默认支持下载该数据集，但是由于网络问题，国内下载数据库需要开飞机，数据集自动下载和导入：</p>
<pre><code class="language-csharp">// 加载训练和验证数据

var train_dataset = datasets.CIFAR10(root: "E:/datasets/CIFAR-10", train: true, download: true, target_transform: transform);
var val_dataset = datasets.CIFAR10(root: "E:/datasets/CIFAR-10", train: false, download: true, target_transform: transform);
</code></pre>
<h4 id="opendatalab-数据集社区">opendatalab 数据集社区</h4>
<p>opendatalab 是一个开源数据集社区仓库，里面有大量免费下载的数据集，借此机会给读者讲解一下如何从 opendatalab 下载数据集，这对读者学习非常有帮助。</p>
<p>CIFAR-10 数据集仓库地址：</p>
<p><a href="https://opendatalab.com/OpenDataLab/CIFAR-10/cli/main" target="_blank" rel="noopener nofollow">https://opendatalab.com/OpenDataLab/CIFAR-10/cli/main</a></p>
<p>打开 <a href="https://opendatalab.com" target="_blank" rel="noopener nofollow">https://opendatalab.com</a> 注册账号，然后在个人信息中心添加密钥。</p>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957113-498735089.png" alt="1739449592381" loading="lazy"></p>
<p>然后下载 openxlab 提供的 cli 工具：</p>
<pre><code class="language-bash">pip install openxlab #安装
</code></pre>
<p>安装 openxlab 后，会要求添加路径到环境变量，环境变量地址是 Scripts 地址，示例：</p>
<pre><code>C:\Users\%USER%\AppData\Roaming\Python\Python312\Scripts
</code></pre>
<p>接着进行登录，输入命令后按照提示输入 key 和 secret：</p>
<pre><code class="language-bash">openxlab login # 进行登录，输入对应的AK/SK，可在个人中心查看AK/SK
</code></pre>
<p>然后打开空目录下载数据集，数据集仓库会被下载到 <code>OpenDataLab___CIFAR-10</code> 目录中：</p>
<pre><code class="language-bash">openxlab dataset info --dataset-repo OpenDataLab/CIFAR-10 # 数据集信息及文件列表查看

openxlab dataset get --dataset-repo OpenDataLab/CIFAR-10 #数据集下载
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957130-988182852.png" alt="image-20250213203259114" loading="lazy"></p>
<p>数据集信息及文件列表查看</p>
<pre><code>openxlab dataset info --dataset-repo OpenDataLab/CIFAR-10
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957151-358689040.png" alt="image-20250213202802853" loading="lazy"></p>
<p>下载的文件比较多，但是我们只需要用到 <code>cifar-10-binary.tar.gz</code>，直接解压 <code>cifar-10-binary.tar.gz</code> 到目录中（也可以不解压）。</p>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957087-1459584407.png" alt="image-20250213210939996" loading="lazy"></p>
<p>然后导入数据：</p>
<pre><code class="language-csharp">// 加载训练和验证数据

var train_dataset = datasets.CIFAR10(root: "E:/datasets/OpenDataLab___CIFAR-10", train: true, download: false, target_transform: transform);
var val_dataset = datasets.CIFAR10(root: "E:/datasets/OpenDataLab___CIFAR-10", train: false, download: false, target_transform: transform);
</code></pre>
<h4 id="自定义数据集">自定义数据集</h4>
<p>Maomi.Torch 提供了自定义数据集导入方式，降低了开发者制作数据集的难度。自定义数据集也要区分训练数据集和测试数据集，训练数据集用于特征识别和训练，而测试数据集用于验证模型训练的准确率和损失值。</p>
<p>测试数据集和训练数据集可以放到不同的目录中，具体名称没有要求，然后每个分类单独一个目录，目录名称就是分类名称，按照目录名称的排序从 0 生成标签值。</p>
<pre><code>├─test
│  ├─airplane
│  ├─automobile
│  ├─bird
│  ├─cat
│  ├─deer
│  ├─dog
│  ├─frog
│  ├─horse
│  ├─ship
│  └─truck
└─train
│  ├─airplane
│  ├─automobile
│  ├─bird
│  ├─cat
│  ├─deer
│  ├─dog
│  ├─frog
│  ├─horse
│  ├─ship
│  └─truck
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957138-1738916002.png" alt="image-20250215205033982" loading="lazy"></p>
<p>读者可以参考 <code>exportdataset</code>项目，将 CIFAR-10 数据集生成导出到目录中。</p>
<p>通过自定义目录导入数据集的代码为：</p>
<pre><code class="language-csharp">var train_dataset = MM.Datasets.ImageFolder(root: "E:/datasets/t1/train", target_transform: transform);
var val_dataset = MM.Datasets.ImageFolder(root: "E:/datasets/t1/test", target_transform: transform);
</code></pre>
<h3 id="模型训练">模型训练</h3>
<p>定义图像预处理转换代码，代码如下所示：</p>
<pre><code class="language-csharp">Device defaultDevice = MM.GetOpTimalDevice();
torch.set_default_device(defaultDevice);

Console.WriteLine("当前正在使用 {defaultDevice}");

// 数据预处理
var transform = transforms.Compose([
    transforms.Resize(32, 32),
    transforms.ConvertImageDtype( ScalarType.Float32),
   MM.transforms.ReshapeTransform(new long[]{ 1,3,32,32}),
    transforms.Normalize(means: new double[] { 0.485, 0.456, 0.406 }, stdevs: new double[] { 0.229, 0.224, 0.225 }),
    MM.transforms.ReshapeTransform(new long[]{ 3,32,32})
]);
</code></pre>
<p>因为 TorchSharp 对图像维度处理的兼容性不好，没有 Pytorch 的自动处理，因此导入的图片维度和批处理维度、transforms 处理的维度兼容性不好，容易报错，因此这里需要使用 Maomi.Torch 的转换函数，以便在导入图片和进行图像批处理的时候，保障 shape 符合要求。</p>
<p>分批加载数据集：</p>
<pre><code class="language-csharp">// 加载训练和验证数据

var train_dataset = datasets.CIFAR10(root: "E:/datasets/CIFAR-10", train: true, download: true, target_transform: transform);
var val_dataset = datasets.CIFAR10(root: "E:/datasets/CIFAR-10", train: false, download: true, target_transform: transform);

var train_loader = new DataLoader(train_dataset, batchSize: 1024, shuffle: true, device: defaultDevice, num_worker: 10);
var val_loader = new DataLoader(val_dataset, batchSize: 1024, shuffle: false, device: defaultDevice, num_worker: 10);
</code></pre>
<p>初始化 vgg16 网络：</p>
<pre><code class="language-csharp">var model = torchvision.models.vgg16(num_classes: 10);
model.to(device: defaultDevice);
</code></pre>
<p>设置损失函数和优化器：</p>
<pre><code class="language-csharp">var criterion = nn.CrossEntropyLoss();
var optimizer = optim.SGD(model.parameters(), learningRate: 0.001, momentum: 0.9);
</code></pre>
<p>训练模型并保存：</p>
<pre><code class="language-csharp">int num_epochs = 150;

for (int epoch = 0; epoch &lt; num_epochs; epoch++)
{
    model.train();
    double running_loss = 0.0;
    int i = 0;
    foreach (var item in train_loader)
    {
        var (inputs, labels) = (item["data"], item["label"]);
        var inputs_device = inputs.to(defaultDevice);
        var labels_device = labels.to(defaultDevice);

        optimizer.zero_grad();
        var outputs = model.call(inputs_device);
        var loss = criterion.call(outputs, labels_device);
        loss.backward();
        optimizer.step();

        running_loss += loss.item&lt;float&gt;() * inputs.size(0);
        Console.WriteLine($"[{epoch}/{num_epochs}][{i % train_loader.Count}/{train_loader.Count}]");
        i++;
    }
    double epoch_loss = running_loss / train_dataset.Count;
    Console.WriteLine($"Train Loss: {epoch_loss:F4}");

    model.eval();
    long correct = 0;
    int total = 0;
    using (torch.no_grad())
    {
        foreach (var item in val_loader)
        {
            var (inputs, labels) = (item["data"], item["label"]);

            var inputs_device = inputs.to(defaultDevice);
            var labels_device = labels.to(defaultDevice);
            var outputs = model.call(inputs_device);
            var predicted = outputs.argmax(1);
            total += (int)labels.size(0);
            correct += (predicted == labels_device).sum().item&lt;long&gt;();
        }
    }

    double val_accuracy = 100.0 * correct / total;
    Console.WriteLine($"Validation Accuracy: {val_accuracy:F2}%");
}

model.save("model.dat");
</code></pre>
<p>启动项目后可以直接执行训练，训练一百多轮后，准确率在 70% 左右，损失值在 <code>0.0010</code> 左右，继续训练已经提高不了准确率了。</p>
<p>导出的模型还是比较大的：</p>
<pre><code>513M model.dat
</code></pre>
<p>下面来编写图像识别测试，在示例项目 <code>vggdemo</code> 中自带了三张图片，读者可以直接导入使用。</p>
<pre><code class="language-csharp">
model.load("model.dat");
model.to(device: defaultDevice);
model.eval();


var classes = new string[] {
"airplane",
"automobile",
"bird",
"cat",
"deer",
"dog",
"frog",
"horse",
"ship",
"truck"
};

List&lt;Tensor&gt; imgs = new();
imgs.Add(transform.call(MM.LoadImage("airplane.jpg").to(defaultDevice)).view(1, 3, 32, 32));
imgs.Add(transform.call(MM.LoadImage("cat.jpg").to(defaultDevice)).view(1, 3, 32, 32));
imgs.Add(transform.call(MM.LoadImage("dog.jpg").to(defaultDevice)).view(1, 3, 32, 32));

using (torch.no_grad())
{

    foreach (var data in imgs)
    {
        var outputs = model.call(data);

        var index = outputs[0].argmax(0).ToInt32();

        // 转换为归一化的概率
        // outputs.shape = [1,10]，所以取 [dim:1]
        var array = torch.nn.functional.softmax(outputs, dim: 1);
        var max = array[0].ToFloat32Array();
        var predicted1 = classes[index];
        Console.WriteLine($"识别结果 {predicted1}，准确率：{max[index] * 100}%");
    }
}
</code></pre>
<p>识别结果：</p>
<pre><code>当前正在使用 cuda:0
识别结果 airplane，准确率：99.99983%
识别结果 cat，准确率：99.83113%
识别结果 dog，准确率：100%
</code></pre>
<p>用到的三张图片均从网络上搜索而来：</p>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957089-344123816.jpg" alt="airplane" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957125-1868400699.jpg" alt="cat" loading="lazy"></p>
<p><img src="https://img2024.cnblogs.com/blog/1315495/202502/1315495-20250217082957086-1894437056.jpg" alt="dog" loading="lazy"></p>

</div>
<div id="MySignature" role="contentinfo">
    痴者工良(https://whuanle.cn)
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.022525455663194444" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-17 08:31">2025-02-17 08:27</span>&nbsp;
<a href="https://www.cnblogs.com/whuanle">痴者工良</a>&nbsp;
阅读(<span id="post_view_count">15</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18719302" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18719302);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18719302', targetLink: 'https://www.cnblogs.com/whuanle/p/18719302', title: 'C# TorchSharp 图像分类实战：VGG大规模图像识别的超深度卷积网络' })">举报</a>
</div>
        