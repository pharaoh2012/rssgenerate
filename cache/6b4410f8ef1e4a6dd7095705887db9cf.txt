
	<h1 class="postTitle"><a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/yexiaochai/p/18825611" title="发布于 2025-04-14 20:25">
    <span role="heading" aria-level="2">垂直模型和AI Workflow是开AGI的历史倒车</span>
    

</a>
</h1>
	<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<blockquote>
<p>提供<strong>AI咨询</strong>+<strong>AI项目陪跑</strong>服务，有需要回复1</p>
</blockquote>
<p><strong>RL 之父 Rich Sutton</strong>在 2019 年的文章《苦涩的教训》中指出：</p>
<blockquote>
<p>70 年的 AI 研究历史告诉我们一个最重要的道理：依靠纯粹算力的通用方法，最终总能以压倒性优势胜出</p>
</blockquote>
<p>怎么说呢？他认为试图将人类知识编码到AI中（如专家系统、手工设计特征）短期有效，但长期会限制发展。</p>
<p>比如AlphaGo/GPT-3的成功并非源于复杂规则，而是大规模算力支撑的简单算法（神经网络+海量数据）。</p>
<p>而后又有一些案例：最近 Gemini 和 4o 更新的图片功能，可能直接取代了很多图片工作流：用自然语言对话完成现在复杂的 SD 图像生成工作流。</p>
<p>于是很多人会认为：<strong>模型的通用能力，正在取代现在那些复杂的 Workflow。</strong></p>
<blockquote>
<p>但我认为<strong>这是不对的</strong>，至少说在这几年是不对的，因为GPT是基于统计学的逻辑，他并不具备真正的思考能力</p>
</blockquote>
<h2 id="知识的有损性">知识的有损性</h2>
<p>我们知道，知识/数据是对<strong>真实世界的描述</strong>，就简单一个事物，事实上我们平时只会关注他不到1/10的部分，以糖尿病为例：</p>
<p><img src="https://files.mdnice.com/user/25507/c09ff275-d992-4646-92eb-5a710fda2a9a.png" alt="" loading="lazy"></p>
<p>我们讨论的最多的是其症状和药物，文化经济模块很少会涉及，这里造成的结果就是<strong>数据残缺性与知识表征瓶颈</strong>。</p>
<p>比如医生在实际诊断过程中，不仅依赖临床指南，还有大量的内化知识，包括：</p>
<ol>
<li>患者微表情解读（疼痛忍耐度）；</li>
<li>社会经济因素权衡（治疗方案可行性）；</li>
<li>伦理判断（生命质量 vs 延长寿命）；</li>
</ol>
<p>这是当前AI难以跨越的困局：<strong>隐性知识难以结构化，导致训练数据本质残缺。</strong></p>
<p>GPT-4的医学考试高分≠临床能力，恰如通过飞行理论考试≠能处理空中特情，一个道理。</p>
<p>AlphaGo的成功建立在围棋<strong>规则完全透明、状态空间有限的基础上。</strong>而真实医疗场景存在：</p>
<ol>
<li>模糊边界（症状相似的不同疾病）；</li>
<li>动态演化（患者病情突变）；</li>
<li>价值冲突（不同科室意见相左）；</li>
</ol>
<p>这类开放性问题需要<strong>元认知能力（反思自身决策局限）</strong>，而当前AI仍停留在<strong>“统计拟合”</strong>层面。</p>
<p>综上，<strong>RL 之父所谓的算力碾压需要一个大前提</strong>：<strong>算力需作用于正确架构</strong>。</p>
<p>若基础模型无法表征某类知识（如医学伦理），单纯堆算力可能陷入<strong>“自以为是又严密而精准的错误”</strong>。</p>
<p>而GPT的预训练是基于词序列的条件概率建模，其核心是通过海量文本学习<strong>在特定上下文中，下一个词的概率分布</strong>。</p>
<p>确实不能否定其可能出现<strong>涌现</strong>的可能，但那也要建立在对世界全量知识的输入，显然现在是做不到的，毕竟文字可不能完全描述真实世界。</p>
<p>现有研究表明，语言文字至多能描述真实世界的30-40%（以可编码信息量计算），根据描述对象的不同，语言的有效性差异显著：</p>
<p><img src="https://files.mdnice.com/user/25507/8c0f24bc-e93a-4ed0-816d-25cc92cbd3e6.png" alt="" loading="lazy"></p>
<p>这里很多多模态设备需要进一步发展才行，所以这个窗口期早着呢！</p>
<p>综上，现在鼓吹<strong>零Workflow</strong>的人都<strong>“其心可诛”</strong>，没准他们在释放错误的技术路径，自己晚上偷偷的组装各种Workflow做训练呢！</p>
<h2 id="偏向性公平不可取">“偏向性”公平不可取</h2>
<p>其实，<strong>零Workflow</strong>是完全适应于OpenAI的Agent发展预测的（山姆·奥特曼提出）：</p>
<p><strong>L1级别（聊天机器人）。</strong>AI系统能够进行基本的对话和交流，显示出对自然语言的基本理解能力，并能对各种提示和问题作出响应。</p>
<p><strong>L2：推理者（Reasoners）。</strong>AI系统能够以人类专家的熟练程度解决复杂问题，标志着其从单纯模仿人类行为升级到展现真实的智能水平。这些AI不仅擅长对话，更具备了解决问题的能力，其推理和决策能力已接近人类水平。</p>
<p><strong>L3：智能体（Agents）。</strong>AI系统能够承担复杂的任务、作出决策和适应不断变化的环境，并在无须持续人类监督的情况下自主行动。这一阶段的AI不仅具备推理能力，更能自主执行各类复杂的操作任务。</p>
<p><strong>L4：创新者（Innovators）。</strong>AI系统具有创造性和独创性，能够提出突破性的想法和解决方案。它们不仅能模仿人类的创造力，更能突破思维的局限，提出令人耳目一新的创新理念。</p>
<p><strong>L5：组织者（Organizations）。</strong>AI系统不仅具备战略思维，还拥有实现组织目标所需的高效率和强适应性，能够管理复杂的系统。它们能够灵活协调多个智能体，合理分配任务，实时监控进度，并依据实际情况作出迅速调整。</p>
<p>当前正处于L2到L3的分界线，L3-L5全是<strong>脏活累活，在LLM的基础上不断叠加各种能力，说人话一点就是开放API/开放知识/开放能力给大模型</strong>。</p>
<p>L1是是否问题，L2是增强问题，L3-L5其实是数据和能力组织问题。他包括了<strong>多模态、环境感知、具身智能、AR/VR甚至脑机接口</strong>撒的。</p>
<p>这本事没什么问题，慢慢发展即可，<strong>但很多人为了吹嘘所谓尚不成熟的Agent框架</strong>，在一再贬低基于Workflow（或者说SOP）的AI应用：</p>
<p><img src="https://files.mdnice.com/user/25507/4a6b89c9-8005-4012-8cf7-2bc82266ffdb.png" alt="" loading="lazy"></p>
<p>比如，这里说SOP AI应用只能靠<strong>指令主动触发</strong>或者只能做到<strong>单次请求响应</strong>，完全就是YY；</p>
<p>然后他们所谓的AI Agent可以自动感知环境主动触发，其实严格意义上也需要触发器的，这样带着<strong>偏见</strong>去叙事，抬高一个打压一个是很神奇的，<strong>瞒者瞒不识，识者不能瞒</strong>。</p>
<p>在看AI Agent框架的定义：</p>
<p><img src="https://files.mdnice.com/user/25507/1dc8f79c-c1ca-470e-a6e5-0b4ea85f747e.jpg" alt="" loading="lazy"></p>
<p>所谓的记忆与工具且早着呢，单记忆好多公司就搞不定，每个行业各种黑科学、黑话，<strong>坐着等待大模型慢慢发展，其实约等于等待大模型将各行各业的SOP内部封装做完</strong>。</p>
<blockquote>
<p>醒醒吧，这是一场入口之争，是你想入口在哪的问题！</p>
</blockquote>
<p>其实，仅仅是<strong>鼓吹零Workflow</strong>也就算了，但是当前有些信号正在逐渐打压垂直领域的模型，会认为垂直模型是开倒车，这真的是胡说八道了...</p>
<h2 id="垂直模型开倒车">垂直模型开倒车</h2>
<p>首先，AI产品的实现在于两极：<strong>模型与工程</strong>，基座模型能力越强那么对应工程实现就可以越简单，只不过这又该临界点。比如，这个临界点是：</p>
<ol>
<li><strong>模型可以不必做规划，但他真的能精准抽取关键词，这是是否问题</strong>；</li>
<li><strong>工程能切实补足大模型的天生缺陷，比如幻觉、比如记忆问题</strong>；</li>
</ol>
<p>就我去年到今年看到的20家企业，在AI产品实现全部是基于Workflow在做设计，他们对于模型是否会完全颠覆自己的提示词工程表现出了<strong>几无所谓</strong>的态度，原因是：</p>
<ol>
<li>浅尝则止的公司，提示词工程本来成本就很低，10多20万就搞定了，模型要取代就取代呗，他们<strong>毫无所谓</strong>；</li>
<li><strong>行业深度</strong>运用的公司，已经是领域非常资深的玩家，他们的提示词工程依赖于大量KnowHow，偶尔他们自己都玩不明白，所以对于模型马上会具备超越他们行业认知的事情，是<strong>毫不担心</strong>的；</li>
</ol>
<p>这里要注意的是，这里所谓的行业深度并不是只程序员行业、图像行业这种规则性完善的公司，而是指医疗、金融、法律等领域。</p>
<p>所以，真实生产在用的技术路径，和某些公司在鬼扯的路径完全不是一套，这是什么原因呢？</p>
<h2 id="入口之争">入口之争</h2>
<p>其实前面已经说过了，垂直领域的玩家当前只能基于Workflow自己玩，而类似DeepResearch、Genspark、Agent、Manus甚至门槛更高的Coze这种玩家当然是希望：<strong>你们什么都别做，等我好了，就用我的！</strong></p>
<p>以Genspark为例，他们就发现直接抓取网络或者完全依赖大模型只能解决简单问题时，就有一系列改进策略了，包括：</p>
<ol>
<li><strong>加入专业数据源（如学术、财经、旅游等）</strong>；</li>
<li>并行搜索处理复杂问题；</li>
<li>多代理交叉验证信息避免幻觉；</li>
<li>引入专门的深度调研 Agent；</li>
</ol>
<p>特别是这点需要特别引人注意：<br>
<strong>使用高质量数据源、专家审核内容；数据由离线 Agent 审核，确保准确性，避免信息冗杂和虚假</strong>。</p>
<p>虽然鼓吹的是更少的控制，更多的工具，只不过什么是工具就需要仔细揣摩了。</p>
<p>举个例子，如果我现在要做医疗场景的Agent，那么我完全可以基于Workflow做基础实现，然后开启用户验证。</p>
<p>而当我验证的差不多后，立马宣传大家都不要使用Workflow，并且马上用DeepSeek包装出一套Agent框架，将我的Workflow、数据全部<strong>以知识的形式内置进模型</strong>。</p>
<blockquote>
<p>那么，此时这个所谓Agent框架，他到底是框架还是垂直模型呢？</p>
</blockquote>
<p>再比如，我野心再大点，已经不满足于一个医疗领域。于是去收购了一家特别优秀的教育做AI Workflow的公司，然后用同样的方法论将知识内置，并开始鼓吹<strong>专家模型</strong>...</p>
<p>如果体验较好，也不知道最后会怎么样。</p>
<h2 id="结语">结语</h2>
<p>在Agent与Workflow的博弈中，技术演进的本质是效率与<strong>安全稳定性</strong>的动态平衡。</p>
<p>当前的讨论焦点并非“谁取代谁”，而是如何在不断变化的应用场景中找到最优解。通过深入分析行业实践，可以归纳出以下三个关键结论：</p>
<p><strong>一、通用性需以基础模型突破为前提</strong></p>
<p>GPT的崛起证明了，当底层架构足够强大时，统一的框架可以打破细分领域的“专家系统”垄断。然而，要实现Agent的类似颠覆，我们面临两大障碍：</p>
<ol>
<li><strong>长程规划的可靠性：</strong>当前，模型在超过50步的任务中错误率呈指数级上升（0.95^50≈0.07），难以满足生产环境中对稳定性的高要求；</li>
<li><strong>工具调用的完备性：</strong>现有的Function Calling功能主要支持基础操作（如浏览器、文件读取等），而对垂直领域的专业工具链支持则明显不足；</li>
</ol>
<p>没有强大的基础模型与多模态工具支撑，Agent无法实现从一般任务到专业任务的跨越。</p>
<p><strong>二、垂直Workflow仍是产业落地的现实选择</strong></p>
<p>尽管通用Agent充满潜力，但在金融、医疗等高要求行业，Workflow依然在多个维度上具备不可替代的优势：</p>
<ol>
<li><strong>确定性交付：</strong>通过预设规则和标准化流程，能够有效规避模型幻觉的风险。以医疗诊断为例，强制嵌入临床指南的校验模块，确保输出的可靠性；</li>
<li><strong>成本效率：</strong>与其让Agent进行冗长的推理，不如直接调用已预设的流程来完成任务，这不仅能降低错误率，还能节省大量计算资源，减少90%的Token消耗；</li>
<li><strong>数据反哺：</strong>通过执行Workflow生成的日志数据，可以为基础模型训练提供高质量的轨迹数据，进一步提升模型在特定领域的能力。</li>
</ol>
<p>这正是吕老师所说的<strong>Workflow是模型能力边界的缓冲层</strong>的意思，它实际上是人类经验的结构化封装，为AI的实际应用提供稳定的基础。</p>
<p><strong>三、融合架构将成为中期主流</strong></p>
<p>随着技术的不断进步，我们看到行业中逐渐形成新的技术范式：<strong>通用模型作协调层，垂直Workflow作执行层。</strong></p>
<p>这一架构能够在避免纯Agent的失控风险的同时，突破传统Workflow的僵化局限，成为一种灵活且高效的解决方案。典型的案例包括：</p>
<ol>
<li><strong>Coze的“混合编排”模式：</strong>用户自定义的Workflow节点中，嵌入了Agent的决策点，在关键环节留有人工干预入口，从而平衡了灵活性与可控性；</li>
<li><strong>Deepseek的“能力蒸馏”路径：</strong>通过将垂直场景中的Workflow执行数据反向训练基座模型，逐步内化领域知识，最终实现高效的自主决策；</li>
</ol>
<p>这种架构的核心在于，它将工具链的标准化视为Agent落地的必经之路，而工具本身的设计，往往源自于既有Workflow的抽象。</p>
<p>这不仅提高了模型的自主性，还保持了在复杂场景中的高效执行。</p>
<p><strong>未来五年的关键命题</strong></p>
<p>行业发展正在向着更加成熟的方向前进，但在这一过程中，我们也需警惕两类极端倾向：</p>
<p>第一，<strong>盲目追求“零Workflow”：</strong></p>
<p>在模型尚未成熟时，急于推向通用Agent，可能会让产品陷入<strong>“高概念、低可用”</strong>的陷阱。</p>
<p>真正的技术进步应当是在能力达到临界点后，再让Agent承担更多任务；</p>
<p>第二，<strong>固守手工规则：</strong></p>
<p>拒绝拥抱基础模型的进化，可能会错失自动生成Workflow的技术浪潮，导致技术逐步落后。</p>
<blockquote>
<p>真正的机会并不在于简单的“零Workflow”或“手工规则”的选择，而在于建立动态适配体系。</p>
</blockquote>
<p>通过实时监控模型的能力边界，将可预测的任务交给Agent自主规划，而对于不确定的环节，依然需要保留Workflow的硬性约束。</p>
<p>这种方法才是真正的<strong>“More Intelligence, Less Structure”</strong>的务实解读：不是消除结构，而是让人工智能学会在规则与自由之间找到最佳平衡，动态适应不同场景的需求。</p>
<p>最后，未来的AI产品将不再是简单的“工具”或“执行系统”，而是能够在动态变化的环境中自主学习、进化，并根据实际需求切换工作模式的智能体。</p>
<p>从应用角度看，真正的挑战在于如何平衡技术创新与可控性，如何让AI技术服务于特定行业的需求，而不仅仅是追逐“通用智能”的梦想。</p>
<p><strong>短期内，Workflow仍将在很多行业中扮演关键角色，而长远来看，随着基础模型的不断完善，AI将逐步迈向更加灵活与自主的阶段，助力各行各业的智能化转型。</strong></p>
<p><img src="https://files.mdnice.com/user/25507/2de720b0-1cd9-48e6-b009-5f1ce49f7eed.png" alt="" loading="lazy"></p>

</div>
<div id="MySignature" role="contentinfo">
    <img id="view_img" src="https://img2022.cnblogs.com/blog/294743/202202/294743-20220216140902628-1163053035.png" width="80%" alt="" border="0">

</div>
<div class="clear"></div>

	<div class="postDesc">posted on 
<span id="post-date" data-last-update-days="0.7478435939861111" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-14 20:26">2025-04-14 20:25</span>&nbsp;
<a href="https://www.cnblogs.com/yexiaochai">叶小钗</a>&nbsp;
阅读(<span id="post_view_count">76</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18825611);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18825611', targetLink: 'https://www.cnblogs.com/yexiaochai/p/18825611', title: '垂直模型和AI Workflow是开AGI的历史倒车' })">举报</a>
</div>
