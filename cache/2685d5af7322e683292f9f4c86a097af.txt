
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/wang_yb/p/18838090" title="发布于 2025-04-21 10:30">
    <span role="heading" aria-level="2">核函数：让支持向量机从“青铜”变“王者”</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>在机器学习领域，支持向量机（<code>SVM</code>）是一种强大的分类算法，而核函数则是其核心组件之一。</p>
<p><strong>核函数</strong>的本质是一个「空间映射工具」。</p>
<p>当原始数据在低维空间中线性不可分时（如环形、月牙形数据），核函数能将数据隐式地映射到更高维的特征空间，使得在高维空间中数据变得线性可分，同时避免直接计算高维特征的爆炸性计算量（即"核技巧"）。</p>
<p>本文将介绍<strong>核函数</strong>的作用、常用类型，并通过 scikit-learn 的实际案例展示其效果。</p>
<h1 id="1-核心作用">1. 核心作用</h1>
<p>在许多实际场景中，数据往往不是线性可分的，直接应用线性分类器效果不佳。</p>
<p><strong>核函数</strong>通过巧妙的数学变换，将数据映射到一个更高维度的空间，在这个空间中，原本线性不可分的数据可能变得线性可分。</p>
<p>这样，<code>SVM</code> 就可以在这个高维空间中找到一个最优的超平面来进行分类。</p>
<p><strong>核函数</strong>的核心优势在于它避免了显式地计算高维空间中的坐标，而是通过核技巧直接计算映射后的内积。</p>
<p>这种方法不仅提高了计算效率，还减少了内存消耗，使得 <code>SVM</code> 能够高效地处理大规模数据集。</p>
<p>总的来说，核函数主要为了解决下面几个核心问题：</p>
<ol>
<li>避免直接计算高维空间中的内积（维度爆炸问题，核技巧通过数学变换简化计算）</li>
<li>为非线性数据提供高效的分类解决方案</li>
<li>通过不同核函数的选择，适应多样化的数据分布特征</li>
</ol>
<h1 id="2-常用核函数">2. 常用核函数</h1>
<p>一般我们在训练<code>SVM</code>模型时，常用的<strong>核函数</strong>主要有4种：</p>
<h2 id="21-线性核函数">2.1. 线性核函数</h2>
<p><strong>线性核函数</strong>（Linear Kernel）是最简单的核函数，其公式为：$ K(x,y)=x^Ty $。</p>
<p>它适用于<strong>线性可分</strong>的数据集。</p>
<p>如果数据在原始空间中已经可以通过一个线性超平面进行分类，那么<strong>线性核函数</strong>是一个高效且简单的选择。</p>
<h2 id="22-多项式核函数">2.2. 多项式核函数</h2>
<p><strong>多项式核函数</strong>（Linear Kernel）的公式为：$ K(x,y)=(x<sup>Ty+c)</sup>d $。</p>
<p>其中， $ c $是一个常数项， $ d $是多项式的度数。</p>
<p><strong>多项式核函数</strong>可以通过调整 $ d $ 和 $ c $ 的值来增加模型的复杂度，从而更好地拟合非线性数据。</p>
<p>它适用于数据具有多项式关系的场景。</p>
<h2 id="23-径向基核函数rbf">2.3. 径向基核函数（RBF）</h2>
<p><strong>RBF 核函数</strong>（Radial Basis Function）是<code>SVM</code>中最常用的核函数之一，其公式为：$ K(x,y)=exp(-\frac{||x-y||<sup>2}{2\sigma</sup>2}) $。</p>
<p>其中， $ \sigma $是控制高斯分布宽度的参数。</p>
<p><strong>RBF 核函数</strong>能够将数据映射到无穷维空间，具有很强的灵活性，适用于大多数非线性问题。</p>
<p>它对数据的局部变化非常敏感，能够很好地捕捉数据的复杂结构。</p>
<h2 id="24-sigmoid-核函数">2.4. sigmoid 核函数</h2>
<p><strong>Sigmoid 核函数</strong>的公式为：$ K(x,y)=\tanh(ax^Ty+b) $。</p>
<p>其中， $ a <span class="math inline">\(和\)</span> b $是参数。</p>
<p><strong>Sigmoid 核函数</strong>类似于神经网络中的激活函数，它在某些特定的非线性问题中表现良好，但使用时需要谨慎调整参数，以避免过拟合或欠拟合。</p>
<h1 id="3-核函数实践">3. 核函数实践</h1>
<p>为了展示核函数的作用，我们使用<code>scikit-learn</code>库构造一个测试数据集，并比较不同核函数的效果。</p>
<p>首先，使用<code>make_moons</code>函数生成一个非线性可分的数据集。</p>
<p>这个数据集包含两个半月形的类别，用线性分类器很难进行区分。</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
from sklearn.datasets import make_moons

# 生成非线性可分的数据集
X, y = make_moons(n_samples=200, noise=0.1, random_state=42)

# 绘制数据集
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')
plt.title("非线性可分数据集")
plt.show()
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/83005/202504/83005-20250421102857194-1423872059.png" alt="" loading="lazy"></p>
<p>接下来，我们使用<code>scikit-learn</code>的<code>SVC</code>（支持向量分类器）分别应用<strong>线性核函数</strong>、<strong>多项式核函数</strong>、<strong>RBF 核函数</strong>和 <strong>Sigmoid 核函数</strong>，并比较它们的效果。</p>
<pre><code class="language-python">from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 线性核函数
svm_linear = SVC(kernel='linear')
svm_linear.fit(X_train, y_train)
y_pred_linear = svm_linear.predict(X_test)
print("线性核函数的准确率：", accuracy_score(y_test, y_pred_linear))

# 多项式核函数
svm_poly = SVC(kernel='poly', degree=3)
svm_poly.fit(X_train, y_train)
y_pred_poly = svm_poly.predict(X_test)
print("多项式核函数的准确率：", accuracy_score(y_test, y_pred_poly))

# RBF 核函数
svm_rbf = SVC(kernel='rbf', gamma='scale')
svm_rbf.fit(X_train, y_train)
y_pred_rbf = svm_rbf.predict(X_test)
print("RBF 核函数的准确率：", accuracy_score(y_test, y_pred_rbf))

# Sigmoid 核函数
svm_sigmoid = SVC(kernel='sigmoid')
svm_sigmoid.fit(X_train, y_train)
y_pred_sigmoid = svm_sigmoid.predict(X_test)
print("Sigmoid 核函数的准确率：", accuracy_score(y_test, y_pred_sigmoid))
</code></pre>
<p>运行结果：</p>
<pre><code class="language-plain">线性核函数的准确率： 0.8833333333333333
多项式核函数的准确率： 0.95
RBF 核函数的准确率： 0.9833333333333333
Sigmoid 核函数的准确率： 0.6666666666666666
</code></pre>
<p>从结果来看，<strong>线性核函数</strong>在这种非线性数据集上的表现一般，而 <strong>RBF 核函数</strong>和<strong>多项式核函数</strong>取得了较好的效果，</p>
<p><strong>Sigmoid 核函数</strong>表现最差，它仅在特定场景（如模拟神经网络）可能有用，其他场景下效果普遍较差。</p>
<p>为了更加直观，我们可以把四种核函数的分类结果绘制出来：</p>
<pre><code class="language-python">plt.figure(figsize=(20, 10))
models = [svm_linear, svm_poly, svm_rbf, svm_sigmoid]
for i, model in enumerate(models, 1):
    plt.subplot(2, 2, i)

    h = 0.02  # 网格间隔
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.contourf(xx, yy, Z, alpha=0.8, cmap="viridis")
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors="k", cmap="viridis")

plt.tight_layout()
plt.show()
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/83005/202504/83005-20250421102857092-1497533534.png" alt="" loading="lazy"></p>
<h1 id="4-总结">4. 总结</h1>
<p><strong>核函数</strong>是支持向量机中不可或缺的组成部分，它通过将数据映射到高维空间，解决了线性不可分问题，使 <code>SVM</code> 能够处理复杂的非线性分类任务。</p>
<p>在实际应用中，选择合适的核函数至关重要。</p>
<p><strong>线性核函数</strong>适用于线性可分数据，<strong>多项式核函数</strong>和 <strong>RBF 核函数</strong>则更适合处理非线性问题。</p>
<p>通过基于<code>scikit-learn</code>的实验，我们直观地看到了核函数在不同数据集上的效果差异。</p>
<p>在实际项目中，建议根据数据的特点和需求选择合适的核函数，并通过交叉验证等方法调整参数，以达到最佳的分类效果。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.1622681374699074" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-04-21 10:30">2025-04-21 10:30</span>&nbsp;
<a href="https://www.cnblogs.com/wang_yb">wang_yb</a>&nbsp;
阅读(<span id="post_view_count">14</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18838090);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18838090', targetLink: 'https://www.cnblogs.com/wang_yb/p/18838090', title: '核函数：让支持向量机从“青铜”变“王者”' })">举报</a>
</div>
        