
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/wyh-study/p/18739498" title="发布于 2025-02-26 20:09">
    <span role="heading" aria-level="2">纯离线部署本地知识库LLM大模型</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="纯离线部署本地知识库llm大模型">纯离线部署本地知识库LLM大模型</h2>
<h3 id="一下载离线大模型">一、下载离线大模型</h3>
<blockquote>
<p>下载的网址：<a href="https://hf-mirror.com/" target="_blank" rel="noopener nofollow">https://hf-mirror.com/</a></p>
</blockquote>
<pre><code>deepseek qwen 相关的模型，只建议使用1.5B的，GGUF后缀的模型
推荐下载llama相关模型，同样是GGUF后缀的，自己笔记本电脑推荐下载8B的	
</code></pre>
<p><img src="https://gitee.com/xiaohuya1/image_test/raw/master/png/image-20250208091357388.png" alt="image-20250208091357388" loading="lazy"></p>
<h3 id="二下载大模型管理平台-lm-studio">二、下载大模型管理平台 LM Studio</h3>
<blockquote>
<p>下载网址：<a href="https://lmstudio.ai/" target="_blank" rel="noopener nofollow">https://lmstudio.ai/</a></p>
<p>安装过程只需要修改一个安装路径，后面一直下一步安装成功。</p>
</blockquote>
<h3 id="三将离线大模型导入到-lm-studio-中">三、将离线大模型导入到 LM Studio 中</h3>
<blockquote>
<p>注意：默认情况下，LM Studio 所识别的大模型的目录在C盘</p>
<p>默认路径：C:\Users\用户名\.lmstudio\models</p>
</blockquote>
<p><img src="https://gitee.com/xiaohuya1/image_test/raw/master/png/image-20250208092315983.png" alt="image-20250208092315983" loading="lazy"></p>
<blockquote>
<p>修改大模型的加载目录</p>
<ul>
<li>先创建一个根目录 ，例如：F:\LMStudioModels</li>
<li>再创建一个二级目录，例如：F:\LMStudioModels\shujia_models 【必须要有一个二级目录】</li>
<li>将模型除.gguf意外的名字拷贝出来，当作一个文件夹的名字</li>
<li>将该模型放在这个文件夹里面</li>
</ul>
</blockquote>
<p><strong>上面操作做完后，LM Studio就可以读取到我们的大模型。</strong></p>
<h3 id="四通过lm-studio加载我们的大模型重要涉及gpu的能力">四、通过LM Studio加载我们的大模型【重要，涉及GPU的能力】</h3>
<ul>
<li>点击对话正上方的<code>select a model to load</code> ,选择该对象要使用的大模型</li>
<li>参数解释：
<ul>
<li>Context Length: 该模型一次最大可以加载多少个token
<ul>
<li>若是简单的问答，推荐4096</li>
<li>若是小红书文案，推荐10000以上</li>
<li>若是写作文，小说，推荐100000左右</li>
</ul>
</li>
<li>GPU Offload: 运行时，所占用的GPU显存，建议先给一半</li>
<li>CPU Thread Pool Size: 拉满</li>
<li>Evaluation Batch Size: 512</li>
<li>后面不动，都以推荐为准</li>
</ul>
</li>
</ul>
<h3 id="五调整参数进行对话">五、调整参数，进行对话</h3>
<blockquote>
<p>点击右上角实验室器皿图标，show settings，设置Preset，例如添加一个：数学家</p>
<p>理解为：将当前对话的大模型设置成一个固定的角色</p>
<p>设置System Prompt，形容一下这个数学家</p>
</blockquote>
<h3 id="六使用anythingllm工具使用lm-studio中的模型加载知识库">六、使用AnythingLLM工具使用LM Studio中的模型，加载知识库</h3>
<ul>
<li>将LM Studio作为一个服务对外提供，让AnythingLLM连接上LM Studio
<ul>
<li>打开LM Studio点击左边的Developer</li>
<li>打开 Start Server按钮</li>
</ul>
</li>
<li>再AnythingLLM中，点击聊天设置，配置LM Studio，选择，模型</li>
</ul>
<h3 id="七提供api服务">七、提供API服务</h3>
<ul>
<li>在AnythingLLM中左下角点击open settings</li>
<li>点击工具</li>
<li>点击API密钥，生成密钥</li>
</ul>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.013063856695601853" data-date-created="BlogServer.Application.Dto.BlogPost.BlogPostDto" data-date-updated="2025-02-26 20:10">2025-02-26 20:09</span>&nbsp;
<a href="https://www.cnblogs.com/wyh-study">Xiaohu_BigData</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=18739498" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(18739498);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '18739498', targetLink: 'https://www.cnblogs.com/wyh-study/p/18739498', title: '纯离线部署本地知识库LLM大模型' })">举报</a>
</div>
        